WEBVTT

00:00:07.440 --> 00:00:12.000
Caption: hello everybody

00:00:09.039 --> 00:00:13.519
Caption: i am dr felicity millman and i want to

00:00:12.000 --> 00:00:16.000
Caption: share with you some reasons we should

00:00:13.519 --> 00:00:18.479
Caption: begin to consider rethinking artificial

00:00:16.000 --> 00:00:20.159
Caption: intelligence and our automated systems

00:00:18.479 --> 00:00:22.399
Caption: to begin to understand some of the

00:00:20.159 --> 00:00:24.479
Caption: unintended consequences

00:00:22.399 --> 00:00:27.598
Caption: but before i do

00:00:24.479 --> 00:00:29.598
Caption: i want to say a giant thank you to our

00:00:27.599 --> 00:00:32.159
Caption: wonderful sponsors who are helping us be

00:00:29.599 --> 00:00:34.800
Caption: here today wherever you are physically

00:00:32.159 --> 00:00:36.238
Caption: virtually any time of day or night thank

00:00:34.799 --> 00:00:38.078
Caption: you

00:00:36.238 --> 00:00:39.599
Caption: and i wanted to let you know a little

00:00:38.078 --> 00:00:41.759
Caption: bit about me to begin

00:00:39.599 --> 00:00:43.759
Caption: i originally did a phd in psychology and

00:00:41.759 --> 00:00:46.319
Caption: genetics which turns out means i&#39;m a bit

00:00:43.759 --> 00:00:48.799
Caption: of a data nurse um and transitioning

00:00:46.319 --> 00:00:51.199
Caption: from there i have recently a couple of

00:00:48.799 --> 00:00:53.680
Caption: years ago i went and got a masters in

00:00:51.199 --> 00:00:55.280
Caption: cybernetics which basically means

00:00:53.680 --> 00:00:57.039
Caption: artificial intelligence and how we think

00:00:55.279 --> 00:00:59.279
Caption: about it

00:00:57.039 --> 00:01:02.800
Caption: went on to work in the cyber security

00:00:59.279 --> 00:01:04.558
Caption: institute as a threat caster which means

00:01:02.799 --> 00:01:05.839
Caption: i work to try and understand where our

00:01:04.558 --> 00:01:07.919
Caption: future threats are going to come from

00:01:05.839 --> 00:01:10.399
Caption: and how we should mitigate them and

00:01:07.919 --> 00:01:11.438
Caption: these days i also do a little bit of

00:01:10.400 --> 00:01:12.560
Caption: teaching

00:01:11.439 --> 00:01:15.119
Caption: innovation

00:01:12.559 --> 00:01:16.478
Caption: um for engineering and computer science

00:01:15.119 --> 00:01:18.000
Caption: as well as building cyber security

00:01:16.478 --> 00:01:19.839
Caption: simulations that are actually inclusive

00:01:18.000 --> 00:01:21.919
Caption: for everyone not just the cyber security

00:01:19.839 --> 00:01:24.000
Caption: professionals but government people

00:01:21.919 --> 00:01:26.080
Caption: policy people your admin people

00:01:24.000 --> 00:01:28.158
Caption: everywhere for the national security

00:01:26.080 --> 00:01:29.360
Caption: college at anu

00:01:28.158 --> 00:01:30.959
Caption: so

00:01:29.360 --> 00:01:32.400
Caption: from that

00:01:30.959 --> 00:01:34.239
Caption: given that we&#39;re all on country

00:01:32.400 --> 00:01:36.159
Caption: somewhere i want to say

00:01:34.239 --> 00:01:38.000
Caption: a big acknowledgement to the traditional

00:01:36.158 --> 00:01:40.639
Caption: custodians of the land that i&#39;m standing

00:01:38.000 --> 00:01:43.519
Caption: on at the moment so that is the wajak

00:01:40.639 --> 00:01:45.759
Caption: people of the noongar nation as well as

00:01:43.519 --> 00:01:48.078
Caption: others in other places around us there

00:01:45.759 --> 00:01:50.960
Caption: are so many to name that

00:01:48.079 --> 00:01:51.680
Caption: but thank you and acknowledging

00:01:50.959 --> 00:01:53.599
Caption: so

00:01:51.680 --> 00:01:55.599
Caption: why do we need to think about artificial

00:01:53.599 --> 00:01:56.879
Caption: intelligence and what actually happens

00:01:55.599 --> 00:01:58.478
Caption: with it well

00:01:56.879 --> 00:02:00.158
Caption: i imagine when we think of technology

00:01:58.478 --> 00:02:01.679
Caption: and in general we don&#39;t always think of

00:02:00.158 --> 00:02:03.519
Caption: where it&#39;s going to go

00:02:01.680 --> 00:02:05.199
Caption: so i imagine when the first steam

00:02:03.519 --> 00:02:07.039
Caption: engines were built they didn&#39;t quite

00:02:05.199 --> 00:02:08.479
Caption: accidentally think that they might cause

00:02:07.040 --> 00:02:11.199
Caption: climate change

00:02:08.479 --> 00:02:13.680
Caption: by basically fueling their engines with

00:02:11.199 --> 00:02:16.720
Caption: fossilized trees and bits of animal

00:02:13.679 --> 00:02:18.878
Caption: bones they didn&#39;t realize that

00:02:16.720 --> 00:02:20.878
Caption: create systems that would include huge

00:02:18.878 --> 00:02:23.440
Caption: amounts of pollution but yes we get

00:02:20.878 --> 00:02:26.160
Caption: pretty cool cars out of it

00:02:23.440 --> 00:02:28.000
Caption: we also look at things like drones we

00:02:26.160 --> 00:02:30.000
Caption: think awesome i get to take some really

00:02:28.000 --> 00:02:32.319
Caption: cool photos personally i am a drone

00:02:30.000 --> 00:02:35.279
Caption: lover i have done this myself but it

00:02:32.319 --> 00:02:37.360
Caption: also enables us to have some quite scary

00:02:35.279 --> 00:02:39.279
Caption: weapons like the one you can see in my

00:02:37.360 --> 00:02:42.000
Caption: hand there as well as the big drones

00:02:39.279 --> 00:02:44.319
Caption: they have or the swarms of drones that

00:02:42.000 --> 00:02:47.518
Caption: currently our technical systems

00:02:44.319 --> 00:02:47.518
Caption: struggle to manage and that

00:02:48.839 --> 00:02:53.360
Caption: perhaps not too re not too long ago

00:02:52.399 --> 00:02:55.279
Caption: um

00:02:53.360 --> 00:02:57.440
Caption: and we also have things like our

00:02:55.279 --> 00:02:59.119
Caption: satellite technology

00:02:57.440 --> 00:03:01.760
Caption: dear older elon musk put a few up

00:02:59.119 --> 00:03:03.279
Caption: recently and when i say i mean a lot and

00:03:01.759 --> 00:03:05.439
Caption: while that&#39;s great it&#39;s connecting

00:03:03.279 --> 00:03:07.119
Caption: people all over the globe it&#39;s actually

00:03:05.440 --> 00:03:09.518
Caption: kind of causing a few problems for our

00:03:07.119 --> 00:03:11.360
Caption: astronomers who aren&#39;t actually able

00:03:09.518 --> 00:03:12.800
Caption: to pictures that they want to take to be

00:03:11.360 --> 00:03:15.279
Caption: able to understand where our world has

00:03:12.800 --> 00:03:17.518
Caption: come from bit of a problem there

00:03:15.279 --> 00:03:20.158
Caption: so i guess it kind of makes us think

00:03:17.518 --> 00:03:21.279
Caption: technology is neither good nor bad

00:03:20.158 --> 00:03:23.199
Caption: i think most people have kind of

00:03:21.279 --> 00:03:25.839
Caption: understood that but the one thing we

00:03:23.199 --> 00:03:27.199
Caption: often do forget is technology is not

00:03:25.839 --> 00:03:28.559
Caption: either

00:03:27.199 --> 00:03:29.919
Caption: so when we think of artificial

00:03:28.559 --> 00:03:31.919
Caption: intelligence one of the things we often

00:03:29.919 --> 00:03:33.919
Caption: think about is data mining it&#39;s how you

00:03:31.919 --> 00:03:36.559
Caption: make a lot of machine learning types of

00:03:33.919 --> 00:03:38.479
Caption: systems you actually extract value from

00:03:36.559 --> 00:03:39.598
Caption: the you create

00:03:38.479 --> 00:03:42.319
Caption: now

00:03:39.598 --> 00:03:44.798
Caption: it&#39;s it really is an extracted process

00:03:42.319 --> 00:03:46.479
Caption: data mining is is important

00:03:44.798 --> 00:03:47.839
Caption: something that we actually do well in

00:03:46.479 --> 00:03:51.199
Caption: western australia and australia in

00:03:47.839 --> 00:03:52.479
Caption: general is mining we do it well

00:03:51.199 --> 00:03:53.919
Caption: something that a lot of people don&#39;t

00:03:52.479 --> 00:03:55.679
Caption: realize about western australia is we

00:03:53.919 --> 00:03:59.039
Caption: actually have one of the most enduring

00:03:55.679 --> 00:04:00.798
Caption: histories of mining on the planet i&#39;m

00:03:59.039 --> 00:04:03.119
Caption: not just talking you know a couple of

00:04:00.798 --> 00:04:04.319
Caption: thousand years i&#39;m talking a really long

00:04:03.119 --> 00:04:05.759
Caption: time

00:04:04.319 --> 00:04:07.119
Caption: hey this is something we can actually

00:04:05.759 --> 00:04:10.158
Caption: learn from

00:04:07.119 --> 00:04:12.319
Caption: so this is wiljumia it&#39;s a couple

00:04:10.158 --> 00:04:13.759
Caption: hundred kilometers out of mount magnet

00:04:12.319 --> 00:04:15.360
Caption: it&#39;s in the it&#39;s in the middle of

00:04:13.759 --> 00:04:17.359
Caption: western australia it&#39;s a beautiful

00:04:15.360 --> 00:04:20.320
Caption: beautiful place but it&#39;s actually over

00:04:17.359 --> 00:04:22.639
Caption: 30 000 years old it is the world one of

00:04:20.320 --> 00:04:24.479
Caption: the world&#39;s oldest mines it has been

00:04:22.639 --> 00:04:26.479
Caption: used continuously

00:04:24.479 --> 00:04:29.600
Caption: for 30 years

00:04:26.479 --> 00:04:30.959
Caption: think of that the people who

00:04:29.600 --> 00:04:33.759
Caption: have been doing this

00:04:30.959 --> 00:04:35.679
Caption: created one of the largest networks on

00:04:33.759 --> 00:04:37.119
Caption: the planet they learned how to extract

00:04:35.679 --> 00:04:39.359
Caption: value from the ground

00:04:37.119 --> 00:04:42.239
Caption: and to transmit it and pass it between

00:04:39.359 --> 00:04:43.519
Caption: people and culture and to use it they

00:04:42.239 --> 00:04:45.119
Caption: also created

00:04:43.519 --> 00:04:47.679
Caption: some really really ingenious early

00:04:45.119 --> 00:04:49.519
Caption: safety systems where they would ensure

00:04:47.679 --> 00:04:51.119
Caption: that people had different layers so they

00:04:49.519 --> 00:04:53.440
Caption: could extract data from different places

00:04:51.119 --> 00:04:54.959
Caption: by having different pile systems they

00:04:53.440 --> 00:04:57.440
Caption: actually built

00:04:54.959 --> 00:04:59.119
Caption: structures to ensure that people the

00:04:57.440 --> 00:05:01.119
Caption: rocks weren&#39;t caving in and falling on

00:04:59.119 --> 00:05:02.880
Caption: them it was pretty impressive when you

00:05:01.119 --> 00:05:05.600
Caption: think about it and they also used

00:05:02.880 --> 00:05:06.800
Caption: regulations to ensure that their people

00:05:05.600 --> 00:05:08.240
Caption: in their community weren&#39;t going to be

00:05:06.799 --> 00:05:10.319
Caption: harmed so they actually had rules about

00:05:08.239 --> 00:05:11.419
Caption: who could go in who wasn&#39;t allowed in

00:05:10.320 --> 00:05:14.080
Caption: when they could go in and how

00:05:11.420 --> 00:05:15.919
Caption: [Laughter]

00:05:14.079 --> 00:05:17.279
Caption: later and when we think about mining

00:05:15.919 --> 00:05:18.479
Caption: this is a really really good place to

00:05:17.279 --> 00:05:21.279
Caption: talk about it

00:05:18.479 --> 00:05:22.399
Caption: we also have the largest robot

00:05:21.279 --> 00:05:25.440
Caption: on the planet

00:05:22.399 --> 00:05:28.320
Caption: so the auto whole system by rio tinto is

00:05:25.440 --> 00:05:30.559
Caption: actually huge if you&#39;ve ever been

00:05:28.320 --> 00:05:32.320
Caption: fortunate enough to see it

00:05:30.559 --> 00:05:34.320
Caption: is an automated system

00:05:32.320 --> 00:05:36.559
Caption: mining is something we do well whether

00:05:34.320 --> 00:05:38.240
Caption: it&#39;s been historically in the past or

00:05:36.559 --> 00:05:40.559
Caption: currently right here right now in this

00:05:38.239 --> 00:05:42.079
Caption: space this is something we do

00:05:40.559 --> 00:05:43.679
Caption: let&#39;s kind of begin to understand a

00:05:42.079 --> 00:05:44.959
Caption: little bit better

00:05:43.679 --> 00:05:46.559
Caption: what are we actually looking at when

00:05:44.959 --> 00:05:48.880
Caption: we&#39;re talking about automated systems

00:05:46.559 --> 00:05:50.320
Caption: and cyber cyber physical systems

00:05:48.880 --> 00:05:52.720
Caption: we know that everything is a has a

00:05:50.320 --> 00:05:54.160
Caption: context we know that they&#39;re systems

00:05:52.720 --> 00:05:55.360
Caption: where is the human labor in all these

00:05:54.160 --> 00:05:57.279
Caption: artificial intelligence systems

00:05:55.359 --> 00:05:59.038
Caption: sometimes we don&#39;t talk about that we

00:05:57.279 --> 00:06:00.239
Caption: also don&#39;t talk about

00:05:59.039 --> 00:06:03.119
Caption: sometimes

00:06:00.239 --> 00:06:05.119
Caption: where the physical resources are

00:06:03.119 --> 00:06:09.039
Caption: how we&#39;re actually extracting value out

00:06:05.119 --> 00:06:11.199
Caption: of data and how do we make sense of it

00:06:09.039 --> 00:06:11.199
Caption: so

00:06:11.679 --> 00:06:17.039
Caption: when we think about it

00:06:13.600 --> 00:06:17.039
Caption: as i said how do we make sense of it

00:06:17.279 --> 00:06:19.440
Caption: well

00:06:18.160 --> 00:06:21.119
Caption: one of the first questions i think it&#39;s

00:06:19.440 --> 00:06:22.319
Caption: important to ask is what is artificial

00:06:21.119 --> 00:06:24.000
Caption: intelligence

00:06:22.319 --> 00:06:25.919
Caption: a lot of the time when i talk to

00:06:24.000 --> 00:06:28.880
Caption: technical people they will give me some

00:06:25.919 --> 00:06:30.800
Caption: variation of data and networks and how

00:06:28.880 --> 00:06:32.000
Caption: we put them together and there&#39;s a model

00:06:30.799 --> 00:06:33.198
Caption: and these things are all technical and

00:06:32.000 --> 00:06:36.479
Caption: they&#39;re right

00:06:33.199 --> 00:06:39.919
Caption: however it&#39;s not the only thing

00:06:36.479 --> 00:06:39.919
Caption: this doesn&#39;t come out of nowhere

00:06:41.039 --> 00:06:44.559
Caption: there are networks there are cultures

00:06:43.039 --> 00:06:45.839
Caption: and contexts where this stuff is all

00:06:44.559 --> 00:06:47.279
Caption: coming from

00:06:45.839 --> 00:06:50.319
Caption: so i actually think it&#39;s important that

00:06:47.279 --> 00:06:51.679
Caption: we recognize systems create artificial

00:06:50.319 --> 00:06:52.720
Caption: intelligence and our machine learning

00:06:51.679 --> 00:06:54.000
Caption: systems

00:06:52.720 --> 00:06:55.839
Caption: and they are actually

00:06:54.000 --> 00:06:57.039
Caption: cyber physical systems when we put these

00:06:55.839 --> 00:06:58.959
Caption: things together

00:06:57.039 --> 00:07:02.000
Caption: we&#39;re talking about a whole structure of

00:06:58.959 --> 00:07:04.160
Caption: people and places places and objects in

00:07:02.000 --> 00:07:04.880
Caption: a time and place

00:07:04.160 --> 00:07:07.440
Caption: so

00:07:04.880 --> 00:07:09.440
Caption: going back to how we make sense of it

00:07:07.440 --> 00:07:10.959
Caption: do we actually look at a component or do

00:07:09.440 --> 00:07:13.119
Caption: we look at the system

00:07:10.959 --> 00:07:14.638
Caption: a lot of the time when we talk about

00:07:13.119 --> 00:07:16.319
Caption: artificial intelligence i will hear

00:07:14.639 --> 00:07:17.440
Caption: people tell me about chips and how much

00:07:16.319 --> 00:07:19.279
Caption: storage they have and how much

00:07:17.440 --> 00:07:23.039
Caption: processing they have

00:07:19.279 --> 00:07:24.959
Caption: we are really exquisitely good at taking

00:07:23.039 --> 00:07:27.440
Caption: a microscopic view

00:07:24.959 --> 00:07:29.039
Caption: we go down into the tiny tiny tiny tiny

00:07:27.440 --> 00:07:31.360
Caption: tiny tiny details

00:07:29.039 --> 00:07:33.039
Caption: to figure out how somethings works

00:07:31.359 --> 00:07:34.159
Caption: sometimes it might be useful to take

00:07:33.039 --> 00:07:36.399
Caption: step back

00:07:34.160 --> 00:07:38.080
Caption: of a telescope try and look out what

00:07:36.399 --> 00:07:40.319
Caption: system is this part of how does it

00:07:38.079 --> 00:07:42.478
Caption: connect to everything else

00:07:40.319 --> 00:07:43.919
Caption: i think it&#39;s important to remember

00:07:42.479 --> 00:07:45.919
Caption: everything has a history and everything

00:07:43.919 --> 00:07:47.759
Caption: has a context so when we&#39;re looking at

00:07:45.919 --> 00:07:48.800
Caption: systems we need to look at when we&#39;re

00:07:47.759 --> 00:07:50.000
Caption: looking at

00:07:48.799 --> 00:07:51.440
Caption: machine learning

00:07:50.000 --> 00:07:54.479
Caption: intelligence we need to try and

00:07:51.440 --> 00:07:56.080
Caption: understand where they come from

00:07:54.479 --> 00:07:58.319
Caption: so

00:07:56.079 --> 00:08:00.319
Caption: again it&#39;s looking at cyber physical

00:07:58.319 --> 00:08:01.839
Caption: systems

00:08:00.319 --> 00:08:04.000
Caption: one of the big questions i like to ask

00:08:01.839 --> 00:08:06.720
Caption: is how something comes into being how

00:08:04.000 --> 00:08:08.878
Caption: does it made where does it come from

00:08:06.720 --> 00:08:10.479
Caption: why was it made

00:08:08.878 --> 00:08:12.000
Caption: one of the big questions i always look

00:08:10.479 --> 00:08:13.440
Caption: at is physical resources and again

00:08:12.000 --> 00:08:14.799
Caption: that&#39;s not talking just about your

00:08:13.440 --> 00:08:17.119
Caption: network cables

00:08:14.799 --> 00:08:18.720
Caption: and your hardware and your chips it&#39;s

00:08:17.119 --> 00:08:20.079
Caption: actually talking about how they&#39;re

00:08:18.720 --> 00:08:20.799
Caption: connected

00:08:20.079 --> 00:08:22.319
Caption: so

00:08:20.799 --> 00:08:24.159
Caption: i think this is important because the

00:08:22.319 --> 00:08:25.359
Caption: connection points can actually hint

00:08:24.160 --> 00:08:28.160
Caption: where the inherent value is in the

00:08:25.359 --> 00:08:29.359
Caption: system how we actually understand what

00:08:28.160 --> 00:08:30.720
Caption: we&#39;re extracting what are we actually

00:08:29.359 --> 00:08:32.559
Caption: using here

00:08:30.720 --> 00:08:34.000
Caption: one of the best examples i&#39;ve ever seen

00:08:32.559 --> 00:08:35.760
Caption: of this was going back in history a

00:08:34.000 --> 00:08:38.239
Caption: little bit and looking at how our

00:08:35.760 --> 00:08:40.239
Caption: original networks were made so these

00:08:38.239 --> 00:08:42.718
Caption: were the sub c cables which were

00:08:40.239 --> 00:08:44.398
Caption: connecting all through the globe

00:08:42.718 --> 00:08:46.479
Caption: connecting telegraphs

00:08:44.398 --> 00:08:47.599
Caption: now on the screen you can actually see

00:08:46.479 --> 00:08:49.838
Caption: their

00:08:47.599 --> 00:08:51.359
Caption: cutout sections of the original network

00:08:49.838 --> 00:08:52.159
Caption: cables

00:08:51.359 --> 00:08:54.880
Caption: so

00:08:52.159 --> 00:08:56.398
Caption: how are they made probably not something

00:08:54.880 --> 00:08:57.518
Caption: most people think about

00:08:56.398 --> 00:08:59.440
Caption: turns out

00:08:57.518 --> 00:09:01.119
Caption: the original subsea cables just like our

00:08:59.440 --> 00:09:02.799
Caption: modern cables required insulation

00:09:01.119 --> 00:09:04.239
Caption: because you know seawater degrades

00:09:02.799 --> 00:09:05.919
Caption: things you know

00:09:04.239 --> 00:09:07.278
Caption: um it&#39;s something that

00:09:05.919 --> 00:09:08.719
Caption: previous generations actually had to

00:09:07.278 --> 00:09:10.640
Caption: grapple with

00:09:08.719 --> 00:09:12.319
Caption: turns out one of the best things they

00:09:10.640 --> 00:09:14.958
Caption: could insulate with

00:09:12.320 --> 00:09:16.239
Caption: was tree sap so from the good of percher

00:09:14.958 --> 00:09:17.919
Caption: tray because it&#39;s naturally

00:09:16.239 --> 00:09:20.080
Caption: thermoplastic so when you heat it up

00:09:17.919 --> 00:09:22.479
Caption: it&#39;s all melty and when you cool it down

00:09:20.080 --> 00:09:24.880
Caption: it&#39;s quite rigid and stable that&#39;s kind

00:09:22.479 --> 00:09:26.398
Caption: of cool kind of interesting so that um

00:09:24.880 --> 00:09:29.599
Caption: kind of happened around

00:09:26.398 --> 00:09:31.599
Caption: 18 20 18 30. they begin to figure out oh

00:09:29.599 --> 00:09:33.599
Caption: we&#39;ve got something

00:09:31.599 --> 00:09:35.599
Caption: so one of the things about this trade

00:09:33.599 --> 00:09:39.838
Caption: this very special tree is it actually

00:09:35.599 --> 00:09:41.278
Caption: takes 30 years to reach maturity andre

00:09:39.838 --> 00:09:42.719
Caption: it&#39;s kind of interesting we&#39;ve got some

00:09:41.278 --> 00:09:44.559
Caption: old trades around 30 years doesn&#39;t seem

00:09:42.719 --> 00:09:45.518
Caption: that much

00:09:44.559 --> 00:09:48.838
Caption: but

00:09:45.518 --> 00:09:52.479
Caption: how much sap do you think a tree

00:09:48.838 --> 00:09:54.479
Caption: makes for one tree

00:09:52.479 --> 00:09:56.880
Caption: not even a kilogram

00:09:54.479 --> 00:09:58.799
Caption: of their sap

00:09:56.880 --> 00:10:00.239
Caption: so these blocks are some of the original

00:09:58.799 --> 00:10:01.919
Caption: blocks that were from the good of percha

00:10:00.239 --> 00:10:04.078
Caption: tree when it was processed they cut them

00:10:01.919 --> 00:10:05.679
Caption: all up effectively boil them then they

00:10:04.078 --> 00:10:07.599
Caption: process them so they get off the stuff

00:10:05.679 --> 00:10:09.359
Caption: that&#39;s not actually the sap

00:10:07.599 --> 00:10:11.119
Caption: and they turn them in into these blocks

00:10:09.359 --> 00:10:12.880
Caption: that they then would extrude over the

00:10:11.119 --> 00:10:15.119
Caption: actual cables

00:10:12.880 --> 00:10:17.760
Caption: so

00:10:15.119 --> 00:10:19.599
Caption: just in this time frame just a year

00:10:17.760 --> 00:10:20.720
Caption: three hundred and nine three thousand

00:10:19.599 --> 00:10:23.679
Caption: nine

00:10:20.719 --> 00:10:26.239
Caption: three thousand nine hundred and sixty

00:10:23.679 --> 00:10:28.719
Caption: nautical miles of cable were late

00:10:26.239 --> 00:10:31.278
Caption: and that was about 181 kilos of good

00:10:28.719 --> 00:10:31.278
Caption: aperture

00:10:31.518 --> 00:10:37.119
Caption: so if you do the math

00:10:33.760 --> 00:10:40.880
Caption: that&#39;s one point two million trees

00:10:37.119 --> 00:10:40.880
Caption: three hundred trees per nautical mile

00:10:41.838 --> 00:10:45.278
Caption: in the hundred years that this stuff was

00:10:43.200 --> 00:10:48.559
Caption: predominantly used

00:10:45.278 --> 00:10:51.760
Caption: there were three well just this is just

00:10:48.559 --> 00:10:54.159
Caption: one set of cabling 315 nautical miles of

00:10:51.760 --> 00:10:57.440
Caption: cable we used

00:10:54.159 --> 00:10:58.559
Caption: equated to 47 million

00:10:57.440 --> 00:11:00.320
Caption: trees

00:10:58.559 --> 00:11:03.838
Caption: and that&#39;s a conservative estimate

00:11:00.320 --> 00:11:05.359
Caption: that&#39;s if we actually have the amount of

00:11:03.838 --> 00:11:07.119
Caption: um good a purchase they used on each

00:11:05.359 --> 00:11:09.760
Caption: cable in case they&#39;ll be using some thin

00:11:07.119 --> 00:11:12.239
Caption: sections some thick sections so chances

00:11:09.760 --> 00:11:14.720
Caption: are over 100 million of these trays

00:11:12.239 --> 00:11:14.719
Caption: were used

00:11:14.880 --> 00:11:20.479
Caption: by one company

00:11:17.119 --> 00:11:20.479
Caption: in one country

00:11:20.958 --> 00:11:24.799
Caption: that isn&#39;t even all the cables run

00:11:22.880 --> 00:11:25.919
Caption: across the planet

00:11:24.799 --> 00:11:28.398
Caption: so

00:11:25.919 --> 00:11:30.479
Caption: guess what guys we made one of the

00:11:28.398 --> 00:11:33.119
Caption: earliest human

00:11:30.479 --> 00:11:34.799
Caption: made disasters at human ecologically

00:11:33.119 --> 00:11:37.919
Caption: human-made disasters

00:11:34.799 --> 00:11:39.278
Caption: building our technological systems

00:11:37.919 --> 00:11:40.799
Caption: now

00:11:39.278 --> 00:11:42.559
Caption: how did it come into being

00:11:40.799 --> 00:11:44.159
Caption: we made it

00:11:42.559 --> 00:11:45.760
Caption: we also need to recognize that when i

00:11:44.159 --> 00:11:48.799
Caption: say these connection points hint at the

00:11:45.760 --> 00:11:52.000
Caption: inherent value in the system

00:11:48.799 --> 00:11:54.000
Caption: human labor was also involved

00:11:52.000 --> 00:11:55.599
Caption: so there were workers in predominantly

00:11:54.000 --> 00:11:57.278
Caption: malaysia and borneo who were going out

00:11:55.599 --> 00:11:59.518
Caption: and cutting down these trees

00:11:57.278 --> 00:12:01.919
Caption: and try initially trying to actually

00:11:59.518 --> 00:12:03.200
Caption: drain the sap out of them and logging

00:12:01.919 --> 00:12:04.880
Caption: them and bringing them to ships and

00:12:03.200 --> 00:12:06.720
Caption: ports all over the globe there were

00:12:04.880 --> 00:12:07.760
Caption: little kids in factories often in

00:12:06.719 --> 00:12:09.199
Caption: england

00:12:07.760 --> 00:12:12.078
Caption: who were cutting this stuff up working

00:12:09.200 --> 00:12:13.600
Caption: with boiling tree sap not a nice job

00:12:12.078 --> 00:12:15.760
Caption: many of these people weren&#39;t paid

00:12:13.599 --> 00:12:17.440
Caption: particularly much money and historically

00:12:15.760 --> 00:12:19.440
Caption: if we look at where the value went it

00:12:17.440 --> 00:12:20.799
Caption: was not to the workers nor was it to the

00:12:19.440 --> 00:12:23.119
Caption: people whose land these trades would

00:12:20.799 --> 00:12:25.838
Caption: take from

00:12:23.119 --> 00:12:25.838
Caption: so

00:12:26.159 --> 00:12:32.000
Caption: we know that a lot of these cables

00:12:29.119 --> 00:12:33.679
Caption: were actually made to strategic points

00:12:32.000 --> 00:12:36.559
Caption: of strategic intake

00:12:33.679 --> 00:12:38.159
Caption: importance for colonies so where these

00:12:36.559 --> 00:12:39.838
Caption: cables were being laid weren&#39;t

00:12:38.159 --> 00:12:40.879
Caption: necessarily going back to the people

00:12:39.838 --> 00:12:43.039
Caption: who&#39;s

00:12:40.880 --> 00:12:44.000
Caption: been cut down they were often going

00:12:43.039 --> 00:12:46.078
Caption: between

00:12:44.000 --> 00:12:48.719
Caption: europe and america

00:12:46.078 --> 00:12:50.559
Caption: and various europeans

00:12:48.719 --> 00:12:52.159
Caption: so even though we were taking all these

00:12:50.559 --> 00:12:53.278
Caption: wonderful trees and making these amazing

00:12:52.159 --> 00:12:55.518
Caption: systems

00:12:53.278 --> 00:12:57.119
Caption: the value was not necessarily where we

00:12:55.518 --> 00:12:59.518
Caption: thought it would have been

00:12:57.119 --> 00:13:01.039
Caption: but it hints at the value that we was

00:12:59.518 --> 00:13:04.479
Caption: actually present in the system and how

00:13:01.039 --> 00:13:06.320
Caption: it directed how it was actually built

00:13:04.479 --> 00:13:07.838
Caption: so worthwhile considering when you&#39;re

00:13:06.320 --> 00:13:09.919
Caption: building

00:13:07.838 --> 00:13:12.078
Caption: technological systems

00:13:09.919 --> 00:13:15.119
Caption: our cables and those values were not

00:13:12.078 --> 00:13:15.119
Caption: distributed evenly

00:13:16.000 --> 00:13:19.359
Caption: worthwhile considering

00:13:18.479 --> 00:13:20.958
Caption: so

00:13:19.359 --> 00:13:23.039
Caption: the decisions of those people in the

00:13:20.958 --> 00:13:24.479
Caption: past are still impacting

00:13:23.039 --> 00:13:26.799
Caption: us today

00:13:24.479 --> 00:13:28.559
Caption: those network cables impact who has

00:13:26.799 --> 00:13:30.559
Caption: actual internet connection to this very

00:13:28.559 --> 00:13:31.919
Caption: very day we&#39;re in western australia and

00:13:30.559 --> 00:13:33.359
Caption: i&#39;m sure many of you will have either

00:13:31.919 --> 00:13:35.200
Caption: been in mining or dealt with mining or i

00:13:33.359 --> 00:13:36.638
Caption: had to go out bush for some reason

00:13:35.200 --> 00:13:37.919
Caption: trying to get internet connection out

00:13:36.638 --> 00:13:39.198
Caption: bush

00:13:37.919 --> 00:13:42.078
Caption: not fun

00:13:39.198 --> 00:13:44.000
Caption: a couple of months ago i was driving out

00:13:42.078 --> 00:13:45.518
Caption: to go on holiday and had the unfortunate

00:13:44.000 --> 00:13:47.359
Caption: experience of getting

00:13:45.518 --> 00:13:48.719
Caption: 60 kilometers out of perth before i

00:13:47.359 --> 00:13:51.679
Caption: realized that i needed internet

00:13:48.719 --> 00:13:54.159
Caption: connection to connect my sat phone turns

00:13:51.679 --> 00:13:55.919
Caption: out i actually gotta use the internet to

00:13:54.159 --> 00:13:58.078
Caption: connect a sat phone and if you drive too

00:13:55.919 --> 00:14:00.880
Caption: far out can&#39;t do that

00:13:58.078 --> 00:14:02.880
Caption: so those decisions far back then

00:14:00.880 --> 00:14:04.320
Caption: impacted my ability on this to this very

00:14:02.880 --> 00:14:06.559
Caption: very day based on where we&#39;ve got

00:14:04.320 --> 00:14:09.440
Caption: connection points and we&#39;ve chosen to

00:14:06.559 --> 00:14:11.599
Caption: build our systems

00:14:09.440 --> 00:14:11.599
Caption: so

00:14:12.479 --> 00:14:16.078
Caption: recognizing again our technological

00:14:14.479 --> 00:14:18.320
Caption: systems

00:14:16.078 --> 00:14:21.039
Caption: have created ecological disasters they

00:14:18.320 --> 00:14:22.720
Caption: have exploited traditional knowledge

00:14:21.039 --> 00:14:25.198
Caption: but at the same time they were the

00:14:22.719 --> 00:14:26.638
Caption: foundations of the industrial revolution

00:14:25.198 --> 00:14:28.799
Caption: they&#39;ve enabled us innovation they&#39;ve

00:14:26.638 --> 00:14:31.919
Caption: enabled us to be here right today this

00:14:28.799 --> 00:14:33.518
Caption: very moment talking to you in this room

00:14:31.919 --> 00:14:35.278
Caption: talking to you wherever you are sitting

00:14:33.518 --> 00:14:37.278
Caption: on this planet

00:14:35.278 --> 00:14:39.599
Caption: technology isn&#39;t good or bad

00:14:37.278 --> 00:14:42.239
Caption: but it does come very very very well in

00:14:39.599 --> 00:14:45.119
Caption: transition values

00:14:42.239 --> 00:14:46.479
Caption: so what about again human labor i don&#39;t

00:14:45.119 --> 00:14:49.359
Caption: know how many people here have heard the

00:14:46.479 --> 00:14:50.799
Caption: story of the mechanical turk

00:14:49.359 --> 00:14:52.398
Caption: fair while ago

00:14:50.799 --> 00:14:53.440
Caption: there was

00:14:52.398 --> 00:14:55.838
Caption: um

00:14:53.440 --> 00:14:57.359
Caption: a person who decided he&#39;d built a box

00:14:55.838 --> 00:14:59.440
Caption: and had told people that it could

00:14:57.359 --> 00:15:01.440
Caption: magically play chess

00:14:59.440 --> 00:15:03.440
Caption: without a human involved and it was

00:15:01.440 --> 00:15:05.278
Caption: carted around europe

00:15:03.440 --> 00:15:07.119
Caption: and said to be this amazing invention

00:15:05.278 --> 00:15:09.198
Caption: because it could play chess

00:15:07.119 --> 00:15:10.719
Caption: however

00:15:09.198 --> 00:15:13.198
Caption: turns out

00:15:10.719 --> 00:15:14.000
Caption: that what was actually inside

00:15:13.198 --> 00:15:16.398
Caption: it

00:15:14.000 --> 00:15:18.559
Caption: was a machine partially

00:15:16.398 --> 00:15:20.719
Caption: but the machine actually contained a

00:15:18.559 --> 00:15:22.719
Caption: very small human who was a grand test

00:15:20.719 --> 00:15:24.838
Caption: master who could actually move the

00:15:22.719 --> 00:15:26.799
Caption: little dials

00:15:24.838 --> 00:15:29.198
Caption: inside so

00:15:26.799 --> 00:15:31.198
Caption: the mechanical turk and i admit hideous

00:15:29.198 --> 00:15:32.078
Caption: name but it&#39;s historically what the name

00:15:31.198 --> 00:15:35.359
Caption: is

00:15:32.078 --> 00:15:38.159
Caption: kind of showed people wait a second some

00:15:35.359 --> 00:15:39.679
Caption: of our technical systems we think

00:15:38.159 --> 00:15:40.958
Caption: are artificially intelligent that we

00:15:39.679 --> 00:15:42.398
Caption: think a mechanical that we think it&#39;s

00:15:40.958 --> 00:15:44.958
Caption: smart

00:15:42.398 --> 00:15:46.159
Caption: have people involved

00:15:44.958 --> 00:15:47.919
Caption: where is it

00:15:46.159 --> 00:15:50.638
Caption: where&#39;s it hidden

00:15:47.919 --> 00:15:51.758
Caption: and often it is hidden

00:15:50.638 --> 00:15:53.518
Caption: so

00:15:51.758 --> 00:15:55.440
Caption: amazon&#39;s mechanical turk system the

00:15:53.518 --> 00:15:57.359
Caption: reason it is called mturk is from

00:15:55.440 --> 00:16:00.159
Caption: mechanical turk because what it actually

00:15:57.359 --> 00:16:03.278
Caption: is is humans all around the globe who

00:16:00.159 --> 00:16:06.159
Caption: aren&#39;t paid particularly may i say

00:16:03.278 --> 00:16:08.799
Caption: competitive laborious and boring tasks

00:16:06.159 --> 00:16:10.799
Caption: for a very very cheap price which often

00:16:08.799 --> 00:16:12.398
Caption: startups not looking at anybody in the

00:16:10.799 --> 00:16:14.398
Caption: room

00:16:12.398 --> 00:16:17.359
Caption: build or they they actually use the m

00:16:14.398 --> 00:16:18.559
Caption: turks system these tasks done of which

00:16:17.359 --> 00:16:20.479
Caption: they then suggest it is actually

00:16:18.559 --> 00:16:23.599
Caption: artificial intelligence it&#39;s just a

00:16:20.479 --> 00:16:26.880
Caption: human hidden somewhere else

00:16:23.599 --> 00:16:29.119
Caption: to make these systems work

00:16:26.880 --> 00:16:29.119
Caption: um

00:16:30.479 --> 00:16:36.559
Caption: we also have situations

00:16:33.838 --> 00:16:39.359
Caption: where you are the human labor

00:16:36.559 --> 00:16:41.679
Caption: how often do we actually think about

00:16:39.359 --> 00:16:42.880
Caption: the capture systems that we use

00:16:41.679 --> 00:16:44.398
Caption: because again

00:16:42.880 --> 00:16:46.638
Caption: that is you training an artificial

00:16:44.398 --> 00:16:50.159
Caption: intelligence system object recognition

00:16:46.638 --> 00:16:52.958
Caption: often how to identify an object are you

00:16:50.159 --> 00:16:54.958
Caption: valuing your time

00:16:52.958 --> 00:16:57.440
Caption: the company certainly is and often these

00:16:54.958 --> 00:17:00.398
Caption: are already used on websites and

00:16:57.440 --> 00:17:02.398
Caption: services which you pay to use

00:17:00.398 --> 00:17:04.160
Caption: calling out paypal

00:17:02.398 --> 00:17:05.918
Caption: they certainly use object they certainly

00:17:04.160 --> 00:17:07.838
Caption: use capture again they call it a

00:17:05.918 --> 00:17:09.119
Caption: security feature but you&#39;re already

00:17:07.838 --> 00:17:11.038
Caption: getting charged in one sense you&#39;re

00:17:09.119 --> 00:17:13.678
Caption: getting charged again in your labor

00:17:11.038 --> 00:17:15.438
Caption: it&#39;s a choice that&#39;s being made

00:17:13.678 --> 00:17:16.719
Caption: again it&#39;s hidden they&#39;re not actually

00:17:15.438 --> 00:17:17.678
Caption: acknowledging that is what is happening

00:17:16.719 --> 00:17:20.000
Caption: here

00:17:17.678 --> 00:17:23.198
Caption: we also have again our really really

00:17:20.000 --> 00:17:24.798
Caption: large companies facebook google amazon

00:17:23.198 --> 00:17:26.160
Caption: we certainly know or i&#39;m sure many

00:17:24.798 --> 00:17:28.318
Caption: people have heard the stories of the

00:17:26.160 --> 00:17:31.119
Caption: amazon workers who are actually working

00:17:28.318 --> 00:17:32.798
Caption: in warehouses who are picking and

00:17:31.119 --> 00:17:35.280
Caption: packing those objects that all of us

00:17:32.798 --> 00:17:36.880
Caption: have kind of ordered given we&#39;re in the

00:17:35.280 --> 00:17:38.479
Caption: middle of a pandemic many people have

00:17:36.880 --> 00:17:39.678
Caption: ordered things online because it&#39;s easy

00:17:38.479 --> 00:17:41.119
Caption: fair enough

00:17:39.678 --> 00:17:43.038
Caption: but the people are actually getting them

00:17:41.119 --> 00:17:45.599
Caption: are real humans who actually have to

00:17:43.038 --> 00:17:46.879
Caption: work to a very very specific clock the

00:17:45.599 --> 00:17:48.798
Caption: point

00:17:46.880 --> 00:17:50.880
Caption: being so specific that they actually

00:17:48.798 --> 00:17:52.639
Caption: expect high rates of injury because the

00:17:50.880 --> 00:17:54.160
Caption: humans have to work to the machine not

00:17:52.640 --> 00:17:56.640
Caption: the machines working to the humans or

00:17:54.160 --> 00:17:58.559
Caption: their abilities which is kind of scary

00:17:56.640 --> 00:18:00.000
Caption: when you think about it all your data

00:17:58.558 --> 00:18:01.599
Caption: you put on facebook and what you put on

00:18:00.000 --> 00:18:03.678
Caption: google again these are used to train

00:18:01.599 --> 00:18:07.678
Caption: artificially intelligent systems that is

00:18:03.678 --> 00:18:10.719
Caption: your human labor is it valued

00:18:07.678 --> 00:18:13.678
Caption: also got data content moderators

00:18:10.719 --> 00:18:15.439
Caption: and data classification systems

00:18:13.678 --> 00:18:17.839
Caption: what about the extraction process so how

00:18:15.439 --> 00:18:19.359
Caption: do we get

00:18:17.839 --> 00:18:20.798
Caption: we know that like okay we can get some

00:18:19.359 --> 00:18:22.640
Caption: data that&#39;s great

00:18:20.798 --> 00:18:24.959
Caption: where does it come from

00:18:22.640 --> 00:18:25.919
Caption: and how they influence us

00:18:24.959 --> 00:18:27.760
Caption: so

00:18:25.918 --> 00:18:29.599
Caption: we know our machine learning models are

00:18:27.760 --> 00:18:31.678
Caption: actually built from data

00:18:29.599 --> 00:18:33.760
Caption: it has come from somewhere

00:18:31.678 --> 00:18:36.959
Caption: as i said where does the data come from

00:18:33.760 --> 00:18:36.959
Caption: and where are those choices hidden

00:18:39.520 --> 00:18:42.558
Caption: let&#39;s talk about natural language

00:18:40.798 --> 00:18:44.798
Caption: processing because you know that&#39;s an

00:18:42.558 --> 00:18:45.918
Caption: easy topic we use words words are

00:18:44.798 --> 00:18:47.279
Caption: important

00:18:45.918 --> 00:18:49.519
Caption: if you actually look back in history

00:18:47.280 --> 00:18:51.840
Caption: some of the oldest language uh

00:18:49.520 --> 00:18:55.359
Caption: oldest nlp models and the oldest data

00:18:51.839 --> 00:18:56.880
Caption: sex sets actually come from

00:18:55.359 --> 00:19:03.359
Caption: legal battles

00:18:56.880 --> 00:19:05.839
Caption: so 19 ibm&#39;s 1969 13-year legal battle

00:19:03.359 --> 00:19:08.719
Caption: and enron&#39;s bankruptcy proceedings have

00:19:05.839 --> 00:19:11.199
Caption: actually been used to train a lot of our

00:19:08.719 --> 00:19:12.959
Caption: natural language processing systems so

00:19:11.199 --> 00:19:15.038
Caption: again if you trace things like gpt

00:19:12.959 --> 00:19:17.119
Caption: threes data modeling back and back and

00:19:15.038 --> 00:19:18.558
Caption: back and back and back you actually get

00:19:17.119 --> 00:19:21.199
Caption: to some of these places where some of

00:19:18.558 --> 00:19:24.640
Caption: the raw input was initially put in

00:19:21.199 --> 00:19:26.719
Caption: we have a criteria

00:19:24.640 --> 00:19:28.000
Caption: when we use these systems

00:19:26.719 --> 00:19:30.959
Caption: do you think the way that you speak in

00:19:28.000 --> 00:19:33.678
Caption: the way that i speak reflects the words

00:19:30.959 --> 00:19:35.119
Caption: that are in those legal battles

00:19:33.678 --> 00:19:37.359
Caption: i don&#39;t think i speak like a legal

00:19:35.119 --> 00:19:38.400
Caption: person at all times i imagine i probably

00:19:37.359 --> 00:19:40.000
Caption: don&#39;t

00:19:38.400 --> 00:19:42.000
Caption: not only because i&#39;m australian and

00:19:40.000 --> 00:19:43.678
Caption: let&#39;s be honest we have a tendency for

00:19:42.000 --> 00:19:44.640
Caption: profanity

00:19:43.678 --> 00:19:47.199
Caption: um

00:19:44.640 --> 00:19:49.440
Caption: but because we also have our own culture

00:19:47.199 --> 00:19:51.678
Caption: our own jargon that doesn&#39;t necessarily

00:19:49.439 --> 00:19:53.279
Caption: match the ones that have been used

00:19:51.678 --> 00:19:54.719
Caption: we&#39;re repeatingly building on these

00:19:53.280 --> 00:19:56.559
Caption: systems our models are getting better

00:19:54.719 --> 00:19:58.400
Caption: and better and better and we&#39;re getting

00:19:56.558 --> 00:20:00.880
Caption: further and further and further and

00:19:58.400 --> 00:20:03.839
Caption: further away from some of these systems

00:20:00.880 --> 00:20:05.440
Caption: knowing where they&#39;ve come from

00:20:03.839 --> 00:20:08.959
Caption: unfortunately the assumption with these

00:20:05.439 --> 00:20:10.399
Caption: systems is language in them is

00:20:08.959 --> 00:20:13.119
Caption: unbiased

00:20:10.400 --> 00:20:16.080
Caption: and it&#39;s neutral

00:20:13.119 --> 00:20:16.079
Caption: i would say it&#39;s probably

00:20:16.798 --> 00:20:19.599
Caption: so

00:20:17.599 --> 00:20:21.359
Caption: what can that actually do

00:20:19.599 --> 00:20:24.959
Caption: when we start looking at these systems

00:20:21.359 --> 00:20:27.038
Caption: if we put automated systems in to say

00:20:24.959 --> 00:20:28.798
Caption: challenge if somebody is being rude or

00:20:27.038 --> 00:20:31.519
Caption: is it hate speech

00:20:28.798 --> 00:20:33.599
Caption: it can often penalize people who don&#39;t

00:20:31.520 --> 00:20:35.679
Caption: come from the same background as where

00:20:33.599 --> 00:20:37.119
Caption: the data has been trained so if you

00:20:35.678 --> 00:20:39.279
Caption: happen to be

00:20:37.119 --> 00:20:41.199
Caption: a bit of a sweary pants sorry some

00:20:39.280 --> 00:20:43.679
Caption: australians

00:20:41.199 --> 00:20:46.000
Caption: or you happen to be from

00:20:43.678 --> 00:20:47.918
Caption: black african american culture that one

00:20:46.000 --> 00:20:49.599
Caption: certainly happened there tends to be

00:20:47.918 --> 00:20:51.599
Caption: higher rates of flagging for hate speech

00:20:49.599 --> 00:20:53.280
Caption: when it really if human moderators rate

00:20:51.599 --> 00:20:54.400
Caption: it it&#39;s not hate speech this is a

00:20:53.280 --> 00:20:56.159
Caption: different culture and a different

00:20:54.400 --> 00:20:57.679
Caption: context that this information is

00:20:56.159 --> 00:20:59.039
Caption: actually coming from

00:20:57.678 --> 00:21:00.798
Caption: trying to begin to actually pull that

00:20:59.038 --> 00:21:04.558
Caption: apart we need to actually understand

00:21:00.798 --> 00:21:04.558
Caption: where is our data coming from

00:21:04.880 --> 00:21:08.640
Caption: are we making sense of it

00:21:07.199 --> 00:21:10.319
Caption: i think it&#39;s important to realize here

00:21:08.640 --> 00:21:12.159
Caption: that standardized

00:21:10.319 --> 00:21:14.399
Caption: does not mean objective

00:21:12.159 --> 00:21:15.919
Caption: so just because a particular model might

00:21:14.400 --> 00:21:17.119
Caption: be standardized doesn&#39;t mean it&#39;s

00:21:15.918 --> 00:21:19.359
Caption: objective

00:21:17.119 --> 00:21:21.918
Caption: so we may try and classify data by

00:21:19.359 --> 00:21:25.839
Caption: saying that&#39;s a cat and that&#39;s a dog

00:21:21.918 --> 00:21:27.918
Caption: that&#39;s a boat that&#39;s a pig

00:21:25.839 --> 00:21:30.959
Caption: that&#39;s it&#39;s standardized it&#39;s not

00:21:27.918 --> 00:21:31.918
Caption: necessarily objective

00:21:30.959 --> 00:21:33.199
Caption: so

00:21:31.918 --> 00:21:35.279
Caption: we know that we can look at the output

00:21:33.199 --> 00:21:37.359
Caption: and say this is great

00:21:35.280 --> 00:21:39.919
Caption: but where does the output come from

00:21:37.359 --> 00:21:41.280
Caption: comes from a model which is built

00:21:39.918 --> 00:21:43.038
Caption: from data

00:21:41.280 --> 00:21:45.280
Caption: which that makes fair enough amount of

00:21:43.038 --> 00:21:47.599
Caption: sense cool

00:21:45.280 --> 00:21:47.599
Caption: but

00:21:48.079 --> 00:21:53.678
Caption: who actually gets to classify those

00:21:49.760 --> 00:21:53.678
Caption: images who gets to create the data

00:21:56.159 --> 00:22:00.960
Caption: how do they do it

00:21:58.640 --> 00:22:02.640
Caption: do you know

00:22:00.959 --> 00:22:04.239
Caption: turns out a lot of the original data

00:22:02.640 --> 00:22:06.320
Caption: sets go back to those people who are

00:22:04.239 --> 00:22:07.918
Caption: working for a mechanical turk there are

00:22:06.319 --> 00:22:10.239
Caption: other ones which go back in other

00:22:07.918 --> 00:22:11.678
Caption: different ways but these people live in

00:22:10.239 --> 00:22:13.199
Caption: different cultures different contexts

00:22:11.678 --> 00:22:14.640
Caption: and different places

00:22:13.199 --> 00:22:15.439
Caption: and have been portrayed

00:22:14.640 --> 00:22:17.440
Caption: paid

00:22:15.439 --> 00:22:19.359
Caption: again not necessarily very much to make

00:22:17.439 --> 00:22:21.839
Caption: these decisions that impact our lives

00:22:19.359 --> 00:22:21.839
Caption: right now

00:22:23.199 --> 00:22:29.279
Caption: do you call someone young old

00:22:26.558 --> 00:22:30.959
Caption: do you give them a race

00:22:29.280 --> 00:22:32.960
Caption: how about assigning their identity for

00:22:30.959 --> 00:22:35.439
Caption: them i wonder if they like that

00:22:32.959 --> 00:22:37.599
Caption: worst of all hot or not back to mark

00:22:35.439 --> 00:22:39.839
Caption: zuckerberg and his famous initial

00:22:37.599 --> 00:22:41.199
Caption: experiment some of this stuff is being

00:22:39.839 --> 00:22:44.558
Caption: done for us by people in different

00:22:41.199 --> 00:22:46.399
Caption: places making decisions that impact our

00:22:44.558 --> 00:22:48.719
Caption: lives

00:22:46.400 --> 00:22:50.640
Caption: some of the

00:22:48.719 --> 00:22:52.158
Caption: facial recognition data sets and some of

00:22:50.640 --> 00:22:54.320
Caption: those that are actually used

00:22:52.159 --> 00:22:56.240
Caption: by the us for their standardizing

00:22:54.319 --> 00:22:57.439
Caption: situation by nist

00:22:56.239 --> 00:22:59.520
Caption: um

00:22:57.439 --> 00:23:01.439
Caption: unfortunately are actually made from

00:22:59.520 --> 00:23:02.959
Caption: people who did not consent

00:23:01.439 --> 00:23:04.319
Caption: often these people

00:23:02.959 --> 00:23:05.918
Caption: many of them have actually died or were

00:23:04.319 --> 00:23:08.399
Caption: deceased when they took the photos think

00:23:05.918 --> 00:23:08.399
Caption: about that

00:23:08.719 --> 00:23:12.319
Caption: and many of them were also convicted

00:23:10.558 --> 00:23:15.038
Caption: criminals and these images were taken

00:23:12.319 --> 00:23:15.038
Caption: over time

00:23:15.280 --> 00:23:18.559
Caption: it gets a little bit creepy when you

00:23:17.119 --> 00:23:20.959
Caption: think about that because they&#39;re devoid

00:23:18.558 --> 00:23:23.599
Caption: of context and meaning and story and

00:23:20.959 --> 00:23:25.038
Caption: personhood what we consider a criminal

00:23:23.599 --> 00:23:26.479
Caption: now is not necessarily what was

00:23:25.038 --> 00:23:28.558
Caption: considered criminal when some of these

00:23:26.479 --> 00:23:30.959
Caption: voters were taken so unfortunately

00:23:28.558 --> 00:23:33.119
Caption: people who may have

00:23:30.959 --> 00:23:35.199
Caption: done something just as simple as being

00:23:33.119 --> 00:23:37.599
Caption: gay was considered a criminal they&#39;ve

00:23:35.199 --> 00:23:39.599
Caption: ended up in a data set whether they&#39;re

00:23:37.599 --> 00:23:40.959
Caption: whether that&#39;s okay or not we&#39;ve not

00:23:39.599 --> 00:23:42.239
Caption: looked at

00:23:40.959 --> 00:23:44.158
Caption: certainly possible and it certainly

00:23:42.239 --> 00:23:45.918
Caption: happens

00:23:44.159 --> 00:23:48.000
Caption: we&#39;re beginning to shift the way that we

00:23:45.918 --> 00:23:49.119
Caption: see images of data from single little

00:23:48.000 --> 00:23:51.439
Caption: objects

00:23:49.119 --> 00:23:53.038
Caption: to infrastructure these are a resource a

00:23:51.439 --> 00:23:55.278
Caption: data set that we can all go in and use

00:23:53.038 --> 00:23:56.639
Caption: apply for opportunity to download the

00:23:55.279 --> 00:23:58.240
Caption: data set and train your model and off

00:23:56.640 --> 00:24:01.200
Caption: you go without actually recognizing the

00:23:58.239 --> 00:24:03.678
Caption: humans who are involved

00:24:01.199 --> 00:24:06.319
Caption: what happens if these models

00:24:03.678 --> 00:24:08.319
Caption: were built on your data

00:24:06.319 --> 00:24:09.678
Caption: what about your baby photos it&#39;s kind of

00:24:08.319 --> 00:24:11.519
Caption: cool

00:24:09.678 --> 00:24:13.839
Caption: what about that really nice warming

00:24:11.520 --> 00:24:15.279
Caption: brace you have with a friend

00:24:13.839 --> 00:24:17.839
Caption: or the last photo you&#39;ve got a grandma

00:24:15.279 --> 00:24:19.520
Caption: before she died

00:24:17.839 --> 00:24:22.479
Caption: would you like them to be classified and

00:24:19.520 --> 00:24:22.479
Caption: who gets that choice

00:24:22.640 --> 00:24:25.760
Caption: well

00:24:23.520 --> 00:24:27.359
Caption: those photos are online chances are they

00:24:25.760 --> 00:24:30.079
Caption: probably are already

00:24:27.359 --> 00:24:30.079
Caption: into those things

00:24:30.839 --> 00:24:34.400
Caption: so

00:24:32.400 --> 00:24:36.239
Caption: all many object recognition systems are

00:24:34.400 --> 00:24:38.000
Caption: providing the backbone of that cyber

00:24:36.239 --> 00:24:39.599
Caption: physical system

00:24:38.000 --> 00:24:41.439
Caption: and yet we are not making the decisions

00:24:39.599 --> 00:24:43.918
Caption: or even considering

00:24:41.439 --> 00:24:46.719
Caption: or even considering

00:24:43.918 --> 00:24:48.798
Caption: where the voice of the create creator is

00:24:46.719 --> 00:24:51.199
Caption: what do your baby photos mean to you

00:24:48.798 --> 00:24:52.399
Caption: what about a man&#39;s last photo

00:24:51.199 --> 00:24:54.959
Caption: who&#39;s got the right to use them can

00:24:52.400 --> 00:24:56.960
Caption: anybody use them

00:24:54.959 --> 00:24:59.278
Caption: and how do they get to interpret them

00:24:56.959 --> 00:25:01.520
Caption: what&#39;s actually interpreted

00:24:59.279 --> 00:25:03.200
Caption: is grandma&#39;s photo one that&#39;s

00:25:01.520 --> 00:25:04.159
Caption: tagged with love

00:25:03.199 --> 00:25:06.798
Caption: or just

00:25:04.159 --> 00:25:08.240
Caption: old woman world out hot or not starts

00:25:06.798 --> 00:25:10.959
Caption: getting particularly creepy when you

00:25:08.239 --> 00:25:12.839
Caption: think about it like that

00:25:10.959 --> 00:25:15.359
Caption: everything has a history and a

00:25:12.839 --> 00:25:17.119
Caption: context when we start

00:25:15.359 --> 00:25:18.400
Caption: separating our history and context from

00:25:17.119 --> 00:25:19.599
Caption: the data that we have and the systems

00:25:18.400 --> 00:25:21.359
Caption: that we use

00:25:19.599 --> 00:25:22.880
Caption: we lose a lot

00:25:21.359 --> 00:25:24.479
Caption: a lot of the meaning goes by the wave

00:25:22.880 --> 00:25:26.159
Caption: side and it actually shifts the systems

00:25:24.479 --> 00:25:27.359
Caption: that we have

00:25:26.159 --> 00:25:28.799
Caption: all around us

00:25:27.359 --> 00:25:31.520
Caption: so what are the choices we&#39;re making and

00:25:28.798 --> 00:25:34.079
Caption: how are they hidden

00:25:31.520 --> 00:25:35.599
Caption: data does involve choices i hear a lot

00:25:34.079 --> 00:25:37.839
Caption: of people tell me

00:25:35.599 --> 00:25:39.278
Caption: it&#39;s okay it&#39;s standardized it&#39;s

00:25:37.839 --> 00:25:41.199
Caption: objective

00:25:39.279 --> 00:25:44.159
Caption: well i&#39;d say it&#39;s not standardized i&#39;d

00:25:41.199 --> 00:25:46.880
Caption: say i&#39;d say it&#39;s not objected objective

00:25:44.159 --> 00:25:48.320
Caption: i&#39;d say it&#39;s standardized

00:25:46.880 --> 00:25:50.239
Caption: because we are making

00:25:48.319 --> 00:25:52.558
Caption: life choices

00:25:50.239 --> 00:25:52.558
Caption: which are

00:25:53.279 --> 00:25:56.799
Caption: prioritizing one aspect in that photo

00:25:55.599 --> 00:25:58.319
Caption: over another

00:25:56.798 --> 00:26:00.239
Caption: it may be tagging

00:25:58.319 --> 00:26:01.519
Caption: woman it may be tagging ocean it may be

00:26:00.239 --> 00:26:03.199
Caption: tagging c

00:26:01.520 --> 00:26:04.719
Caption: maybe tagging an emotion but man&#39;s

00:26:03.199 --> 00:26:08.239
Caption: prioritizing something over another it

00:26:04.719 --> 00:26:09.599
Caption: doesn&#39;t give the meaning in the context

00:26:08.239 --> 00:26:11.359
Caption: these are excluded and things are

00:26:09.599 --> 00:26:13.678
Caption: included and what is that he gets to

00:26:11.359 --> 00:26:16.239
Caption: make that choice

00:26:13.678 --> 00:26:18.640
Caption: it impacts us all

00:26:16.239 --> 00:26:20.880
Caption: all those models when they build on the

00:26:18.640 --> 00:26:22.479
Caption: data and the systems and the structures

00:26:20.880 --> 00:26:24.959
Caption: they reflect those decisions straight

00:26:22.479 --> 00:26:26.880
Caption: back to us

00:26:24.959 --> 00:26:29.278
Caption: all of those photos i took i showed in

00:26:26.880 --> 00:26:30.719
Caption: the previous example were not photos of

00:26:29.279 --> 00:26:34.240
Caption: real people

00:26:30.719 --> 00:26:35.918
Caption: they were actually photos from a gang

00:26:34.239 --> 00:26:37.119
Caption: which actually created

00:26:35.918 --> 00:26:39.359
Caption: people

00:26:37.119 --> 00:26:41.199
Caption: if you go back and look at those photos

00:26:39.359 --> 00:26:43.119
Caption: you&#39;ll notice most of them are of a

00:26:41.199 --> 00:26:45.839
Caption: certain skin tone

00:26:43.119 --> 00:26:48.640
Caption: and you&#39;ll also notice yeah

00:26:45.839 --> 00:26:48.640
Caption: gender and culture

00:26:49.038 --> 00:26:53.599
Caption: more commonalities than others

00:26:52.159 --> 00:26:55.120
Caption: that doesn&#39;t necessarily reflect

00:26:53.599 --> 00:26:56.640
Caption: humanity

00:26:55.119 --> 00:26:59.279
Caption: that reflects the data that the system

00:26:56.640 --> 00:26:59.279
Caption: was trained on

00:27:01.279 --> 00:27:05.360
Caption: so

00:27:02.558 --> 00:27:07.520
Caption: what we&#39;re looking at

00:27:05.359 --> 00:27:10.158
Caption: is a lot of subjective choices that are

00:27:07.520 --> 00:27:11.520
Caption: being made every day for us

00:27:10.159 --> 00:27:13.279
Caption: again

00:27:11.520 --> 00:27:16.159
Caption: everything has a history and everything

00:27:13.279 --> 00:27:16.159
Caption: has a context

00:27:16.239 --> 00:27:20.479
Caption: those cyber physical systems really are

00:27:18.798 --> 00:27:22.959
Caption: systems they are structures there are

00:27:20.479 --> 00:27:25.119
Caption: processes and people

00:27:22.959 --> 00:27:26.719
Caption: we know these things are important

00:27:25.119 --> 00:27:28.079
Caption: how can we adapt to them

00:27:26.719 --> 00:27:29.599
Caption: i hear a lot of people getting quite

00:27:28.079 --> 00:27:31.599
Caption: upset when they hear some of the awful

00:27:29.599 --> 00:27:33.119
Caption: things that some of our artificially

00:27:31.599 --> 00:27:34.880
Caption: intelligent or machine learning systems

00:27:33.119 --> 00:27:36.798
Caption: can do from things like

00:27:34.880 --> 00:27:38.558
Caption: uh deep fake

00:27:36.798 --> 00:27:41.199
Caption: deep fake porn being one that is just

00:27:38.558 --> 00:27:42.239
Caption: particularly creepy on a huge number of

00:27:41.199 --> 00:27:43.119
Caption: levels

00:27:42.239 --> 00:27:45.760
Caption: to

00:27:43.119 --> 00:27:47.760
Caption: some really creepy twitter

00:27:45.760 --> 00:27:50.159
Caption: kind of twitter creations where we have

00:27:47.760 --> 00:27:51.520
Caption: bots who kind of swear back at us and do

00:27:50.159 --> 00:27:53.039
Caption: some awful things

00:27:51.520 --> 00:27:55.440
Caption: um

00:27:53.038 --> 00:27:57.599
Caption: people say regulate it i love regulation

00:27:55.439 --> 00:27:59.038
Caption: this is great we can just make it do not

00:27:57.599 --> 00:28:00.798
Caption: do that because regulations will just

00:27:59.038 --> 00:28:03.519
Caption: stop everything and while i really like

00:28:00.798 --> 00:28:05.839
Caption: the idea kind of don&#39;t think it actually

00:28:03.520 --> 00:28:07.039
Caption: works but even if it does well what are

00:28:05.839 --> 00:28:08.558
Caption: we going to do we know these there&#39;s

00:28:07.038 --> 00:28:09.599
Caption: things that we don&#39;t want our systems to

00:28:08.558 --> 00:28:11.359
Caption: be

00:28:09.599 --> 00:28:13.278
Caption: we don&#39;t want them to be

00:28:11.359 --> 00:28:15.278
Caption: machine driven we don&#39;t want those

00:28:13.279 --> 00:28:17.679
Caption: people in amazon warehouses having to

00:28:15.279 --> 00:28:19.840
Caption: move exactly to the machine their entire

00:28:17.678 --> 00:28:21.519
Caption: lives being driven by those machines

00:28:19.839 --> 00:28:22.719
Caption: we know that we don&#39;t want our lives

00:28:21.520 --> 00:28:23.520
Caption: controlled

00:28:22.719 --> 00:28:26.319
Caption: by

00:28:23.520 --> 00:28:28.479
Caption: machines around us or i certainly don&#39;t

00:28:26.319 --> 00:28:29.599
Caption: we want trustworthy safe reliable

00:28:28.479 --> 00:28:31.599
Caption: systems

00:28:29.599 --> 00:28:33.520
Caption: so how do we build them

00:28:31.599 --> 00:28:35.760
Caption: well

00:28:33.520 --> 00:28:37.279
Caption: in australia at the moment we have an ai

00:28:35.760 --> 00:28:39.919
Caption: ethics framework where some of these

00:28:37.279 --> 00:28:41.200
Caption: values are stated how we build systems

00:28:39.918 --> 00:28:42.479
Caption: and what should we be trying to build

00:28:41.199 --> 00:28:44.158
Caption: them to

00:28:42.479 --> 00:28:45.520
Caption: that seemed pretty fair to me i like the

00:28:44.159 --> 00:28:47.279
Caption: idea

00:28:45.520 --> 00:28:50.080
Caption: but

00:28:47.279 --> 00:28:51.279
Caption: regulations just like our data just like

00:28:50.079 --> 00:28:53.599
Caption: our models

00:28:51.279 --> 00:28:55.440
Caption: are decisions

00:28:53.599 --> 00:28:56.959
Caption: they&#39;re prior to people or they&#39;re

00:28:55.439 --> 00:28:58.558
Caption: prioritizing

00:28:56.959 --> 00:29:01.599
Caption: what is important for a certain group of

00:28:58.558 --> 00:29:03.839
Caption: people at a certain place in time

00:29:01.599 --> 00:29:05.359
Caption: they are not objective

00:29:03.839 --> 00:29:07.119
Caption: the world is messy

00:29:05.359 --> 00:29:09.439
Caption: it&#39;s complex and it&#39;s always in flux

00:29:07.119 --> 00:29:11.199
Caption: things are changing you&#39;re changing i&#39;m

00:29:09.439 --> 00:29:12.639
Caption: changing i hope you all learn i hope the

00:29:11.199 --> 00:29:14.239
Caption: person that you are yesterday is

00:29:12.640 --> 00:29:15.520
Caption: different to the one you are tomorrow i

00:29:14.239 --> 00:29:16.719
Caption: hope you&#39;re not the same person you were

00:29:15.520 --> 00:29:18.558
Caption: when you were three because that&#39;d be

00:29:16.719 --> 00:29:19.678
Caption: weird

00:29:18.558 --> 00:29:21.918
Caption: but

00:29:19.678 --> 00:29:24.319
Caption: it&#39;s something we need to recognize the

00:29:21.918 --> 00:29:27.839
Caption: world is messy it&#39;s complex

00:29:24.319 --> 00:29:27.839
Caption: sort of cyber physical systems

00:29:28.239 --> 00:29:32.798
Caption: how do we adapt them

00:29:30.558 --> 00:29:34.319
Caption: well those regulations need to adapt to

00:29:32.798 --> 00:29:35.760
Caption: changing systems

00:29:34.319 --> 00:29:38.239
Caption: what is it within our regulations that

00:29:35.760 --> 00:29:40.959
Caption: it allows us to go back and say well

00:29:38.239 --> 00:29:42.959
Caption: you know we put in this rule

00:29:40.959 --> 00:29:45.520
Caption: it didn&#39;t work very well maybe we could

00:29:42.959 --> 00:29:46.959
Caption: try something else

00:29:45.520 --> 00:29:48.640
Caption: we know that if we don&#39;t have enough

00:29:46.959 --> 00:29:51.278
Caption: regulation it leads to harm and that&#39;s

00:29:48.640 --> 00:29:54.558
Caption: how we end up with

00:29:51.279 --> 00:29:56.880
Caption: uh some pretty dodgy system so i my mind

00:29:54.558 --> 00:29:58.239
Caption: immediately goes to the d-flat porn

00:29:56.880 --> 00:30:01.440
Caption: situation because it is just so

00:29:58.239 --> 00:30:03.678
Caption: apparently awful um we know those things

00:30:01.439 --> 00:30:04.959
Caption: can happen so we we don&#39;t do something

00:30:03.678 --> 00:30:06.719
Caption: about it that&#39;s a really predictable

00:30:04.959 --> 00:30:09.038
Caption: harm and we know we should probably do

00:30:06.719 --> 00:30:12.479
Caption: something about that but the other thing

00:30:09.038 --> 00:30:14.719
Caption: we need to recognize is over regulating

00:30:12.479 --> 00:30:16.000
Caption: can actually cause some significant

00:30:14.719 --> 00:30:18.640
Caption: problems too

00:30:16.000 --> 00:30:20.079
Caption: it has the capacity to solidify

00:30:18.640 --> 00:30:22.880
Caption: structures people processes and

00:30:20.079 --> 00:30:25.760
Caption: decisions that aren&#39;t necessarily good

00:30:22.880 --> 00:30:28.159
Caption: so i know that within the life span and

00:30:25.760 --> 00:30:29.599
Caption: the living memory of people some of whom

00:30:28.159 --> 00:30:31.600
Caption: may be here today

00:30:29.599 --> 00:30:34.079
Caption: an indigenous person was not considered

00:30:31.599 --> 00:30:34.079
Caption: a human

00:30:34.839 --> 00:30:40.398
Caption: 1960 i think that was changed

00:30:38.558 --> 00:30:43.839
Caption: it&#39;s kind of scary

00:30:40.399 --> 00:30:45.840
Caption: certainly within my lifetime i think

00:30:43.839 --> 00:30:49.278
Caption: being

00:30:45.839 --> 00:30:51.918
Caption: gay lesbian lgbtqi

00:30:49.279 --> 00:30:53.760
Caption: anything under that banner

00:30:51.918 --> 00:30:56.719
Caption: was considered

00:30:53.760 --> 00:30:58.558
Caption: actually an a an illness or a disease in

00:30:56.719 --> 00:31:01.839
Caption: the diagnostic and statistical manual

00:30:58.558 --> 00:31:04.640
Caption: for psychologists psychiatrists doctors

00:31:01.839 --> 00:31:05.918
Caption: and it was made illegal in our legal

00:31:04.640 --> 00:31:08.079
Caption: systems

00:31:05.918 --> 00:31:10.158
Caption: so if we run regulations completely

00:31:08.079 --> 00:31:12.479
Caption: solid and we don&#39;t recognize change we

00:31:10.159 --> 00:31:16.640
Caption: can actually start putting in values in

00:31:12.479 --> 00:31:16.640
Caption: place which maybe aren&#39;t so good for us

00:31:17.199 --> 00:31:20.639
Caption: this

00:31:18.000 --> 00:31:21.760
Caption: this also means we can over optimize

00:31:20.640 --> 00:31:23.760
Caption: systems because i think a lot of the

00:31:21.760 --> 00:31:26.079
Caption: time when we talk about regulations the

00:31:23.760 --> 00:31:27.839
Caption: concept of regulation or rules

00:31:26.079 --> 00:31:30.479
Caption: can go not just from the way that our

00:31:27.839 --> 00:31:33.038
Caption: society makes decisions but how we build

00:31:30.479 --> 00:31:35.439
Caption: companies and how we build teams and how

00:31:33.038 --> 00:31:36.239
Caption: we build data sets

00:31:35.439 --> 00:31:38.239
Caption: so

00:31:36.239 --> 00:31:40.319
Caption: if all of your data sets

00:31:38.239 --> 00:31:43.439
Caption: or all of your data comes from one

00:31:40.319 --> 00:31:45.518
Caption: gender one age one particular skin tone

00:31:43.439 --> 00:31:47.278
Caption: chances are if you try and release it in

00:31:45.519 --> 00:31:48.799
Caption: a different place in the world that

00:31:47.279 --> 00:31:50.559
Caption: system will break

00:31:48.798 --> 00:31:52.239
Caption: or it will be biased or it will be just

00:31:50.558 --> 00:31:55.359
Caption: flat out wrong

00:31:52.239 --> 00:31:57.119
Caption: the same news for organizations people

00:31:55.359 --> 00:31:58.798
Caption: governments regulations

00:31:57.119 --> 00:32:00.880
Caption: if we actually only make systems that

00:31:58.798 --> 00:32:03.119
Caption: can only take into account such a tiny

00:32:00.880 --> 00:32:05.440
Caption: little thing systems break

00:32:03.119 --> 00:32:06.558
Caption: we actually need flexibility in systems

00:32:05.439 --> 00:32:09.359
Caption: we need

00:32:06.558 --> 00:32:11.678
Caption: space for thinking we need diversity we

00:32:09.359 --> 00:32:12.839
Caption: need people to have the opportunity to

00:32:11.678 --> 00:32:14.398
Caption: see

00:32:12.839 --> 00:32:16.558
Caption: difference

00:32:14.399 --> 00:32:17.679
Caption: when we start making the reins of what

00:32:16.558 --> 00:32:19.439
Caption: we do tighter and tighter and tighter

00:32:17.678 --> 00:32:22.479
Caption: and tighter and tighter

00:32:19.439 --> 00:32:23.918
Caption: we can actually cause harm

00:32:22.479 --> 00:32:26.079
Caption: again

00:32:23.918 --> 00:32:28.239
Caption: our systems are created

00:32:26.079 --> 00:32:30.719
Caption: they&#39;re based on decisions that

00:32:28.239 --> 00:32:32.959
Caption: prioritize

00:32:30.719 --> 00:32:36.000
Caption: we change

00:32:32.959 --> 00:32:36.000
Caption: so to our systems

00:32:38.719 --> 00:32:42.398
Caption: let&#39;s actually try and make sense of the

00:32:40.880 --> 00:32:43.678
Caption: change rather than pretend that it

00:32:42.399 --> 00:32:45.679
Caption: doesn&#39;t happen

00:32:43.678 --> 00:32:47.839
Caption: how do we do that

00:32:45.678 --> 00:32:49.439
Caption: we bring in diversity

00:32:47.839 --> 00:32:52.000
Caption: diversity actually straddles the line

00:32:49.439 --> 00:32:54.398
Caption: between fragile and chaos we know our

00:32:52.000 --> 00:32:56.479
Caption: systems need to be robust enough

00:32:54.399 --> 00:32:58.799
Caption: that they can cope with a little bit of

00:32:56.479 --> 00:33:01.119
Caption: change so we need rules and regulations

00:32:58.798 --> 00:33:02.719
Caption: but they&#39;ve got to be flexible enough

00:33:01.119 --> 00:33:04.558
Caption: that they can take into account

00:33:02.719 --> 00:33:06.558
Caption: unexpected changes because if we don&#39;t

00:33:04.558 --> 00:33:08.479
Caption: we make dangerous things

00:33:06.558 --> 00:33:10.959
Caption: when we&#39;re talking diversity we need

00:33:08.479 --> 00:33:14.000
Caption: data ideas experiences and people

00:33:10.959 --> 00:33:16.239
Caption: we need it at all levels

00:33:14.000 --> 00:33:17.519
Caption: so why should this really matter to you

00:33:16.239 --> 00:33:18.719
Caption: i&#39;m here today

00:33:17.519 --> 00:33:20.880
Caption: because most people think that&#39;s a

00:33:18.719 --> 00:33:21.839
Caption: really nice idea i like diversity that&#39;s

00:33:20.880 --> 00:33:25.199
Caption: great

00:33:21.839 --> 00:33:25.918
Caption: um and yeah human labor makes an impact

00:33:25.199 --> 00:33:27.599
Caption: on

00:33:25.918 --> 00:33:29.278
Caption: what we build and yes sometimes it&#39;s

00:33:27.599 --> 00:33:30.558
Caption: hidden and physical resources also

00:33:29.279 --> 00:33:31.679
Caption: really count but why should it matter to

00:33:30.558 --> 00:33:32.959
Caption: you

00:33:31.678 --> 00:33:36.000
Caption: well

00:33:32.959 --> 00:33:37.599
Caption: wa australia we are actually at the

00:33:36.000 --> 00:33:39.199
Caption: epicentre of somewhere some of the

00:33:37.599 --> 00:33:40.959
Caption: physical resources that build our cyber

00:33:39.199 --> 00:33:42.558
Caption: physical systems

00:33:40.959 --> 00:33:44.558
Caption: come from

00:33:42.558 --> 00:33:46.398
Caption: so in w

00:33:44.558 --> 00:33:48.880
Caption: in wa

00:33:46.399 --> 00:33:51.200
Caption: we prese produce 41 percent of the

00:33:48.880 --> 00:33:52.719
Caption: global supply of lithium

00:33:51.199 --> 00:33:55.439
Caption: if you actually have

00:33:52.719 --> 00:33:56.398
Caption: um a device that requires a little

00:33:55.439 --> 00:33:57.759
Caption: battery

00:33:56.399 --> 00:33:59.679
Caption: or you happen to be cool enough to have

00:33:57.760 --> 00:34:02.320
Caption: your telstra

00:33:59.678 --> 00:34:03.278
Caption: tesla car right we&#39;ll get the word out

00:34:02.319 --> 00:34:04.479
Caption: um

00:34:03.279 --> 00:34:05.840
Caption: what we&#39;re actually seeing is they

00:34:04.479 --> 00:34:08.000
Caption: actually have lithium in the batteries

00:34:05.839 --> 00:34:10.000
Caption: so all these systems require lithium

00:34:08.000 --> 00:34:11.918
Caption: we actually supply that

00:34:10.000 --> 00:34:13.599
Caption: many of these devices also require rare

00:34:11.918 --> 00:34:14.800
Caption: earth metals

00:34:13.599 --> 00:34:16.960
Caption: that comes

00:34:14.800 --> 00:34:18.560
Caption: from right here in western australia

00:34:16.959 --> 00:34:21.040
Caption: just as a bit of an aside one of the

00:34:18.560 --> 00:34:22.719
Caption: major owners of one of the companies who

00:34:21.040 --> 00:34:23.678
Caption: actually built some of this

00:34:22.719 --> 00:34:25.520
Caption: is

00:34:23.678 --> 00:34:27.838
Caption: an australian

00:34:25.520 --> 00:34:30.398
Caption: mineral resources does a huge amount of

00:34:27.839 --> 00:34:32.800
Caption: lithium mining owned by our

00:34:30.398 --> 00:34:35.520
Caption: very own australian

00:34:32.800 --> 00:34:37.839
Caption: who is making decisions

00:34:35.520 --> 00:34:39.599
Caption: about where money is spent

00:34:37.839 --> 00:34:42.079
Caption: what information is shared

00:34:39.599 --> 00:34:45.200
Caption: who gets to hear what

00:34:42.079 --> 00:34:45.200
Caption: these decisions matter

00:34:47.599 --> 00:34:51.760
Caption: again

00:34:49.520 --> 00:34:51.760
Caption: book

00:34:52.239 --> 00:34:55.918
Caption: this is what happens when i click

00:34:53.439 --> 00:34:57.280
Caption: buttons wrong sorry everybody

00:34:55.918 --> 00:34:59.919
Caption: um

00:34:57.280 --> 00:35:02.959
Caption: as technologists designers just general

00:34:59.919 --> 00:35:04.719
Caption: citizens as people as regulators

00:35:02.959 --> 00:35:06.078
Caption: you get to make choices that change this

00:35:04.719 --> 00:35:08.560
Caption: world

00:35:06.079 --> 00:35:10.400
Caption: and those tiny little choices about

00:35:08.560 --> 00:35:13.199
Caption: what data&#39;s included are excluded which

00:35:10.399 --> 00:35:14.479
Caption: models you use where does it come from

00:35:13.199 --> 00:35:16.719
Caption: you can actually choose to make the

00:35:14.479 --> 00:35:19.520
Caption: world better or not

00:35:16.719 --> 00:35:19.520
Caption: that is up to you

00:35:20.159 --> 00:35:22.799
Caption: so

00:35:21.358 --> 00:35:24.719
Caption: how are the choices you&#39;re making

00:35:22.800 --> 00:35:26.560
Caption: influencing the world

00:35:24.719 --> 00:35:27.838
Caption: how are you looking at your human labor

00:35:26.560 --> 00:35:29.760
Caption: and the human labor of the people who

00:35:27.839 --> 00:35:32.239
Caption: contribute to these systems

00:35:29.760 --> 00:35:34.000
Caption: how the environment the raw resources in

00:35:32.239 --> 00:35:35.760
Caption: our own environment

00:35:34.000 --> 00:35:38.159
Caption: impact on the supply chain that goes

00:35:35.760 --> 00:35:40.239
Caption: along not just for us now but for people

00:35:38.159 --> 00:35:43.118
Caption: in the future

00:35:40.239 --> 00:35:44.479
Caption: where is it all hidden in the process

00:35:43.118 --> 00:35:45.679
Caption: where is the feedback

00:35:44.479 --> 00:35:47.520
Caption: how do we actually understand what

00:35:45.679 --> 00:35:48.879
Caption: happens to these things because at the

00:35:47.520 --> 00:35:52.560
Caption: moment these are discussions we don&#39;t

00:35:48.879 --> 00:35:52.559
Caption: seem to have as often as maybe we could

00:35:54.159 --> 00:35:56.799
Caption: i think it&#39;s worth

00:35:56.959 --> 00:36:02.368
Caption: thank you

00:35:59.570 --> 00:36:02.369
Caption: [Applause]

