[
    {
        "text": ">> You're not going to want to",
        "start": 0.0,
        "duration": 1.35
    },
    {
        "text": "miss this episode of the AI Show,",
        "start": 1.35,
        "duration": 1.56
    },
    {
        "text": "where we look at Azure Machine Learning service,",
        "start": 2.91,
        "duration": 2.115
    },
    {
        "text": "and all of the awesome developer tools that help",
        "start": 5.025,
        "duration": 2.385
    },
    {
        "text": "us be productive with AI in the Cloud.",
        "start": 7.41,
        "duration": 2.655
    },
    {
        "text": "See you then. Hello. Welcome to",
        "start": 10.065,
        "duration": 8.875
    },
    {
        "text": "this episode of the AI Show,",
        "start": 18.94,
        "duration": 1.52
    },
    {
        "text": "where we're going to look at",
        "start": 20.46,
        "duration": 0.585
    },
    {
        "text": "Azure Machine Learning Service,",
        "start": 21.045,
        "duration": 1.815
    },
    {
        "text": "but specifically the tooling behind it,",
        "start": 22.86,
        "duration": 1.82
    },
    {
        "text": "I have a special guest today.",
        "start": 24.68,
        "duration": 1.255
    },
    {
        "text": "Chris how are you doing buddy?",
        "start": 25.935,
        "duration": 1.06
    },
    {
        "text": ">> I'm doing awesome. Thanks Seth for having me.",
        "start": 26.995,
        "duration": 2.18
    },
    {
        "text": ">> Why don't you introduce yourself.",
        "start": 29.175,
        "duration": 1.205
    },
    {
        "text": ">> Absolutely. So, I'm a Program Manager",
        "start": 30.38,
        "duration": 2.23
    },
    {
        "text": "in Azure AI Team,",
        "start": 32.61,
        "duration": 1.935
    },
    {
        "text": "focused on developer tooling,",
        "start": 34.545,
        "duration": 2.18
    },
    {
        "text": "and specifically today we're going to talk",
        "start": 36.725,
        "duration": 1.825
    },
    {
        "text": "about Visual Studio Code Tools for AI,",
        "start": 38.55,
        "duration": 2.78
    },
    {
        "text": "and how you can do AI2,",
        "start": 41.33,
        "duration": 2.245
    },
    {
        "text": "locally and in the Cloud.",
        "start": 43.575,
        "duration": 1.485
    },
    {
        "text": ">> Fantastic. So, let's start out",
        "start": 45.06,
        "duration": 1.37
    },
    {
        "text": "with what's Azure Machine Learning Service,",
        "start": 46.43,
        "duration": 2.86
    },
    {
        "text": "we'll do like a quick overview,",
        "start": 49.29,
        "duration": 1.085
    },
    {
        "text": "and then we'll look at the tooling that's available.",
        "start": 50.375,
        "duration": 1.415
    },
    {
        "text": ">> Sure.",
        "start": 51.79,
        "duration": 0.53
    },
    {
        "text": ">> Let's do it.",
        "start": 52.32,
        "duration": 0.41
    },
    {
        "text": ">> Absolutely. So, Azure Machine Learning",
        "start": 52.73,
        "duration": 2.925
    },
    {
        "text": "is a service that runs in",
        "start": 55.655,
        "duration": 1.515
    },
    {
        "text": "Azure to keep track of all of",
        "start": 57.17,
        "duration": 1.89
    },
    {
        "text": "your Machine Learning experiments, your data,",
        "start": 59.06,
        "duration": 2.925
    },
    {
        "text": "your compute targets, your models,",
        "start": 61.985,
        "duration": 2.605
    },
    {
        "text": "and your deployed services,",
        "start": 64.59,
        "duration": 1.79
    },
    {
        "text": "that use those models like",
        "start": 66.38,
        "duration": 1.29
    },
    {
        "text": "an intelligent function that you can call via a REST API,",
        "start": 67.67,
        "duration": 3.21
    },
    {
        "text": "and get back a result from your training model.",
        "start": 70.88,
        "duration": 2.89
    },
    {
        "text": ">> Awesome.",
        "start": 73.77,
        "duration": 0.58
    },
    {
        "text": ">> Now, you can train those models anywhere,",
        "start": 74.35,
        "duration": 2.615
    },
    {
        "text": "and deploy them in Azure using",
        "start": 76.965,
        "duration": 2.36
    },
    {
        "text": "Docker containers that run on Kubernetes service.",
        "start": 79.325,
        "duration": 3.46
    },
    {
        "text": "So, that it's highly load balanced,",
        "start": 82.785,
        "duration": 1.395
    },
    {
        "text": "and super easy to use, and super performant.",
        "start": 84.18,
        "duration": 2.555
    },
    {
        "text": ">> So, if you're a Data Scientist,",
        "start": 86.735,
        "duration": 1.125
    },
    {
        "text": "do you understand all this",
        "start": 87.86,
        "duration": 1.08
    },
    {
        "text": "Docker container Kubernetes stuff?",
        "start": 88.94,
        "duration": 1.915
    },
    {
        "text": "Because I have a hard time with",
        "start": 90.855,
        "duration": 1.115
    },
    {
        "text": "Kubernetes and Docker sometimes.",
        "start": 91.97,
        "duration": 1.91
    },
    {
        "text": "Do you have to know what that",
        "start": 93.88,
        "duration": 1.07
    },
    {
        "text": "is in order to make this work?",
        "start": 94.95,
        "duration": 1.49
    },
    {
        "text": ">> Absolutely not. I'm not actually going to show you how",
        "start": 96.44,
        "duration": 2.46
    },
    {
        "text": "using Visual Studio Code Tools for AI,",
        "start": 98.9,
        "duration": 2.595
    },
    {
        "text": "you can generate a new Azure Kubernetes cluster,",
        "start": 101.495,
        "duration": 3.285
    },
    {
        "text": "which is right-clicking something,",
        "start": 104.78,
        "duration": 1.695
    },
    {
        "text": "and you can even generate",
        "start": 106.475,
        "duration": 1.365
    },
    {
        "text": "your Docker image that has your model",
        "start": 107.84,
        "duration": 2.01
    },
    {
        "text": "and deploy it and get",
        "start": 109.85,
        "duration": 1.26
    },
    {
        "text": "a REST API again, just right-clicking.",
        "start": 111.11,
        "duration": 2.485
    },
    {
        "text": "Almost no-code, except for just your Python code that runs",
        "start": 113.595,
        "duration": 3.845
    },
    {
        "text": "your model which you would run anywhere in",
        "start": 117.44,
        "duration": 2.13
    },
    {
        "text": "any Jupyter Notebook or in Visual Studio Code.",
        "start": 119.57,
        "duration": 2.425
    },
    {
        "text": ">> Fantastic. So, let's get into the actual service,",
        "start": 121.995,
        "duration": 3.53
    },
    {
        "text": "what are we looking at right here?",
        "start": 125.525,
        "duration": 1.27
    },
    {
        "text": ">> Sure, absolutely. So, this is the Azure Portal,",
        "start": 126.795,
        "duration": 3.05
    },
    {
        "text": "and in the Azure Portal,",
        "start": 129.845,
        "duration": 1.8
    },
    {
        "text": "then you can see we've got a bunch of experiments.",
        "start": 131.645,
        "duration": 3.27
    },
    {
        "text": "You can see \"Compute\" targets, \"Models\",",
        "start": 134.915,
        "duration": 2.73
    },
    {
        "text": "\"Images\", these are Docker images and \"Deployments\".",
        "start": 137.645,
        "duration": 3.97
    },
    {
        "text": "So, those are your actual running services.",
        "start": 141.615,
        "duration": 2.4
    },
    {
        "text": "On the right you can see I run a couple of",
        "start": 144.015,
        "duration": 2.135
    },
    {
        "text": "experiments within the context of this Workspace.",
        "start": 146.15,
        "duration": 4.245
    },
    {
        "text": "As we scroll down you can see that there's",
        "start": 150.395,
        "duration": 3.255
    },
    {
        "text": "multiple different runs for the same experiment,",
        "start": 153.65,
        "duration": 2.67
    },
    {
        "text": "because I always try the same thing",
        "start": 156.32,
        "duration": 2.145
    },
    {
        "text": "over and over to try and get a little bit better,",
        "start": 158.465,
        "duration": 2.085
    },
    {
        "text": "a little bit faster,",
        "start": 160.55,
        "duration": 1.05
    },
    {
        "text": "a little bit better quality results.",
        "start": 161.6,
        "duration": 2.055
    },
    {
        "text": "So, quickly and easily you can",
        "start": 163.655,
        "duration": 1.485
    },
    {
        "text": "see all the different experiments that I",
        "start": 165.14,
        "duration": 1.68
    },
    {
        "text": "run and you can see an overview of the \"Duration\".",
        "start": 166.82,
        "duration": 3.34
    },
    {
        "text": "But if you drill into any given one of these,",
        "start": 170.16,
        "duration": 3.02
    },
    {
        "text": "then you can also see",
        "start": 173.18,
        "duration": 1.29
    },
    {
        "text": "the different quality metrics that",
        "start": 174.47,
        "duration": 1.735
    },
    {
        "text": "I logged during that experiment.",
        "start": 176.205,
        "duration": 2.095
    },
    {
        "text": ">> Fantastic. So, let me see if I understand this.",
        "start": 178.3,
        "duration": 2.305
    },
    {
        "text": "This whole thing I'm seeing is called",
        "start": 180.605,
        "duration": 2.005
    },
    {
        "text": "Machine Learning Service Workspace.",
        "start": 182.61,
        "duration": 2.085
    },
    {
        "text": "What is a Workspace? How should I think about it?",
        "start": 184.695,
        "duration": 2.575
    },
    {
        "text": ">> You should think about it as",
        "start": 187.27,
        "duration": 1.36
    },
    {
        "text": "just a big container or a box of stuff.",
        "start": 188.63,
        "duration": 3.455
    },
    {
        "text": "Inside that box of stuff,",
        "start": 192.085,
        "duration": 1.82
    },
    {
        "text": "then I've got different experiments.",
        "start": 193.905,
        "duration": 2.06
    },
    {
        "text": "I've got my models that I",
        "start": 195.965,
        "duration": 1.785
    },
    {
        "text": "can keep track of where they are.",
        "start": 197.75,
        "duration": 1.91
    },
    {
        "text": "I've got different compute target.",
        "start": 199.66,
        "duration": 1.67
    },
    {
        "text": "So, if I've got, instead of having",
        "start": 201.33,
        "duration": 1.79
    },
    {
        "text": "just a bunch of virtual machines scattered around",
        "start": 203.12,
        "duration": 2.25
    },
    {
        "text": "Azure and all the data scientists on",
        "start": 205.37,
        "duration": 1.95
    },
    {
        "text": "my team not knowing where to find them for example.",
        "start": 207.32,
        "duration": 3.055
    },
    {
        "text": ">> I see.",
        "start": 210.375,
        "duration": 0.535
    },
    {
        "text": ">> Then we can put all these different things",
        "start": 210.91,
        "duration": 1.945
    },
    {
        "text": "inside a Workspace.",
        "start": 212.855,
        "duration": 1.48
    },
    {
        "text": "In that Workspace, then we can",
        "start": 214.335,
        "duration": 2.675
    },
    {
        "text": "find them and share them and get access to them,",
        "start": 217.01,
        "duration": 2.765
    },
    {
        "text": "just by granting access to the Workspace,",
        "start": 219.775,
        "duration": 2.305
    },
    {
        "text": "then I get access to all the different compute targets.",
        "start": 222.08,
        "duration": 2.2
    },
    {
        "text": "So, I can not just find them,",
        "start": 224.28,
        "duration": 1.73
    },
    {
        "text": "but also actually use them.",
        "start": 226.01,
        "duration": 1.47
    },
    {
        "text": ">> I see.",
        "start": 227.48,
        "duration": 0.2
    },
    {
        "text": ">> So, I don't have to go and grant",
        "start": 227.68,
        "duration": 1.72
    },
    {
        "text": "permissions to all the individual things.",
        "start": 229.4,
        "duration": 2.07
    },
    {
        "text": ">> That's awesome because generally my trail",
        "start": 231.47,
        "duration": 4.24
    },
    {
        "text": "of sadness when doing AI is",
        "start": 235.71,
        "duration": 1.65
    },
    {
        "text": "I'm basically changing code over and over again and I",
        "start": 237.36,
        "duration": 3.02
    },
    {
        "text": "can't see what did I do three times ago.",
        "start": 240.38,
        "duration": 3.24
    },
    {
        "text": "So, this allows you to remember",
        "start": 243.62,
        "duration": 1.85
    },
    {
        "text": "how you went about actually solving the AI problem.",
        "start": 245.47,
        "duration": 2.8
    },
    {
        "text": ">> That's absolutely right and where you did it.",
        "start": 248.27,
        "duration": 2.33
    },
    {
        "text": "So, if somebody wanted to reproduce",
        "start": 250.6,
        "duration": 1.99
    },
    {
        "text": "it using the same set of machines,",
        "start": 252.59,
        "duration": 2.07
    },
    {
        "text": "then they can absolutely find",
        "start": 254.66,
        "duration": 1.17
    },
    {
        "text": "those in the Workspace as well.",
        "start": 255.83,
        "duration": 1.165
    },
    {
        "text": ">> Fantastic. So, this is a super good overview",
        "start": 256.995,
        "duration": 2.105
    },
    {
        "text": "of Azure Machine Learning Service.",
        "start": 259.1,
        "duration": 1.975
    },
    {
        "text": "But as a developer,",
        "start": 261.075,
        "duration": 1.375
    },
    {
        "text": "usually data scientists are going",
        "start": 262.45,
        "duration": 1.96
    },
    {
        "text": "to be using the things that they like to use.",
        "start": 264.41,
        "duration": 2.385
    },
    {
        "text": "How do we support them in that?",
        "start": 266.795,
        "duration": 1.345
    },
    {
        "text": ">> Sure. So, I personally don't",
        "start": 268.14,
        "duration": 2.57
    },
    {
        "text": "like to use the Azure Portal for actually writing code,",
        "start": 270.71,
        "duration": 2.635
    },
    {
        "text": "that makes no sense to me as a Developer.",
        "start": 273.345,
        "duration": 2.255
    },
    {
        "text": "I prefer to use Visual Studio Code.",
        "start": 275.6,
        "duration": 2.345
    },
    {
        "text": "So, let me show you how with",
        "start": 277.945,
        "duration": 2.44
    },
    {
        "text": "Visual Studio Code Tools for AI extension,",
        "start": 280.385,
        "duration": 3.2
    },
    {
        "text": "that's available in Visual Studio Code.",
        "start": 283.585,
        "duration": 2.665
    },
    {
        "text": "Not only can I see all my different code,",
        "start": 286.25,
        "duration": 2.34
    },
    {
        "text": "so I've got a Python script",
        "start": 288.59,
        "duration": 2.13
    },
    {
        "text": "here to train a machine learning model.",
        "start": 290.72,
        "duration": 2.175
    },
    {
        "text": "But if I click the \"Azure Activity Bar\",",
        "start": 292.895,
        "duration": 3.175
    },
    {
        "text": "then we can see I've got this \"Azure Machine",
        "start": 296.07,
        "duration": 2.12
    },
    {
        "text": "Learning View\" here as well and",
        "start": 298.19,
        "duration": 2.22
    },
    {
        "text": "notice this same Azure Machine Learning Workspace",
        "start": 300.41,
        "duration": 2.995
    },
    {
        "text": "is available within the subscription.",
        "start": 303.405,
        "duration": 2.245
    },
    {
        "text": "Now, I can filter to",
        "start": 305.65,
        "duration": 1.66
    },
    {
        "text": "all the different Azure subscriptions that I have so I",
        "start": 307.31,
        "duration": 2.94
    },
    {
        "text": "don't have to see all of them all at",
        "start": 310.25,
        "duration": 1.71
    },
    {
        "text": "once in the VS Code View,",
        "start": 311.96,
        "duration": 2.86
    },
    {
        "text": "because that's just clutters things out.",
        "start": 314.82,
        "duration": 1.3
    },
    {
        "text": ">> Of course.",
        "start": 316.12,
        "duration": 0.875
    },
    {
        "text": ">> Then within that Workspace,",
        "start": 316.995,
        "duration": 1.985
    },
    {
        "text": "then those same experiments",
        "start": 318.98,
        "duration": 1.38
    },
    {
        "text": "that I was looking at earlier,",
        "start": 320.36,
        "duration": 1.515
    },
    {
        "text": "I can see them here.",
        "start": 321.875,
        "duration": 1.615
    },
    {
        "text": "Now, this \"Folder of Code\" that I have in VS Code,",
        "start": 323.49,
        "duration": 4.5
    },
    {
        "text": "I need to attach it to the the \"Folder to an Experiment\".",
        "start": 327.99,
        "duration": 4.49
    },
    {
        "text": "So I say, this code I'm working on,",
        "start": 332.48,
        "duration": 1.81
    },
    {
        "text": "on my local machine,",
        "start": 334.29,
        "duration": 1.34
    },
    {
        "text": "I'm going to attach it to",
        "start": 335.63,
        "duration": 1.14
    },
    {
        "text": "this experiment in Azure Machine Learning.",
        "start": 336.77,
        "duration": 2.06
    },
    {
        "text": ">> That's where you get all those cool metrics",
        "start": 338.83,
        "duration": 1.69
    },
    {
        "text": "that we saw before.",
        "start": 340.52,
        "duration": 1.37
    },
    {
        "text": "So, if I'm a Data Scientist,",
        "start": 341.89,
        "duration": 1.65
    },
    {
        "text": "I already have my own,",
        "start": 343.54,
        "duration": 1.475
    },
    {
        "text": "let's just say MNCs for sake of arguments,",
        "start": 345.015,
        "duration": 2.855
    },
    {
        "text": "because it's the easiest one for everyone to understand.",
        "start": 347.87,
        "duration": 2.0
    },
    {
        "text": "I already wrote my own code,",
        "start": 349.87,
        "duration": 1.53
    },
    {
        "text": "do I need to change anything to make it",
        "start": 351.4,
        "duration": 1.54
    },
    {
        "text": "work inside of Azure Machine Learning Service?",
        "start": 352.94,
        "duration": 1.915
    },
    {
        "text": ">> You don't need to change a whole lot.",
        "start": 354.855,
        "duration": 2.24
    },
    {
        "text": "What you do need to do is, you need to look at,",
        "start": 357.095,
        "duration": 4.055
    },
    {
        "text": "define the \"Run.GetContext\",",
        "start": 361.15,
        "duration": 3.185
    },
    {
        "text": "this is an Azure Machine Learning run.",
        "start": 364.335,
        "duration": 1.955
    },
    {
        "text": "So every time I run my experiment, it's a new run.",
        "start": 366.29,
        "duration": 3.27
    },
    {
        "text": ">> I see.",
        "start": 369.56,
        "duration": 1.22
    },
    {
        "text": ">> So, then I'm going to get a handle to",
        "start": 370.78,
        "duration": 2.26
    },
    {
        "text": "the run if I'm running",
        "start": 373.04,
        "duration": 1.8
    },
    {
        "text": "in the context of Azure Machine Learning,",
        "start": 374.84,
        "duration": 1.94
    },
    {
        "text": "and if so, then I can use the",
        "start": 376.78,
        "duration": 2.265
    },
    {
        "text": "\"Run.Log\" method for example,",
        "start": 379.045,
        "duration": 3.645
    },
    {
        "text": "to log the metrics that I care about.",
        "start": 382.69,
        "duration": 1.76
    },
    {
        "text": ">> I see. So, if you want the cool visualizations,",
        "start": 384.45,
        "duration": 2.445
    },
    {
        "text": "you can log, but if you don't log in it will",
        "start": 386.895,
        "duration": 1.625
    },
    {
        "text": "still run in the Cloud as is.",
        "start": 388.52,
        "duration": 1.885
    },
    {
        "text": ">> Or it can even run locally",
        "start": 390.405,
        "duration": 1.85
    },
    {
        "text": "and just log all the metrics to the Cloud.",
        "start": 392.255,
        "duration": 2.115
    },
    {
        "text": ">> I see.",
        "start": 394.37,
        "duration": 0.4
    },
    {
        "text": ">> So, as I'm stepping through",
        "start": 394.77,
        "duration": 2.09
    },
    {
        "text": "debugging my code on my local machine,",
        "start": 396.86,
        "duration": 2.11
    },
    {
        "text": "then I can still just keep track of",
        "start": 398.97,
        "duration": 1.52
    },
    {
        "text": "my experiment using Azure Machine Learning.",
        "start": 400.49,
        "duration": 2.32
    },
    {
        "text": ">> That's pretty cool. So, look as",
        "start": 402.81,
        "duration": 2.03
    },
    {
        "text": "a Data Scientist usually what I",
        "start": 404.84,
        "duration": 1.59
    },
    {
        "text": "do is I don't know what I'm doing,",
        "start": 406.43,
        "duration": 2.135
    },
    {
        "text": "and then I usually pull up a notebook,",
        "start": 408.565,
        "duration": 2.815
    },
    {
        "text": "try some things out.",
        "start": 411.38,
        "duration": 1.395
    },
    {
        "text": "Okay, this works, I cut and",
        "start": 412.775,
        "duration": 1.815
    },
    {
        "text": "paste the code into something like this.",
        "start": 414.59,
        "duration": 2.1
    },
    {
        "text": "How are you going to support me with Jupyter Notebooks?",
        "start": 416.69,
        "duration": 3.795
    },
    {
        "text": ">> Sure, absolutely.",
        "start": 420.485,
        "duration": 1.25
    },
    {
        "text": "So, a lot of Data Scientists",
        "start": 421.735,
        "duration": 1.885
    },
    {
        "text": "get started early in their process",
        "start": 423.62,
        "duration": 1.8
    },
    {
        "text": "using Jupyter Notebooks and I'm no exception.",
        "start": 425.42,
        "duration": 3.92
    },
    {
        "text": "Now, we've added support in",
        "start": 429.34,
        "duration": 1.66
    },
    {
        "text": "Visual Studio Code for Jupyter Notebooks,",
        "start": 431.0,
        "duration": 2.96
    },
    {
        "text": "such that you can use",
        "start": 433.96,
        "duration": 1.9
    },
    {
        "text": "the Azure Machine Learning Python SDK",
        "start": 435.86,
        "duration": 2.945
    },
    {
        "text": "to keep track of your experiment",
        "start": 438.805,
        "duration": 1.915
    },
    {
        "text": "from code if you'd like to or use",
        "start": 440.72,
        "duration": 2.67
    },
    {
        "text": "any other Python libraries",
        "start": 443.39,
        "duration": 1.98
    },
    {
        "text": "inside Jupyter notebooks as well.",
        "start": 445.37,
        "duration": 2.425
    },
    {
        "text": "Now, this is not just a viewer of the notebook,",
        "start": 447.795,
        "duration": 3.305
    },
    {
        "text": "you can actually step through and execute",
        "start": 451.1,
        "duration": 2.28
    },
    {
        "text": "all the individual commands just like you normally would.",
        "start": 453.38,
        "duration": 2.76
    },
    {
        "text": ">> So, you find that Jupyter Notebooks",
        "start": 456.14,
        "duration": 1.19
    },
    {
        "text": "Service and you're running it just",
        "start": 457.33,
        "duration": 1.9
    },
    {
        "text": "like I would any other time except",
        "start": 459.23,
        "duration": 1.47
    },
    {
        "text": "it's in the context of Visual Studio Code.",
        "start": 460.7,
        "duration": 1.65
    },
    {
        "text": ">> That's right. Which is",
        "start": 462.35,
        "duration": 1.555
    },
    {
        "text": "great for me because personally,",
        "start": 463.905,
        "duration": 2.045
    },
    {
        "text": "once I step through and get",
        "start": 465.95,
        "duration": 2.745
    },
    {
        "text": "an idea as to whether",
        "start": 468.695,
        "duration": 1.065
    },
    {
        "text": "an experiment is really going to work or not,",
        "start": 469.76,
        "duration": 1.91
    },
    {
        "text": "then I want to take the code out of the Jupyter Notebook",
        "start": 471.67,
        "duration": 2.915
    },
    {
        "text": "and usually put it into individual Python files,",
        "start": 474.585,
        "duration": 3.055
    },
    {
        "text": "so I can check them into source control, share them,",
        "start": 477.64,
        "duration": 2.33
    },
    {
        "text": "version them, debug, refactor.",
        "start": 479.97,
        "duration": 2.505
    },
    {
        "text": "So, working on both the notebook",
        "start": 482.475,
        "duration": 2.045
    },
    {
        "text": "and the code all in VS Code,",
        "start": 484.52,
        "duration": 2.295
    },
    {
        "text": "really helps me to be super productive.",
        "start": 486.815,
        "duration": 1.96
    },
    {
        "text": ">> Awesome. So, let's take a look at",
        "start": 488.775,
        "duration": 1.115
    },
    {
        "text": "the Azure tab again to see what's available.",
        "start": 489.89,
        "duration": 3.54
    },
    {
        "text": ">> Absolutely.",
        "start": 493.43,
        "duration": 0.16
    },
    {
        "text": ">> So, when I'm looking at this \"TeamWorkspace\",",
        "start": 493.59,
        "duration": 2.785
    },
    {
        "text": "everything that everyone on the team has done,",
        "start": 496.375,
        "duration": 2.065
    },
    {
        "text": "you'll be able to see from their experiments,",
        "start": 498.44,
        "duration": 2.12
    },
    {
        "text": "from what they're computing et cetera.",
        "start": 500.56,
        "duration": 2.18
    },
    {
        "text": ">> Yeah, that's right.",
        "start": 502.74,
        "duration": 1.395
    },
    {
        "text": "So, you can even see this \"Compute\" node.",
        "start": 504.135,
        "duration": 2.755
    },
    {
        "text": "So, we talked about what an experiment is.",
        "start": 506.89,
        "duration": 2.555
    },
    {
        "text": "The \"Compute\" node, I can easily create",
        "start": 509.445,
        "duration": 2.54
    },
    {
        "text": "more powerful \"Compute\" contexts",
        "start": 511.985,
        "duration": 2.325
    },
    {
        "text": "in Azure if I would like to.",
        "start": 514.31,
        "duration": 1.4
    },
    {
        "text": "So, let me show you quickly,",
        "start": 515.71,
        "duration": 1.5
    },
    {
        "text": "we can create a compute.",
        "start": 517.21,
        "duration": 1.635
    },
    {
        "text": "We can say, create an Azure Kubernetes service",
        "start": 518.845,
        "duration": 2.785
    },
    {
        "text": "if we wanted to deploy my models to use in production.",
        "start": 521.63,
        "duration": 2.925
    },
    {
        "text": "Or if I wanted to create a Batch AI cluster for example,",
        "start": 524.555,
        "duration": 3.24
    },
    {
        "text": "I think Seth, you probably deserve",
        "start": 527.795,
        "duration": 1.395
    },
    {
        "text": "a GPU cluster of your own.",
        "start": 529.19,
        "duration": 1.82
    },
    {
        "text": ">> I do, at least on two or three machines.",
        "start": 531.01,
        "duration": 0.45
    },
    {
        "text": ">> So, I'm just going to go ahead and",
        "start": 531.46,
        "duration": 1.465
    },
    {
        "text": "create Seth's GPU cluster.",
        "start": 532.925,
        "duration": 2.085
    },
    {
        "text": ">> Of course.",
        "start": 535.01,
        "duration": 0.705
    },
    {
        "text": ">> I'm going to give it a name. Now, I've",
        "start": 535.715,
        "duration": 1.845
    },
    {
        "text": "got a bunch of different sizes of",
        "start": 537.56,
        "duration": 1.2
    },
    {
        "text": "virtual machines and I honestly can",
        "start": 538.76,
        "duration": 1.8
    },
    {
        "text": "never keep track of exactly what the name is.",
        "start": 540.56,
        "duration": 2.405
    },
    {
        "text": "So, I'm just going to go ahead and",
        "start": 542.965,
        "duration": 1.885
    },
    {
        "text": "search for something with a GPU in here.",
        "start": 544.85,
        "duration": 2.33
    },
    {
        "text": "I find, oh well,",
        "start": 547.18,
        "duration": 1.46
    },
    {
        "text": "the V3 sounds pretty good,",
        "start": 548.64,
        "duration": 1.91
    },
    {
        "text": "it's got a GPU of V100",
        "start": 550.55,
        "duration": 1.81
    },
    {
        "text": "and it has four of them.",
        "start": 552.36,
        "duration": 1.13
    },
    {
        "text": "Do you think that would meet your need?",
        "start": 553.49,
        "duration": 0.87
    },
    {
        "text": ">> I feel like I need some of those.",
        "start": 554.36,
        "duration": 1.95
    },
    {
        "text": ">> Yeah, okay, great. So, let's go ahead and create that.",
        "start": 556.31,
        "duration": 2.25
    },
    {
        "text": "Now, I've added this config file,",
        "start": 558.56,
        "duration": 1.92
    },
    {
        "text": "you see one of the interesting things about",
        "start": 560.48,
        "duration": 2.16
    },
    {
        "text": "the Batch AI service is that,",
        "start": 562.64,
        "duration": 2.285
    },
    {
        "text": "it actually can automatically",
        "start": 564.925,
        "duration": 1.555
    },
    {
        "text": "scale to the certain number of nodes,",
        "start": 566.48,
        "duration": 2.49
    },
    {
        "text": "these are the number of virtual machines in the cluster.",
        "start": 568.97,
        "duration": 2.37
    },
    {
        "text": "So, by default you are going to have zero machines,",
        "start": 571.34,
        "duration": 2.98
    },
    {
        "text": "which means that when no jobs are running,",
        "start": 574.32,
        "duration": 1.815
    },
    {
        "text": "the cluster actually doesn't exist.",
        "start": 576.135,
        "duration": 1.645
    },
    {
        "text": ">> So. I'm not going to be charged for this stuff.",
        "start": 577.78,
        "duration": 2.49
    },
    {
        "text": ">> You're not paying for anything.",
        "start": 580.27,
        "duration": 0.3
    },
    {
        "text": ">> That's awesome.",
        "start": 580.57,
        "duration": 0.745
    },
    {
        "text": ">> But then as you submit jobs,",
        "start": 581.315,
        "duration": 1.845
    },
    {
        "text": "then it'll create the virtual machine,",
        "start": 583.16,
        "duration": 1.97
    },
    {
        "text": "it'll put your Docker container there,",
        "start": 585.13,
        "duration": 1.71
    },
    {
        "text": "it'll run it and that's awesome.",
        "start": 586.84,
        "duration": 2.345
    },
    {
        "text": "You can set some controls on here,",
        "start": 589.185,
        "duration": 2.28
    },
    {
        "text": "I'll never have more than four virtual machines",
        "start": 591.465,
        "duration": 3.215
    },
    {
        "text": "at a time for example.",
        "start": 594.68,
        "duration": 1.46
    },
    {
        "text": "We selected the GPU of four V100s.",
        "start": 596.14,
        "duration": 5.01
    },
    {
        "text": "So, if we had four virtual machines with four V100s each,",
        "start": 601.15,
        "duration": 4.175
    },
    {
        "text": "you actually would have up to",
        "start": 605.325,
        "duration": 1.055
    },
    {
        "text": "16 GPUs in this cluster or you could have,",
        "start": 606.38,
        "duration": 3.555
    },
    {
        "text": "if I really liked you I could get you a whole lot.",
        "start": 609.935,
        "duration": 2.825
    },
    {
        "text": ">> Wow.",
        "start": 612.76,
        "duration": 0.57
    },
    {
        "text": ">> I don't like you that much.",
        "start": 613.33,
        "duration": 1.285
    },
    {
        "text": ">> That's a lot of digits we're going to be",
        "start": 614.615,
        "duration": 1.695
    },
    {
        "text": "recognizing in the Cloud, I'm pretty excited.",
        "start": 616.31,
        "duration": 2.145
    },
    {
        "text": ">> Absolutely. So, we can go ahead and click",
        "start": 618.455,
        "duration": 2.335
    },
    {
        "text": "\"Finish\" and create the machine.",
        "start": 620.79,
        "duration": 2.92
    },
    {
        "text": "The cluster now I already have one",
        "start": 623.71,
        "duration": 2.08
    },
    {
        "text": "here for the purpose of the show today.",
        "start": 625.79,
        "duration": 2.525
    },
    {
        "text": "Now, within the context of a particular compute context,",
        "start": 628.315,
        "duration": 5.735
    },
    {
        "text": "you need to have what we call a run configuration file.",
        "start": 634.05,
        "duration": 3.75
    },
    {
        "text": "The run configuration file enables repeating",
        "start": 637.8,
        "duration": 2.9
    },
    {
        "text": "an experiment over and over",
        "start": 640.7,
        "duration": 1.68
    },
    {
        "text": "if you'd like in a consistent way.",
        "start": 642.38,
        "duration": 2.19
    },
    {
        "text": "So, that says what script do",
        "start": 644.57,
        "duration": 2.11
    },
    {
        "text": "you want to run as your primary script.",
        "start": 646.68,
        "duration": 2.005
    },
    {
        "text": "What parameters do you want to",
        "start": 648.685,
        "duration": 1.525
    },
    {
        "text": "run and that sort of thing.",
        "start": 650.21,
        "duration": 2.195
    },
    {
        "text": "So, you can just simply right-click you",
        "start": 652.405,
        "duration": 2.155
    },
    {
        "text": "can create your \"Run Configuration\" file,",
        "start": 654.56,
        "duration": 2.25
    },
    {
        "text": "and you can again see that down here",
        "start": 656.81,
        "duration": 2.055
    },
    {
        "text": "we have multiple \"Run Configuration\" files.",
        "start": 658.865,
        "duration": 2.28
    },
    {
        "text": ">> Okay. So, let me see if I understand, this went fast.",
        "start": 661.145,
        "duration": 2.635
    },
    {
        "text": "So, when you're looking at your local folder",
        "start": 663.78,
        "duration": 2.0
    },
    {
        "text": "that now you've attached to an experiment.",
        "start": 665.78,
        "duration": 2.03
    },
    {
        "text": ">> Yeah.",
        "start": 667.81,
        "duration": 0.64
    },
    {
        "text": ">> There are \"Run Configurations\" that allow you to",
        "start": 668.45,
        "duration": 2.79
    },
    {
        "text": "submit jobs to the GPU cluster.",
        "start": 671.24,
        "duration": 3.095
    },
    {
        "text": ">> That's right.",
        "start": 674.335,
        "duration": 0.44
    },
    {
        "text": ">> I'm seeing two other ones there; Docker and local.",
        "start": 674.775,
        "duration": 2.87
    },
    {
        "text": "Are those just \"Run Configurations\"",
        "start": 677.645,
        "duration": 1.545
    },
    {
        "text": "that exists by default?",
        "start": 679.19,
        "duration": 1.145
    },
    {
        "text": ">> That's right. So as soon as I attach",
        "start": 680.335,
        "duration": 2.705
    },
    {
        "text": "my folder to the experiment,",
        "start": 683.04,
        "duration": 2.395
    },
    {
        "text": "then VS Code will automatically",
        "start": 685.435,
        "duration": 2.094
    },
    {
        "text": "create these two \"Run Configurations\"",
        "start": 687.529,
        "duration": 1.916
    },
    {
        "text": "for you and set",
        "start": 689.445,
        "duration": 2.075
    },
    {
        "text": "up all the default settings automatically.",
        "start": 691.52,
        "duration": 2.585
    },
    {
        "text": ">> All right.",
        "start": 694.105,
        "duration": 0.285
    },
    {
        "text": "So, let's see if I can summarize what we've learned.",
        "start": 694.39,
        "duration": 1.94
    },
    {
        "text": "So, the first thing is we looked",
        "start": 696.33,
        "duration": 1.1
    },
    {
        "text": "at the Azure Portal and what",
        "start": 697.43,
        "duration": 1.16
    },
    {
        "text": "an Azure Machine Learning Service Workspace was.",
        "start": 698.59,
        "duration": 3.24
    },
    {
        "text": "It's a configuration where you can have",
        "start": 701.83,
        "duration": 2.065
    },
    {
        "text": "a bunch of people",
        "start": 703.895,
        "duration": 0.645
    },
    {
        "text": "collaborating and have a bunch of assets,",
        "start": 704.54,
        "duration": 1.71
    },
    {
        "text": "it's your AI toolbox for machine learning.",
        "start": 706.25,
        "duration": 2.53
    },
    {
        "text": ">> That's right.",
        "start": 708.78,
        "duration": 0.535
    },
    {
        "text": ">> The second thing we looked at is",
        "start": 709.315,
        "duration": 1.69
    },
    {
        "text": "Visual Studio Code Tools for AI that lets",
        "start": 711.005,
        "duration": 2.775
    },
    {
        "text": "you run notebooks within",
        "start": 713.78,
        "duration": 1.53
    },
    {
        "text": "the context that you know and you love.",
        "start": 715.31,
        "duration": 3.155
    },
    {
        "text": "You can run Azure Notebook or not,",
        "start": 718.465,
        "duration": 1.905
    },
    {
        "text": "I keep saying Azure Notebooks because we",
        "start": 720.37,
        "duration": 1.32
    },
    {
        "text": "have an Azure version of Jupyter Notebooks.",
        "start": 721.69,
        "duration": 3.26
    },
    {
        "text": ">> They're so easy to use in Azure Notebooks,",
        "start": 724.95,
        "duration": 1.76
    },
    {
        "text": "they've become synonymous for you.",
        "start": 726.71,
        "duration": 1.52
    },
    {
        "text": ">> So, Jupyter Notebooks, you can run it",
        "start": 728.23,
        "duration": 1.45
    },
    {
        "text": "in there and then test your code.",
        "start": 729.68,
        "duration": 1.56
    },
    {
        "text": "Then you can move it into",
        "start": 731.24,
        "duration": 1.59
    },
    {
        "text": "regular Python files that you tend to run and you can",
        "start": 732.83,
        "duration": 3.3
    },
    {
        "text": "submit them into",
        "start": 736.13,
        "duration": 1.125
    },
    {
        "text": "the TeamWorkspace experimentation service by targeting",
        "start": 737.255,
        "duration": 3.36
    },
    {
        "text": "different compute clusters or",
        "start": 740.615,
        "duration": 3.69
    },
    {
        "text": "where the Run Configs will",
        "start": 744.305,
        "duration": 0.995
    },
    {
        "text": "tell you how you want to submit them.",
        "start": 745.3,
        "duration": 1.2
    },
    {
        "text": ">> Or you can even just run them on",
        "start": 746.5,
        "duration": 1.48
    },
    {
        "text": "your local machine and log the metrics to Azure as well.",
        "start": 747.98,
        "duration": 3.085
    },
    {
        "text": ">> Awesome.",
        "start": 751.065,
        "duration": 0.555
    },
    {
        "text": ">> So, you can experiment quickly,",
        "start": 751.62,
        "duration": 1.365
    },
    {
        "text": "step through and debug on your local machine,",
        "start": 752.985,
        "duration": 2.26
    },
    {
        "text": "make super productive in Visual Studio Code.",
        "start": 755.245,
        "duration": 2.475
    },
    {
        "text": ">> So, it was awesome, I feel like I want to",
        "start": 757.72,
        "duration": 1.58
    },
    {
        "text": "still go through an actual example of it.",
        "start": 759.3,
        "duration": 2.66
    },
    {
        "text": "But I feel like this is a super good overview of what",
        "start": 761.96,
        "duration": 2.34
    },
    {
        "text": "AI Developers can do on Azure and Visual Studio Code.",
        "start": 764.3,
        "duration": 3.44
    },
    {
        "text": ">> Yeah, absolutely.",
        "start": 767.74,
        "duration": 1.045
    },
    {
        "text": ">> Well, thanks so much for spending some time with us.",
        "start": 768.785,
        "duration": 1.745
    },
    {
        "text": "Thanks so much for watching,",
        "start": 770.53,
        "duration": 1.48
    },
    {
        "text": "and we'll see you next time, take care.",
        "start": 772.01,
        "duration": 2.38
    }
]