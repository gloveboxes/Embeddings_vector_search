[
    {
        "text": ">> On the special build edition of the AI Show,",
        "start": 1.31,
        "duration": 3.205
    },
    {
        "text": "learn more about the differential privacy research",
        "start": 4.515,
        "duration": 2.925
    },
    {
        "text": "that powers White Noise from Salil Vadhan,",
        "start": 7.44,
        "duration": 2.805
    },
    {
        "text": "leader of the Privacy Tools Project",
        "start": 10.245,
        "duration": 2.55
    },
    {
        "text": "at Harvard University. Make sure you tune in.",
        "start": 12.795,
        "duration": 2.745
    },
    {
        "text": "[MUSIC].",
        "start": 15.54,
        "duration": 8.55
    },
    {
        "text": ">> Hello. I'm Salil Vadhan,",
        "start": 24.09,
        "duration": 2.175
    },
    {
        "text": "a computer science faculty member at Harvard University.",
        "start": 26.265,
        "duration": 2.85
    },
    {
        "text": "I'm excited to tell you about differential privacy, White Noise,",
        "start": 29.115,
        "duration": 3.885
    },
    {
        "text": "the system we are building in collaboration with Microsoft,",
        "start": 33.0,
        "duration": 2.505
    },
    {
        "text": "and OpenDP, the larger",
        "start": 35.505,
        "duration": 2.07
    },
    {
        "text": "open source community effort it is feeding into.",
        "start": 37.575,
        "duration": 2.995
    },
    {
        "text": "Before jumping into the science,",
        "start": 40.57,
        "duration": 2.23
    },
    {
        "text": "I'd like to mention that my own start",
        "start": 42.8,
        "duration": 1.59
    },
    {
        "text": "in differential privacy came with",
        "start": 44.39,
        "duration": 1.5
    },
    {
        "text": "two wonderful visits to the Microsoft Research Silicon Valley lab.",
        "start": 45.89,
        "duration": 3.845
    },
    {
        "text": "With just two months in 2008,",
        "start": 49.735,
        "duration": 2.555
    },
    {
        "text": "my collaborations with Microsoft researchers,",
        "start": 52.29,
        "duration": 2.12
    },
    {
        "text": "Cynthia Dwork and others led,",
        "start": 54.41,
        "duration": 1.74
    },
    {
        "text": "to my first four papers on differential privacy,",
        "start": 56.15,
        "duration": 2.41
    },
    {
        "text": "a topic which I am still working on to this day.",
        "start": 58.56,
        "duration": 3.085
    },
    {
        "text": "What is the motivation for differential privacy?",
        "start": 61.645,
        "duration": 2.995
    },
    {
        "text": "It was the realization that",
        "start": 64.64,
        "duration": 1.68
    },
    {
        "text": "the publication of what seems to be even innocuous,",
        "start": 66.32,
        "duration": 2.85
    },
    {
        "text": "aggregate statistics can lead to severe privacy risks.",
        "start": 69.17,
        "duration": 4.02
    },
    {
        "text": "What do we mean by aggregate statistics?",
        "start": 73.19,
        "duration": 3.195
    },
    {
        "text": "These can be publications of",
        "start": 76.385,
        "duration": 1.635
    },
    {
        "text": "statistical tables as done by government agencies,",
        "start": 78.02,
        "duration": 3.11
    },
    {
        "text": "like the Census Bureau,",
        "start": 81.13,
        "duration": 1.405
    },
    {
        "text": "the releasing of trained machine learning models",
        "start": 82.535,
        "duration": 2.925
    },
    {
        "text": "as done by tech companies,",
        "start": 85.46,
        "duration": 1.79
    },
    {
        "text": "and it can also include interactive query systems,",
        "start": 87.25,
        "duration": 2.8
    },
    {
        "text": "where analysts can present queries of their own,",
        "start": 90.05,
        "duration": 2.19
    },
    {
        "text": "like a regression they'd like to run and get back results.",
        "start": 92.24,
        "duration": 2.97
    },
    {
        "text": "Such query systems are often used in practice,",
        "start": 95.21,
        "duration": 2.954
    },
    {
        "text": "and hope that not giving analyst",
        "start": 98.164,
        "duration": 1.606
    },
    {
        "text": "direct access to sensitive data will protect privacy.",
        "start": 99.77,
        "duration": 3.78
    },
    {
        "text": "However, we now know that we have to be very careful,",
        "start": 103.55,
        "duration": 5.085
    },
    {
        "text": "even with statistical aggregates.",
        "start": 108.635,
        "duration": 2.57
    },
    {
        "text": "In the early 2000s,",
        "start": 111.205,
        "duration": 1.684
    },
    {
        "text": "Dinur and Nissim proved a mathematical theorem saying that",
        "start": 112.889,
        "duration": 3.231
    },
    {
        "text": "the publication of too many accurate aggregate statistics,",
        "start": 116.12,
        "duration": 3.72
    },
    {
        "text": "each one just a simple random count,",
        "start": 119.84,
        "duration": 3.015
    },
    {
        "text": "allows an adversary to reconstruct",
        "start": 122.855,
        "duration": 2.22
    },
    {
        "text": "almost the entire underlying sensitive dataset.",
        "start": 125.075,
        "duration": 3.345
    },
    {
        "text": "The US Census Bureau internally applied a form of this attack",
        "start": 128.42,
        "duration": 3.885
    },
    {
        "text": "to the billions of statistics they released from the 2010 census,",
        "start": 132.305,
        "duration": 3.765
    },
    {
        "text": "and discovered that they could reconstruct and",
        "start": 136.07,
        "duration": 2.67
    },
    {
        "text": "re-identify a significant fraction",
        "start": 138.74,
        "duration": 2.04
    },
    {
        "text": "of responses from individual households,",
        "start": 140.78,
        "duration": 2.13
    },
    {
        "text": "motivating them to modernize",
        "start": 142.91,
        "duration": 1.86
    },
    {
        "text": "their disclosure limitation methods and adopt",
        "start": 144.77,
        "duration": 2.175
    },
    {
        "text": "differential privacy for the 2020 census.",
        "start": 146.945,
        "duration": 3.08
    },
    {
        "text": "Related vulnerabilities have been found for",
        "start": 150.025,
        "duration": 2.485
    },
    {
        "text": "genetic data and machine learning models.",
        "start": 152.51,
        "duration": 2.37
    },
    {
        "text": "To hammer this point home with",
        "start": 154.88,
        "duration": 1.53
    },
    {
        "text": "a concrete example, a couple of years ago,",
        "start": 156.41,
        "duration": 2.76
    },
    {
        "text": "Reddit users discover that if you entered",
        "start": 159.17,
        "duration": 1.68
    },
    {
        "text": "nonsense into Google translate,",
        "start": 160.85,
        "duration": 2.01
    },
    {
        "text": "it would start spitting out passages from the Bible verbatim.",
        "start": 162.86,
        "duration": 4.325
    },
    {
        "text": "Why did this happen? It turns out that the millions",
        "start": 167.185,
        "duration": 3.565
    },
    {
        "text": "of parameters in the deep neural net doing translation,",
        "start": 170.75,
        "duration": 3.06
    },
    {
        "text": "which again seem like statistics",
        "start": 173.81,
        "duration": 1.889
    },
    {
        "text": "aggregated over huge training dataset,",
        "start": 175.699,
        "duration": 2.911
    },
    {
        "text": "had inadvertently memorized some of the training examples.",
        "start": 178.61,
        "duration": 3.705
    },
    {
        "text": "Now this may not be so worrisome",
        "start": 182.315,
        "duration": 1.935
    },
    {
        "text": "when it's passages from the Bible,",
        "start": 184.25,
        "duration": 1.665
    },
    {
        "text": "but imagine a system trained on e-mails,",
        "start": 185.915,
        "duration": 2.955
    },
    {
        "text": "or personal images, or medical data.",
        "start": 188.87,
        "duration": 2.75
    },
    {
        "text": "What's the message from all this?",
        "start": 191.62,
        "duration": 2.33
    },
    {
        "text": "It's not that all statistical releases are always dangerous,",
        "start": 193.95,
        "duration": 3.77
    },
    {
        "text": "but rather we need a quantitative to theory",
        "start": 197.72,
        "duration": 2.28
    },
    {
        "text": "to tell us how much is too much.",
        "start": 200.0,
        "duration": 3.05
    },
    {
        "text": "How to ensure that we are not publishing",
        "start": 203.05,
        "duration": 2.515
    },
    {
        "text": "too much statistical information too accurately,",
        "start": 205.565,
        "duration": 2.519
    },
    {
        "text": "and be sure that it can't be combined to yield such attacks?",
        "start": 208.084,
        "duration": 3.316
    },
    {
        "text": "Differential privacy offer such a quantitative theory.",
        "start": 211.4,
        "duration": 4.51
    },
    {
        "text": "In doing so, it aims to allow statistical analysis,",
        "start": 216.22,
        "duration": 4.134
    },
    {
        "text": "such as drawing inferences about",
        "start": 220.354,
        "duration": 2.026
    },
    {
        "text": "a population from which a dataset is drawn,",
        "start": 222.38,
        "duration": 2.25
    },
    {
        "text": "training machine learning models that generalize,",
        "start": 224.63,
        "duration": 2.7
    },
    {
        "text": "while mathematically ensuring that",
        "start": 227.33,
        "duration": 2.235
    },
    {
        "text": "individual level data is not leaked,",
        "start": 229.565,
        "duration": 2.355
    },
    {
        "text": "no matter what attack strategy is used by an adversary and",
        "start": 231.92,
        "duration": 3.15
    },
    {
        "text": "what kind of auxiliary information an adversary has in hand.",
        "start": 235.07,
        "duration": 4.69
    },
    {
        "text": "How is differential privacy achieved?",
        "start": 240.16,
        "duration": 3.68
    },
    {
        "text": "It is achieved by injecting small amounts of random noise into",
        "start": 243.88,
        "duration": 6.43
    },
    {
        "text": "statistical computations to obscure the effect of each",
        "start": 250.31,
        "duration": 3.15
    },
    {
        "text": "individual while still allowing",
        "start": 253.46,
        "duration": 2.07
    },
    {
        "text": "useful statistical signal to come through.",
        "start": 255.53,
        "duration": 2.855
    },
    {
        "text": "In a bit more detail,",
        "start": 258.385,
        "duration": 2.479
    },
    {
        "text": "differential privacy requires that even if",
        "start": 260.864,
        "duration": 2.646
    },
    {
        "text": "an adversary is interacting with the system,",
        "start": 263.51,
        "duration": 2.73
    },
    {
        "text": "choosing queries to try to learn",
        "start": 266.24,
        "duration": 2.16
    },
    {
        "text": "about a specific individual in the dataset,",
        "start": 268.4,
        "duration": 2.52
    },
    {
        "text": "what it sees should be essentially the same",
        "start": 270.92,
        "duration": 2.82
    },
    {
        "text": "as if we had removed that individual's data",
        "start": 273.74,
        "duration": 3.18
    },
    {
        "text": "from the dataset and replaced it with arbitrary other values.",
        "start": 276.92,
        "duration": 7.45
    },
    {
        "text": "More precisely, for any two dataset,",
        "start": 286.97,
        "duration": 4.905
    },
    {
        "text": "these datasets that differ on one individual's data,",
        "start": 291.875,
        "duration": 2.945
    },
    {
        "text": "like a dataset with your data in it",
        "start": 294.82,
        "duration": 1.965
    },
    {
        "text": "and one with your data removed or modified,",
        "start": 296.785,
        "duration": 2.879
    },
    {
        "text": "the probability distribution of results seen",
        "start": 299.664,
        "duration": 2.146
    },
    {
        "text": "by the adversary should be essentially the same.",
        "start": 301.81,
        "duration": 2.59
    },
    {
        "text": "How close these probability distributions are is",
        "start": 304.4,
        "duration": 3.71
    },
    {
        "text": "given by what's called the privacy loss",
        "start": 308.11,
        "duration": 1.62
    },
    {
        "text": "parameter, often denoted epsilon.",
        "start": 309.73,
        "duration": 2.335
    },
    {
        "text": "The smaller epsilon is,",
        "start": 312.065,
        "duration": 1.565
    },
    {
        "text": "the greater the level of privacy protection and",
        "start": 313.63,
        "duration": 1.92
    },
    {
        "text": "hence the greater amount of noise that needs to be introduced.",
        "start": 315.55,
        "duration": 2.67
    },
    {
        "text": "This is the sense in which",
        "start": 318.22,
        "duration": 1.545
    },
    {
        "text": "differential privacy offers a quantitative theory of privacy.",
        "start": 319.765,
        "duration": 4.165
    },
    {
        "text": "I don't have time to tell you about how",
        "start": 323.94,
        "duration": 2.62
    },
    {
        "text": "differentially private algorithms are constructed,",
        "start": 326.56,
        "duration": 1.92
    },
    {
        "text": "which can be quite sophisticated.",
        "start": 328.48,
        "duration": 1.61
    },
    {
        "text": "But already as a six years ago,",
        "start": 330.09,
        "duration": 2.015
    },
    {
        "text": "there was a wide theoretical literature showing that many data",
        "start": 332.105,
        "duration": 2.745
    },
    {
        "text": "analysis tasks can be done in a differentially private manner,",
        "start": 334.85,
        "duration": 2.97
    },
    {
        "text": "and this has only exploded since then.",
        "start": 337.82,
        "duration": 2.57
    },
    {
        "text": "There are also some remarkably general theorems,",
        "start": 340.39,
        "duration": 3.2
    },
    {
        "text": "saying a very wide range of statistical estimation and machine",
        "start": 343.59,
        "duration": 3.62
    },
    {
        "text": "learning problems can be done with",
        "start": 347.21,
        "duration": 2.4
    },
    {
        "text": "almost no asymptotic cost for differential privacy.",
        "start": 349.61,
        "duration": 3.29
    },
    {
        "text": "That is, the amount of error due to",
        "start": 352.9,
        "duration": 2.17
    },
    {
        "text": "the noise introduced for privacy vanishes",
        "start": 355.07,
        "duration": 2.01
    },
    {
        "text": "more quickly than the sampling error",
        "start": 357.08,
        "duration": 2.22
    },
    {
        "text": "as the size of your dataset grows.",
        "start": 359.3,
        "duration": 2.775
    },
    {
        "text": "Another amazing theoretical possibility is that of generating",
        "start": 362.075,
        "duration": 3.945
    },
    {
        "text": "rich synthetic data with differential privacy.",
        "start": 366.02,
        "duration": 3.38
    },
    {
        "text": "That is, publishing a dataset consisting of",
        "start": 369.4,
        "duration": 3.07
    },
    {
        "text": "artificially constructed records that preserve",
        "start": 372.47,
        "duration": 3.54
    },
    {
        "text": "an exponentially large collection of",
        "start": 376.01,
        "duration": 1.92
    },
    {
        "text": "statistical properties of the original dataset,",
        "start": 377.93,
        "duration": 2.295
    },
    {
        "text": "yet does not leak",
        "start": 380.225,
        "duration": 1.755
    },
    {
        "text": "noticeable information about any individual record",
        "start": 381.98,
        "duration": 2.49
    },
    {
        "text": "from the sensitive data.",
        "start": 384.47,
        "duration": 1.91
    },
    {
        "text": "There remain significant challenges to make",
        "start": 386.38,
        "duration": 3.97
    },
    {
        "text": "these remarkable theoretical results",
        "start": 390.35,
        "duration": 1.74
    },
    {
        "text": "on this in the previous slide practical.",
        "start": 392.09,
        "duration": 1.905
    },
    {
        "text": "But they tell us that there is a lot",
        "start": 393.995,
        "duration": 1.605
    },
    {
        "text": "we can hope for from differential privacy.",
        "start": 395.6,
        "duration": 2.56
    },
    {
        "text": "Beyond all of this beautiful theory,",
        "start": 398.68,
        "duration": 2.755
    },
    {
        "text": "we have also seen a number of",
        "start": 401.435,
        "duration": 1.665
    },
    {
        "text": "exciting practical deployments of",
        "start": 403.1,
        "duration": 1.65
    },
    {
        "text": "differential privacy in recent years.",
        "start": 404.75,
        "duration": 1.905
    },
    {
        "text": "This includes the landmark decision by",
        "start": 406.655,
        "duration": 2.175
    },
    {
        "text": "the US Census Bureau, that I mentioned earlier,",
        "start": 408.83,
        "duration": 1.95
    },
    {
        "text": "to use differential privacy for the 2020 census,",
        "start": 410.78,
        "duration": 2.73
    },
    {
        "text": "as well as a number of deployments by large tech companies.",
        "start": 413.51,
        "duration": 3.82
    },
    {
        "text": "All of these, however, are organizations with lots of",
        "start": 417.37,
        "duration": 3.31
    },
    {
        "text": "in-house technical expertise to develop",
        "start": 420.68,
        "duration": 1.95
    },
    {
        "text": "their own customized differential privacy solutions.",
        "start": 422.63,
        "duration": 2.67
    },
    {
        "text": "So a goal of the work we are doing and our collaboration with",
        "start": 425.3,
        "duration": 2.97
    },
    {
        "text": "Microsoft is to enable wider adoption of differential privacy.",
        "start": 428.27,
        "duration": 4.54
    },
    {
        "text": "There are a number of challenges to achieving this,",
        "start": 432.91,
        "duration": 2.995
    },
    {
        "text": "and our efforts address a number of them.",
        "start": 435.905,
        "duration": 2.525
    },
    {
        "text": "We've been working towards this at Harvard in",
        "start": 438.43,
        "duration": 2.44
    },
    {
        "text": "our interdisciplinary Privacy Tools Project since 2012,",
        "start": 440.87,
        "duration": 3.975
    },
    {
        "text": "and we're excited to now be working with Microsoft",
        "start": 444.845,
        "duration": 2.624
    },
    {
        "text": "on the White Noise system that is designed to",
        "start": 447.469,
        "duration": 2.341
    },
    {
        "text": "be an end-to-end system that can allow",
        "start": 449.81,
        "duration": 2.07
    },
    {
        "text": "non-experts to make effective use of differential privacy.",
        "start": 451.88,
        "duration": 3.39
    },
    {
        "text": "We're also building on this experience to launch",
        "start": 455.27,
        "duration": 3.0
    },
    {
        "text": "a larger community open source software project",
        "start": 458.27,
        "duration": 2.61
    },
    {
        "text": "in differential privacy called OpenDP,",
        "start": 460.88,
        "duration": 2.375
    },
    {
        "text": "in which collaborations between",
        "start": 463.255,
        "duration": 1.495
    },
    {
        "text": "academia and industry can bring ideas from",
        "start": 464.75,
        "duration": 2.25
    },
    {
        "text": "the research literature into",
        "start": 467.0,
        "duration": 1.35
    },
    {
        "text": "production quality software that can be used by all.",
        "start": 468.35,
        "duration": 3.255
    },
    {
        "text": "One use case, which has been a driver for our efforts at Harvard,",
        "start": 471.605,
        "duration": 4.175
    },
    {
        "text": "is the incorporation of",
        "start": 475.78,
        "duration": 1.09
    },
    {
        "text": "differential privacy into data repositories,",
        "start": 476.87,
        "duration": 2.775
    },
    {
        "text": "such as the Dataverse software that",
        "start": 479.645,
        "duration": 1.98
    },
    {
        "text": "others on our Harvard team have built and is used by",
        "start": 481.625,
        "duration": 2.175
    },
    {
        "text": "social scientists and researchers around",
        "start": 483.8,
        "duration": 1.77
    },
    {
        "text": "the world to share their datasets with others to verify,",
        "start": 485.57,
        "duration": 3.33
    },
    {
        "text": "replicate, and extend their findings.",
        "start": 488.9,
        "duration": 2.66
    },
    {
        "text": "Unfortunately, today,",
        "start": 491.56,
        "duration": 2.625
    },
    {
        "text": "most data repositories are not",
        "start": 494.185,
        "duration": 1.6
    },
    {
        "text": "equipped to take on privacy sensitive data,",
        "start": 495.785,
        "duration": 2.04
    },
    {
        "text": "and when they do, it is not made available for download.",
        "start": 497.825,
        "duration": 2.805
    },
    {
        "text": "The only way to get access to",
        "start": 500.63,
        "duration": 3.52
    },
    {
        "text": "such data is through a manual application and approval process,",
        "start": 504.15,
        "duration": 4.415
    },
    {
        "text": "which can take months of negotiation between institutions.",
        "start": 508.565,
        "duration": 2.67
    },
    {
        "text": "Our goal is to enable wider sharing of",
        "start": 511.235,
        "duration": 2.355
    },
    {
        "text": "sensitive data while providing strong protections of privacy.",
        "start": 513.59,
        "duration": 3.375
    },
    {
        "text": "We plan for a future version of White Noise to have",
        "start": 516.965,
        "duration": 3.015
    },
    {
        "text": "a simple graphical user interface",
        "start": 519.98,
        "duration": 1.74
    },
    {
        "text": "that a researcher coming to deposit data",
        "start": 521.72,
        "duration": 1.845
    },
    {
        "text": "in a Dataverse repository can use to release",
        "start": 523.565,
        "duration": 3.855
    },
    {
        "text": "differentially private statistics about their dataset",
        "start": 527.42,
        "duration": 2.235
    },
    {
        "text": "without having any prior expertise in differential privacy.",
        "start": 529.655,
        "duration": 3.32
    },
    {
        "text": "Then another researcher can come, explore these releases,",
        "start": 532.975,
        "duration": 3.46
    },
    {
        "text": "including the uncertainty coming",
        "start": 536.435,
        "duration": 1.785
    },
    {
        "text": "from the noise introduced for privacy,",
        "start": 538.22,
        "duration": 1.71
    },
    {
        "text": "as well as make queries of their own.",
        "start": 539.93,
        "duration": 2.62
    },
    {
        "text": "To summarize, statistical releases do carry real privacy risks,",
        "start": 543.16,
        "duration": 4.765
    },
    {
        "text": "and differential privacy provides",
        "start": 547.925,
        "duration": 1.515
    },
    {
        "text": "the only principled way we know for avoiding them.",
        "start": 549.44,
        "duration": 2.82
    },
    {
        "text": "There is a rapidly advancing science of",
        "start": 552.26,
        "duration": 2.04
    },
    {
        "text": "how to get increased utility with differentially private releases,",
        "start": 554.3,
        "duration": 3.42
    },
    {
        "text": "and we are all working together to turn",
        "start": 557.72,
        "duration": 1.92
    },
    {
        "text": "this science into software. Thank you.",
        "start": 559.64,
        "duration": 2.71
    },
    {
        "text": "[MUSIC].",
        "start": 562.35,
        "duration": 12.34
    }
]