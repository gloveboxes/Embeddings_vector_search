[
    {
        "text": ">> You're not going to want to miss this episode of the AI Show we",
        "start": 0.0,
        "duration": 2.55
    },
    {
        "text": "talk all about, MLOps v2.",
        "start": 2.55,
        "duration": 2.97
    },
    {
        "text": "Unifying MLOps at Microsoft,",
        "start": 5.52,
        "duration": 1.86
    },
    {
        "text": "make sure you tune in.",
        "start": 7.38,
        "duration": 7.53
    },
    {
        "text": "[MUSIC]",
        "start": 14.91,
        "duration": 0.21
    },
    {
        "text": ">> Hello and welcome to this episode of the AI Show.",
        "start": 15.12,
        "duration": 2.05
    },
    {
        "text": "We're talking all about MLOps v2,",
        "start": 17.17,
        "duration": 1.98
    },
    {
        "text": "Unifying MLOps at Microsoft.",
        "start": 19.15,
        "duration": 3.0
    },
    {
        "text": "I have two special guests, Moe and Setu.",
        "start": 22.15,
        "duration": 3.195
    },
    {
        "text": "Hello, my friends. Why don't you",
        "start": 25.345,
        "duration": 1.515
    },
    {
        "text": "introduce yourselves? We'll start with you, Moe.",
        "start": 26.86,
        "duration": 1.96
    },
    {
        "text": ">> Hey, very good to be here. I'm very excited.",
        "start": 28.82,
        "duration": 3.05
    },
    {
        "text": "Moe Steller, I'm the Chief Architect and",
        "start": 31.87,
        "duration": 2.97
    },
    {
        "text": "main designer of the Solution Accelerator, MLOps v2.",
        "start": 34.84,
        "duration": 3.65
    },
    {
        "text": "Happy to be here. Setu.",
        "start": 38.49,
        "duration": 2.295
    },
    {
        "text": ">> Hi. This is Setu from warm and sunny Singapore.",
        "start": 40.785,
        "duration": 4.32
    },
    {
        "text": "I'm a colleague of Moe doing",
        "start": 45.105,
        "duration": 1.575
    },
    {
        "text": "the same MLOps piece and building up the solution architecture.",
        "start": 46.68,
        "duration": 3.575
    },
    {
        "text": ">> Fantastic. Here's the thing that I want to start with,",
        "start": 50.255,
        "duration": 3.065
    },
    {
        "text": "because we hear MLOps,",
        "start": 53.32,
        "duration": 1.785
    },
    {
        "text": "but sometimes it becomes a little confusing as",
        "start": 55.105,
        "duration": 2.385
    },
    {
        "text": "to exactly how we should think about it.",
        "start": 57.49,
        "duration": 3.1
    },
    {
        "text": "Moe, we'll start with you. Why don't you take us through how",
        "start": 60.59,
        "duration": 2.48
    },
    {
        "text": "one should think about MLOps?",
        "start": 63.07,
        "duration": 3.38
    },
    {
        "text": ">> How much time do I have?",
        "start": 66.45,
        "duration": 2.09
    },
    {
        "text": "That's the first question.",
        "start": 68.54,
        "duration": 2.13
    },
    {
        "text": "It's really a process of platform,",
        "start": 70.67,
        "duration": 3.885
    },
    {
        "text": "people and overall processes,",
        "start": 74.555,
        "duration": 2.51
    },
    {
        "text": "often organization essentially on",
        "start": 77.065,
        "duration": 2.565
    },
    {
        "text": "how to design a system that helps you to",
        "start": 79.63,
        "duration": 2.19
    },
    {
        "text": "operationalize MLOps models or",
        "start": 81.82,
        "duration": 2.82
    },
    {
        "text": "any type of artificial intelligence with a particular tool stack.",
        "start": 84.64,
        "duration": 2.91
    },
    {
        "text": "You see my sentences are already very long and very convoluted.",
        "start": 87.55,
        "duration": 3.225
    },
    {
        "text": "That's the main challenge really with MLOps, why,",
        "start": 90.775,
        "duration": 2.925
    },
    {
        "text": "it is like an unsolved field,",
        "start": 93.7,
        "duration": 2.33
    },
    {
        "text": "everybody talks about it but then there is",
        "start": 96.03,
        "duration": 1.84
    },
    {
        "text": "something new every month that comes out.",
        "start": 97.87,
        "duration": 2.445
    },
    {
        "text": "Today we are here to give you a solution,",
        "start": 100.315,
        "duration": 3.255
    },
    {
        "text": "essentially, that helps you to solve this really hard problem.",
        "start": 103.57,
        "duration": 3.37
    },
    {
        "text": ">> Awesome. Well, do you have something to show us or something",
        "start": 106.94,
        "duration": 2.9
    },
    {
        "text": "to get our frame of mind in the right way?",
        "start": 109.84,
        "duration": 3.225
    },
    {
        "text": ">> Of course. What we are talking about today is MLOps v2.",
        "start": 113.065,
        "duration": 6.0
    },
    {
        "text": "I'm here with Setu,",
        "start": 119.065,
        "duration": 1.945
    },
    {
        "text": "who really helped form",
        "start": 121.01,
        "duration": 2.055
    },
    {
        "text": "a development standpoint to support this effort.",
        "start": 123.065,
        "duration": 3.5
    },
    {
        "text": "We're two of the heroes, basically,",
        "start": 126.565,
        "duration": 2.235
    },
    {
        "text": "that are going to introduce the solution accelerator to you.",
        "start": 128.8,
        "duration": 3.66
    },
    {
        "text": "How I'm thinking about what we can cover",
        "start": 132.46,
        "duration": 2.4
    },
    {
        "text": "over the next couple of minutes is",
        "start": 134.86,
        "duration": 2.97
    },
    {
        "text": "talking about what fundamentally MLOps",
        "start": 137.83,
        "duration": 2.85
    },
    {
        "text": "is and how it translates into these techniques,",
        "start": 140.68,
        "duration": 3.16
    },
    {
        "text": "basically that help you to enable MLOps at",
        "start": 143.84,
        "duration": 2.9
    },
    {
        "text": "scale in a modular and very secure way.",
        "start": 146.74,
        "duration": 3.205
    },
    {
        "text": "I put up a small definition of MLOps,",
        "start": 149.945,
        "duration": 3.545
    },
    {
        "text": "how Microsoft defines MLOps.",
        "start": 153.49,
        "duration": 2.505
    },
    {
        "text": "There are certain types of variations out there and I don't want",
        "start": 155.995,
        "duration": 3.345
    },
    {
        "text": "you to get hung up on this particular definition.",
        "start": 159.34,
        "duration": 3.585
    },
    {
        "text": "This is a definition that helps you to",
        "start": 162.925,
        "duration": 2.91
    },
    {
        "text": "enable and really define MLOps in your organizations.",
        "start": 165.835,
        "duration": 4.56
    },
    {
        "text": "But if you're working in a particular industry for example,",
        "start": 170.395,
        "duration": 3.315
    },
    {
        "text": "the definition can look a little bit different,",
        "start": 173.71,
        "duration": 1.83
    },
    {
        "text": "and that's what makes it really so hard.",
        "start": 175.54,
        "duration": 1.835
    },
    {
        "text": "Everybody has a slightly different understanding of it, but again,",
        "start": 177.375,
        "duration": 3.97
    },
    {
        "text": "this is the view of how we are interpreting it with",
        "start": 181.345,
        "duration": 3.825
    },
    {
        "text": "our tool and our solution accelerator that we have built,",
        "start": 185.17,
        "duration": 4.215
    },
    {
        "text": "Unifying MLOps at Microsoft.",
        "start": 189.385,
        "duration": 2.935
    },
    {
        "text": ">> Awesome.",
        "start": 192.32,
        "duration": 2.0
    },
    {
        "text": ">> If you're looking,",
        "start": 194.45,
        "duration": 2.439
    },
    {
        "text": "so to speak at the state of the MLOps.",
        "start": 196.889,
        "duration": 3.391
    },
    {
        "text": "We have these five big areas",
        "start": 200.28,
        "duration": 3.475
    },
    {
        "text": "available and they're really concepts in itself.",
        "start": 203.755,
        "duration": 4.785
    },
    {
        "text": "You can already see that",
        "start": 208.54,
        "duration": 3.015
    },
    {
        "text": "in the train model piece and then the package model piece,",
        "start": 211.555,
        "duration": 3.69
    },
    {
        "text": "you probably see more like a data scientist type of persona,",
        "start": 215.245,
        "duration": 3.135
    },
    {
        "text": "maybe also in the validate model but when it comes to",
        "start": 218.38,
        "duration": 2.82
    },
    {
        "text": "deploy and the model monitoring other personas",
        "start": 221.2,
        "duration": 4.2
    },
    {
        "text": "such as an ML engineer or a DevOps engineer or whomever is",
        "start": 225.4,
        "duration": 3.63
    },
    {
        "text": "available depending on the size of",
        "start": 229.03,
        "duration": 1.65
    },
    {
        "text": "the company is really becoming important there.",
        "start": 230.68,
        "duration": 3.53
    },
    {
        "text": "You see that with this very simplification here that",
        "start": 234.21,
        "duration": 4.39
    },
    {
        "text": "many people actually take part within an MLOps process.",
        "start": 238.6,
        "duration": 5.545
    },
    {
        "text": "When we see these type of diagrams like this,",
        "start": 244.145,
        "duration": 3.17
    },
    {
        "text": "I just can say as a data scientist,",
        "start": 247.315,
        "duration": 2.815
    },
    {
        "text": "this is easier, I can do this all myself.",
        "start": 250.13,
        "duration": 2.645
    },
    {
        "text": "I write Python pipelines and I'm good to go.",
        "start": 252.775,
        "duration": 3.345
    },
    {
        "text": "But the really rude awakening is that this is",
        "start": 256.12,
        "duration": 3.21
    },
    {
        "text": "a hyper-complex process with many different tools,",
        "start": 259.33,
        "duration": 4.13
    },
    {
        "text": "CICD tools, standards and practices",
        "start": 263.46,
        "duration": 3.13
    },
    {
        "text": "basically that apply individually to each of these brackets.",
        "start": 266.59,
        "duration": 3.675
    },
    {
        "text": "Then overall automation tools that help me to",
        "start": 270.265,
        "duration": 3.555
    },
    {
        "text": "enable security and scalability of models.",
        "start": 273.82,
        "duration": 4.165
    },
    {
        "text": ">> That's cool. Like I said,",
        "start": 277.985,
        "duration": 3.235
    },
    {
        "text": "it's a process and it's cool that you're laying it out this way",
        "start": 281.22,
        "duration": 3.74
    },
    {
        "text": "because as a data scientist field-type guy,",
        "start": 284.96,
        "duration": 4.44
    },
    {
        "text": "I love the model part but that's not where",
        "start": 289.4,
        "duration": 2.68
    },
    {
        "text": "all the value is and you extracting it this way is pretty cool.",
        "start": 292.08,
        "duration": 3.93
    },
    {
        "text": ">> This is what I always going to say.",
        "start": 296.05,
        "duration": 2.485
    },
    {
        "text": "The modeling is the easy part and it's",
        "start": 298.535,
        "duration": 2.295
    },
    {
        "text": "the smallest percentage in the overall pipeline.",
        "start": 300.83,
        "duration": 2.96
    },
    {
        "text": "I like the modeling too because it's exciting,",
        "start": 303.79,
        "duration": 2.26
    },
    {
        "text": "you can dive into algorithms,",
        "start": 306.05,
        "duration": 1.815
    },
    {
        "text": "if all the nerdy talk going on.",
        "start": 307.865,
        "duration": 2.1
    },
    {
        "text": "But ruling the other I almost want to",
        "start": 309.965,
        "duration": 1.965
    },
    {
        "text": "say 90 percent of the work is",
        "start": 311.93,
        "duration": 1.995
    },
    {
        "text": "operationalization standards, practices, solutioning.",
        "start": 313.925,
        "duration": 5.29
    },
    {
        "text": "How does it fit in the enterprise architecture?",
        "start": 319.215,
        "duration": 2.285
    },
    {
        "text": "There are so many questions around this,",
        "start": 321.5,
        "duration": 2.07
    },
    {
        "text": "that can be very interesting but it's not really like this,",
        "start": 323.57,
        "duration": 4.0
    },
    {
        "text": "the sexy type of work essentially.",
        "start": 327.57,
        "duration": 1.88
    },
    {
        "text": ">> That makes sense.",
        "start": 329.45,
        "duration": 1.725
    },
    {
        "text": "Here's another question because I noticed",
        "start": 331.175,
        "duration": 2.985
    },
    {
        "text": "that in the title it's MLOps v2.",
        "start": 334.16,
        "duration": 3.635
    },
    {
        "text": "Can you explain the v2 part?",
        "start": 337.795,
        "duration": 2.53
    },
    {
        "text": "What are we talking about here?",
        "start": 340.325,
        "duration": 1.555
    },
    {
        "text": ">> Certainly. In the past in Microsoft,",
        "start": 341.88,
        "duration": 3.21
    },
    {
        "text": "we approach usually MLOps at scale and very different variations,",
        "start": 345.09,
        "duration": 4.74
    },
    {
        "text": "so many smart people had many really good ideas.",
        "start": 349.83,
        "duration": 3.21
    },
    {
        "text": "But sometimes if you talk, let's say,",
        "start": 353.04,
        "duration": 2.535
    },
    {
        "text": "to a healthcare customer and a retail customer,",
        "start": 355.575,
        "duration": 3.689
    },
    {
        "text": "the solution that was built for either or was not really a fit.",
        "start": 359.264,
        "duration": 3.106
    },
    {
        "text": "We understood that because of these variations of",
        "start": 362.37,
        "duration": 4.23
    },
    {
        "text": "technology stacks and also the variation of AI workloads.",
        "start": 366.6,
        "duration": 5.925
    },
    {
        "text": "What I mean by that is NLP, CB,",
        "start": 372.525,
        "duration": 2.205
    },
    {
        "text": "and classical ML,",
        "start": 374.73,
        "duration": 1.47
    },
    {
        "text": "we really needed a very modular solution essentially.",
        "start": 376.2,
        "duration": 3.915
    },
    {
        "text": "When we basically morphed from MLOps v1, you may say, hey too,",
        "start": 380.115,
        "duration": 5.025
    },
    {
        "text": "MLOps v2 and I don't want to make this a product term here,",
        "start": 385.14,
        "duration": 2.7
    },
    {
        "text": "more like a evolving state.",
        "start": 387.84,
        "duration": 2.72
    },
    {
        "text": "We were able to create an asset that can dynamically",
        "start": 390.56,
        "duration": 3.94
    },
    {
        "text": "create a system for you depending on your choices.",
        "start": 394.5,
        "duration": 4.395
    },
    {
        "text": "Think about a large Cartesian product where you decide,",
        "start": 398.895,
        "duration": 3.075
    },
    {
        "text": "I want this,",
        "start": 401.97,
        "duration": 2.25
    },
    {
        "text": "I throw it in the box and then you have a ship system.",
        "start": 404.22,
        "duration": 3.66
    },
    {
        "text": "That's the big new thing here.",
        "start": 407.88,
        "duration": 2.82
    },
    {
        "text": ">> Awesome. I love it.",
        "start": 410.7,
        "duration": 2.055
    },
    {
        "text": "Well, what else you got to show us, my friend?",
        "start": 412.755,
        "duration": 2.595
    },
    {
        "text": ">> I want to show you a little bit the value proposition of",
        "start": 415.35,
        "duration": 3.24
    },
    {
        "text": "what's going to happen within MLOps v2.",
        "start": 418.59,
        "duration": 3.525
    },
    {
        "text": "I always like to start off with something funny.",
        "start": 422.115,
        "duration": 4.605
    },
    {
        "text": "This cartoon actually looks like one of my dear colleagues.",
        "start": 426.72,
        "duration": 3.855
    },
    {
        "text": "I always like to show this,",
        "start": 430.575,
        "duration": 1.815
    },
    {
        "text": "and it really exemplifies the state of",
        "start": 432.39,
        "duration": 3.375
    },
    {
        "text": "MLOps of what's going on within this very complex system.",
        "start": 435.765,
        "duration": 4.035
    },
    {
        "text": "You run error messages,",
        "start": 439.8,
        "duration": 1.53
    },
    {
        "text": "it is a very tedious process to set up the automation of AI.",
        "start": 441.33,
        "duration": 5.745
    },
    {
        "text": "Also if you think about ISO impactful or can",
        "start": 447.075,
        "duration": 2.965
    },
    {
        "text": "make such hard decisions for humans that are in",
        "start": 450.04,
        "duration": 3.26
    },
    {
        "text": "the end need to be monitored and need to be",
        "start": 453.3,
        "duration": 3.93
    },
    {
        "text": "very closely watched by",
        "start": 457.23,
        "duration": 1.89
    },
    {
        "text": "business decision makers and technical decision makers.",
        "start": 459.12,
        "duration": 4.03
    },
    {
        "text": ">> Go ahead.",
        "start": 465.44,
        "duration": 1.66
    },
    {
        "text": ">> No. That makes total sense.",
        "start": 467.1,
        "duration": 2.025
    },
    {
        "text": "I was empathizing with the guy, that's like, wow,",
        "start": 469.125,
        "duration": 3.515
    },
    {
        "text": "I got a different error message because I have",
        "start": 472.64,
        "duration": 1.95
    },
    {
        "text": "been there as many of our viewers have as well.",
        "start": 474.59,
        "duration": 2.555
    },
    {
        "text": ">> Me too. It can be painful",
        "start": 477.145,
        "duration": 2.495
    },
    {
        "text": "but we're really trying to make this easier here.",
        "start": 479.64,
        "duration": 3.155
    },
    {
        "text": "This is the end goal that if you think about your data scientist,",
        "start": 482.795,
        "duration": 4.35
    },
    {
        "text": "you want to ship your product,",
        "start": 487.145,
        "duration": 1.815
    },
    {
        "text": "your model fast, you want to go fast to production essentially.",
        "start": 488.96,
        "duration": 3.3
    },
    {
        "text": "There's so much automation in between and",
        "start": 492.26,
        "duration": 1.83
    },
    {
        "text": "so much tedious work that we are",
        "start": 494.09,
        "duration": 1.86
    },
    {
        "text": "trying to take out of the equation,",
        "start": 495.95,
        "duration": 1.92
    },
    {
        "text": "so that you're happy as",
        "start": 497.87,
        "duration": 1.35
    },
    {
        "text": "a data scientist but also your product manager is happy,",
        "start": 499.22,
        "duration": 3.18
    },
    {
        "text": "the person that is responsible of getting the solution out.",
        "start": 502.4,
        "duration": 4.33
    },
    {
        "text": "We've identified different types of",
        "start": 507.17,
        "duration": 2.31
    },
    {
        "text": "challenges when we talk to customers.",
        "start": 509.48,
        "duration": 2.055
    },
    {
        "text": "One is roles and skills related.",
        "start": 511.535,
        "duration": 2.43
    },
    {
        "text": "You have many different personas in an enterprise.",
        "start": 513.965,
        "duration": 3.405
    },
    {
        "text": "I always like to say as larger the enterprise as",
        "start": 517.37,
        "duration": 3.66
    },
    {
        "text": "more role diversity you have",
        "start": 521.03,
        "duration": 1.815
    },
    {
        "text": "and is more specialized the tasks are.",
        "start": 522.845,
        "duration": 2.355
    },
    {
        "text": "The project really starts to blow up",
        "start": 525.2,
        "duration": 2.94
    },
    {
        "text": "essentially with whom works on an MLOps type of project.",
        "start": 528.14,
        "duration": 5.07
    },
    {
        "text": "Second, we have this tool variation.",
        "start": 533.21,
        "duration": 3.445
    },
    {
        "text": "An enterprise may have a studio or visual studio code,",
        "start": 536.655,
        "duration": 4.89
    },
    {
        "text": "certain type of machine learning services,",
        "start": 541.545,
        "duration": 1.925
    },
    {
        "text": "different CICD tools, container holds the tools and so forth.",
        "start": 543.47,
        "duration": 5.52
    },
    {
        "text": "It creates this huge tech stack",
        "start": 548.99,
        "duration": 2.22
    },
    {
        "text": "essentially that is sometimes even",
        "start": 551.21,
        "duration": 1.92
    },
    {
        "text": "different from department to department.",
        "start": 553.13,
        "duration": 2.415
    },
    {
        "text": "It is really hard to say,",
        "start": 555.545,
        "duration": 2.085
    },
    {
        "text": "I have developed one MLOps system and we're going to bring this to",
        "start": 557.63,
        "duration": 3.81
    },
    {
        "text": "my neighboring departments so they can",
        "start": 561.44,
        "duration": 1.86
    },
    {
        "text": "benefit from the same system.",
        "start": 563.3,
        "duration": 2.085
    },
    {
        "text": "Well, guess what?",
        "start": 565.385,
        "duration": 1.095
    },
    {
        "text": "They use a different tool and the work that has",
        "start": 566.48,
        "duration": 3.15
    },
    {
        "text": "been done over the last month is not really applicable.",
        "start": 569.63,
        "duration": 3.75
    },
    {
        "text": "Thirdly, we see that in artifacts and versioning,",
        "start": 573.38,
        "duration": 4.23
    },
    {
        "text": "often there are challenges around model registries",
        "start": 577.61,
        "duration": 3.044
    },
    {
        "text": "and really trying to understand how to tag models,",
        "start": 580.654,
        "duration": 3.286
    },
    {
        "text": "how they can be tagged and create metadata",
        "start": 583.94,
        "duration": 2.49
    },
    {
        "text": "so that people have insights in the model state,",
        "start": 586.43,
        "duration": 3.05
    },
    {
        "text": "and also how to define source code",
        "start": 589.48,
        "duration": 2.83
    },
    {
        "text": "that is resilient and secure for the future.",
        "start": 592.31,
        "duration": 3.95
    },
    {
        "text": "Lastly, when it comes to the development and production,",
        "start": 596.26,
        "duration": 4.209
    },
    {
        "text": "the goal is really to move fast to product.",
        "start": 600.469,
        "duration": 4.471
    },
    {
        "text": "Often data science projects are getting",
        "start": 604.94,
        "duration": 2.22
    },
    {
        "text": "stuck in this experimentation iteration,",
        "start": 607.16,
        "duration": 3.03
    },
    {
        "text": "which again is cool for",
        "start": 610.19,
        "duration": 1.02
    },
    {
        "text": "the data scientist because you learn a lot.",
        "start": 611.21,
        "duration": 1.92
    },
    {
        "text": "But in the end for a business,",
        "start": 613.13,
        "duration": 2.355
    },
    {
        "text": "essentially, the needs to make business decisions on AI,",
        "start": 615.485,
        "duration": 3.705
    },
    {
        "text": "they basically want to move fast to product and want to be",
        "start": 619.19,
        "duration": 3.96
    },
    {
        "text": "able to monitor these solutions in a sufficient way.",
        "start": 623.15,
        "duration": 4.78
    },
    {
        "text": ">> This is cool stuff.",
        "start": 630.06,
        "duration": 2.695
    },
    {
        "text": "These are clearly challenges that I've seen.",
        "start": 632.755,
        "duration": 2.985
    },
    {
        "text": "I'm working on a project just by myself,",
        "start": 635.74,
        "duration": 2.82
    },
    {
        "text": "and there's a lot of different choices",
        "start": 638.56,
        "duration": 1.71
    },
    {
        "text": "people can make just on their own.",
        "start": 640.27,
        "duration": 1.62
    },
    {
        "text": "Now, imagine all the other people that are involved too.",
        "start": 641.89,
        "duration": 2.745
    },
    {
        "text": ">> It is really complex.",
        "start": 644.635,
        "duration": 2.355
    },
    {
        "text": "I'm working with a couple of customers together here at Microsoft.",
        "start": 646.99,
        "duration": 3.405
    },
    {
        "text": "Those are really large global enterprises",
        "start": 650.395,
        "duration": 3.405
    },
    {
        "text": "and they are just seeking so hard for",
        "start": 653.8,
        "duration": 2.67
    },
    {
        "text": "a system that they can dynamically create and",
        "start": 656.47,
        "duration": 3.42
    },
    {
        "text": "apply worldwide to any type of Data Science Department they go.",
        "start": 659.89,
        "duration": 4.35
    },
    {
        "text": "Be it in Finance, be it in Marketing,",
        "start": 664.24,
        "duration": 2.07
    },
    {
        "text": "be it on the product side anywhere.",
        "start": 666.31,
        "duration": 2.82
    },
    {
        "text": "It is just a tough challenge.",
        "start": 669.13,
        "duration": 3.375
    },
    {
        "text": "What we have identified, essentially,",
        "start": 672.505,
        "duration": 3.03
    },
    {
        "text": "it really comes down to if you're",
        "start": 675.535,
        "duration": 1.845
    },
    {
        "text": "thinking from an MLOps centric perspective,",
        "start": 677.38,
        "duration": 2.55
    },
    {
        "text": "that you want to include",
        "start": 679.93,
        "duration": 1.29
    },
    {
        "text": "people and I can't highlight this point enough",
        "start": 681.22,
        "duration": 2.415
    },
    {
        "text": "because the people create",
        "start": 683.635,
        "duration": 1.905
    },
    {
        "text": "the product so why not include the people?",
        "start": 685.54,
        "duration": 2.94
    },
    {
        "text": "Why not include the process?",
        "start": 688.48,
        "duration": 1.83
    },
    {
        "text": "Everybody has their own particular process,",
        "start": 690.31,
        "duration": 2.475
    },
    {
        "text": "and it is very important to create",
        "start": 692.785,
        "duration": 2.805
    },
    {
        "text": "an agnostic system that can take on any type of process",
        "start": 695.59,
        "duration": 4.395
    },
    {
        "text": "and make it applicable back to the enterprise and the platform so",
        "start": 699.985,
        "duration": 4.725
    },
    {
        "text": "that you have two variations you",
        "start": 704.71,
        "duration": 2.28
    },
    {
        "text": "can pick from or different type of services,",
        "start": 706.99,
        "duration": 2.67
    },
    {
        "text": "so you have a very agile way of bringing",
        "start": 709.66,
        "duration": 2.82
    },
    {
        "text": "basically an MLOps system at scale to an enterprise.",
        "start": 712.48,
        "duration": 5.41
    },
    {
        "text": ">> Again, I have always been a fan of",
        "start": 718.17,
        "duration": 3.31
    },
    {
        "text": "the Union of the People process.",
        "start": 721.48,
        "duration": 2.43
    },
    {
        "text": "I say product, but platform is just equally the same you have.",
        "start": 723.91,
        "duration": 3.375
    },
    {
        "text": "If you don't have all three, it's not going to work.",
        "start": 727.285,
        "duration": 2.43
    },
    {
        "text": ">> I always like to say the three P's.",
        "start": 729.715,
        "duration": 2.25
    },
    {
        "text": "I'm not trying to market a new term here,",
        "start": 731.965,
        "duration": 2.925
    },
    {
        "text": "but I think that works very well because it",
        "start": 734.89,
        "duration": 1.815
    },
    {
        "text": "refers to these three large pillars.",
        "start": 736.705,
        "duration": 2.97
    },
    {
        "text": ">> Correct.",
        "start": 739.675,
        "duration": 1.32
    },
    {
        "text": ">> Let's get a little bit more",
        "start": 740.995,
        "duration": 2.295
    },
    {
        "text": "technical and talk about the approach,",
        "start": 743.29,
        "duration": 2.085
    },
    {
        "text": "because I think that's what people are interested in.",
        "start": 745.375,
        "duration": 2.25
    },
    {
        "text": "You have seen basically in the prior slides the holistic motion,",
        "start": 747.625,
        "duration": 5.16
    },
    {
        "text": "which is really important for MLOps.",
        "start": 752.785,
        "duration": 1.695
    },
    {
        "text": "It is not just you write code and you're done.",
        "start": 754.48,
        "duration": 2.7
    },
    {
        "text": "Everybody has to be somehow on board.",
        "start": 757.18,
        "duration": 2.235
    },
    {
        "text": "With MLOps v2 from a technical perspective,",
        "start": 759.415,
        "duration": 2.625
    },
    {
        "text": "we are five pillars.",
        "start": 762.04,
        "duration": 1.53
    },
    {
        "text": "We are realizing in this work here.",
        "start": 763.57,
        "duration": 2.355
    },
    {
        "text": "First, we are offering something very simple.",
        "start": 765.925,
        "duration": 3.135
    },
    {
        "text": "In the end, if you think about we want to have",
        "start": 769.06,
        "duration": 2.64
    },
    {
        "text": "a solution where the Data Scientist can focus on",
        "start": 771.7,
        "duration": 3.48
    },
    {
        "text": "their project and doesn't need to worry about",
        "start": 775.18,
        "duration": 2.895
    },
    {
        "text": "automated pieces that they have right over and over again.",
        "start": 778.075,
        "duration": 3.735
    },
    {
        "text": "That's maintenance work for ML engineers.",
        "start": 781.81,
        "duration": 2.67
    },
    {
        "text": "All the type of personas that work in AI ecosystems.",
        "start": 784.48,
        "duration": 3.285
    },
    {
        "text": "We want to offer a secure systems.",
        "start": 787.765,
        "duration": 2.325
    },
    {
        "text": "When we're talking about secure workspaces in ML,",
        "start": 790.09,
        "duration": 2.505
    },
    {
        "text": "the solution is basically comes natively secure.",
        "start": 792.595,
        "duration": 4.11
    },
    {
        "text": "This entire motion of you have to worry about your VNet,",
        "start": 796.705,
        "duration": 4.575
    },
    {
        "text": "you have to worry about,",
        "start": 801.28,
        "duration": 1.605
    },
    {
        "text": "I don't know, different types of security measures.",
        "start": 802.885,
        "duration": 2.685
    },
    {
        "text": "You have to build them in basically into a system.",
        "start": 805.57,
        "duration": 2.34
    },
    {
        "text": "We'll take it out of the equation and we give it to",
        "start": 807.91,
        "duration": 2.22
    },
    {
        "text": "you naturally and by default.",
        "start": 810.13,
        "duration": 3.45
    },
    {
        "text": "We want to have a solution that is focused on speed.",
        "start": 813.58,
        "duration": 3.885
    },
    {
        "text": "I mentioned this before,",
        "start": 817.465,
        "duration": 1.545
    },
    {
        "text": "that the value proposition of",
        "start": 819.01,
        "duration": 1.845
    },
    {
        "text": "MLOps should really be we're moving fast to",
        "start": 820.855,
        "duration": 3.015
    },
    {
        "text": "product and not being in these six month plus cycles of",
        "start": 823.87,
        "duration": 4.44
    },
    {
        "text": "building systems over and over again and we'll never get done.",
        "start": 828.31,
        "duration": 5.01
    },
    {
        "text": "We want something that is basically",
        "start": 833.32,
        "duration": 2.595
    },
    {
        "text": "repeatable at scale for your enterprise and lastly,",
        "start": 835.915,
        "duration": 4.68
    },
    {
        "text": "focused on modularity so that you can pick I want this workload,",
        "start": 840.595,
        "duration": 5.025
    },
    {
        "text": "I want this CI/CD tool.",
        "start": 845.62,
        "duration": 2.16
    },
    {
        "text": "I want, I don't know, Azure Databricks,",
        "start": 847.78,
        "duration": 2.52
    },
    {
        "text": "I want Azure ML,",
        "start": 850.3,
        "duration": 1.38
    },
    {
        "text": "I want Azure Synapse.",
        "start": 851.68,
        "duration": 1.395
    },
    {
        "text": "It gives you a stack of",
        "start": 853.075,
        "duration": 1.905
    },
    {
        "text": "technologies and a stack of choices depending on",
        "start": 854.98,
        "duration": 3.6
    },
    {
        "text": "your AI workload that makes it",
        "start": 858.58,
        "duration": 2.16
    },
    {
        "text": "possible to work through a single pane of glass, essentially.",
        "start": 860.74,
        "duration": 4.515
    },
    {
        "text": "What I mean by that is really that you have a solution.",
        "start": 865.255,
        "duration": 4.305
    },
    {
        "text": "You can over and over and over,",
        "start": 869.56,
        "duration": 1.38
    },
    {
        "text": "redeploy with different type",
        "start": 870.94,
        "duration": 2.4
    },
    {
        "text": "of measures depending on your personal decision,",
        "start": 873.34,
        "duration": 2.325
    },
    {
        "text": "so we give the decision how you",
        "start": 875.665,
        "duration": 1.635
    },
    {
        "text": "want to rebuilt your system back to you,",
        "start": 877.3,
        "duration": 2.1
    },
    {
        "text": "but the entire code back and automate it and abstract it for",
        "start": 879.4,
        "duration": 4.08
    },
    {
        "text": "you so that your Data Scientists can focus on building models.",
        "start": 883.48,
        "duration": 5.38
    },
    {
        "text": ">> This is cool. I feel like I'm sold.",
        "start": 889.02,
        "duration": 4.285
    },
    {
        "text": "I feel like I want to get into how does someone do this?",
        "start": 893.305,
        "duration": 4.88
    },
    {
        "text": ">> Yes.",
        "start": 898.185,
        "duration": 0.405
    },
    {
        "text": ">> You know what I'm saying? Is there,",
        "start": 898.59,
        "duration": 1.395
    },
    {
        "text": "like you mentioned the approach,",
        "start": 899.985,
        "duration": 2.01
    },
    {
        "text": "how should someone set up their projects?",
        "start": 901.995,
        "duration": 2.445
    },
    {
        "text": "You mentioned like a template and re-usability.",
        "start": 904.44,
        "duration": 2.655
    },
    {
        "text": "I'd love to see the thinking behind that a little bit.",
        "start": 907.095,
        "duration": 2.555
    },
    {
        "text": ">> Yeah, totally. We are",
        "start": 909.65,
        "duration": 2.51
    },
    {
        "text": "currently operating of three repositories.",
        "start": 912.16,
        "duration": 3.345
    },
    {
        "text": "We basically have a header repository that",
        "start": 915.505,
        "duration": 3.645
    },
    {
        "text": "is really just a concept that we call a spa's checkout,",
        "start": 919.15,
        "duration": 4.17
    },
    {
        "text": "which is an SH script where you define",
        "start": 923.32,
        "duration": 2.97
    },
    {
        "text": "basically these variables of what you want to use.",
        "start": 926.29,
        "duration": 3.495
    },
    {
        "text": "Do you want to use a ML basically?",
        "start": 929.785,
        "duration": 2.07
    },
    {
        "text": "I want classical ML,",
        "start": 931.855,
        "duration": 1.62
    },
    {
        "text": "I want as a CI/CD tool,",
        "start": 933.475,
        "duration": 1.665
    },
    {
        "text": "Azure DevOps, I want and so forth.",
        "start": 935.14,
        "duration": 3.285
    },
    {
        "text": "Then we have a repo",
        "start": 938.425,
        "duration": 2.115
    },
    {
        "text": "basically that holds our infrastructure templates,",
        "start": 940.54,
        "duration": 2.76
    },
    {
        "text": "basically that allow you to deploy in Bicep and Terraform.",
        "start": 943.3,
        "duration": 4.005
    },
    {
        "text": "Again, more decisions.",
        "start": 947.305,
        "duration": 1.395
    },
    {
        "text": ">> Right.",
        "start": 948.7,
        "duration": 1.035
    },
    {
        "text": ">> Then we have a Repo,",
        "start": 949.735,
        "duration": 2.25
    },
    {
        "text": "which is the third and last Repo that",
        "start": 951.985,
        "duration": 2.175
    },
    {
        "text": "basically holds all our project code.",
        "start": 954.16,
        "duration": 3.09
    },
    {
        "text": "If you decide to deploy an LP workload or a classical ML workload,",
        "start": 957.25,
        "duration": 5.354
    },
    {
        "text": "we give you a demo where you can",
        "start": 962.604,
        "duration": 2.116
    },
    {
        "text": "see how everything works out of the box,",
        "start": 964.72,
        "duration": 2.4
    },
    {
        "text": "and then you say, I want to try this myself with my own model,",
        "start": 967.12,
        "duration": 3.375
    },
    {
        "text": "and you just plug in and play your own model",
        "start": 970.495,
        "duration": 2.7
    },
    {
        "text": "and a certain type of conformity,",
        "start": 973.195,
        "duration": 3.045
    },
    {
        "text": "I may say, having a separate train script",
        "start": 976.24,
        "duration": 3.06
    },
    {
        "text": "and so forth, which are more.",
        "start": 979.3,
        "duration": 1.92
    },
    {
        "text": "Development standards you should need to adhere to.",
        "start": 981.22,
        "duration": 3.615
    },
    {
        "text": "But you can plug it in and just run it yourself.",
        "start": 984.835,
        "duration": 2.655
    },
    {
        "text": "What you can see here in the lower part of the slide is you can",
        "start": 987.49,
        "duration": 3.48
    },
    {
        "text": "basically build a project over and over again,",
        "start": 990.97,
        "duration": 4.23
    },
    {
        "text": "and I can just stand here and say and over",
        "start": 995.2,
        "duration": 2.82
    },
    {
        "text": "because it is just so repeatable.",
        "start": 998.02,
        "duration": 2.97
    },
    {
        "text": "The system that you basically deploy applies for any type",
        "start": 1000.99,
        "duration": 4.47
    },
    {
        "text": "of the personas that are part of this type of MLOps approach.",
        "start": 1005.46,
        "duration": 4.875
    },
    {
        "text": "Seth, I would like to show you",
        "start": 1010.335,
        "duration": 1.755
    },
    {
        "text": "an architecture, if you don't mind.",
        "start": 1012.09,
        "duration": 1.38
    },
    {
        "text": ">> Yeah.",
        "start": 1013.47,
        "duration": 0.17
    },
    {
        "text": ">> Maybe this becomes really clear.",
        "start": 1013.64,
        "duration": 1.93
    },
    {
        "text": ">> Because like I said, I'm understanding now that this is more of",
        "start": 1015.57,
        "duration": 4.26
    },
    {
        "text": "like here's all this stuff and",
        "start": 1019.83,
        "duration": 2.01
    },
    {
        "text": "you basically from the menu of options,",
        "start": 1021.84,
        "duration": 2.55
    },
    {
        "text": "pull what you want or if you know is an NLP or a vision,",
        "start": 1024.39,
        "duration": 3.615
    },
    {
        "text": "you already have something you built and you can just run it and",
        "start": 1028.005,
        "duration": 2.535
    },
    {
        "text": "then substitute with your stuff. Am I getting this right?",
        "start": 1030.54,
        "duration": 2.79
    },
    {
        "text": ">> Yes, that is correct.",
        "start": 1033.33,
        "duration": 2.64
    },
    {
        "text": "On the next slide, actually,",
        "start": 1035.97,
        "duration": 2.415
    },
    {
        "text": "we have an architecture here.",
        "start": 1038.385,
        "duration": 2.055
    },
    {
        "text": "It is admittedly a little bit small to read,",
        "start": 1040.44,
        "duration": 4.05
    },
    {
        "text": "but the problem is that MLOps is",
        "start": 1044.49,
        "duration": 2.4
    },
    {
        "text": "so huge you can't get it on a slide.",
        "start": 1046.89,
        "duration": 3.255
    },
    {
        "text": "I want to just touch on the high ecosystem here,",
        "start": 1050.145,
        "duration": 3.21
    },
    {
        "text": "and I would recommend to you later on to look at",
        "start": 1053.355,
        "duration": 2.895
    },
    {
        "text": "our Solution Accelerator and",
        "start": 1056.25,
        "duration": 1.65
    },
    {
        "text": "you can really double click and zoom in.",
        "start": 1057.9,
        "duration": 1.92
    },
    {
        "text": "But if you look at Number 1 in the left corner,",
        "start": 1059.82,
        "duration": 3.54
    },
    {
        "text": "you see a data estate.",
        "start": 1063.36,
        "duration": 1.695
    },
    {
        "text": "This is for classical machine learning,",
        "start": 1065.055,
        "duration": 1.95
    },
    {
        "text": "which is agnostic to us because",
        "start": 1067.005,
        "duration": 2.879
    },
    {
        "text": "we say we don't care where your data comes from.",
        "start": 1069.884,
        "duration": 3.301
    },
    {
        "text": "You can basically use data from anywhere in your ML pipeline.",
        "start": 1073.185,
        "duration": 5.415
    },
    {
        "text": "Number 2 is focusing on the infrastructure,",
        "start": 1078.6,
        "duration": 3.81
    },
    {
        "text": "so that needs to be set up basically to get everything in place.",
        "start": 1082.41,
        "duration": 4.545
    },
    {
        "text": "What I mean by that is workspaces, compute,",
        "start": 1086.955,
        "duration": 3.42
    },
    {
        "text": "everything basically that goes into",
        "start": 1090.375,
        "duration": 2.145
    },
    {
        "text": "an MLOps system needs to be there to even work with it.",
        "start": 1092.52,
        "duration": 3.765
    },
    {
        "text": "That's also templatized. We basically,",
        "start": 1096.285,
        "duration": 3.885
    },
    {
        "text": "based on your choices,",
        "start": 1100.17,
        "duration": 1.425
    },
    {
        "text": "set that up to you,",
        "start": 1101.595,
        "duration": 1.275
    },
    {
        "text": "so it's like an environment that is",
        "start": 1102.87,
        "duration": 1.47
    },
    {
        "text": "getting built in your subscription.",
        "start": 1104.34,
        "duration": 2.49
    },
    {
        "text": "Versus in Number 3,",
        "start": 1106.83,
        "duration": 2.19
    },
    {
        "text": "in your secure workspace,",
        "start": 1109.02,
        "duration": 1.77
    },
    {
        "text": "you basically have your,",
        "start": 1110.79,
        "duration": 1.395
    },
    {
        "text": "we call this the Inner Loop,",
        "start": 1112.185,
        "duration": 1.53
    },
    {
        "text": "your model essentially that you develop",
        "start": 1113.715,
        "duration": 2.835
    },
    {
        "text": "or you can choose the demo we give you out of the box.",
        "start": 1116.55,
        "duration": 3.09
    },
    {
        "text": "But in here we have",
        "start": 1119.64,
        "duration": 1.8
    },
    {
        "text": "the typical data science life cycle you may call it,",
        "start": 1121.44,
        "duration": 3.06
    },
    {
        "text": "or flow, where you basically build a model step by step.",
        "start": 1124.5,
        "duration": 3.57
    },
    {
        "text": "This is really getting your tabular data from any of",
        "start": 1128.07,
        "duration": 3.15
    },
    {
        "text": "the agnostic data sources.",
        "start": 1131.22,
        "duration": 2.925
    },
    {
        "text": "Then view your EDA of feature engineering, creating a model,",
        "start": 1134.145,
        "duration": 3.555
    },
    {
        "text": "training it and registering it,",
        "start": 1137.7,
        "duration": 1.5
    },
    {
        "text": "and if you're not happy again, you do it all over again.",
        "start": 1139.2,
        "duration": 2.34
    },
    {
        "text": "You do this as long as you're getting to a step that in Number 4,",
        "start": 1141.54,
        "duration": 4.35
    },
    {
        "text": "you're going to register your model in",
        "start": 1145.89,
        "duration": 2.355
    },
    {
        "text": "a agnostic registry in every machine learning essentially.",
        "start": 1148.245,
        "duration": 4.935
    },
    {
        "text": "Once you are there,",
        "start": 1153.18,
        "duration": 1.875
    },
    {
        "text": "you end from a environment perspective,",
        "start": 1155.055,
        "duration": 4.32
    },
    {
        "text": "the Dev lifecycle and you're ready depending on",
        "start": 1159.375,
        "duration": 4.335
    },
    {
        "text": "your organization to move",
        "start": 1163.71,
        "duration": 1.83
    },
    {
        "text": "forward and move this model into a test stage.",
        "start": 1165.54,
        "duration": 3.42
    },
    {
        "text": "In this outer loop, which is here represented in Number 5,",
        "start": 1168.96,
        "duration": 3.345
    },
    {
        "text": "we have this really heavy back end system,",
        "start": 1172.305,
        "duration": 2.895
    },
    {
        "text": "you may call it, that we give you out of the box again.",
        "start": 1175.2,
        "duration": 3.865
    },
    {
        "text": "In Number 6, in your staging workspace,",
        "start": 1179.065,
        "duration": 4.48
    },
    {
        "text": "we run basically a lot of tests out of the box,",
        "start": 1183.545,
        "duration": 2.925
    },
    {
        "text": "so different types of data checks, unit tests,",
        "start": 1186.47,
        "duration": 2.56
    },
    {
        "text": "smoke tests, tests on responsible AI,",
        "start": 1189.03,
        "duration": 2.805
    },
    {
        "text": "basically make sure that the quality",
        "start": 1191.835,
        "duration": 2.295
    },
    {
        "text": "of your model is ensured and that",
        "start": 1194.13,
        "duration": 2.415
    },
    {
        "text": "endpoints can be deployed depending on if you're running",
        "start": 1196.545,
        "duration": 2.775
    },
    {
        "text": "batch or near real time that they are working.",
        "start": 1199.32,
        "duration": 3.45
    },
    {
        "text": "Once you get all these green check marks",
        "start": 1202.77,
        "duration": 2.61
    },
    {
        "text": "there and your system says you're good to go,",
        "start": 1205.38,
        "duration": 3.0
    },
    {
        "text": "we just flip this and deploy this into",
        "start": 1208.38,
        "duration": 1.92
    },
    {
        "text": "your production environment with really three choices.",
        "start": 1210.3,
        "duration": 3.3
    },
    {
        "text": "Again, you have the batch M choice.",
        "start": 1213.6,
        "duration": 2.115
    },
    {
        "text": "You can run Azure Art on a Kubernetes Cluster,",
        "start": 1215.715,
        "duration": 2.775
    },
    {
        "text": "especially when you're multi Cloud and so forth,",
        "start": 1218.49,
        "duration": 2.475
    },
    {
        "text": "or you run the online managed endpoint,",
        "start": 1220.965,
        "duration": 2.58
    },
    {
        "text": "which is more for near real time.",
        "start": 1223.545,
        "duration": 2.1
    },
    {
        "text": "This is all great. Now you have your model in production.",
        "start": 1225.645,
        "duration": 3.465
    },
    {
        "text": "This is all done through like a Yellow Pipeline deployment.",
        "start": 1229.11,
        "duration": 3.075
    },
    {
        "text": "Everything comes out of the box as I mentioned,",
        "start": 1232.185,
        "duration": 1.995
    },
    {
        "text": "Seth will demo this here in a second.",
        "start": 1234.18,
        "duration": 1.785
    },
    {
        "text": "Then in Number 8, you basically have your monitoring portion.",
        "start": 1235.965,
        "duration": 3.72
    },
    {
        "text": "That's where we basically look first at the model and",
        "start": 1239.685,
        "duration": 2.805
    },
    {
        "text": "the data and the model monitoring may appear",
        "start": 1242.49,
        "duration": 3.96
    },
    {
        "text": "a little easier in supervised scenarios",
        "start": 1246.45,
        "duration": 2.4
    },
    {
        "text": "where you have a variable where you can basically",
        "start": 1248.85,
        "duration": 1.92
    },
    {
        "text": "compare your actual versus",
        "start": 1250.77,
        "duration": 1.71
    },
    {
        "text": "the now incoming data or forecast the data and so forth.",
        "start": 1252.48,
        "duration": 3.285
    },
    {
        "text": "But when it comes to data monitoring,",
        "start": 1255.765,
        "duration": 2.515
    },
    {
        "text": "that's something that's really hard, right?",
        "start": 1258.28,
        "duration": 2.5
    },
    {
        "text": "That may work on tabular datasets.",
        "start": 1260.78,
        "duration": 2.24
    },
    {
        "text": "But think about this data monitoring on",
        "start": 1263.02,
        "duration": 2.88
    },
    {
        "text": "images or data monitoring on language, our natural language.",
        "start": 1265.9,
        "duration": 4.785
    },
    {
        "text": "How do you do this.",
        "start": 1270.685,
        "duration": 1.205
    },
    {
        "text": "Those are really sophisticated concepts.",
        "start": 1271.89,
        "duration": 2.3
    },
    {
        "text": ">> Indeed.",
        "start": 1274.19,
        "duration": 0.425
    },
    {
        "text": ">> Or we need to work on with",
        "start": 1274.615,
        "duration": 1.965
    },
    {
        "text": "research to understand how this works.",
        "start": 1276.58,
        "duration": 3.39
    },
    {
        "text": ">> Yeah. I mean, I'm loving",
        "start": 1279.97,
        "duration": 3.65
    },
    {
        "text": "every aspect of this because it goes from the inner,",
        "start": 1283.62,
        "duration": 3.835
    },
    {
        "text": "to the outer and then there's this admin thing as well,",
        "start": 1287.455,
        "duration": 3.925
    },
    {
        "text": "which is our research has shown that's where people",
        "start": 1291.38,
        "duration": 2.23
    },
    {
        "text": "spend the most of their time.",
        "start": 1293.61,
        "duration": 2.38
    },
    {
        "text": "Now, you said if it's a little bit different",
        "start": 1295.99,
        "duration": 2.31
    },
    {
        "text": "for things like NLP and Vision,",
        "start": 1298.3,
        "duration": 2.94
    },
    {
        "text": "how do you account for the changes in those.",
        "start": 1301.24,
        "duration": 3.455
    },
    {
        "text": ">> Yeah. The main difference is that",
        "start": 1304.695,
        "duration": 3.565
    },
    {
        "text": "some NLP tasks tend to be unsupervised.",
        "start": 1308.26,
        "duration": 4.185
    },
    {
        "text": "You have challenges there.",
        "start": 1312.445,
        "duration": 2.045
    },
    {
        "text": "How do you basically on",
        "start": 1314.49,
        "duration": 1.335
    },
    {
        "text": "a summarization model understand data drift,",
        "start": 1315.825,
        "duration": 3.88
    },
    {
        "text": "if you don't really have a label.",
        "start": 1319.705,
        "duration": 2.055
    },
    {
        "text": "That's just really hard to figure",
        "start": 1321.76,
        "duration": 2.73
    },
    {
        "text": "out and there needs to be worked on also from",
        "start": 1324.49,
        "duration": 2.49
    },
    {
        "text": "a research standpoint to get to an enterprise solution",
        "start": 1326.98,
        "duration": 3.585
    },
    {
        "text": "that is a little bit more abstracted in the applied AI area.",
        "start": 1330.565,
        "duration": 4.115
    },
    {
        "text": "Then if you look at number nine and number 10,",
        "start": 1334.68,
        "duration": 3.295
    },
    {
        "text": "now I want to focus the actually more number nine.",
        "start": 1337.975,
        "duration": 2.415
    },
    {
        "text": "How do you retrain a models?",
        "start": 1340.39,
        "duration": 1.895
    },
    {
        "text": "In this classical machine learning use case,",
        "start": 1342.285,
        "duration": 2.71
    },
    {
        "text": "you see that you can have maybe in forecasting examples,",
        "start": 1344.995,
        "duration": 3.555
    },
    {
        "text": "you can have an automated retrain or you trigger",
        "start": 1348.55,
        "duration": 2.315
    },
    {
        "text": "a new data science project where you then have a manual retrain,",
        "start": 1350.865,
        "duration": 3.545
    },
    {
        "text": "where the arrow goes all the way back to the model deployment.",
        "start": 1354.41,
        "duration": 4.04
    },
    {
        "text": "But for example, in a computer version scenario,",
        "start": 1358.45,
        "duration": 3.41
    },
    {
        "text": "we don't recommend to automatically",
        "start": 1361.86,
        "duration": 2.744
    },
    {
        "text": "retrain rather to re label images,",
        "start": 1364.604,
        "duration": 3.721
    },
    {
        "text": "which is the task of responsible AI in itself.",
        "start": 1368.325,
        "duration": 3.03
    },
    {
        "text": "How do you basically label the person who labels is this bias?",
        "start": 1371.355,
        "duration": 3.48
    },
    {
        "text": "But the recommendation from our site",
        "start": 1374.835,
        "duration": 2.095
    },
    {
        "text": "is just kick off this project again,",
        "start": 1376.93,
        "duration": 3.085
    },
    {
        "text": "because we have understood in the past that",
        "start": 1380.015,
        "duration": 2.435
    },
    {
        "text": "computer vision can be fairly complex,",
        "start": 1382.45,
        "duration": 3.14
    },
    {
        "text": "especially by creating training data.",
        "start": 1385.59,
        "duration": 2.485
    },
    {
        "text": "To your question with NLP,",
        "start": 1388.075,
        "duration": 2.285
    },
    {
        "text": "this is an architecture that now",
        "start": 1390.36,
        "duration": 1.61
    },
    {
        "text": "focuses on NLP so you see a little bit that",
        "start": 1391.97,
        "duration": 2.395
    },
    {
        "text": "the inner loop is quite different and",
        "start": 1394.365,
        "duration": 1.915
    },
    {
        "text": "focuses more on NLP steps to build a model.",
        "start": 1396.28,
        "duration": 2.9
    },
    {
        "text": "We also recommend to basically not necessarily auto retrain.",
        "start": 1399.18,
        "duration": 4.57
    },
    {
        "text": "If language changes over time and let's",
        "start": 1403.75,
        "duration": 2.76
    },
    {
        "text": "say you're able to identify some type of drift,",
        "start": 1406.51,
        "duration": 2.97
    },
    {
        "text": "you often have to recreate a new corpus to fine tune your model.",
        "start": 1409.48,
        "duration": 5.46
    },
    {
        "text": "I say fine tune here because we know",
        "start": 1414.94,
        "duration": 2.34
    },
    {
        "text": "the reality is in the world of Transformers",
        "start": 1417.28,
        "duration": 2.555
    },
    {
        "text": "nowadays that nobody trains a model",
        "start": 1419.835,
        "duration": 2.915
    },
    {
        "text": "for the least amount of people let me put it this way,",
        "start": 1422.75,
        "duration": 3.595
    },
    {
        "text": "train a model from scratch for many months,",
        "start": 1426.345,
        "duration": 2.305
    },
    {
        "text": "most people download the model embeddings",
        "start": 1428.65,
        "duration": 2.58
    },
    {
        "text": "and just fine tune them with their own data.",
        "start": 1431.23,
        "duration": 2.48
    },
    {
        "text": ">> Yeah, and that makes sense.",
        "start": 1433.71,
        "duration": 2.02
    },
    {
        "text": "I'm looking over there, I think it's number let me double check.",
        "start": 1435.73,
        "duration": 3.72
    },
    {
        "text": "It's number nine.",
        "start": 1439.45,
        "duration": 1.04
    },
    {
        "text": "I see that now there's a human in",
        "start": 1440.49,
        "duration": 1.81
    },
    {
        "text": "the loop as part of the recommendation..",
        "start": 1442.3,
        "duration": 2.22
    },
    {
        "text": "I saw that for computer vision and for NLP. Is that right?",
        "start": 1444.52,
        "duration": 3.45
    },
    {
        "text": ">> That is right. Here again,",
        "start": 1447.97,
        "duration": 2.135
    },
    {
        "text": "I just want to underline this.",
        "start": 1450.105,
        "duration": 1.455
    },
    {
        "text": "We're working under an ethical framework.",
        "start": 1451.56,
        "duration": 3.87
    },
    {
        "text": "We want to ensure that the most sensitive tasks which we define as",
        "start": 1455.43,
        "duration": 4.185
    },
    {
        "text": "computer vision as we know that they are very",
        "start": 1459.615,
        "duration": 2.365
    },
    {
        "text": "like responsible AI use cases for computer vision,",
        "start": 1461.98,
        "duration": 3.03
    },
    {
        "text": "but also language where you basically have certain type of",
        "start": 1465.01,
        "duration": 3.08
    },
    {
        "text": "isms in language essentially that can introduce bias,",
        "start": 1468.09,
        "duration": 3.385
    },
    {
        "text": "are checked by a human.",
        "start": 1471.475,
        "duration": 1.77
    },
    {
        "text": "The human in the loop in these up systems is MLOps really,",
        "start": 1473.245,
        "duration": 3.32
    },
    {
        "text": "really important. The full automation.",
        "start": 1476.565,
        "duration": 3.265
    },
    {
        "text": "I can just say this personally,",
        "start": 1479.83,
        "duration": 1.92
    },
    {
        "text": "as one of the creators here,",
        "start": 1481.75,
        "duration": 1.42
    },
    {
        "text": "we do not fully support because",
        "start": 1483.17,
        "duration": 2.105
    },
    {
        "text": "we want to have data scientists and",
        "start": 1485.275,
        "duration": 2.295
    },
    {
        "text": "business decision makers looking at the data",
        "start": 1487.57,
        "duration": 3.17
    },
    {
        "text": "and looking at potential bias implications of models,",
        "start": 1490.74,
        "duration": 3.505
    },
    {
        "text": "especially in the transformer space.",
        "start": 1494.245,
        "duration": 1.965
    },
    {
        "text": ">> Yeah and that makes sense.",
        "start": 1496.21,
        "duration": 2.325
    },
    {
        "text": "Essentially this is all a very cookie cutter approach with",
        "start": 1498.535,
        "duration": 4.245
    },
    {
        "text": "specific approaches to things",
        "start": 1502.78,
        "duration": 3.18
    },
    {
        "text": "that need humans in the loop too, which is really cool.",
        "start": 1505.96,
        "duration": 2.985
    },
    {
        "text": ">> Yeah, that's correct.",
        "start": 1508.945,
        "duration": 1.505
    },
    {
        "text": "I want to give it now the microphone actually to to Seth",
        "start": 1510.45,
        "duration": 3.655
    },
    {
        "text": "I'm sorry to Setu see now I'm",
        "start": 1514.105,
        "duration": 1.605
    },
    {
        "text": "confusing you too as well. You started this.",
        "start": 1515.71,
        "duration": 2.165
    },
    {
        "text": ">> I know.",
        "start": 1517.875,
        "duration": 1.15
    },
    {
        "text": ">> To Setu and I have Setu talk a little",
        "start": 1519.025,
        "duration": 3.045
    },
    {
        "text": "bit more about the technical implementation so",
        "start": 1522.07,
        "duration": 2.525
    },
    {
        "text": "that you can see how this architecture that we are providing",
        "start": 1524.595,
        "duration": 4.02
    },
    {
        "text": "you more like as a blueprint",
        "start": 1528.615,
        "duration": 1.83
    },
    {
        "text": "really becomes life within your ecosystem.",
        "start": 1530.445,
        "duration": 2.91
    },
    {
        "text": ">> Yeah, and I love that because I wanted to go to you Setu,",
        "start": 1533.355,
        "duration": 3.87
    },
    {
        "text": "because I think I get a sense",
        "start": 1537.225,
        "duration": 2.345
    },
    {
        "text": "for what this looks like in principle,",
        "start": 1539.57,
        "duration": 2.305
    },
    {
        "text": "but I'd love to see what it looks like in action.",
        "start": 1541.875,
        "duration": 2.785
    },
    {
        "text": "Do you think you could share some of that with us?",
        "start": 1544.66,
        "duration": 1.805
    },
    {
        "text": ">> Yeah, sure. I think Moe",
        "start": 1546.465,
        "duration": 2.41
    },
    {
        "text": "gave a pretty good overview of what's there.",
        "start": 1548.875,
        "duration": 3.485
    },
    {
        "text": "Let me jump on to the GitHub and, get started.",
        "start": 1552.36,
        "duration": 4.3
    },
    {
        "text": "After all, we are all coders here,",
        "start": 1556.66,
        "duration": 1.715
    },
    {
        "text": "so we can get going with that.",
        "start": 1558.375,
        "duration": 1.87
    },
    {
        "text": ">> Let's start.",
        "start": 1560.245,
        "duration": 1.24
    },
    {
        "text": ">> All right so here's our page,",
        "start": 1561.485,
        "duration": 2.655
    },
    {
        "text": "which is on GitHub Azure MLOpsv2 as Moe mentioned.",
        "start": 1564.14,
        "duration": 5.265
    },
    {
        "text": "This is essentially our header repo.",
        "start": 1569.405,
        "duration": 3.535
    },
    {
        "text": "It doesn't have any code,",
        "start": 1572.94,
        "duration": 1.65
    },
    {
        "text": "but it does have getting started",
        "start": 1574.59,
        "duration": 1.94
    },
    {
        "text": "documentation that you can work with.",
        "start": 1576.53,
        "duration": 2.39
    },
    {
        "text": "It also has our architectures that Moe was sharing",
        "start": 1578.92,
        "duration": 4.025
    },
    {
        "text": "some very high quality versions of it so you",
        "start": 1582.945,
        "duration": 2.605
    },
    {
        "text": "can zoom in figure out if that's what it's needed.",
        "start": 1585.55,
        "duration": 3.21
    },
    {
        "text": "The good part of it is we have actually with",
        "start": 1588.76,
        "duration": 2.53
    },
    {
        "text": "our code we have replicated that architecture",
        "start": 1591.29,
        "duration": 2.39
    },
    {
        "text": "so you can play around with",
        "start": 1593.68,
        "duration": 1.98
    },
    {
        "text": "the solution that we have given up and work with that.",
        "start": 1595.66,
        "duration": 3.465
    },
    {
        "text": "The other good part of this is,",
        "start": 1599.125,
        "duration": 2.695
    },
    {
        "text": "even though it's like a demo",
        "start": 1601.82,
        "duration": 1.975
    },
    {
        "text": "repo from what Moe mentioned as well,",
        "start": 1603.795,
        "duration": 3.07
    },
    {
        "text": "you can pick and choose how you want to deploy it.",
        "start": 1606.865,
        "duration": 3.615
    },
    {
        "text": "Let's say you're using terraform, you know,",
        "start": 1610.48,
        "duration": 2.16
    },
    {
        "text": "we'll give you a terraform script or you want to use",
        "start": 1612.64,
        "duration": 2.04
    },
    {
        "text": "Bicep for your infrastructure we'll give you that as well.",
        "start": 1614.68,
        "duration": 2.775
    },
    {
        "text": "You want to use CLI or some people prefer a sticky version of it.",
        "start": 1617.455,
        "duration": 4.035
    },
    {
        "text": "All of these combinations are available for people to get",
        "start": 1621.49,
        "duration": 3.78
    },
    {
        "text": "started and they can pick and choose how to get to that.",
        "start": 1625.27,
        "duration": 4.175
    },
    {
        "text": "The first step of this would be go here,",
        "start": 1629.445,
        "duration": 3.265
    },
    {
        "text": "clone your repo and start to modify the script.",
        "start": 1632.71,
        "duration": 3.545
    },
    {
        "text": "Once you modify the script,",
        "start": 1636.255,
        "duration": 2.485
    },
    {
        "text": "this is how it's going to look like",
        "start": 1638.74,
        "duration": 1.4
    },
    {
        "text": "your first few lines are going to be about,",
        "start": 1640.14,
        "duration": 4.255
    },
    {
        "text": "tell me what you want to do.",
        "start": 1644.395,
        "duration": 1.575
    },
    {
        "text": "We have the first line which talks about infrastructure.",
        "start": 1645.97,
        "duration": 3.555
    },
    {
        "text": "The second line essentially about classical,",
        "start": 1649.525,
        "duration": 2.395
    },
    {
        "text": "AML or NLP or computer Vision.",
        "start": 1651.92,
        "duration": 2.84
    },
    {
        "text": "How do you want to do this deployment.",
        "start": 1654.76,
        "duration": 1.985
    },
    {
        "text": "Some people prefer CLI,",
        "start": 1656.745,
        "duration": 1.375
    },
    {
        "text": "some prefer SDK so we give you",
        "start": 1658.12,
        "duration": 2.13
    },
    {
        "text": "that choice and then give your a repo name.",
        "start": 1660.25,
        "duration": 2.825
    },
    {
        "text": "All this is essentially doing is sparse check out.",
        "start": 1663.075,
        "duration": 3.115
    },
    {
        "text": "Now sparse check out the relatively new feature of Git.",
        "start": 1666.19,
        "duration": 3.63
    },
    {
        "text": "Make sure you are updating",
        "start": 1669.82,
        "duration": 1.5
    },
    {
        "text": "your Git version to the",
        "start": 1671.32,
        "duration": 1.95
    },
    {
        "text": "latest one so that you will be able to use that.",
        "start": 1673.27,
        "duration": 2.07
    },
    {
        "text": "Otherwise you will run in all the bunch of errors in there.",
        "start": 1675.34,
        "duration": 2.99
    },
    {
        "text": ">> Of course.",
        "start": 1678.33,
        "duration": 1.375
    },
    {
        "text": ">> All right. Once you configure",
        "start": 1679.705,
        "duration": 2.095
    },
    {
        "text": "your script the way you want it now,",
        "start": 1681.8,
        "duration": 1.94
    },
    {
        "text": "this will create a custom code for you,",
        "start": 1683.74,
        "duration": 3.63
    },
    {
        "text": "which you can then push it into your own code repo.",
        "start": 1687.37,
        "duration": 4.44
    },
    {
        "text": "I've given that oh my new project name is going to be",
        "start": 1691.81,
        "duration": 3.12
    },
    {
        "text": "Mlops test and I'm doing it on my personal repo,",
        "start": 1694.93,
        "duration": 3.66
    },
    {
        "text": "so it's going to be saved to C.",
        "start": 1698.59,
        "duration": 1.855
    },
    {
        "text": "It's going to push that code for you.",
        "start": 1700.445,
        "duration": 2.58
    },
    {
        "text": "Again, you know, make sure you are setting up",
        "start": 1703.025,
        "duration": 1.485
    },
    {
        "text": "your gate and everything so that it's good to go.",
        "start": 1704.51,
        "duration": 2.275
    },
    {
        "text": "Now let me run the script.",
        "start": 1706.785,
        "duration": 1.405
    },
    {
        "text": "It's not going to push the code out there,",
        "start": 1708.19,
        "duration": 1.65
    },
    {
        "text": "but it will show you that,",
        "start": 1709.84,
        "duration": 1.475
    },
    {
        "text": "just the steps that I mentioned,",
        "start": 1711.315,
        "duration": 1.995
    },
    {
        "text": "it's going to quickly configure it",
        "start": 1713.31,
        "duration": 2.2
    },
    {
        "text": "to the settings that you have given and now you are good to go.",
        "start": 1715.51,
        "duration": 3.68
    },
    {
        "text": "Now what our code it has,",
        "start": 1719.19,
        "duration": 1.71
    },
    {
        "text": "it has code for infrastructure.",
        "start": 1720.9,
        "duration": 1.69
    },
    {
        "text": "Now you can set up your infrastructure",
        "start": 1722.59,
        "duration": 2.355
    },
    {
        "text": "the way it's shown in the architecture.",
        "start": 1724.945,
        "duration": 2.145
    },
    {
        "text": "Do you have a secure version.",
        "start": 1727.09,
        "duration": 1.265
    },
    {
        "text": "You have a non-secure version",
        "start": 1728.355,
        "duration": 1.81
    },
    {
        "text": "with your different types of environment.",
        "start": 1730.165,
        "duration": 3.105
    },
    {
        "text": "You have a dev environment,",
        "start": 1733.27,
        "duration": 1.15
    },
    {
        "text": "you have a broad environment.",
        "start": 1734.42,
        "duration": 1.04
    },
    {
        "text": "You can set that up as well with your Python code,",
        "start": 1735.46,
        "duration": 3.63
    },
    {
        "text": "the CLI SDK version of it.",
        "start": 1739.09,
        "duration": 2.32
    },
    {
        "text": "It's not going to push it, but you can start to get to that.",
        "start": 1741.41,
        "duration": 4.64
    },
    {
        "text": "Now let me go back to GitHub and show you how it looks like.",
        "start": 1746.05,
        "duration": 5.67
    },
    {
        "text": "Once again I've pushed the code,",
        "start": 1751.72,
        "duration": 1.66
    },
    {
        "text": "I've done it a while back and you get",
        "start": 1753.38,
        "duration": 1.88
    },
    {
        "text": "a code that's good to get started with.",
        "start": 1755.26,
        "duration": 2.565
    },
    {
        "text": "Now, the way we did this is",
        "start": 1757.825,
        "duration": 2.205
    },
    {
        "text": "kept it in a very, very configurable manner.",
        "start": 1760.03,
        "duration": 3.255
    },
    {
        "text": "Like we said, we have two environments,",
        "start": 1763.285,
        "duration": 2.715
    },
    {
        "text": "dev and prod, and you can configure your names in here.",
        "start": 1766.0,
        "duration": 3.695
    },
    {
        "text": "Make sure some of these names are",
        "start": 1769.695,
        "duration": 1.745
    },
    {
        "text": "unique so that you know when you going to go out and deploy it,",
        "start": 1771.44,
        "duration": 3.46
    },
    {
        "text": "it's going to work through that.",
        "start": 1774.9,
        "duration": 1.635
    },
    {
        "text": ">> Right.",
        "start": 1776.535,
        "duration": 0.715
    },
    {
        "text": ">> You give your names to your namespace, your post space,",
        "start": 1777.25,
        "duration": 3.75
    },
    {
        "text": "and if you want, you know,",
        "start": 1781.0,
        "duration": 1.05
    },
    {
        "text": "feel free to configure any of these things. All right.",
        "start": 1782.05,
        "duration": 3.45
    },
    {
        "text": "Once you set this up, now you're good to go.",
        "start": 1785.5,
        "duration": 3.38
    },
    {
        "text": "Now you can say,",
        "start": 1788.88,
        "duration": 1.78
    },
    {
        "text": "let's build our pipelines and deploy our infrastructure,",
        "start": 1790.66,
        "duration": 3.905
    },
    {
        "text": "deploy our model training pipeline.",
        "start": 1794.565,
        "duration": 2.605
    },
    {
        "text": "Let me walk you through that.",
        "start": 1797.17,
        "duration": 2.92
    },
    {
        "text": ">> Now, before I set up my pipelines and everything,",
        "start": 1801.19,
        "duration": 4.6
    },
    {
        "text": "I need to make sure I have",
        "start": 1805.79,
        "duration": 1.605
    },
    {
        "text": "my service principles set up so that",
        "start": 1807.395,
        "duration": 2.355
    },
    {
        "text": "the pipelines can do what I'm asking it to do.",
        "start": 1809.75,
        "duration": 2.655
    },
    {
        "text": "Again, I set up two of them beforehand.",
        "start": 1812.405,
        "duration": 3.705
    },
    {
        "text": "Again, in the start getting guide,",
        "start": 1816.11,
        "duration": 2.025
    },
    {
        "text": "it walks you through the step of",
        "start": 1818.135,
        "duration": 1.575
    },
    {
        "text": "what permissions you need and how tight",
        "start": 1819.71,
        "duration": 2.25
    },
    {
        "text": "or how loose you want it to keep it",
        "start": 1821.96,
        "duration": 1.785
    },
    {
        "text": "right depending on your organization needs.",
        "start": 1823.745,
        "duration": 2.385
    },
    {
        "text": "You set up your service connections.",
        "start": 1826.13,
        "duration": 2.16
    },
    {
        "text": "I want to set up my GitHub connection",
        "start": 1828.29,
        "duration": 1.86
    },
    {
        "text": "because it certainly needs to",
        "start": 1830.15,
        "duration": 1.2
    },
    {
        "text": "pull in the pipelines and the codes for it as well,",
        "start": 1831.35,
        "duration": 3.36
    },
    {
        "text": "once you do that, now you're good to go.",
        "start": 1834.71,
        "duration": 2.895
    },
    {
        "text": "Let's start with adding a new pipeline.",
        "start": 1837.605,
        "duration": 3.06
    },
    {
        "text": "I've already connected my GitHub,",
        "start": 1840.665,
        "duration": 1.725
    },
    {
        "text": "so I don't need to get started.",
        "start": 1842.39,
        "duration": 1.35
    },
    {
        "text": "Now, I say that my MLOps test,",
        "start": 1843.74,
        "duration": 2.565
    },
    {
        "text": "my new fresh repo that was",
        "start": 1846.305,
        "duration": 2.505
    },
    {
        "text": "created by the cookie cutter is now ready.",
        "start": 1848.81,
        "duration": 2.895
    },
    {
        "text": "I can start to use this.",
        "start": 1851.705,
        "duration": 2.475
    },
    {
        "text": "Now I've picked up my repo,",
        "start": 1854.18,
        "duration": 1.965
    },
    {
        "text": "now it's going to ask me,",
        "start": 1856.145,
        "duration": 1.455
    },
    {
        "text": "where are my body, do you want to start",
        "start": 1857.6,
        "duration": 2.04
    },
    {
        "text": "with you or you want to pick existing ones?",
        "start": 1859.64,
        "duration": 2.175
    },
    {
        "text": "The good part is we give you existing pipeline to go with.",
        "start": 1861.815,
        "duration": 3.705
    },
    {
        "text": "We are going to pick the last option in the existing pipelines,",
        "start": 1865.52,
        "duration": 3.48
    },
    {
        "text": "which I already have in my YAML,",
        "start": 1869.0,
        "duration": 1.665
    },
    {
        "text": "and you will find a bunch of them that are in there.",
        "start": 1870.665,
        "duration": 2.97
    },
    {
        "text": "A good way to look at it as understand,",
        "start": 1873.635,
        "duration": 3.33
    },
    {
        "text": "if you're looking at your DevOps for your models,",
        "start": 1876.965,
        "duration": 2.325
    },
    {
        "text": "it's going to be sitting in there.",
        "start": 1879.29,
        "duration": 1.815
    },
    {
        "text": "For the infrastructure we have",
        "start": 1881.105,
        "duration": 2.13
    },
    {
        "text": "sitting it in the infrastructure pipeline.",
        "start": 1883.235,
        "duration": 2.115
    },
    {
        "text": "I'm just going to pick that just for the demo",
        "start": 1885.35,
        "duration": 2.85
    },
    {
        "text": "and it will show you the data part of it.",
        "start": 1888.2,
        "duration": 3.96
    },
    {
        "text": "Now, let me just take",
        "start": 1892.16,
        "duration": 1.89
    },
    {
        "text": "a couple of minutes to explain how we did it,",
        "start": 1894.05,
        "duration": 2.79
    },
    {
        "text": "I modified it for our demo here today.",
        "start": 1896.84,
        "duration": 3.765
    },
    {
        "text": "Now, some people might have more than one environment.",
        "start": 1900.605,
        "duration": 3.525
    },
    {
        "text": "Depending on how you're promoting your model,",
        "start": 1904.13,
        "duration": 2.82
    },
    {
        "text": "how you are promoting your code,",
        "start": 1906.95,
        "duration": 1.575
    },
    {
        "text": "we are showing you a approach of doing that.",
        "start": 1908.525,
        "duration": 3.465
    },
    {
        "text": "Now, instead of working with",
        "start": 1911.99,
        "duration": 1.68
    },
    {
        "text": "your approvals and everything through Azure DevOps,",
        "start": 1913.67,
        "duration": 3.915
    },
    {
        "text": "I am sure a lot of DevOps engineers know how to do it.",
        "start": 1917.585,
        "duration": 2.82
    },
    {
        "text": "One approach that we have here is do it via GitHub.",
        "start": 1920.405,
        "duration": 2.97
    },
    {
        "text": "When your code get promoted,",
        "start": 1923.375,
        "duration": 2.07
    },
    {
        "text": "you're working with the latest code in the specific environment,",
        "start": 1925.445,
        "duration": 4.365
    },
    {
        "text": "then I can pick up the names",
        "start": 1929.81,
        "duration": 1.98
    },
    {
        "text": "from the YAML that I showed you earlier.",
        "start": 1931.79,
        "duration": 3.105
    },
    {
        "text": ">> Got it.",
        "start": 1934.895,
        "duration": 2.1
    },
    {
        "text": ">> The other cool part of it is a lot of these are",
        "start": 1936.995,
        "duration": 4.485
    },
    {
        "text": "reusable templates which are also set out in a separate repo,",
        "start": 1941.48,
        "duration": 4.275
    },
    {
        "text": "because a lot of times you're going to",
        "start": 1945.755,
        "duration": 1.92
    },
    {
        "text": "reuse those steps over and over again.",
        "start": 1947.675,
        "duration": 2.625
    },
    {
        "text": "Imagine, we love to copy paste,",
        "start": 1950.3,
        "duration": 2.61
    },
    {
        "text": "and a lot of times a lot of",
        "start": 1952.91,
        "duration": 2.52
    },
    {
        "text": "errors are introduced because your copy pasting them.",
        "start": 1955.43,
        "duration": 2.94
    },
    {
        "text": "What we have done is now you have a template in there.",
        "start": 1958.37,
        "duration": 3.21
    },
    {
        "text": "Instead of saying that, okay,",
        "start": 1961.58,
        "duration": 1.59
    },
    {
        "text": "create a resource group or connect",
        "start": 1963.17,
        "duration": 2.16
    },
    {
        "text": "to a workspace for every step that you do,",
        "start": 1965.33,
        "duration": 2.625
    },
    {
        "text": "you can just refer to",
        "start": 1967.955,
        "duration": 1.905
    },
    {
        "text": "a YAML file and then it will just copy those steps from there.",
        "start": 1969.86,
        "duration": 3.465
    },
    {
        "text": "In a sense for organizations,",
        "start": 1973.325,
        "duration": 2.925
    },
    {
        "text": "you can create a more structured way of",
        "start": 1976.25,
        "duration": 2.85
    },
    {
        "text": "how your organization does MLOps and this is one",
        "start": 1979.1,
        "duration": 3.6
    },
    {
        "text": "of the suggested component approaches that we",
        "start": 1982.7,
        "duration": 3.12
    },
    {
        "text": "have adopted for this MLOps steps.",
        "start": 1985.82,
        "duration": 3.645
    },
    {
        "text": ">> This is cool. Basically this is",
        "start": 1989.465,
        "duration": 2.61
    },
    {
        "text": "setting up the full infrastructure",
        "start": 1992.075,
        "duration": 1.995
    },
    {
        "text": "that you would need to run the whole thing.",
        "start": 1994.07,
        "duration": 1.89
    },
    {
        "text": ">> Yeah, absolutely.",
        "start": 1995.96,
        "duration": 1.185
    },
    {
        "text": ">> That's Cool.",
        "start": 1997.145,
        "duration": 1.495
    },
    {
        "text": ">> Once you've set this up, run it.",
        "start": 1998.77,
        "duration": 3.175
    },
    {
        "text": "I did my pre work,",
        "start": 2001.945,
        "duration": 1.995
    },
    {
        "text": "I baked the cake ready,",
        "start": 2003.94,
        "duration": 1.29
    },
    {
        "text": "on the tv, it looks good.",
        "start": 2005.23,
        "duration": 1.815
    },
    {
        "text": "I do have my infrastructure,",
        "start": 2007.045,
        "duration": 2.13
    },
    {
        "text": "the one that I was just deploying so far,",
        "start": 2009.175,
        "duration": 2.28
    },
    {
        "text": "I did my model training online deployment and batch deployment.",
        "start": 2011.455,
        "duration": 4.125
    },
    {
        "text": "Let's just dive a little bit deeper into MLOps model.",
        "start": 2015.58,
        "duration": 4.96
    },
    {
        "text": "Now, when we go in there,",
        "start": 2020.67,
        "duration": 2.53
    },
    {
        "text": "I ran it a couple of times and I wanted to show you how.",
        "start": 2023.2,
        "duration": 2.925
    },
    {
        "text": "What it's taking is,",
        "start": 2026.125,
        "duration": 1.47
    },
    {
        "text": "it's taking my data that I already have,",
        "start": 2027.595,
        "duration": 2.49
    },
    {
        "text": "going through what we call as",
        "start": 2030.085,
        "duration": 2.205
    },
    {
        "text": "inner loop steps of preparing the data,",
        "start": 2032.29,
        "duration": 2.235
    },
    {
        "text": "cleaning it up, training it and creating a model out of it.",
        "start": 2034.525,
        "duration": 4.125
    },
    {
        "text": "It's doing all these steps for me",
        "start": 2038.65,
        "duration": 2.52
    },
    {
        "text": "and let me show you how the pipeline really looks like.",
        "start": 2041.17,
        "duration": 3.915
    },
    {
        "text": "Now, I check out my code,",
        "start": 2045.085,
        "duration": 3.855
    },
    {
        "text": "I install the AMLCLI,",
        "start": 2048.94,
        "duration": 2.655
    },
    {
        "text": "connect to Azure Workspace and then start running my job.",
        "start": 2051.595,
        "duration": 4.02
    },
    {
        "text": "When I run my job,",
        "start": 2055.615,
        "duration": 1.74
    },
    {
        "text": "you can see here, it's taking about 27 minutes,",
        "start": 2057.355,
        "duration": 2.67
    },
    {
        "text": "this is where it's setting up my compute,",
        "start": 2060.025,
        "duration": 3.645
    },
    {
        "text": "setting up my workspace and running the code in there,",
        "start": 2063.67,
        "duration": 3.885
    },
    {
        "text": "let me show you how the pipeline really looks like.",
        "start": 2067.555,
        "duration": 3.175
    },
    {
        "text": ">> As this is getting started,",
        "start": 2074.22,
        "duration": 2.26
    },
    {
        "text": "if you run it again,",
        "start": 2076.48,
        "duration": 1.395
    },
    {
        "text": "is it going to set up all the compute again for you or is",
        "start": 2077.875,
        "duration": 2.565
    },
    {
        "text": "it just going to use whatever was set up before?",
        "start": 2080.44,
        "duration": 3.06
    },
    {
        "text": ">> It's going to reuse what you have set up before,",
        "start": 2083.5,
        "duration": 3.06
    },
    {
        "text": "the first time when you run it,",
        "start": 2086.56,
        "duration": 1.2
    },
    {
        "text": "it often takes a longer time because it's setting up your compute,",
        "start": 2087.76,
        "duration": 3.48
    },
    {
        "text": "it's setting up your environment,",
        "start": 2091.24,
        "duration": 1.485
    },
    {
        "text": "but subsequent runs are much faster.",
        "start": 2092.725,
        "duration": 3.72
    },
    {
        "text": ">> That's cool.",
        "start": 2096.445,
        "duration": 0.54
    },
    {
        "text": ">> The other thing that I wanted to point out is you saw",
        "start": 2096.985,
        "duration": 2.985
    },
    {
        "text": "that the by-pipeline was",
        "start": 2099.97,
        "duration": 3.87
    },
    {
        "text": "running for about 27 minutes while it was doing the training.",
        "start": 2103.84,
        "duration": 3.165
    },
    {
        "text": "I'm sure a lot of DevOps guys who are watching",
        "start": 2107.005,
        "duration": 2.835
    },
    {
        "text": "this right now would feel a little bit uneasy.",
        "start": 2109.84,
        "duration": 3.15
    },
    {
        "text": "This is only for demo,",
        "start": 2112.99,
        "duration": 1.5
    },
    {
        "text": "you can pick and choose if",
        "start": 2114.49,
        "duration": 2.16
    },
    {
        "text": "you don't want to keep it up, blocking it.",
        "start": 2116.65,
        "duration": 2.325
    },
    {
        "text": "If you believe that, hey,",
        "start": 2118.975,
        "duration": 1.575
    },
    {
        "text": "once they submit the pipeline,",
        "start": 2120.55,
        "duration": 1.695
    },
    {
        "text": "let it run on its own and not block my MLOps runners,",
        "start": 2122.245,
        "duration": 3.705
    },
    {
        "text": "you can do that as well.",
        "start": 2125.95,
        "duration": 2.32
    },
    {
        "text": ">> I mean, that's machine learning folks were like, oh,",
        "start": 2128.64,
        "duration": 2.92
    },
    {
        "text": "it it only took 27 minutes,",
        "start": 2131.56,
        "duration": 1.95
    },
    {
        "text": "that's awesome, with infrastructure, too, really?",
        "start": 2133.51,
        "duration": 3.915
    },
    {
        "text": "I mean, do you know what I'm saying,",
        "start": 2137.425,
        "duration": 1.365
    },
    {
        "text": "because I feel like you said 27 minutes and I didn't bark at all,",
        "start": 2138.79,
        "duration": 3.69
    },
    {
        "text": "I was like, oh, okay, yeah, it's a nice model.",
        "start": 2142.48,
        "duration": 3.58
    },
    {
        "text": "But, a lot of folks get upset about this, right?",
        "start": 2147.45,
        "duration": 4.21
    },
    {
        "text": ">> Yeah, you're blocking my runners, free it up.",
        "start": 2151.66,
        "duration": 3.9
    },
    {
        "text": "You can do that you can submit your pipeline and let",
        "start": 2155.56,
        "duration": 2.64
    },
    {
        "text": "it run and it's going to go out and do it stuff.",
        "start": 2158.2,
        "duration": 2.85
    },
    {
        "text": "But then again, you have to make sure",
        "start": 2161.05,
        "duration": 2.34
    },
    {
        "text": "that the run is completed before you do that.",
        "start": 2163.39,
        "duration": 2.43
    },
    {
        "text": "Now, in my steps itself,",
        "start": 2165.82,
        "duration": 2.295
    },
    {
        "text": "what I did was I broke it out into",
        "start": 2168.115,
        "duration": 1.845
    },
    {
        "text": "different components and you can see",
        "start": 2169.96,
        "duration": 1.68
    },
    {
        "text": "that my pipeline is fairly I wouldn't say complex,",
        "start": 2171.64,
        "duration": 3.72
    },
    {
        "text": "but there are a lot of flows going in from one place to another.",
        "start": 2175.36,
        "duration": 4.215
    },
    {
        "text": "The good part of this is I can reuse this components that",
        "start": 2179.575,
        "duration": 4.035
    },
    {
        "text": "I have in another project",
        "start": 2183.61,
        "duration": 1.8
    },
    {
        "text": "so somebody doesn't have to write it again.",
        "start": 2185.41,
        "duration": 2.505
    },
    {
        "text": "Let's say, I have my evaluate model that I have built up or my",
        "start": 2187.915,
        "duration": 4.035
    },
    {
        "text": "train model which I'm using like GBM model.",
        "start": 2191.95,
        "duration": 3.75
    },
    {
        "text": "I can reuse this in a different project itself.",
        "start": 2195.7,
        "duration": 2.94
    },
    {
        "text": "Once you have a component, you register it,",
        "start": 2198.64,
        "duration": 3.63
    },
    {
        "text": "the reuse comes in there as well",
        "start": 2202.27,
        "duration": 2.085
    },
    {
        "text": "in your machine learning workspace too.",
        "start": 2204.355,
        "duration": 2.55
    },
    {
        "text": "Then you can connect it however you want it based",
        "start": 2206.905,
        "duration": 3.165
    },
    {
        "text": "on the needs that you have for the team as well.",
        "start": 2210.07,
        "duration": 3.315
    },
    {
        "text": "It's not opinionated from that perspective and it allows",
        "start": 2213.385,
        "duration": 3.165
    },
    {
        "text": "for reuse and sharing across the organizations.",
        "start": 2216.55,
        "duration": 2.925
    },
    {
        "text": ">> Here's the question how do you evaluate the models,",
        "start": 2219.475,
        "duration": 2.325
    },
    {
        "text": "looks like you made an evaluate model component.",
        "start": 2221.8,
        "duration": 2.64
    },
    {
        "text": "Are you comparing against other models",
        "start": 2224.44,
        "duration": 2.61
    },
    {
        "text": "or what's the evaluation process like?",
        "start": 2227.05,
        "duration": 3.825
    },
    {
        "text": ">> In evaluation we do quite a few things in there,",
        "start": 2230.875,
        "duration": 3.585
    },
    {
        "text": "let's say you're running with a couple of other models in there.",
        "start": 2234.46,
        "duration": 4.68
    },
    {
        "text": "The first time when it runs,",
        "start": 2239.14,
        "duration": 2.01
    },
    {
        "text": "it registers the model because it doesn't have",
        "start": 2241.15,
        "duration": 1.86
    },
    {
        "text": "any reference to compare it with.",
        "start": 2243.01,
        "duration": 2.415
    },
    {
        "text": "But when you run that subsequent run under the same experiment,",
        "start": 2245.425,
        "duration": 3.87
    },
    {
        "text": "what it's going to do is it's going to compare",
        "start": 2249.295,
        "duration": 2.715
    },
    {
        "text": "the model performance with",
        "start": 2252.01,
        "duration": 2.1
    },
    {
        "text": "that of the previously registered model.",
        "start": 2254.11,
        "duration": 2.43
    },
    {
        "text": "Let's say that registered model is in production now,",
        "start": 2256.54,
        "duration": 2.97
    },
    {
        "text": "it's going to be based on certain metrics.",
        "start": 2259.51,
        "duration": 2.52
    },
    {
        "text": "It's going to say, is my model performing better,",
        "start": 2262.03,
        "duration": 2.685
    },
    {
        "text": "yes or no, if it's not,",
        "start": 2264.715,
        "duration": 1.665
    },
    {
        "text": "I am not going to deploy it.",
        "start": 2266.38,
        "duration": 2.52
    },
    {
        "text": "We use that as one of the ways to make sure that,",
        "start": 2268.9,
        "duration": 4.98
    },
    {
        "text": "I'm not just randomly registering",
        "start": 2273.88,
        "duration": 2.19
    },
    {
        "text": "the models if it doesn't make sense.",
        "start": 2276.07,
        "duration": 2.475
    },
    {
        "text": "If people are playing around with algorithms,",
        "start": 2278.545,
        "duration": 2.835
    },
    {
        "text": "with feature engineering and developing their model's right,",
        "start": 2281.38,
        "duration": 3.99
    },
    {
        "text": "you can still do your experiment,",
        "start": 2285.37,
        "duration": 2.04
    },
    {
        "text": "but only the best model gets registered.",
        "start": 2287.41,
        "duration": 2.385
    },
    {
        "text": "In some sense, it brings",
        "start": 2289.795,
        "duration": 2.025
    },
    {
        "text": "some semblance into how your pipelines are run.",
        "start": 2291.82,
        "duration": 3.39
    },
    {
        "text": ">> That's clever because you said you're looking at",
        "start": 2295.21,
        "duration": 2.88
    },
    {
        "text": "previously registered models and",
        "start": 2298.09,
        "duration": 1.98
    },
    {
        "text": "comparing because just because you train a new model,",
        "start": 2300.07,
        "duration": 2.22
    },
    {
        "text": "does it mean it's going to be better,",
        "start": 2302.29,
        "duration": 2.17
    },
    {
        "text": "that's really smart, I like that.",
        "start": 2305.25,
        "duration": 3.65
    },
    {
        "text": ">> As an example, right,",
        "start": 2309.03,
        "duration": 2.41
    },
    {
        "text": "I think the screens are smaller,",
        "start": 2311.44,
        "duration": 1.41
    },
    {
        "text": "but you can see in the small window of mine,",
        "start": 2312.85,
        "duration": 3.555
    },
    {
        "text": "let me try to bring it up.",
        "start": 2316.405,
        "duration": 2.635
    },
    {
        "text": "In a small window of mine,",
        "start": 2319.11,
        "duration": 2.17
    },
    {
        "text": "it's also showing you the comparison,",
        "start": 2321.28,
        "duration": 2.43
    },
    {
        "text": "blue one is the previously registered model,",
        "start": 2323.71,
        "duration": 2.295
    },
    {
        "text": "the orange one is what I did.",
        "start": 2326.005,
        "duration": 2.085
    },
    {
        "text": "You can see that it didn't do well,",
        "start": 2328.09,
        "duration": 2.025
    },
    {
        "text": "it's going to skip registering the model,",
        "start": 2330.115,
        "duration": 2.46
    },
    {
        "text": "that's what is happening in my step at this point.",
        "start": 2332.575,
        "duration": 3.06
    },
    {
        "text": ">> That's cool, that makes a ton of sense.",
        "start": 2335.635,
        "duration": 3.775
    },
    {
        "text": ">> We talked about,",
        "start": 2339.93,
        "duration": 2.92
    },
    {
        "text": "doing this in a responsible way,",
        "start": 2342.85,
        "duration": 2.55
    },
    {
        "text": "my evaluate model also does a couple of things,",
        "start": 2345.4,
        "duration": 2.88
    },
    {
        "text": "it also evaluate for fairness.",
        "start": 2348.28,
        "duration": 2.595
    },
    {
        "text": "In the whole thing of doing this,",
        "start": 2350.875,
        "duration": 4.275
    },
    {
        "text": "I never explained what I'm doing in this whole process.",
        "start": 2355.15,
        "duration": 2.76
    },
    {
        "text": "My whole data set and the model that I'm building in",
        "start": 2357.91,
        "duration": 3.0
    },
    {
        "text": "here is about taxi fare prediction.",
        "start": 2360.91,
        "duration": 3.9
    },
    {
        "text": "Given a starting location,",
        "start": 2364.81,
        "duration": 1.965
    },
    {
        "text": "given an ending location and the daytime parameters,",
        "start": 2366.775,
        "duration": 3.255
    },
    {
        "text": "I try to estimate what is it going to cost?",
        "start": 2370.03,
        "duration": 2.88
    },
    {
        "text": "In my city for this demo,",
        "start": 2372.91,
        "duration": 2.61
    },
    {
        "text": "I have two vendors in there,",
        "start": 2375.52,
        "duration": 2.205
    },
    {
        "text": "I want to make sure that,",
        "start": 2377.725,
        "duration": 1.755
    },
    {
        "text": "my model is being fair to",
        "start": 2379.48,
        "duration": 1.53
    },
    {
        "text": "those vendors and not being biased across that.",
        "start": 2381.01,
        "duration": 2.61
    },
    {
        "text": "I use responsibly AI toolkit to do that evaluation in there so",
        "start": 2383.62,
        "duration": 4.26
    },
    {
        "text": "that model fairness evaluation",
        "start": 2387.88,
        "duration": 2.835
    },
    {
        "text": "is also done as part of my evaluation.",
        "start": 2390.715,
        "duration": 2.73
    },
    {
        "text": ">> Awesome. There's a little expand button,",
        "start": 2393.445,
        "duration": 3.3
    },
    {
        "text": "beneath job overview,",
        "start": 2396.745,
        "duration": 1.875
    },
    {
        "text": "click that one right there, down.",
        "start": 2398.62,
        "duration": 2.985
    },
    {
        "text": "Sorry, no, not that one.",
        "start": 2401.605,
        "duration": 7.185
    },
    {
        "text": ">> Let me get back to where I was.",
        "start": 2408.79,
        "duration": 1.875
    },
    {
        "text": ">> Yeah, there you go.",
        "start": 2410.665,
        "duration": 3.96
    },
    {
        "text": "You see right next to the one that closes it,",
        "start": 2414.625,
        "duration": 2.355
    },
    {
        "text": "is an expand button too.",
        "start": 2416.98,
        "duration": 2.4
    },
    {
        "text": "Not that one, that one, yes, lovely.",
        "start": 2419.38,
        "duration": 3.7
    },
    {
        "text": ">> In my model I have set up, like I said,",
        "start": 2425.37,
        "duration": 4.135
    },
    {
        "text": "there are two vendors in my city and",
        "start": 2429.505,
        "duration": 1.845
    },
    {
        "text": "these are the two subgroups that I have.",
        "start": 2431.35,
        "duration": 1.95
    },
    {
        "text": "I have already set up the fairness,",
        "start": 2433.3,
        "duration": 1.95
    },
    {
        "text": "let me walk you through which metrics that I'm going to run.",
        "start": 2435.25,
        "duration": 3.315
    },
    {
        "text": "Since this is a cost,",
        "start": 2438.565,
        "duration": 1.62
    },
    {
        "text": "I'm predicting a real number",
        "start": 2440.185,
        "duration": 2.975
    },
    {
        "text": "this essentially becomes a regression problem,",
        "start": 2443.16,
        "duration": 2.625
    },
    {
        "text": "I'm just going to work with means squared error and what is",
        "start": 2445.785,
        "duration": 3.915
    },
    {
        "text": "the metric that I'm going to evaluate the model with.",
        "start": 2449.7,
        "duration": 4.79
    },
    {
        "text": ">> I have my model.",
        "start": 2458.67,
        "duration": 4.33
    },
    {
        "text": "You can see that right now I'm comparing",
        "start": 2463.0,
        "duration": 2.385
    },
    {
        "text": "the two models that I have created and you can",
        "start": 2465.385,
        "duration": 3.195
    },
    {
        "text": "see that my current model does have some amount of",
        "start": 2468.58,
        "duration": 3.45
    },
    {
        "text": "bias in there as compared to the previously trained model,",
        "start": 2472.03,
        "duration": 3.81
    },
    {
        "text": "which had relatively lesser errors associated with that.",
        "start": 2475.84,
        "duration": 4.87
    },
    {
        "text": "It's not doing good. It still needs a little bit of tuning,",
        "start": 2481.08,
        "duration": 3.73
    },
    {
        "text": "but it gives you an idea that I",
        "start": 2484.81,
        "duration": 2.13
    },
    {
        "text": "can make this as part of my workflow.",
        "start": 2486.94,
        "duration": 2.79
    },
    {
        "text": "I don't have to go out and do this separately.",
        "start": 2489.73,
        "duration": 3.09
    },
    {
        "text": "I can use my existing models and",
        "start": 2492.82,
        "duration": 2.34
    },
    {
        "text": "existing steps to do it right in my process.",
        "start": 2495.16,
        "duration": 3.75
    },
    {
        "text": ">> Yeah, and that's cool because then in your evaluate step,",
        "start": 2498.91,
        "duration": 2.985
    },
    {
        "text": "you can actually use fairness as",
        "start": 2501.895,
        "duration": 2.865
    },
    {
        "text": "a measure of whether something is good or",
        "start": 2504.76,
        "duration": 1.8
    },
    {
        "text": "not and whether you want to put it in the registry.",
        "start": 2506.56,
        "duration": 2.505
    },
    {
        "text": ">> Absolutely, yeah?",
        "start": 2509.065,
        "duration": 1.545
    },
    {
        "text": ">> That's cool.",
        "start": 2510.61,
        "duration": 1.54
    },
    {
        "text": ">> I also have another step that I did as part of my evaluate,",
        "start": 2514.2,
        "duration": 4.689
    },
    {
        "text": "which is my model explanations right again.",
        "start": 2518.889,
        "duration": 3.731
    },
    {
        "text": "You want to make sure that the models that you're",
        "start": 2522.96,
        "duration": 3.25
    },
    {
        "text": "putting out are doing what they're supposed to do.",
        "start": 2526.21,
        "duration": 2.835
    },
    {
        "text": "They're not looking at this in CVs,",
        "start": 2529.045,
        "duration": 2.115
    },
    {
        "text": "if you've seen you look at",
        "start": 2531.16,
        "duration": 1.32
    },
    {
        "text": "the background and it's predicting where things are.",
        "start": 2532.48,
        "duration": 2.49
    },
    {
        "text": "Your typical feature are",
        "start": 2534.97,
        "duration": 1.86
    },
    {
        "text": "important so is or whether you want to play around.",
        "start": 2536.83,
        "duration": 2.085
    },
    {
        "text": "This whole explorer is",
        "start": 2538.915,
        "duration": 2.475
    },
    {
        "text": "out there for people to start to play with them.",
        "start": 2541.39,
        "duration": 2.085
    },
    {
        "text": "This is also one of the steps that",
        "start": 2543.475,
        "duration": 2.085
    },
    {
        "text": "we set up for working through that.",
        "start": 2545.56,
        "duration": 2.415
    },
    {
        "text": "As expected, your distance",
        "start": 2547.975,
        "duration": 2.34
    },
    {
        "text": "is one of the bigger factors of your cost,",
        "start": 2550.315,
        "duration": 2.07
    },
    {
        "text": "which is how it should be.",
        "start": 2552.385,
        "duration": 2.185
    },
    {
        "text": ">> This is really cool. That's why it",
        "start": 2554.64,
        "duration": 2.56
    },
    {
        "text": "took 27 minutes and it did all of this too.",
        "start": 2557.2,
        "duration": 4.62
    },
    {
        "text": ">> Yes, as part of the whole process.",
        "start": 2561.82,
        "duration": 3.51
    },
    {
        "text": ">> That's really cool.",
        "start": 2565.33,
        "duration": 2.59
    },
    {
        "text": ">> Once I have done my steps and the model is destroying that",
        "start": 2577.35,
        "duration": 6.37
    },
    {
        "text": "and you can see",
        "start": 2583.72,
        "duration": 2.7
    },
    {
        "text": "that the model does get registered in the model registry,",
        "start": 2586.42,
        "duration": 3.645
    },
    {
        "text": "which is something that now I can start to go out and",
        "start": 2590.065,
        "duration": 2.835
    },
    {
        "text": "deploy as an online endpoint or a batch endpoint.",
        "start": 2592.9,
        "duration": 4.485
    },
    {
        "text": "Again, the way we do this,",
        "start": 2597.385,
        "duration": 2.325
    },
    {
        "text": "typically people know that you write a scoring code and you do",
        "start": 2599.71,
        "duration": 4.68
    },
    {
        "text": "your online or batch deployments the way we have",
        "start": 2604.39,
        "duration": 2.49
    },
    {
        "text": "done it is through that e-mail flow models,",
        "start": 2606.88,
        "duration": 2.685
    },
    {
        "text": "which doesn't require a scoring code, which is cool.",
        "start": 2609.565,
        "duration": 3.03
    },
    {
        "text": "Because you have built your model,",
        "start": 2612.595,
        "duration": 1.155
    },
    {
        "text": "you have build your pipeline,",
        "start": 2613.75,
        "duration": 1.245
    },
    {
        "text": "why don't does that when you're doing that so you don't",
        "start": 2614.995,
        "duration": 2.355
    },
    {
        "text": "essentially require a scoring code itself.",
        "start": 2617.35,
        "duration": 2.805
    },
    {
        "text": "We use e-mail flow model to register it and that essentially",
        "start": 2620.155,
        "duration": 3.945
    },
    {
        "text": "can just go into your online or",
        "start": 2624.1,
        "duration": 2.16
    },
    {
        "text": "batch endpoints without much inputs in there.",
        "start": 2626.26,
        "duration": 3.42
    },
    {
        "text": ">> That's cool. That's why ML flow is awesome",
        "start": 2629.68,
        "duration": 3.36
    },
    {
        "text": "and we love it here at where we work.",
        "start": 2633.04,
        "duration": 2.625
    },
    {
        "text": "That's cool. We're running low on time.",
        "start": 2635.665,
        "duration": 3.33
    },
    {
        "text": "Any other things that you want to show us to wrap up?",
        "start": 2638.995,
        "duration": 3.435
    },
    {
        "text": ">> It's amazing of what it can do.",
        "start": 2642.43,
        "duration": 3.34
    },
    {
        "text": "The next one I am going to show you is",
        "start": 2649.86,
        "duration": 2.395
    },
    {
        "text": "online deployment and batch deployment.",
        "start": 2652.255,
        "duration": 2.535
    },
    {
        "text": "Just wanted to show you that all of",
        "start": 2654.79,
        "duration": 1.29
    },
    {
        "text": "these pipelines are available as part of the demo.",
        "start": 2656.08,
        "duration": 2.415
    },
    {
        "text": "In the online pipeline,",
        "start": 2658.495,
        "duration": 1.53
    },
    {
        "text": "I'm not going to walk you through the steps.",
        "start": 2660.025,
        "duration": 1.92
    },
    {
        "text": "You can believe me that it works.",
        "start": 2661.945,
        "duration": 2.205
    },
    {
        "text": "You can see that I did it.",
        "start": 2664.15,
        "duration": 2.7
    },
    {
        "text": "Not too long ago.",
        "start": 2666.85,
        "duration": 2.11
    },
    {
        "text": "Let me open up the endpoint.",
        "start": 2671.13,
        "duration": 2.635
    },
    {
        "text": "As you know, for most folks who have worked with Azure,",
        "start": 2673.765,
        "duration": 4.275
    },
    {
        "text": "the managed endpoint are essentially what we have",
        "start": 2678.04,
        "duration": 4.8
    },
    {
        "text": "it create both real-time and batch endpoint.",
        "start": 2682.84,
        "duration": 4.47
    },
    {
        "text": "It has a flexibility for allowing you to",
        "start": 2687.31,
        "duration": 2.55
    },
    {
        "text": "scale up and down as the demand permits.",
        "start": 2689.86,
        "duration": 2.895
    },
    {
        "text": "I have my, actually online model,",
        "start": 2692.755,
        "duration": 4.65
    },
    {
        "text": "which is deployed using my pipelines and it's up and running.",
        "start": 2697.405,
        "duration": 5.715
    },
    {
        "text": "After pipelines, we also do the test",
        "start": 2703.12,
        "duration": 2.19
    },
    {
        "text": "and typically people have different means of deploying that.",
        "start": 2705.31,
        "duration": 2.625
    },
    {
        "text": "You have taken a blue-green approach where",
        "start": 2707.935,
        "duration": 2.34
    },
    {
        "text": "you start with the existing model batch and",
        "start": 2710.275,
        "duration": 2.835
    },
    {
        "text": "smaller data to the newer models and scale it",
        "start": 2713.11,
        "duration": 2.28
    },
    {
        "text": "up as we start to believe that the model is doing well.",
        "start": 2715.39,
        "duration": 3.28
    },
    {
        "text": "That's there in the existing pipeline",
        "start": 2718.67,
        "duration": 2.8
    },
    {
        "text": "and it will swap out blue and",
        "start": 2721.47,
        "duration": 1.53
    },
    {
        "text": "green depending on how many times you have deployed it.",
        "start": 2723.0,
        "duration": 5.535
    },
    {
        "text": "I have a sample data in here.",
        "start": 2728.535,
        "duration": 2.67
    },
    {
        "text": "Just quickly copy it and show you that it works.",
        "start": 2731.205,
        "duration": 9.325
    },
    {
        "text": "This is my real-time endpoint.",
        "start": 2742.59,
        "duration": 2.44
    },
    {
        "text": "I can do my batch as well.",
        "start": 2745.03,
        "duration": 2.055
    },
    {
        "text": "Batch will not keep your machines running only when it's needed.",
        "start": 2747.085,
        "duration": 4.455
    },
    {
        "text": "It will create that cluster and do",
        "start": 2751.54,
        "duration": 2.34
    },
    {
        "text": "its job and then throw the output and then you're good to go.",
        "start": 2753.88,
        "duration": 3.18
    },
    {
        "text": ">> Well, these [inaudible].",
        "start": 2757.06,
        "duration": 1.29
    },
    {
        "text": ">> These are the pipelines that we have and we have more in-",
        "start": 2758.35,
        "duration": 4.42
    },
    {
        "text": ">> Yeah. I feel like you're lacking a little bit.",
        "start": 2763.41,
        "duration": 3.49
    },
    {
        "text": "I just want to say this is",
        "start": 2766.9,
        "duration": 1.53
    },
    {
        "text": "awesome stuff and we're running low on time.",
        "start": 2768.43,
        "duration": 2.835
    },
    {
        "text": "I want to go to you Moe just to finish up.",
        "start": 2771.265,
        "duration": 3.225
    },
    {
        "text": "Any wrap-up commentary you have for this?",
        "start": 2774.49,
        "duration": 2.895
    },
    {
        "text": ">> Yeah, I just want to underline that we are",
        "start": 2777.385,
        "duration": 2.43
    },
    {
        "text": "building like these other technology patterns in there.",
        "start": 2779.815,
        "duration": 2.805
    },
    {
        "text": "I mentioned synapse earlier,",
        "start": 2782.62,
        "duration": 1.35
    },
    {
        "text": "IoT we likely going to also look at a recommender solution,",
        "start": 2783.97,
        "duration": 4.26
    },
    {
        "text": "and so forth, a measure data bricks is a big one.",
        "start": 2788.23,
        "duration": 4.05
    },
    {
        "text": "This will be part of the solution accelerator",
        "start": 2792.28,
        "duration": 2.85
    },
    {
        "text": "overall and then I just can say contribute.",
        "start": 2795.13,
        "duration": 3.21
    },
    {
        "text": "This is a framework we basically give everyone",
        "start": 2798.34,
        "duration": 2.97
    },
    {
        "text": "we are looking for PRs we're looking for community engagement.",
        "start": 2801.31,
        "duration": 3.015
    },
    {
        "text": "We're looking for folks just to be active and help us to",
        "start": 2804.325,
        "duration": 3.525
    },
    {
        "text": "really build out something really big here that is unified.",
        "start": 2807.85,
        "duration": 4.695
    },
    {
        "text": "If you want to capture us at conferences or anywhere,",
        "start": 2812.545,
        "duration": 4.215
    },
    {
        "text": "we are always love helping others to be successful there,",
        "start": 2816.76,
        "duration": 3.6
    },
    {
        "text": "to speak there, and so forth. Please do so.",
        "start": 2820.36,
        "duration": 2.055
    },
    {
        "text": ">> Awesome, I'm putting a link. This is the GitHub link.",
        "start": 2822.415,
        "duration": 2.265
    },
    {
        "text": "It should be below for those that want to participate.",
        "start": 2824.68,
        "duration": 2.43
    },
    {
        "text": "Again, it feels like a very nice cookie-cutter way of doing",
        "start": 2827.11,
        "duration": 4.575
    },
    {
        "text": "a complex MLOps process set to show",
        "start": 2831.685,
        "duration": 3.465
    },
    {
        "text": "some amazing stuff when it comes to",
        "start": 2835.15,
        "duration": 2.31
    },
    {
        "text": "even because I didn't really I",
        "start": 2837.46,
        "duration": 1.32
    },
    {
        "text": "thought you just train the model and I was like,",
        "start": 2838.78,
        "duration": 1.41
    },
    {
        "text": "oh, 27 minutes, that's great.",
        "start": 2840.19,
        "duration": 1.305
    },
    {
        "text": "But doing the evaluation on it and then",
        "start": 2841.495,
        "duration": 3.105
    },
    {
        "text": "doing the fairness, that was amazing.",
        "start": 2844.6,
        "duration": 3.495
    },
    {
        "text": "Any final words from you? Moe.",
        "start": 2848.095,
        "duration": 2.835
    },
    {
        "text": ">> I think from my side, I'm good.",
        "start": 2850.93,
        "duration": 1.77
    },
    {
        "text": "I'm really excited.",
        "start": 2852.7,
        "duration": 1.71
    },
    {
        "text": "That's all I can say.",
        "start": 2854.41,
        "duration": 1.41
    },
    {
        "text": "We worked on this for the last couple of months.",
        "start": 2855.82,
        "duration": 2.49
    },
    {
        "text": "A project has its height and it has",
        "start": 2858.31,
        "duration": 2.52
    },
    {
        "text": "its lows and so forth and we're finally at a point",
        "start": 2860.83,
        "duration": 3.135
    },
    {
        "text": "that we can roll something out and then very",
        "start": 2863.965,
        "duration": 2.625
    },
    {
        "text": "unified way and I can just underline this over and over again,",
        "start": 2866.59,
        "duration": 3.615
    },
    {
        "text": "this is something really big and I'm excited Seth I'm excited.",
        "start": 2870.205,
        "duration": 4.5
    },
    {
        "text": ">> Well, I am too. I'm going to try to",
        "start": 2874.705,
        "duration": 1.485
    },
    {
        "text": "incorporate it into some of the stuff I do.",
        "start": 2876.19,
        "duration": 1.905
    },
    {
        "text": "Thanks so much for being with us, Moe",
        "start": 2878.095,
        "duration": 1.545
    },
    {
        "text": "and Setu thank you so much for watching.",
        "start": 2879.64,
        "duration": 1.47
    },
    {
        "text": "We're learning all about MLOps v2 unifying MLOps at Microsoft.",
        "start": 2881.11,
        "duration": 4.59
    },
    {
        "text": "Thank you so much for",
        "start": 2885.7,
        "duration": 1.74
    },
    {
        "text": "watching and hopefully we'll see you next time. Take care.",
        "start": 2887.44,
        "duration": 8.49
    },
    {
        "text": ">> [MUSIC]",
        "start": 2895.93,
        "duration": 3.71
    }
]