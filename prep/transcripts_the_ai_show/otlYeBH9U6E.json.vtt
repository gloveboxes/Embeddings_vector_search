[
    {
        "text": ">> Everyone you're not going to want to miss",
        "start": 1.28,
        "duration": 2.83
    },
    {
        "text": "this episode of the AI Show where we are going to",
        "start": 4.11,
        "duration": 2.34
    },
    {
        "text": "be learning how you can ignite",
        "start": 6.45,
        "duration": 1.65
    },
    {
        "text": "Developer Innovation with Vector Search and Azure Open AI.",
        "start": 8.1,
        "duration": 3.265
    },
    {
        "text": ">> [MUSIC]",
        "start": 11.365,
        "duration": 10.085
    },
    {
        "text": ">> Welcome we're joined by Liam,",
        "start": 21.45,
        "duration": 1.53
    },
    {
        "text": "who is a PM for Azure Cognitive Search with Vector Search.",
        "start": 22.98,
        "duration": 3.81
    },
    {
        "text": "Thank you so much for joining us.",
        "start": 26.79,
        "duration": 1.665
    },
    {
        "text": "Why don't you tell us a little bit about yourself.",
        "start": 28.455,
        "duration": 2.12
    },
    {
        "text": ">> Thanks for having me on the show, Cassie.",
        "start": 30.575,
        "duration": 2.035
    },
    {
        "text": "It's really nice to be here and be back.",
        "start": 32.61,
        "duration": 2.685
    },
    {
        "text": "I am the group Product Manager for Azure Cognitive Search and I'm",
        "start": 35.295,
        "duration": 5.615
    },
    {
        "text": "really excited to introduce",
        "start": 40.91,
        "duration": 2.4
    },
    {
        "text": "a new capability and show you",
        "start": 43.31,
        "duration": 1.74
    },
    {
        "text": "some cool things we've added to the product.",
        "start": 45.05,
        "duration": 2.375
    },
    {
        "text": ">> Great. There's probably a lot of people that might be",
        "start": 47.425,
        "duration": 2.785
    },
    {
        "text": "watching and being like what is even Vector Search?",
        "start": 50.21,
        "duration": 2.88
    },
    {
        "text": "Why don't we start with what it is",
        "start": 53.09,
        "duration": 1.86
    },
    {
        "text": "and how and why people make when use it.",
        "start": 54.95,
        "duration": 3.165
    },
    {
        "text": ">> Absolutely. One of the places that I",
        "start": 58.115,
        "duration": 2.925
    },
    {
        "text": "think would be great to start is this blog",
        "start": 61.04,
        "duration": 2.58
    },
    {
        "text": "close that we released which talks",
        "start": 63.62,
        "duration": 2.52
    },
    {
        "text": "a little bit about what Azure Cognitive Search is.",
        "start": 66.14,
        "duration": 2.805
    },
    {
        "text": "It walks through the details of it,",
        "start": 68.945,
        "duration": 2.25
    },
    {
        "text": "what we've done,",
        "start": 71.195,
        "duration": 1.155
    },
    {
        "text": "and some of the highlights of that.",
        "start": 72.35,
        "duration": 2.235
    },
    {
        "text": "But I think one of the things that",
        "start": 74.585,
        "duration": 2.265
    },
    {
        "text": "I'd love to do in this session is",
        "start": 76.85,
        "duration": 2.04
    },
    {
        "text": "just help people understand what exactly is vector search.",
        "start": 78.89,
        "duration": 4.105
    },
    {
        "text": "Like, why should I care?",
        "start": 82.995,
        "duration": 1.635
    },
    {
        "text": "How does it compare to the old traditional way of",
        "start": 84.63,
        "duration": 3.56
    },
    {
        "text": "doing text search and",
        "start": 88.19,
        "duration": 1.23
    },
    {
        "text": "just the types of things that this opens up, Cassie?",
        "start": 89.42,
        "duration": 3.56
    },
    {
        "text": ">> We know that vector embeddings are numbers,",
        "start": 92.98,
        "duration": 3.37
    },
    {
        "text": "and somehow we go from text to numbers.",
        "start": 96.35,
        "duration": 2.385
    },
    {
        "text": "Can you explain how the process works.",
        "start": 98.735,
        "duration": 2.78
    },
    {
        "text": ">> Absolutely. This is",
        "start": 101.515,
        "duration": 1.735
    },
    {
        "text": "a really interesting capability that it really opens up.",
        "start": 103.25,
        "duration": 3.81
    },
    {
        "text": "Because in the traditional,",
        "start": 107.06,
        "duration": 2.5
    },
    {
        "text": "we'll say the older way of searching,",
        "start": 109.56,
        "duration": 1.8
    },
    {
        "text": "it was all based on words.",
        "start": 111.36,
        "duration": 1.275
    },
    {
        "text": "Like, you could put in run runner running and it can",
        "start": 112.635,
        "duration": 2.885
    },
    {
        "text": "handle different variations of that, which was okay.",
        "start": 115.52,
        "duration": 3.655
    },
    {
        "text": "But what vectors have really unlocked is",
        "start": 119.175,
        "duration": 2.585
    },
    {
        "text": "this ability to take objects.",
        "start": 121.76,
        "duration": 2.49
    },
    {
        "text": "An object could be subtexts,",
        "start": 124.25,
        "duration": 2.34
    },
    {
        "text": "could be an image, could be a video.",
        "start": 126.59,
        "duration": 2.83
    },
    {
        "text": "It could be a molecule or a gene,",
        "start": 129.42,
        "duration": 2.51
    },
    {
        "text": "and it describes that in a vector space.",
        "start": 131.93,
        "duration": 3.3
    },
    {
        "text": "All the vector spaces is a set of",
        "start": 135.23,
        "duration": 2.07
    },
    {
        "text": "numbers that have a description of that.",
        "start": 137.3,
        "duration": 3.505
    },
    {
        "text": "You can see on the left side.",
        "start": 140.805,
        "duration": 1.32
    },
    {
        "text": "What we can do is we can use different types of models such as",
        "start": 142.125,
        "duration": 4.625
    },
    {
        "text": "Azure Open AI has an amazing one which",
        "start": 146.75,
        "duration": 2.37
    },
    {
        "text": "I'll show using something called ada-002,",
        "start": 149.12,
        "duration": 2.94
    },
    {
        "text": "which has this amazing ability to take",
        "start": 152.06,
        "duration": 2.67
    },
    {
        "text": "tax and make a vector representation of it.",
        "start": 154.73,
        "duration": 3.73
    },
    {
        "text": "What you can do is once you have those descriptions,",
        "start": 158.46,
        "duration": 3.17
    },
    {
        "text": "what you can do is then when you ask a question like, hey,",
        "start": 161.63,
        "duration": 2.94
    },
    {
        "text": "I'm looking for the capital of Canada.",
        "start": 164.57,
        "duration": 3.51
    },
    {
        "text": "I can go through and",
        "start": 168.08,
        "duration": 1.32
    },
    {
        "text": "that vectorized query goes through and it tries to",
        "start": 169.4,
        "duration": 2.58
    },
    {
        "text": "find the closest match in that vector space.",
        "start": 171.98,
        "duration": 4.36
    },
    {
        "text": "That is the power of a vector database.",
        "start": 176.34,
        "duration": 2.925
    },
    {
        "text": "Is it allows us to take massive numbers of vectors or content and",
        "start": 179.265,
        "duration": 5.405
    },
    {
        "text": "quickly get those answers effectively which",
        "start": 184.67,
        "duration": 2.535
    },
    {
        "text": "leads to amazing ChatGPT experiences and much more.",
        "start": 187.205,
        "duration": 4.205
    },
    {
        "text": ">> It's really enabling a lot of these next-level things that",
        "start": 191.41,
        "duration": 3.85
    },
    {
        "text": "we've been seeing in the AI space.",
        "start": 195.26,
        "duration": 3.97
    },
    {
        "text": "Now, I understand a little bit about what vectors are,",
        "start": 199.43,
        "duration": 3.69
    },
    {
        "text": "how we're able to take many types of data sources,",
        "start": 203.12,
        "duration": 2.7
    },
    {
        "text": "turn them into a vector representation,",
        "start": 205.82,
        "duration": 1.92
    },
    {
        "text": "and then be able to perform different tasks in order to",
        "start": 207.74,
        "duration": 3.015
    },
    {
        "text": "really enrich our applications and user experiences.",
        "start": 210.755,
        "duration": 3.465
    },
    {
        "text": "How does one use this?",
        "start": 214.22,
        "duration": 1.86
    },
    {
        "text": "How do we leverage this? What are good scenarios to use it for?",
        "start": 216.08,
        "duration": 3.17
    },
    {
        "text": ">> I have some code that I'd love to show to",
        "start": 219.25,
        "duration": 4.45
    },
    {
        "text": "hopefully start showing you",
        "start": 223.7,
        "duration": 2.25
    },
    {
        "text": "some of the things that we can do with this.",
        "start": 225.95,
        "duration": 2.685
    },
    {
        "text": "Luckily, we have some friends coming to talk about",
        "start": 228.635,
        "duration": 4.11
    },
    {
        "text": "some even more advanced scenarios",
        "start": 232.745,
        "duration": 3.045
    },
    {
        "text": "in subsequent sessions with Derek and Marcia.",
        "start": 235.79,
        "duration": 3.075
    },
    {
        "text": "But I thought it would be useful if we just",
        "start": 238.865,
        "duration": 1.95
    },
    {
        "text": "start with this Jupyter Notebook.",
        "start": 240.815,
        "duration": 2.51
    },
    {
        "text": "I can walk through how that all works",
        "start": 243.325,
        "duration": 2.515
    },
    {
        "text": "and show you some of your scenarios. Some work.",
        "start": 245.84,
        "duration": 2.755
    },
    {
        "text": ">> That's awesome.",
        "start": 248.595,
        "duration": 1.06
    },
    {
        "text": ">> That's cool. By the way all this code can be referred to from",
        "start": 249.655,
        "duration": 5.905
    },
    {
        "text": "this GitHub repo at the top here or going",
        "start": 255.56,
        "duration": 2.88
    },
    {
        "text": "to the blog post that you referred to earlier.",
        "start": 258.44,
        "duration": 3.275
    },
    {
        "text": "Let me just walk through this code.",
        "start": 261.715,
        "duration": 1.9
    },
    {
        "text": "Basically, what I'm going to do",
        "start": 263.615,
        "duration": 1.905
    },
    {
        "text": "here is I'm just in this first tab.",
        "start": 265.52,
        "duration": 2.79
    },
    {
        "text": "I'm just setting up all the imports for Python.",
        "start": 268.31,
        "duration": 2.895
    },
    {
        "text": "I'm going to be able to use",
        "start": 271.205,
        "duration": 1.845
    },
    {
        "text": "Azure Cognitive Search which we're going to",
        "start": 273.05,
        "duration": 2.19
    },
    {
        "text": "store all the vectors and do the querying against it.",
        "start": 275.24,
        "duration": 2.61
    },
    {
        "text": "We're going to be using Azure Open AI because we're",
        "start": 277.85,
        "duration": 3.075
    },
    {
        "text": "using Azure Open AI to take",
        "start": 280.925,
        "duration": 1.695
    },
    {
        "text": "the text and actually lies that content.",
        "start": 282.62,
        "duration": 2.615
    },
    {
        "text": "All I'm doing here is I'm",
        "start": 285.235,
        "duration": 2.275
    },
    {
        "text": "just setting up my configuration to connect",
        "start": 287.51,
        "duration": 2.73
    },
    {
        "text": "to Azure Cognitive Search and setting up my Azure Open AI,",
        "start": 290.24,
        "duration": 5.285
    },
    {
        "text": "config, and then I'm just creating",
        "start": 295.525,
        "duration": 2.305
    },
    {
        "text": "some connections that I'll be",
        "start": 297.83,
        "duration": 1.59
    },
    {
        "text": "using to interact with Azure Cognitive Search.",
        "start": 299.42,
        "duration": 2.3
    },
    {
        "text": ">> Here, it looks like you've already set up an Azure service.",
        "start": 301.72,
        "duration": 4.305
    },
    {
        "text": "I know that we're using the Cognitive Search Service but we're",
        "start": 306.025,
        "duration": 3.165
    },
    {
        "text": "using the Vector Search Capability.",
        "start": 309.19,
        "duration": 2.43
    },
    {
        "text": "Is there a different service that I",
        "start": 311.62,
        "duration": 1.51
    },
    {
        "text": "need to set up or how do I do that?",
        "start": 313.13,
        "duration": 2.01
    },
    {
        "text": ">> Great question Cassie. You're right.",
        "start": 315.14,
        "duration": 3.475
    },
    {
        "text": "I had previously created this Azure Cognitive Search Service.",
        "start": 318.615,
        "duration": 3.68
    },
    {
        "text": "You simply just go to the Azure portal",
        "start": 322.295,
        "duration": 2.025
    },
    {
        "text": "and just create the service.",
        "start": 324.32,
        "duration": 1.53
    },
    {
        "text": "You do not need to do anything special to have Vector Search.",
        "start": 325.85,
        "duration": 4.795
    },
    {
        "text": "Is just a new field,",
        "start": 330.645,
        "duration": 1.965
    },
    {
        "text": "a new datatype within",
        "start": 332.61,
        "duration": 2.09
    },
    {
        "text": "your search index that stores these numbers and",
        "start": 334.7,
        "duration": 2.22
    },
    {
        "text": "it allows us to do that similarity the search really effectively.",
        "start": 336.92,
        "duration": 5.165
    },
    {
        "text": ">> Awesome. Thank you.",
        "start": 342.085,
        "duration": 2.24
    },
    {
        "text": ">> Well, so let me keep on going here.",
        "start": 344.325,
        "duration": 2.17
    },
    {
        "text": "I want to walk through a couple of other pieces of code here.",
        "start": 346.495,
        "duration": 3.73
    },
    {
        "text": "I have two functions.",
        "start": 350.225,
        "duration": 1.82
    },
    {
        "text": "One is called generated embeddings.",
        "start": 352.045,
        "duration": 2.225
    },
    {
        "text": "Embeddings and vectors,",
        "start": 354.27,
        "duration": 1.5
    },
    {
        "text": "you can think of them as the same thing.",
        "start": 355.77,
        "duration": 2.325
    },
    {
        "text": "All this does is it receives",
        "start": 358.095,
        "duration": 2.675
    },
    {
        "text": "some text and it converts it to an embedding",
        "start": 360.77,
        "duration": 3.78
    },
    {
        "text": "using the Azure Open AI model called texts",
        "start": 364.55,
        "duration": 3.24
    },
    {
        "text": "embeddings ada-002 and it returns that back.",
        "start": 367.79,
        "duration": 3.965
    },
    {
        "text": "At this other function",
        "start": 371.755,
        "duration": 1.585
    },
    {
        "text": "that does something called cosine similarity.",
        "start": 373.34,
        "duration": 2.25
    },
    {
        "text": "All that is a way of us taking one vector",
        "start": 375.59,
        "duration": 4.53
    },
    {
        "text": "and actually comparing it to another vector and seeing",
        "start": 380.12,
        "duration": 2.4
    },
    {
        "text": "how close they are in similarity.",
        "start": 382.52,
        "duration": 2.805
    },
    {
        "text": "This will hopefully give us an idea of how vectors work and",
        "start": 385.325,
        "duration": 3.735
    },
    {
        "text": "why this idea of being able to search is so useful.",
        "start": 389.06,
        "duration": 3.95
    },
    {
        "text": ">> I see here in the engine you",
        "start": 393.01,
        "duration": 1.65
    },
    {
        "text": "said you're using an Open AI model.",
        "start": 394.66,
        "duration": 1.98
    },
    {
        "text": "What models are supported can I bring my own,",
        "start": 396.64,
        "duration": 2.58
    },
    {
        "text": "or how do I choose which model to",
        "start": 399.22,
        "duration": 1.8
    },
    {
        "text": "use when I'm done my vector embeddings?",
        "start": 401.02,
        "duration": 2.395
    },
    {
        "text": ">> It's really up to you.",
        "start": 403.415,
        "duration": 2.05
    },
    {
        "text": "You can use any model you like.",
        "start": 405.465,
        "duration": 2.445
    },
    {
        "text": "We do find that the vast majority of our customers have",
        "start": 407.91,
        "duration": 3.73
    },
    {
        "text": "been using this ada-002 model because it's so effective.",
        "start": 411.64,
        "duration": 3.9
    },
    {
        "text": "It's so good overtax.",
        "start": 415.54,
        "duration": 2.13
    },
    {
        "text": "However, if you were thinking",
        "start": 417.67,
        "duration": 2.925
    },
    {
        "text": "back to what we were just showing in that architectural diagram,",
        "start": 420.595,
        "duration": 3.75
    },
    {
        "text": "you can do more than texts.",
        "start": 424.345,
        "duration": 2.46
    },
    {
        "text": "Like, for example, that you can do image search.",
        "start": 426.805,
        "duration": 3.295
    },
    {
        "text": ">> In a subsequent session",
        "start": 430.1,
        "duration": 3.04
    },
    {
        "text": "that Vershe is going to come in and show how",
        "start": 433.14,
        "duration": 1.62
    },
    {
        "text": "the affluence model from",
        "start": 434.76,
        "duration": 2.565
    },
    {
        "text": "Vision can be used to convert images to embeddings.",
        "start": 437.325,
        "duration": 5.01
    },
    {
        "text": "But you can also use open source models,",
        "start": 442.335,
        "duration": 3.69
    },
    {
        "text": "some people create their own custom models that",
        "start": 446.025,
        "duration": 2.385
    },
    {
        "text": "are unique to their industry that they can use,",
        "start": 448.41,
        "duration": 2.415
    },
    {
        "text": "so we can support them all.",
        "start": 450.825,
        "duration": 1.845
    },
    {
        "text": ">> That's awesome and that's what I",
        "start": 452.67,
        "duration": 1.5
    },
    {
        "text": "was wondering sometimes you have",
        "start": 454.17,
        "duration": 0.96
    },
    {
        "text": "really specific things to the tasks that you're trying to solve.",
        "start": 455.13,
        "duration": 3.795
    },
    {
        "text": "Although these ones are generally the best right,",
        "start": 458.925,
        "duration": 2.76
    },
    {
        "text": "or for all tasks sometimes you need something more specialized.",
        "start": 461.685,
        "duration": 3.81
    },
    {
        "text": "All of that is supported and when you create",
        "start": 465.495,
        "duration": 2.565
    },
    {
        "text": "the engine or when you're using",
        "start": 468.06,
        "duration": 1.83
    },
    {
        "text": "the API here you can choose the best model.",
        "start": 469.89,
        "duration": 2.175
    },
    {
        "text": ">> That's exactly right. Let keep",
        "start": 472.065,
        "duration": 4.335
    },
    {
        "text": "going and I want to show you an actual example.",
        "start": 476.4,
        "duration": 4.02
    },
    {
        "text": "I love food, so I thought that",
        "start": 480.42,
        "duration": 2.955
    },
    {
        "text": "a good set of data to use would be recipes,",
        "start": 483.375,
        "duration": 4.035
    },
    {
        "text": "so just different food examples to show this.",
        "start": 487.41,
        "duration": 3.87
    },
    {
        "text": "I have to my favorite foods,",
        "start": 491.28,
        "duration": 2.265
    },
    {
        "text": "I have enchilada describes what that is and then pizza.",
        "start": 493.545,
        "duration": 4.95
    },
    {
        "text": "I haven't so what I'm going to do is I'm going",
        "start": 498.495,
        "duration": 2.325
    },
    {
        "text": "to generate embeddings for both increase,",
        "start": 500.82,
        "duration": 2.685
    },
    {
        "text": "and let's actually look at what that embedding looks like.",
        "start": 503.505,
        "duration": 3.84
    },
    {
        "text": "If we look at the first vector and just look",
        "start": 507.345,
        "duration": 2.025
    },
    {
        "text": "at the first 10 digits,",
        "start": 509.37,
        "duration": 2.025
    },
    {
        "text": "this is what ada-002,",
        "start": 511.395,
        "duration": 2.415
    },
    {
        "text": "describe that first sentence as that first set of text as.",
        "start": 513.81,
        "duration": 5.355
    },
    {
        "text": "Now, this means nothing to",
        "start": 519.165,
        "duration": 1.845
    },
    {
        "text": "me but being able to take those numbers,",
        "start": 521.01,
        "duration": 2.91
    },
    {
        "text": "and actually compare them is actually very useful.",
        "start": 523.92,
        "duration": 2.55
    },
    {
        "text": "Let me now do something different,",
        "start": 526.47,
        "duration": 2.265
    },
    {
        "text": "now I'm going to say okay,",
        "start": 528.735,
        "duration": 1.95
    },
    {
        "text": "what is a good Mexican food.",
        "start": 530.685,
        "duration": 2.28
    },
    {
        "text": "You can see here this is my query,",
        "start": 532.965,
        "duration": 2.49
    },
    {
        "text": "I'm going to convert it to a vector.",
        "start": 535.455,
        "duration": 2.175
    },
    {
        "text": "Then I'm going to say using that cosine similarity",
        "start": 537.63,
        "duration": 3.54
    },
    {
        "text": "convert the first vector to the question.",
        "start": 541.17,
        "duration": 4.5
    },
    {
        "text": "The second one and let's see which one is more similar,",
        "start": 545.67,
        "duration": 3.24
    },
    {
        "text": "and if we look at this we can see here that the first",
        "start": 548.91,
        "duration": 4.11
    },
    {
        "text": "one which burst to enchilada is actually more relevant.",
        "start": 553.02,
        "duration": 4.5
    },
    {
        "text": "This is why ada the 002 model is so great,",
        "start": 557.52,
        "duration": 4.99
    },
    {
        "text": "there's nothing referring to Mexico or Mexican in",
        "start": 562.55,
        "duration": 5.29
    },
    {
        "text": "that first since but it knew that",
        "start": 567.84,
        "duration": 1.65
    },
    {
        "text": "the similarity between Mexican and enchilada.",
        "start": 569.49,
        "duration": 2.955
    },
    {
        "text": "What's much more similar or if I change this to",
        "start": 572.445,
        "duration": 3.63
    },
    {
        "text": "Italian and actually let's misspell at here.",
        "start": 576.075,
        "duration": 4.635
    },
    {
        "text": "We can actually see here that the numbers change slightly.",
        "start": 580.71,
        "duration": 4.68
    },
    {
        "text": "It handles these semantics so much more effectively,",
        "start": 585.39,
        "duration": 4.08
    },
    {
        "text": "than some of the ways that we were doing in the textual search.",
        "start": 589.47,
        "duration": 4.85
    },
    {
        "text": ">> I think those are really great way to break down",
        "start": 594.32,
        "duration": 2.4
    },
    {
        "text": "how it's able to understand. We get.",
        "start": 596.72,
        "duration": 2.25
    },
    {
        "text": "words that are turned into",
        "start": 598.97,
        "duration": 1.44
    },
    {
        "text": "numbers and then it's really easy to see what similar.",
        "start": 600.41,
        "duration": 2.325
    },
    {
        "text": "Because in the embedded space",
        "start": 602.735,
        "duration": 1.395
    },
    {
        "text": "they're closer together therefore they're similar.",
        "start": 604.13,
        "duration": 1.835
    },
    {
        "text": ">> Exactly, and so hopefully I've",
        "start": 605.965,
        "duration": 2.405
    },
    {
        "text": "shown this doing this all in Python this is",
        "start": 608.37,
        "duration": 4.11
    },
    {
        "text": "just using out of the box code but",
        "start": 612.48,
        "duration": 3.54
    },
    {
        "text": "realistically most people don't just have two sentences.",
        "start": 616.02,
        "duration": 4.245
    },
    {
        "text": "They have massive numbers of",
        "start": 620.265,
        "duration": 1.815
    },
    {
        "text": "documents that they need to search over,",
        "start": 622.08,
        "duration": 2.1
    },
    {
        "text": "and so having to scan through every single one of",
        "start": 624.18,
        "duration": 3.81
    },
    {
        "text": "these pieces of text and try to find more similar",
        "start": 627.99,
        "duration": 2.58
    },
    {
        "text": "is not an efficient way of doing this.",
        "start": 630.57,
        "duration": 2.925
    },
    {
        "text": "That's where vector databases like Azure Cognitive Search,",
        "start": 633.495,
        "duration": 3.345
    },
    {
        "text": "really allow us to scale that so you can put",
        "start": 636.84,
        "duration": 2.58
    },
    {
        "text": "in massive amounts of vectors.",
        "start": 639.42,
        "duration": 2.73
    },
    {
        "text": "Search through them really quickly and efficiently and I'd love to",
        "start": 642.15,
        "duration": 3.12
    },
    {
        "text": "show how that works within Cognitive Search Cassie.",
        "start": 645.27,
        "duration": 3.54
    },
    {
        "text": ">> That'd be awesome.",
        "start": 648.81,
        "duration": 1.755
    },
    {
        "text": "My brain's going with all the different ways",
        "start": 650.565,
        "duration": 2.07
    },
    {
        "text": "that would be useful in so many different fields,",
        "start": 652.635,
        "duration": 1.875
    },
    {
        "text": "I used to work in the legal field so tons of documents",
        "start": 654.51,
        "duration": 2.43
    },
    {
        "text": "there this is really cool.",
        "start": 656.94,
        "duration": 4.035
    },
    {
        "text": "It's not hard to think about",
        "start": 660.975,
        "duration": 2.175
    },
    {
        "text": "what scenarios people might want to use",
        "start": 663.15,
        "duration": 1.77
    },
    {
        "text": "this for I think that people are",
        "start": 664.92,
        "duration": 1.26
    },
    {
        "text": "probably going crazy with ideas right now.",
        "start": 666.18,
        "duration": 2.34
    },
    {
        "text": ">> It's so true and legal is such an interesting one as well,",
        "start": 668.52,
        "duration": 2.7
    },
    {
        "text": "because all the different ways that a single thing is referred to.",
        "start": 671.22,
        "duration": 5.16
    },
    {
        "text": "All the different variations of those words is really hard,",
        "start": 676.38,
        "duration": 2.64
    },
    {
        "text": "and finding the right content can be hard if you don't",
        "start": 679.02,
        "duration": 3.435
    },
    {
        "text": "know those semantics or those semantically similar words,",
        "start": 682.455,
        "duration": 3.945
    },
    {
        "text": "and this really helps in that space.",
        "start": 686.4,
        "duration": 3.045
    },
    {
        "text": "Let's go into a little bit more of an extensive example,",
        "start": 689.445,
        "duration": 3.81
    },
    {
        "text": "and so here I just have four different examples",
        "start": 693.255,
        "duration": 4.08
    },
    {
        "text": "of content that I want to load",
        "start": 697.335,
        "duration": 2.115
    },
    {
        "text": "into cognitive search that it wanted to do better search over.",
        "start": 699.45,
        "duration": 2.58
    },
    {
        "text": "We have that first ones which talked",
        "start": 702.03,
        "duration": 1.65
    },
    {
        "text": "about the enchilada and the pizza,",
        "start": 703.68,
        "duration": 1.83
    },
    {
        "text": "there's another one here that has a little bit",
        "start": 705.51,
        "duration": 3.69
    },
    {
        "text": "more about a secret ingredients for pizza sauce.",
        "start": 709.2,
        "duration": 3.735
    },
    {
        "text": "This is just another random sentence,",
        "start": 712.935,
        "duration": 2.4
    },
    {
        "text": "you'll notice here that there's also we've",
        "start": 715.335,
        "duration": 1.935
    },
    {
        "text": "added categories to this as well.",
        "start": 717.27,
        "duration": 2.355
    },
    {
        "text": "Because sometimes filtering is informed as well.",
        "start": 719.625,
        "duration": 3.06
    },
    {
        "text": "Let me just take that liaison.",
        "start": 722.685,
        "duration": 3.51
    },
    {
        "text": "All I'm going to do is for every single item in that array,",
        "start": 726.195,
        "duration": 7.155
    },
    {
        "text": "I'm just going to create an embedding for it vector for it.",
        "start": 733.35,
        "duration": 4.455
    },
    {
        "text": "It's going to run through, it's just going to go through",
        "start": 737.805,
        "duration": 2.625
    },
    {
        "text": "each one and it's going to add that,",
        "start": 740.43,
        "duration": 2.81
    },
    {
        "text": "and if I look at this first one here you'll see",
        "start": 743.24,
        "duration": 2.1
    },
    {
        "text": "that it looks pretty much similar.",
        "start": 745.34,
        "duration": 2.4
    },
    {
        "text": "It's got the same text",
        "start": 747.74,
        "duration": 2.56
    },
    {
        "text": "sorry I have to there's a lot of numbers here,",
        "start": 750.3,
        "duration": 2.28
    },
    {
        "text": "to scroll up and we can actually see here that we have",
        "start": 752.58,
        "duration": 3.57
    },
    {
        "text": "the first item the enchilada and here's",
        "start": 756.15,
        "duration": 2.4
    },
    {
        "text": "that vector representation of it, so that's there.",
        "start": 758.55,
        "duration": 4.41
    },
    {
        "text": "Now, what I'm going to do is I'm going to",
        "start": 762.96,
        "duration": 2.82
    },
    {
        "text": "load this into Azure Cognitive Search.",
        "start": 765.78,
        "duration": 2.31
    },
    {
        "text": "I wanted to show you how this works.",
        "start": 768.09,
        "duration": 3.345
    },
    {
        "text": "In Azure Cognitive Search we have something called a search index.",
        "start": 771.435,
        "duration": 3.585
    },
    {
        "text": "Index is just like almost like a table in a database,",
        "start": 775.02,
        "duration": 3.33
    },
    {
        "text": "where you have different fields",
        "start": 778.35,
        "duration": 2.22
    },
    {
        "text": "or columns that you can store the data,",
        "start": 780.57,
        "duration": 2.475
    },
    {
        "text": "and those fields have different capabilities.",
        "start": 783.045,
        "duration": 2.34
    },
    {
        "text": "For example I have a unique identifier for my recipe,",
        "start": 785.385,
        "duration": 3.735
    },
    {
        "text": "remember I was talking about the category which I can then",
        "start": 789.12,
        "duration": 2.85
    },
    {
        "text": "filter or group if I want to.",
        "start": 791.97,
        "duration": 3.195
    },
    {
        "text": "Add the actual text of the recipe and here's",
        "start": 795.165,
        "duration": 3.765
    },
    {
        "text": "that new datatype we're referring to which is a vector field.",
        "start": 798.93,
        "duration": 4.29
    },
    {
        "text": "That allows me to store those numbers and use it for",
        "start": 803.22,
        "duration": 2.88
    },
    {
        "text": "semantic search so I'm going to create that index.",
        "start": 806.1,
        "duration": 4.215
    },
    {
        "text": "We have some configuration for",
        "start": 810.315,
        "duration": 2.415
    },
    {
        "text": "the vector work that we can do so this helps us",
        "start": 812.73,
        "duration": 3.06
    },
    {
        "text": "from that performance and",
        "start": 815.79,
        "duration": 1.83
    },
    {
        "text": "accuracy trade offs that",
        "start": 817.62,
        "duration": 2.31
    },
    {
        "text": "you can apply when you're doing that search.",
        "start": 819.93,
        "duration": 2.55
    },
    {
        "text": "Then I'm going to I'm not going",
        "start": 822.48,
        "duration": 1.86
    },
    {
        "text": "to talk about this right now but I'm going to",
        "start": 824.34,
        "duration": 1.47
    },
    {
        "text": "show you in a few minutes",
        "start": 825.81,
        "duration": 1.08
    },
    {
        "text": "this other capability we have called semantic.",
        "start": 826.89,
        "duration": 2.79
    },
    {
        "text": "I'm going to leave that for now,",
        "start": 829.68,
        "duration": 1.515
    },
    {
        "text": "and then we're going to just create that index.",
        "start": 831.195,
        "duration": 3.12
    },
    {
        "text": "Now, that I've created the index,",
        "start": 834.315,
        "duration": 2.385
    },
    {
        "text": "I'm going to take my documents load them up.",
        "start": 836.7,
        "duration": 3.945
    },
    {
        "text": "Which includes all that vector information,",
        "start": 840.645,
        "duration": 3.135
    },
    {
        "text": "it's now existing in Azure Cognitive Search and I can actually",
        "start": 843.78,
        "duration": 3.0
    },
    {
        "text": "start doing my searches against it.",
        "start": 846.78,
        "duration": 4.02
    },
    {
        "text": "The first one I'm going to do,",
        "start": 850.8,
        "duration": 2.91
    },
    {
        "text": "is I'm going to search for Italian food,",
        "start": 853.71,
        "duration": 2.025
    },
    {
        "text": "and of course I misspelled it here,",
        "start": 855.735,
        "duration": 2.31
    },
    {
        "text": "just to make sure it's working.",
        "start": 858.045,
        "duration": 2.04
    },
    {
        "text": "It's going to go through execute that search you can see",
        "start": 860.085,
        "duration": 4.385
    },
    {
        "text": "how it's converting that query to an embedding,",
        "start": 864.47,
        "duration": 4.035
    },
    {
        "text": "and it's going to use my recipe vector field.",
        "start": 868.505,
        "duration": 3.045
    },
    {
        "text": "Because you can have multiple vector fields in",
        "start": 871.55,
        "duration": 2.265
    },
    {
        "text": "Azure Cognitive Search and let's print out the results.",
        "start": 873.815,
        "duration": 3.26
    },
    {
        "text": "We see here that we did pretty well,",
        "start": 877.075,
        "duration": 3.935
    },
    {
        "text": "we put in Italian food and",
        "start": 881.01,
        "duration": 3.11
    },
    {
        "text": "we have all different results that came back here.",
        "start": 884.12,
        "duration": 3.12
    },
    {
        "text": "We have this one about pizza,",
        "start": 887.24,
        "duration": 1.65
    },
    {
        "text": "we have this one about the pizza sauce.",
        "start": 888.89,
        "duration": 3.555
    },
    {
        "text": "Some other items that aren't quite as relevant but it came up.",
        "start": 892.445,
        "duration": 3.925
    },
    {
        "text": "As you can see here we got this result that",
        "start": 896.87,
        "duration": 3.21
    },
    {
        "text": "came back but sometimes it's important to be",
        "start": 900.08,
        "duration": 2.76
    },
    {
        "text": "able to adjust the categories",
        "start": 902.84,
        "duration": 2.64
    },
    {
        "text": "based on what's important to you like maybe if I'm",
        "start": 905.48,
        "duration": 2.37
    },
    {
        "text": "going to a jewelry store I might",
        "start": 907.85,
        "duration": 2.34
    },
    {
        "text": "want to filter it based on whether it's a necklace.",
        "start": 910.19,
        "duration": 3.235
    },
    {
        "text": ">> Bracelet or in this case I have",
        "start": 913.425,
        "duration": 3.115
    },
    {
        "text": "categories of standard content and premium content.",
        "start": 916.54,
        "duration": 3.3
    },
    {
        "text": "Maybe I might want to say is okay I found a great match for here",
        "start": 919.84,
        "duration": 3.84
    },
    {
        "text": "but I only want to bring back content that was standard.",
        "start": 923.68,
        "duration": 3.975
    },
    {
        "text": "What I can do is because search has",
        "start": 927.655,
        "duration": 3.375
    },
    {
        "text": "a lot more functionality than just the vectors I can make",
        "start": 931.03,
        "duration": 3.87
    },
    {
        "text": "a change to this and just say let me",
        "start": 934.9,
        "duration": 1.8
    },
    {
        "text": "filter where the category equals",
        "start": 936.7,
        "duration": 2.37
    },
    {
        "text": "standard execute that exact same search and you can",
        "start": 939.07,
        "duration": 2.82
    },
    {
        "text": "see here how it only rock back that specific information.",
        "start": 941.89,
        "duration": 3.315
    },
    {
        "text": "Being able to allow us to enable",
        "start": 945.205,
        "duration": 2.295
    },
    {
        "text": "metadata and filtering from that is pretty critical as well.",
        "start": 947.5,
        "duration": 4.6
    },
    {
        "text": ">> That's super helpful. I might have a category of",
        "start": 952.1,
        "duration": 2.44
    },
    {
        "text": "documents that I want to already section out",
        "start": 954.54,
        "duration": 2.815
    },
    {
        "text": "and then do my vector search",
        "start": 957.355,
        "duration": 2.625
    },
    {
        "text": "on top of that to get really exact results.",
        "start": 959.98,
        "duration": 2.595
    },
    {
        "text": ">> Exactly. One of the things Cassie I'd love to do",
        "start": 962.575,
        "duration": 4.155
    },
    {
        "text": "is talk a little bit more about some of",
        "start": 966.73,
        "duration": 1.71
    },
    {
        "text": "the limitations of vector search.",
        "start": 968.44,
        "duration": 2.37
    },
    {
        "text": "Some other things that we've approach to help",
        "start": 970.81,
        "duration": 3.345
    },
    {
        "text": "enable vector search along with other different techniques.",
        "start": 974.155,
        "duration": 4.56
    },
    {
        "text": "I think a good way to do that",
        "start": 978.715,
        "duration": 1.995
    },
    {
        "text": "is if I take a different example here.",
        "start": 980.71,
        "duration": 2.025
    },
    {
        "text": "When change the query from Italian food to just food with cheese.",
        "start": 982.735,
        "duration": 4.665
    },
    {
        "text": "You'll notice in this result which was",
        "start": 987.4,
        "duration": 3.24
    },
    {
        "text": "just using vectors it wasn't using text or anything like that,",
        "start": 990.64,
        "duration": 3.81
    },
    {
        "text": "you notice I got an interesting result.",
        "start": 994.45,
        "duration": 2.58
    },
    {
        "text": "I said food with cheese and you could",
        "start": 997.03,
        "duration": 1.8
    },
    {
        "text": "probably guess that my intent",
        "start": 998.83,
        "duration": 1.725
    },
    {
        "text": "was a recipe or food that includes cheese,",
        "start": 1000.555,
        "duration": 4.14
    },
    {
        "text": "which you'll notice here why it came back like",
        "start": 1004.695,
        "duration": 3.18
    },
    {
        "text": "cheesy extremely semantically similar to the word cheese.",
        "start": 1007.875,
        "duration": 4.5
    },
    {
        "text": "Food and cook very similar",
        "start": 1012.375,
        "duration": 2.88
    },
    {
        "text": "and actually the amount of texts that",
        "start": 1015.255,
        "duration": 1.365
    },
    {
        "text": "was there was pretty similar.",
        "start": 1016.62,
        "duration": 1.32
    },
    {
        "text": "You can understand from a recall perspective that",
        "start": 1017.94,
        "duration": 4.29
    },
    {
        "text": "vectors are really good at why it came",
        "start": 1022.23,
        "duration": 2.13
    },
    {
        "text": "back and why it was pretty effective.",
        "start": 1024.36,
        "duration": 2.52
    },
    {
        "text": "But realistically that's not my intent.",
        "start": 1026.88,
        "duration": 3.225
    },
    {
        "text": "I was probably wanting something more like an enchilada or pizza.",
        "start": 1030.105,
        "duration": 4.23
    },
    {
        "text": "That's why what we have is we've also added",
        "start": 1034.335,
        "duration": 3.795
    },
    {
        "text": "not only vector search support but we've added",
        "start": 1038.13,
        "duration": 3.24
    },
    {
        "text": "additional capabilities and we have",
        "start": 1041.37,
        "duration": 1.8
    },
    {
        "text": "two things that really helped there.",
        "start": 1043.17,
        "duration": 2.44
    },
    {
        "text": "The first is something called a hybrid.",
        "start": 1045.61,
        "duration": 2.095
    },
    {
        "text": "I want to be very clear on how we define",
        "start": 1047.705,
        "duration": 2.325
    },
    {
        "text": "hybrid because there's a couple of different definitions.",
        "start": 1050.03,
        "duration": 2.715
    },
    {
        "text": "But what we mean by hybrid is that it leverages scores from",
        "start": 1052.745,
        "duration": 4.785
    },
    {
        "text": "vectors as well as scores",
        "start": 1057.53,
        "duration": 2.26
    },
    {
        "text": "from the traditional texts and using both.",
        "start": 1059.79,
        "duration": 4.365
    },
    {
        "text": "Text is really good a recall.",
        "start": 1064.155,
        "duration": 2.265
    },
    {
        "text": "If we use both that combines and allows us to bump",
        "start": 1066.42,
        "duration": 3.96
    },
    {
        "text": "the relevancy generally just what",
        "start": 1070.38,
        "duration": 3.09
    },
    {
        "text": "the industry really says a lot better.",
        "start": 1073.47,
        "duration": 2.34
    },
    {
        "text": "But on top of that we have",
        "start": 1075.81,
        "duration": 2.28
    },
    {
        "text": "another ranking layer called semantic search which is",
        "start": 1078.09,
        "duration": 4.245
    },
    {
        "text": "a set of family models that come from",
        "start": 1082.335,
        "duration": 2.775
    },
    {
        "text": "Bing that add an extra layer of ranking.",
        "start": 1085.11,
        "duration": 4.5
    },
    {
        "text": "I'd love to show you what that looks like when I apply this.",
        "start": 1089.61,
        "duration": 4.83
    },
    {
        "text": ">> These are just things you going to add in to your search query.",
        "start": 1094.44,
        "duration": 5.655
    },
    {
        "text": ">> Exactly.",
        "start": 1100.095,
        "duration": 0.645
    },
    {
        "text": ">> Add in as additional, that's it. Cool.",
        "start": 1100.74,
        "duration": 2.265
    },
    {
        "text": ">> When you were asking about creating the vector search",
        "start": 1103.005,
        "duration": 3.075
    },
    {
        "text": "that is one thing you do need to enable in your search service.",
        "start": 1106.08,
        "duration": 4.41
    },
    {
        "text": "You just turn it on we have a free option and",
        "start": 1110.49,
        "duration": 1.74
    },
    {
        "text": "a paid option if you wish.",
        "start": 1112.23,
        "duration": 1.83
    },
    {
        "text": "But you can see here I'm just telling you",
        "start": 1114.06,
        "duration": 1.845
    },
    {
        "text": "I'm going to use a semantic query.",
        "start": 1115.905,
        "duration": 2.28
    },
    {
        "text": "I am using it in English.",
        "start": 1118.185,
        "duration": 2.205
    },
    {
        "text": "If you recall when I was creating the index",
        "start": 1120.39,
        "duration": 2.49
    },
    {
        "text": "I had a configuration for that, so I'm going to use it.",
        "start": 1122.88,
        "duration": 2.94
    },
    {
        "text": "Now I'm also going to pass in the query.",
        "start": 1125.82,
        "duration": 2.865
    },
    {
        "text": "Not only am I passing in the vector but",
        "start": 1128.685,
        "duration": 3.795
    },
    {
        "text": "I'm actually passing the text of food with cheese.",
        "start": 1132.48,
        "duration": 3.765
    },
    {
        "text": "If we search this now you'll notice that the results",
        "start": 1136.245,
        "duration": 3.285
    },
    {
        "text": "that come back are a bit more effective.",
        "start": 1139.53,
        "duration": 3.555
    },
    {
        "text": "It did bring that cheesy one but it's much lower down in the list.",
        "start": 1143.085,
        "duration": 4.29
    },
    {
        "text": "Because all of these things are using",
        "start": 1147.375,
        "duration": 3.015
    },
    {
        "text": "text for hybrid as well as our updated semantic model which by",
        "start": 1150.39,
        "duration": 4.32
    },
    {
        "text": "the way we'd just deployed",
        "start": 1154.71,
        "duration": 1.26
    },
    {
        "text": "a brand new updated model at the start",
        "start": 1155.97,
        "duration": 3.21
    },
    {
        "text": "of August which has been really effective.",
        "start": 1159.18,
        "duration": 3.6
    },
    {
        "text": "This has really made a big improvement",
        "start": 1162.78,
        "duration": 2.28
    },
    {
        "text": "to the relevancy of results.",
        "start": 1165.06,
        "duration": 2.1
    },
    {
        "text": ">> That's awesome. That's so cool to be able to see that adding",
        "start": 1167.16,
        "duration": 3.63
    },
    {
        "text": "those into your search queries can improve the results that much.",
        "start": 1170.79,
        "duration": 4.15
    },
    {
        "text": ">> This is so important.",
        "start": 1175.22,
        "duration": 2.23
    },
    {
        "text": "Especially earlier Seth and",
        "start": 1177.45,
        "duration": 3.39
    },
    {
        "text": "I were talking about enterprise ChatGPT,",
        "start": 1180.84,
        "duration": 3.27
    },
    {
        "text": "a Leveraging Azure Cognitive Search,",
        "start": 1184.11,
        "duration": 2.1
    },
    {
        "text": "to recall information that can help the chat experience.",
        "start": 1186.21,
        "duration": 4.44
    },
    {
        "text": "This right here is so important.",
        "start": 1190.65,
        "duration": 2.37
    },
    {
        "text": "Because you can only send a certain amount of",
        "start": 1193.02,
        "duration": 2.4
    },
    {
        "text": "content into Azure Open AI because of token limits and costs.",
        "start": 1195.42,
        "duration": 4.14
    },
    {
        "text": "It is critical to get the top results as effectively as you can.",
        "start": 1199.56,
        "duration": 6.12
    },
    {
        "text": "This is really important not only to search but",
        "start": 1205.68,
        "duration": 2.625
    },
    {
        "text": "even to some of these generative AI applications.",
        "start": 1208.305,
        "duration": 3.36
    },
    {
        "text": ">> That's so true like when I had",
        "start": 1211.665,
        "duration": 2.265
    },
    {
        "text": "been playing with prompt flow in Azure ML and in",
        "start": 1213.93,
        "duration": 2.985
    },
    {
        "text": "generating those prompts using",
        "start": 1216.915,
        "duration": 2.415
    },
    {
        "text": "Cognitive Search with vector embeddings has been extremely",
        "start": 1219.33,
        "duration": 3.03
    },
    {
        "text": "helpful in being able to get the correct documentation",
        "start": 1222.36,
        "duration": 2.94
    },
    {
        "text": "to give context to large linkage model to get those answers.",
        "start": 1225.3,
        "duration": 3.735
    },
    {
        "text": "This adding your own data into",
        "start": 1229.035,
        "duration": 2.265
    },
    {
        "text": "large language models is",
        "start": 1231.3,
        "duration": 1.38
    },
    {
        "text": "a game changer in application development.",
        "start": 1232.68,
        "duration": 2.17
    },
    {
        "text": ">> Absolutely and one of the things that",
        "start": 1234.85,
        "duration": 2.26
    },
    {
        "text": "I'd love to leave everyone with",
        "start": 1237.11,
        "duration": 2.13
    },
    {
        "text": "for some of the subsequent sessions that we're",
        "start": 1239.24,
        "duration": 2.01
    },
    {
        "text": "going to go through is that,",
        "start": 1241.25,
        "duration": 2.475
    },
    {
        "text": "I've showed a really simple example,",
        "start": 1243.725,
        "duration": 1.86
    },
    {
        "text": "a very small set of data.",
        "start": 1245.585,
        "duration": 1.575
    },
    {
        "text": "But we actually use Azure Open AI to create",
        "start": 1247.16,
        "duration": 2.925
    },
    {
        "text": "a couple thousand recipes as well as images for those recipes.",
        "start": 1250.085,
        "duration": 5.19
    },
    {
        "text": "If I change to that index and I'm just going to",
        "start": 1255.275,
        "duration": 3.235
    },
    {
        "text": "do a quick search to give you an idea of what we're going to do.",
        "start": 1258.51,
        "duration": 3.3
    },
    {
        "text": "I'm going to try to find an Italian recipe",
        "start": 1261.81,
        "duration": 2.28
    },
    {
        "text": "that includes meat and parmasan",
        "start": 1264.09,
        "duration": 1.68
    },
    {
        "text": "which I completely misspelled so much in here.",
        "start": 1265.77,
        "duration": 3.93
    },
    {
        "text": "You can see here the result that comes back, we have the image,",
        "start": 1269.7,
        "duration": 5.025
    },
    {
        "text": "we're going to show us some cool things around",
        "start": 1274.725,
        "duration": 1.71
    },
    {
        "text": "image search as well as the ability to",
        "start": 1276.435,
        "duration": 2.475
    },
    {
        "text": "like understand the different variations",
        "start": 1278.91,
        "duration": 1.68
    },
    {
        "text": "of me misspelling all these things.",
        "start": 1280.59,
        "duration": 3.195
    },
    {
        "text": "I'm pure hopeful that everyone's going to join",
        "start": 1283.785,
        "duration": 2.175
    },
    {
        "text": "for some of those subsequent sessions as well.",
        "start": 1285.96,
        "duration": 3.165
    },
    {
        "text": ">> That is super cool. You can",
        "start": 1289.125,
        "duration": 2.895
    },
    {
        "text": "you go back up to the query that you sent in.",
        "start": 1292.02,
        "duration": 2.235
    },
    {
        "text": ">> Absolutely.",
        "start": 1294.255,
        "duration": 0.75
    },
    {
        "text": ">> The only thing you change was the index you were pointing at.",
        "start": 1295.005,
        "duration": 2.25
    },
    {
        "text": "The query and everything else you sent it is the same.",
        "start": 1297.255,
        "duration": 2.19
    },
    {
        "text": ">> That is correct. That was the only change I made.",
        "start": 1299.445,
        "duration": 2.85
    },
    {
        "text": "It has the exact same type",
        "start": 1302.295,
        "duration": 2.895
    },
    {
        "text": "of queries that is using semantic as you can see here.",
        "start": 1305.19,
        "duration": 2.61
    },
    {
        "text": "I do have a couple additional fields",
        "start": 1307.8,
        "duration": 2.175
    },
    {
        "text": "in this one that I didn't have in the undirected index.",
        "start": 1309.975,
        "duration": 2.295
    },
    {
        "text": "That's basically the only change.",
        "start": 1312.27,
        "duration": 2.46
    },
    {
        "text": ">> Amazing and delicious.",
        "start": 1314.73,
        "duration": 4.275
    },
    {
        "text": "Now I want to take the food.",
        "start": 1319.005,
        "duration": 1.74
    },
    {
        "text": ">> I know. That's a downside of doing",
        "start": 1320.745,
        "duration": 2.595
    },
    {
        "text": "this one and it sure makes me very hungry every time that I do it.",
        "start": 1323.34,
        "duration": 3.225
    },
    {
        "text": "But hopefully that gives everyone",
        "start": 1326.565,
        "duration": 4.665
    },
    {
        "text": "a good idea of what vector searches",
        "start": 1331.23,
        "duration": 1.83
    },
    {
        "text": "and hopefully it inspires some ideas of things that you can do.",
        "start": 1333.06,
        "duration": 3.96
    },
    {
        "text": ">> The possibilities are endless I think that probably",
        "start": 1337.02,
        "duration": 2.85
    },
    {
        "text": "a lot of people have had to like",
        "start": 1339.87,
        "duration": 2.295
    },
    {
        "text": "the problems that we're solving our problems that developers have",
        "start": 1342.165,
        "duration": 2.355
    },
    {
        "text": "had before but we haven't had these tools to do it this way.",
        "start": 1344.52,
        "duration": 3.51
    },
    {
        "text": "I think that there's probably",
        "start": 1348.03,
        "duration": 1.68
    },
    {
        "text": "even different scenarios where people have tried to solve this in",
        "start": 1349.71,
        "duration": 2.64
    },
    {
        "text": "probably not get nearly the results that you",
        "start": 1352.35,
        "duration": 1.89
    },
    {
        "text": "can not do by adding on",
        "start": 1354.24,
        "duration": 2.1
    },
    {
        "text": "vector search and different embeddings into what you already have.",
        "start": 1356.34,
        "duration": 4.56
    },
    {
        "text": ">> Absolutely. It really has changed the game that's for sure.",
        "start": 1360.9,
        "duration": 3.975
    },
    {
        "text": ">> We went over a lot of really cool information on how to",
        "start": 1364.875,
        "duration": 3.675
    },
    {
        "text": "start using vectors search within Azure Cognitive Search.",
        "start": 1368.55,
        "duration": 3.54
    },
    {
        "text": "Where can people go to learn more and get started?",
        "start": 1372.09,
        "duration": 3.09
    },
    {
        "text": ">> I think the best place is what we can refer",
        "start": 1375.18,
        "duration": 3.54
    },
    {
        "text": "to that back to this blog post that we were we're talking about.",
        "start": 1378.72,
        "duration": 3.195
    },
    {
        "text": "But we also have the Azure Cognitive Search documentation which is",
        "start": 1381.915,
        "duration": 3.585
    },
    {
        "text": "always a great resource to learn more and get started as well.",
        "start": 1385.5,
        "duration": 4.23
    },
    {
        "text": ">> Awesome. Go out check out these resources get started.",
        "start": 1389.73,
        "duration": 3.9
    },
    {
        "text": "Thank you so much for hanging out with us today.",
        "start": 1393.63,
        "duration": 2.73
    },
    {
        "text": ">> Thank you.",
        "start": 1396.36,
        "duration": 1.87
    }
]