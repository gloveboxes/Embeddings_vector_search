[
    {
        "text": ">> Get caught up on all the new features inside",
        "start": 0.0,
        "duration": 2.07
    },
    {
        "text": "of Computer and Custom Vision in",
        "start": 2.07,
        "duration": 2.14
    },
    {
        "text": "this episode of the AI Show where",
        "start": 4.21,
        "duration": 1.89
    },
    {
        "text": "Kelly takes us through all of the awesome features,",
        "start": 6.1,
        "duration": 2.845
    },
    {
        "text": "make sure you take a look.",
        "start": 8.945,
        "duration": 2.415
    },
    {
        "text": "Hello and welcome to this episode of the AI Show.",
        "start": 13.74,
        "duration": 3.16
    },
    {
        "text": "We're going to talk about Cognitive",
        "start": 16.9,
        "duration": 1.26
    },
    {
        "text": "Services specifically vision services.",
        "start": 18.16,
        "duration": 1.81
    },
    {
        "text": "I got my friend Kelly. How are you doing my friend?",
        "start": 19.97,
        "duration": 1.5
    },
    {
        "text": ">> Pretty good. How are you doing?",
        "start": 21.47,
        "duration": 0.95
    },
    {
        "text": ">> Fantastic. So, tell us",
        "start": 22.42,
        "duration": 1.34
    },
    {
        "text": "what you do, at Cognitive Services.",
        "start": 23.76,
        "duration": 1.585
    },
    {
        "text": ">> So, we work on the vision specifically and we look at",
        "start": 25.345,
        "duration": 2.405
    },
    {
        "text": "how we can add intelligent vision to your apps.",
        "start": 27.75,
        "duration": 2.69
    },
    {
        "text": "So, your custom vision and computer vision will help you",
        "start": 30.44,
        "duration": 3.41
    },
    {
        "text": "build vision models and we also prebuild models for you.",
        "start": 33.85,
        "duration": 3.4
    },
    {
        "text": ">> So, it's like AI,",
        "start": 37.25,
        "duration": 1.36
    },
    {
        "text": "but you don't have to think",
        "start": 38.61,
        "duration": 1.49
    },
    {
        "text": "about it you just call it and it does the right thing.",
        "start": 40.1,
        "duration": 1.66
    },
    {
        "text": ">> Exactly.",
        "start": 41.76,
        "duration": 0.68
    },
    {
        "text": ">> Fantastic. So, what are we talking about",
        "start": 42.44,
        "duration": 1.69
    },
    {
        "text": "the things that are new for this update, right?",
        "start": 44.13,
        "duration": 2.16
    },
    {
        "text": ">> Yes.",
        "start": 46.29,
        "duration": 0.505
    },
    {
        "text": ">> Awesome. So, why don't you go to them?",
        "start": 46.795,
        "duration": 1.655
    },
    {
        "text": ">> All right. So, for computer vision,",
        "start": 48.45,
        "duration": 2.54
    },
    {
        "text": "this is where we have all of our prebuilt models.",
        "start": 50.99,
        "duration": 1.7
    },
    {
        "text": "This is things like image tagging, captioning, OCR.",
        "start": 52.69,
        "duration": 3.04
    },
    {
        "text": "We also now are offering a new version of OCR,",
        "start": 55.73,
        "duration": 3.81
    },
    {
        "text": "which is significantly better,",
        "start": 59.54,
        "duration": 1.4
    },
    {
        "text": "we'll go through some examples of that.",
        "start": 60.94,
        "duration": 1.59
    },
    {
        "text": ">> Cool.",
        "start": 62.53,
        "duration": 0.22
    },
    {
        "text": ">> And we're also expanding the languages",
        "start": 62.75,
        "duration": 1.56
    },
    {
        "text": "available for captioning.",
        "start": 64.31,
        "duration": 1.41
    },
    {
        "text": ">> Awesome and this is really good",
        "start": 65.72,
        "duration": 1.68
    },
    {
        "text": "because like you're building a social media site for",
        "start": 67.4,
        "duration": 2.24
    },
    {
        "text": "example and someone's trying to sneak in",
        "start": 69.64,
        "duration": 1.885
    },
    {
        "text": "offensive material in a picture,",
        "start": 71.525,
        "duration": 2.485
    },
    {
        "text": "you can now capture it",
        "start": 74.01,
        "duration": 1.23
    },
    {
        "text": "right away and know this is happening.",
        "start": 75.24,
        "duration": 1.4
    },
    {
        "text": ">> Exactly. And what",
        "start": 76.64,
        "duration": 1.07
    },
    {
        "text": "this new engine does is it doesn't really well with",
        "start": 77.71,
        "duration": 1.55
    },
    {
        "text": "those pictures that it has",
        "start": 79.26,
        "duration": 1.3
    },
    {
        "text": "a background in pictures and words on top of it.",
        "start": 80.56,
        "duration": 2.38
    },
    {
        "text": ">> Now I'm able to solve",
        "start": 82.94,
        "duration": 1.44
    },
    {
        "text": "those capture problems that everyone wants.",
        "start": 84.38,
        "duration": 2.1
    },
    {
        "text": "I'm just kidding, of course. So these are",
        "start": 86.48,
        "duration": 2.47
    },
    {
        "text": "the new features OCR and language for captioning?",
        "start": 88.95,
        "duration": 2.71
    },
    {
        "text": ">> Yes.",
        "start": 91.66,
        "duration": 0.24
    },
    {
        "text": ">> Anything else that you want to add?",
        "start": 91.9,
        "duration": 2.07
    },
    {
        "text": ">> No, I think that's it for-",
        "start": 93.97,
        "duration": 1.39
    },
    {
        "text": ">> For this one. So are we doing a demo,",
        "start": 95.36,
        "duration": 1.9
    },
    {
        "text": "are you are going to show us what's",
        "start": 97.26,
        "duration": 0.8
    },
    {
        "text": "new in the custom for [inaudible]",
        "start": 98.06,
        "duration": 0.93
    },
    {
        "text": ">> So, let's show a little bit about the OCR [inaudible] first.",
        "start": 98.99,
        "duration": 2.22
    },
    {
        "text": ">> Let's do it.",
        "start": 101.21,
        "duration": 0.84
    },
    {
        "text": ">> So, this is an example of text on image.",
        "start": 102.05,
        "duration": 3.84
    },
    {
        "text": "This is what the old one did",
        "start": 105.89,
        "duration": 1.56
    },
    {
        "text": "and this is what our new one does.",
        "start": 107.45,
        "duration": 1.305
    },
    {
        "text": "So as you can see it catches a whole",
        "start": 108.755,
        "duration": 1.405
    },
    {
        "text": "lot more and a lot more accurately.",
        "start": 110.16,
        "duration": 1.63
    },
    {
        "text": ">> I see. And so, in this case,",
        "start": 111.79,
        "duration": 2.105
    },
    {
        "text": "it's just an API call that you're calling,",
        "start": 113.895,
        "duration": 2.055
    },
    {
        "text": "you're saying the image and then it",
        "start": 115.95,
        "duration": 1.03
    },
    {
        "text": "returns this text back.",
        "start": 116.98,
        "duration": 1.385
    },
    {
        "text": "What is it that you're actually getting back?",
        "start": 118.365,
        "duration": 1.895
    },
    {
        "text": ">> So, you'll get the actual bounding box of where it is.",
        "start": 120.26,
        "duration": 2.665
    },
    {
        "text": ">> Okay.",
        "start": 122.925,
        "duration": 0.265
    },
    {
        "text": ">> And the text in it.",
        "start": 123.19,
        "duration": 1.25
    },
    {
        "text": ">> Okay. That's pretty amazing.",
        "start": 124.44,
        "duration": 1.63
    },
    {
        "text": ">> Yes.",
        "start": 126.07,
        "duration": 0.21
    },
    {
        "text": ">> Awesome.",
        "start": 126.28,
        "duration": 0.53
    },
    {
        "text": ">> So, a few more examples of that.",
        "start": 126.81,
        "duration": 2.75
    },
    {
        "text": "This our old one didn't catch",
        "start": 130.03,
        "duration": 2.23
    },
    {
        "text": "anything and now you can see that the whole sign says.",
        "start": 132.26,
        "duration": 2.26
    },
    {
        "text": "And so, this is one of those where it's hard to see",
        "start": 134.52,
        "duration": 1.67
    },
    {
        "text": "because you have lines over it,",
        "start": 136.19,
        "duration": 1.94
    },
    {
        "text": "it's at an angle but we're still catching the words here.",
        "start": 138.13,
        "duration": 2.32
    },
    {
        "text": ">> That's really cool now.",
        "start": 140.45,
        "duration": 1.01
    },
    {
        "text": "Did you just make a newer OCR model",
        "start": 141.46,
        "duration": 2.16
    },
    {
        "text": "or how why is it that it's better now?",
        "start": 143.62,
        "duration": 1.85
    },
    {
        "text": ">> So, we have two OCR models.",
        "start": 145.47,
        "duration": 2.2
    },
    {
        "text": "We have the handwritten one and",
        "start": 147.67,
        "duration": 1.78
    },
    {
        "text": "the one for text that",
        "start": 149.45,
        "duration": 1.925
    },
    {
        "text": "works and I think it's 23 languages.",
        "start": 151.375,
        "duration": 2.67
    },
    {
        "text": "So, this is an extension of the handwriting one.",
        "start": 154.045,
        "duration": 2.235
    },
    {
        "text": "It only works in English, but it's",
        "start": 156.28,
        "duration": 1.2
    },
    {
        "text": "a much more powerful model.",
        "start": 157.48,
        "duration": 1.485
    },
    {
        "text": ">> I see. Okay. Awesome. All right, what else you got?",
        "start": 158.965,
        "duration": 2.415
    },
    {
        "text": ">> So, you got a few more examples.",
        "start": 161.38,
        "duration": 2.84
    },
    {
        "text": "The old one it caught all the words,",
        "start": 164.22,
        "duration": 2.34
    },
    {
        "text": "but it didn't exactly get them right.",
        "start": 166.56,
        "duration": 1.1
    },
    {
        "text": "And now here I think a more accurate model.",
        "start": 167.66,
        "duration": 2.73
    },
    {
        "text": ">> That's cool.",
        "start": 170.39,
        "duration": 1.35
    },
    {
        "text": ">> And one more. This one you can see those things over",
        "start": 171.74,
        "duration": 2.94
    },
    {
        "text": "the words and yet we're still catching.",
        "start": 174.68,
        "duration": 3.125
    },
    {
        "text": ">> And the bounding box too,",
        "start": 177.805,
        "duration": 2.055
    },
    {
        "text": "which I think is important right?",
        "start": 179.86,
        "duration": 1.23
    },
    {
        "text": "Because you can see the bounding boxes",
        "start": 181.09,
        "duration": 1.67
    },
    {
        "text": "are kind of okay on the first one,",
        "start": 182.76,
        "duration": 1.895
    },
    {
        "text": "but they're even better on the second one.",
        "start": 184.655,
        "duration": 1.4
    },
    {
        "text": ">> Yes, yes.",
        "start": 186.055,
        "duration": 0.885
    },
    {
        "text": ">> And it caught \"AND\" too, that's amazing.",
        "start": 186.94,
        "duration": 2.935
    },
    {
        "text": "Cool. And so again,",
        "start": 189.875,
        "duration": 1.125
    },
    {
        "text": "it's just a call is it's something",
        "start": 191.0,
        "duration": 1.16
    },
    {
        "text": "that you have to- Because I remember when I",
        "start": 192.16,
        "duration": 1.27
    },
    {
        "text": "called the API had to tell it like",
        "start": 193.43,
        "duration": 1.67
    },
    {
        "text": "what I wanted it to return.",
        "start": 195.1,
        "duration": 1.88
    },
    {
        "text": "Is it just another fly that you put in?",
        "start": 196.98,
        "duration": 1.72
    },
    {
        "text": ">> Yes. So, this will be recognized",
        "start": 198.7,
        "duration": 1.24
    },
    {
        "text": "text and then it will say,",
        "start": 199.94,
        "duration": 1.685
    },
    {
        "text": "handwritten, false and you'll get the printed text.",
        "start": 201.625,
        "duration": 3.155
    },
    {
        "text": ">> Fantastic. All right.",
        "start": 204.78,
        "duration": 1.31
    },
    {
        "text": "Now we actually want a custom vision.",
        "start": 206.09,
        "duration": 1.32
    },
    {
        "text": ">> Yes. So, for custom vision,",
        "start": 207.41,
        "duration": 2.2
    },
    {
        "text": "those of you who don't know what it is.",
        "start": 209.61,
        "duration": 1.42
    },
    {
        "text": "It's a tool to build up",
        "start": 211.03,
        "duration": 2.63
    },
    {
        "text": "an image classification models",
        "start": 213.66,
        "duration": 2.23
    },
    {
        "text": "quickly, easily with little data.",
        "start": 215.89,
        "duration": 1.89
    },
    {
        "text": ">> I see. So, this is the case",
        "start": 217.78,
        "duration": 2.16
    },
    {
        "text": "when computer vision isn't quite enough.",
        "start": 219.94,
        "duration": 3.155
    },
    {
        "text": "You want to learn to distinguish between",
        "start": 223.095,
        "duration": 1.405
    },
    {
        "text": "your own stuff. Did I get that right?",
        "start": 224.5,
        "duration": 1.51
    },
    {
        "text": ">> Exactly. And I think that you",
        "start": 226.01,
        "duration": 1.27
    },
    {
        "text": "can't- that we aren't currently looking for.",
        "start": 227.28,
        "duration": 2.18
    },
    {
        "text": "So, if it's something specific to",
        "start": 229.46,
        "duration": 1.34
    },
    {
        "text": "you or to something obscure,",
        "start": 230.8,
        "duration": 1.54
    },
    {
        "text": "you can use custom vision to get that.",
        "start": 232.34,
        "duration": 1.605
    },
    {
        "text": ">> Fantastic. And just an overview.",
        "start": 233.945,
        "duration": 2.265
    },
    {
        "text": "How does one train the thing?",
        "start": 236.21,
        "duration": 1.45
    },
    {
        "text": ">> So, you upload",
        "start": 237.66,
        "duration": 1.23
    },
    {
        "text": "some images you had",
        "start": 238.89,
        "duration": 0.77
    },
    {
        "text": "trained and then you get back a model.",
        "start": 239.66,
        "duration": 1.27
    },
    {
        "text": ">> Awesome.",
        "start": 240.93,
        "duration": 0.41
    },
    {
        "text": ">> You don't need any prior",
        "start": 241.34,
        "duration": 1.13
    },
    {
        "text": "machine learning knowledge to do it.",
        "start": 242.47,
        "duration": 1.275
    },
    {
        "text": ">> Awesome. So, what's new?",
        "start": 243.745,
        "duration": 1.25
    },
    {
        "text": ">> So, we are now extending it to object detection.",
        "start": 244.995,
        "duration": 2.435
    },
    {
        "text": "Previously, you could just tell what was in the image.",
        "start": 247.43,
        "duration": 1.835
    },
    {
        "text": "Now we'll give you a bounding box and",
        "start": 249.265,
        "duration": 1.305
    },
    {
        "text": "tell you where things are in the image.",
        "start": 250.57,
        "duration": 2.04
    },
    {
        "text": ">> Holy cow, that's crazy.",
        "start": 252.61,
        "duration": 1.5
    },
    {
        "text": "So, if I have a set of products that I want to",
        "start": 254.11,
        "duration": 2.02
    },
    {
        "text": "reco- let's say I want to recognize products in an image.",
        "start": 256.13,
        "duration": 2.685
    },
    {
        "text": "I can give it labels",
        "start": 258.815,
        "duration": 1.425
    },
    {
        "text": "of the right products and it will find it?",
        "start": 260.24,
        "duration": 1.8
    },
    {
        "text": "Do I have to tell it where the actual product is?",
        "start": 262.04,
        "duration": 2.3
    },
    {
        "text": ">> Yes. Yes.",
        "start": 264.34,
        "duration": 0.32
    },
    {
        "text": ">> Okay.",
        "start": 264.66,
        "duration": 0.42
    },
    {
        "text": ">> So, we'll do an example of how you do that and we've",
        "start": 265.08,
        "duration": 2.01
    },
    {
        "text": "made it a lot easier to tag a lot of these images.",
        "start": 267.09,
        "duration": 2.16
    },
    {
        "text": "So, anyone who's tried to build",
        "start": 269.25,
        "duration": 1.36
    },
    {
        "text": "object detectors before knows",
        "start": 270.61,
        "duration": 1.07
    },
    {
        "text": "it's very painstaking to draw these boxes around.",
        "start": 271.68,
        "duration": 2.9
    },
    {
        "text": "So, we've made it easier to do that.",
        "start": 274.58,
        "duration": 1.465
    },
    {
        "text": "And then, you only have to do it for",
        "start": 276.045,
        "duration": 2.7
    },
    {
        "text": "maybe a couple hundred images or",
        "start": 278.745,
        "duration": 1.765
    },
    {
        "text": "less and then you have a great model.",
        "start": 280.51,
        "duration": 1.85
    },
    {
        "text": ">> Awesome, let's take a look.",
        "start": 282.36,
        "duration": 0.995
    },
    {
        "text": ">> All right. All right.",
        "start": 283.355,
        "duration": 3.915
    },
    {
        "text": "So, this is custom vision service.",
        "start": 287.27,
        "duration": 1.4
    },
    {
        "text": "So, this is after you sign and you'll see your projects.",
        "start": 288.67,
        "duration": 2.425
    },
    {
        "text": "I've already built an object detector for us.",
        "start": 291.095,
        "duration": 2.175
    },
    {
        "text": "So, I've built, I'm sorry.",
        "start": 293.27,
        "duration": 3.61
    },
    {
        "text": "This is the object detector.",
        "start": 298.43,
        "duration": 2.315
    },
    {
        "text": ">> Okay.",
        "start": 300.745,
        "duration": 0.295
    },
    {
        "text": ">> So, this one detects apples,",
        "start": 301.04,
        "duration": 4.65
    },
    {
        "text": "oranges, and strawberries as you can see.",
        "start": 305.69,
        "duration": 1.975
    },
    {
        "text": "We have anywhere between 15 and 40 images.",
        "start": 307.665,
        "duration": 3.505
    },
    {
        "text": "Forty-five images for each.",
        "start": 311.17,
        "duration": 1.19
    },
    {
        "text": ">> Cool.",
        "start": 312.36,
        "duration": 0.48
    },
    {
        "text": ">> So,",
        "start": 312.84,
        "duration": 2.19
    },
    {
        "text": "what you'd get is when you",
        "start": 315.03,
        "duration": 0.895
    },
    {
        "text": "upload them they would be untagged.",
        "start": 315.925,
        "duration": 1.085
    },
    {
        "text": "And then for an image like this,",
        "start": 317.01,
        "duration": 3.285
    },
    {
        "text": "you'll hover and it will give you",
        "start": 320.295,
        "duration": 2.255
    },
    {
        "text": "suggested bounding boxes so I just click.",
        "start": 322.55,
        "duration": 2.3
    },
    {
        "text": "That's a strawberry. Click. Strawberry. Move to next one.",
        "start": 324.85,
        "duration": 6.955
    },
    {
        "text": ">> That is so cool.",
        "start": 331.805,
        "duration": 2.055
    },
    {
        "text": ">> Yes. And so, it makes it really easy.",
        "start": 333.86,
        "duration": 2.305
    },
    {
        "text": "If you don't like the bounding box",
        "start": 336.165,
        "duration": 1.315
    },
    {
        "text": "you can easily just adjust it,",
        "start": 337.48,
        "duration": 1.53
    },
    {
        "text": "but you don't have to drag and drop each one.",
        "start": 339.01,
        "duration": 2.815
    },
    {
        "text": "Then again, you can always still use drag and drop.",
        "start": 341.825,
        "duration": 3.875
    },
    {
        "text": "If you want to make",
        "start": 345.7,
        "duration": 2.61
    },
    {
        "text": "your own bounding boxes if you don't catch it.",
        "start": 348.31,
        "duration": 1.875
    },
    {
        "text": "But most of them we get pretty close.",
        "start": 350.185,
        "duration": 4.005
    },
    {
        "text": ">> And obviously, the more of these that you",
        "start": 354.19,
        "duration": 2.06
    },
    {
        "text": "give a bounding the box the smarter it gets at this?",
        "start": 356.25,
        "duration": 1.91
    },
    {
        "text": ">> Yes. Yes.",
        "start": 358.16,
        "duration": 0.77
    },
    {
        "text": ">> So, how many do you suggest like.",
        "start": 358.93,
        "duration": 2.18
    },
    {
        "text": "I've always get this question when I talk about",
        "start": 361.11,
        "duration": 1.9
    },
    {
        "text": "customization because it's an amazing",
        "start": 363.01,
        "duration": 1.445
    },
    {
        "text": "thing to talk about.",
        "start": 364.455,
        "duration": 1.34
    },
    {
        "text": "How many images should I have in order to make",
        "start": 365.795,
        "duration": 2.135
    },
    {
        "text": "it distinguishable depending on the number of tags?",
        "start": 367.93,
        "duration": 2.17
    },
    {
        "text": "And then, for the bounding boxes do I need",
        "start": 370.1,
        "duration": 2.095
    },
    {
        "text": "the same or more bounding boxes?",
        "start": 372.195,
        "duration": 2.355
    },
    {
        "text": ">> So, the amount of images we recommend is at least 15.",
        "start": 374.55,
        "duration": 4.05
    },
    {
        "text": "But depending on how different the objects are,",
        "start": 378.6,
        "duration": 2.32
    },
    {
        "text": "depends on how many you need.",
        "start": 380.92,
        "duration": 1.78
    },
    {
        "text": ">> Sure.",
        "start": 382.7,
        "duration": 0.25
    },
    {
        "text": ">> So, if we're going to do people detection.",
        "start": 382.95,
        "duration": 2.785
    },
    {
        "text": "People look very different,",
        "start": 385.735,
        "duration": 1.64
    },
    {
        "text": "from one person to the next.",
        "start": 387.375,
        "duration": 2.095
    },
    {
        "text": "But if you're going to do logo detection,",
        "start": 389.47,
        "duration": 1.72
    },
    {
        "text": "no matter where used the logo,",
        "start": 391.19,
        "duration": 1.17
    },
    {
        "text": "the logo itself, doesn't really change.",
        "start": 392.36,
        "duration": 1.89
    },
    {
        "text": ">> Right.",
        "start": 394.25,
        "duration": 0.22
    },
    {
        "text": ">> So, you need a lot less there.",
        "start": 394.47,
        "duration": 1.34
    },
    {
        "text": ">> Okay.",
        "start": 395.81,
        "duration": 0.43
    },
    {
        "text": ">> So, it really depends on what you're",
        "start": 396.24,
        "duration": 1.64
    },
    {
        "text": "doing and the best advice we can give is,",
        "start": 397.88,
        "duration": 2.11
    },
    {
        "text": "try it and see how many you need.",
        "start": 399.99,
        "duration": 2.84
    },
    {
        "text": ">> Awesome. But not for the bounding box though?",
        "start": 402.83,
        "duration": 2.705
    },
    {
        "text": ">> So, I'd say one per image.",
        "start": 405.535,
        "duration": 5.16
    },
    {
        "text": "We say 15 images because really",
        "start": 410.695,
        "duration": 2.415
    },
    {
        "text": "we're saying 15 bounding boxes, but the more the better.",
        "start": 413.11,
        "duration": 2.12
    },
    {
        "text": ">> Awesome. So, you just try to label",
        "start": 415.23,
        "duration": 1.73
    },
    {
        "text": "as many as you can and put them up there?",
        "start": 416.96,
        "duration": 2.04
    },
    {
        "text": ">> Yes.",
        "start": 419.0,
        "duration": 0.24
    },
    {
        "text": ">> Awesome. All right. So, how",
        "start": 419.24,
        "duration": 1.33
    },
    {
        "text": "does the API actually return the bounding boxes,",
        "start": 420.57,
        "duration": 2.55
    },
    {
        "text": "they look the same as the computer vision one?",
        "start": 423.12,
        "duration": 1.96
    },
    {
        "text": ">> Yes. So, it will give you.",
        "start": 425.08,
        "duration": 1.46
    },
    {
        "text": "It won't be the exact same output, but will be similar,",
        "start": 426.54,
        "duration": 2.07
    },
    {
        "text": "it'll give you the coordinates of",
        "start": 428.61,
        "duration": 1.22
    },
    {
        "text": "the bounding box and what the tags are.",
        "start": 429.83,
        "duration": 1.785
    },
    {
        "text": "And so, this is one that I have already trained so,",
        "start": 431.615,
        "duration": 2.77
    },
    {
        "text": "what you'll get is you'll see this performance.",
        "start": 434.385,
        "duration": 1.74
    },
    {
        "text": "So, I have precision of 89.5 and recall of 100.",
        "start": 436.125,
        "duration": 3.805
    },
    {
        "text": "So, I can say I want it to be",
        "start": 439.93,
        "duration": 1.37
    },
    {
        "text": "a more precise model and less recall so what I would do,",
        "start": 441.3,
        "duration": 2.795
    },
    {
        "text": "is pull up the probability threshold and say,",
        "start": 444.095,
        "duration": 4.015
    },
    {
        "text": "\"I want to be precision of 100 and recall the 100.",
        "start": 448.92,
        "duration": 3.94
    },
    {
        "text": "Only look at things that have a probability",
        "start": 452.86,
        "duration": 1.96
    },
    {
        "text": "of 73 or a lot higher.\"",
        "start": 454.82,
        "duration": 1.19
    },
    {
        "text": ">> And what's the MAP, that's new?",
        "start": 456.01,
        "duration": 1.7
    },
    {
        "text": ">> That's the mean average precision.",
        "start": 457.71,
        "duration": 2.185
    },
    {
        "text": "So, this is the performance across all of the-",
        "start": 459.895,
        "duration": 2.15
    },
    {
        "text": ">> So, this is for object detection?",
        "start": 462.045,
        "duration": 1.665
    },
    {
        "text": ">>Yes.",
        "start": 463.71,
        "duration": 0.22
    },
    {
        "text": ">> Okay. So precision-recall are for",
        "start": 463.93,
        "duration": 1.95
    },
    {
        "text": "tagging and the MAP score",
        "start": 465.88,
        "duration": 2.08
    },
    {
        "text": "mean average precision is",
        "start": 467.96,
        "duration": 1.31
    },
    {
        "text": "the precision of the actual object detection?",
        "start": 469.27,
        "duration": 3.075
    },
    {
        "text": ">> Yes.",
        "start": 472.345,
        "duration": 0.355
    },
    {
        "text": ">> Got it. Okay. Perfect. Perfect. Cause there",
        "start": 472.7,
        "duration": 1.81
    },
    {
        "text": "has to be a new thing if we're introducing a new thing.",
        "start": 474.51,
        "duration": 2.02
    },
    {
        "text": ">> Exactly.",
        "start": 476.53,
        "duration": 0.49
    },
    {
        "text": ">> Awesome.",
        "start": 477.02,
        "duration": 0.86
    },
    {
        "text": ">> So, we can do some quick tests on some images.",
        "start": 477.88,
        "duration": 4.29
    },
    {
        "text": ">> Awesome.",
        "start": 496.98,
        "duration": 2.745
    },
    {
        "text": ">> So, one of the great things about",
        "start": 499.725,
        "duration": 3.065
    },
    {
        "text": "object detection which you don't get with classification,",
        "start": 502.79,
        "duration": 3.015
    },
    {
        "text": "is that you can actually count",
        "start": 505.805,
        "duration": 1.655
    },
    {
        "text": "how many objects there are.",
        "start": 507.46,
        "duration": 1.635
    },
    {
        "text": "So, this one as we said the threshold we wanted",
        "start": 509.095,
        "duration": 2.535
    },
    {
        "text": "was something around 70 percent.",
        "start": 511.63,
        "duration": 2.36
    },
    {
        "text": "Now, you can see that all the boxes actually go around",
        "start": 513.99,
        "duration": 2.54
    },
    {
        "text": "individual strawberries and we missed one,",
        "start": 516.53,
        "duration": 3.17
    },
    {
        "text": "but most of them we see and we can get",
        "start": 519.7,
        "duration": 1.44
    },
    {
        "text": "a rough count of how many are in the option and [inaudible].",
        "start": 521.14,
        "duration": 2.485
    },
    {
        "text": ">> That's amazing.",
        "start": 523.625,
        "duration": 1.515
    },
    {
        "text": "And now the other question I have because before",
        "start": 525.14,
        "duration": 2.43
    },
    {
        "text": "with the custom vision models,",
        "start": 527.57,
        "duration": 2.585
    },
    {
        "text": "you were able to download some",
        "start": 530.155,
        "duration": 1.255
    },
    {
        "text": "them and execute on the Edge.",
        "start": 531.41,
        "duration": 1.04
    },
    {
        "text": "Will the object detection also work on the Edge?",
        "start": 532.45,
        "duration": 1.815
    },
    {
        "text": ">> Not yet, but we're looking to get that soon.",
        "start": 534.265,
        "duration": 1.875
    },
    {
        "text": "So, as you mentioned with export,",
        "start": 536.14,
        "duration": 2.035
    },
    {
        "text": "we've actually added some more export capabilities",
        "start": 538.175,
        "duration": 2.715
    },
    {
        "text": "for classification.",
        "start": 540.89,
        "duration": 1.33
    },
    {
        "text": ">> Okay. Cool.",
        "start": 542.22,
        "duration": 0.69
    },
    {
        "text": ">> So if we go classification,",
        "start": 542.91,
        "duration": 2.69
    },
    {
        "text": "this is the same free classifier I just did in",
        "start": 545.6,
        "duration": 3.13
    },
    {
        "text": "classification instead of object detection.",
        "start": 548.73,
        "duration": 3.39
    },
    {
        "text": ">> Okay.",
        "start": 552.12,
        "duration": 0.33
    },
    {
        "text": ">> And so, we",
        "start": 552.45,
        "duration": 2.18
    },
    {
        "text": "already had core ML and Tensor flow for export.",
        "start": 554.63,
        "duration": 2.525
    },
    {
        "text": "We've now supported ONNX,",
        "start": 557.155,
        "duration": 1.775
    },
    {
        "text": "which is Windows ML and Docker files.",
        "start": 558.93,
        "duration": 3.55
    },
    {
        "text": "So, this is all the pieces you need to create",
        "start": 562.48,
        "duration": 2.19
    },
    {
        "text": "your own container and so, you'll just do.",
        "start": 564.67,
        "duration": 2.715
    },
    {
        "text": "If you have Docker on your machine you just do docker",
        "start": 567.385,
        "duration": 3.015
    },
    {
        "text": "build and you'll have a Linux or Windows container.",
        "start": 570.4,
        "duration": 3.29
    },
    {
        "text": ">> So, what is it that you're actually down is like",
        "start": 573.69,
        "duration": 1.69
    },
    {
        "text": "a zip file of all the stuff that should here?",
        "start": 575.38,
        "duration": 2.015
    },
    {
        "text": ">> Yes, yes. And a readme with",
        "start": 577.395,
        "duration": 1.63
    },
    {
        "text": "very clear instructions of how to turn that into a-",
        "start": 579.025,
        "duration": 2.515
    },
    {
        "text": ">> That's cool.",
        "start": 581.54,
        "duration": 0.76
    },
    {
        "text": ">> Container. And that would run",
        "start": 582.3,
        "duration": 1.25
    },
    {
        "text": "on any docker enabled IoT Edge.",
        "start": 583.55,
        "duration": 2.4
    },
    {
        "text": ">> Well, this is amazing.",
        "start": 585.95,
        "duration": 1.66
    },
    {
        "text": "I love the things that have been added.",
        "start": 587.61,
        "duration": 1.22
    },
    {
        "text": "I use custom vision a lot,",
        "start": 588.83,
        "duration": 1.36
    },
    {
        "text": "I show it to a lot of people, they are super impressed.",
        "start": 590.19,
        "duration": 1.915
    },
    {
        "text": "It's cool that now we have an honest model.",
        "start": 592.105,
        "duration": 1.575
    },
    {
        "text": "So, you can do windows ML.",
        "start": 593.68,
        "duration": 0.95
    },
    {
        "text": "It's cool you have a docker file.",
        "start": 594.63,
        "duration": 1.1
    },
    {
        "text": "So, you can do whatever you want with this.",
        "start": 595.73,
        "duration": 1.685
    },
    {
        "text": "And I love the object detection bit on this.",
        "start": 597.415,
        "duration": 2.48
    },
    {
        "text": "So, this is super amazing.",
        "start": 599.895,
        "duration": 1.405
    },
    {
        "text": "Thanks so much for spending some time with us.",
        "start": 601.3,
        "duration": 1.25
    },
    {
        "text": ">> Thanks for having us out.",
        "start": 602.55,
        "duration": 0.85
    },
    {
        "text": ">> Thanks so much for watching.",
        "start": 603.4,
        "duration": 1.35
    },
    {
        "text": "We've been learning about the new features inside of",
        "start": 604.75,
        "duration": 1.95
    },
    {
        "text": "computer and custom vision",
        "start": 606.7,
        "duration": 1.545
    },
    {
        "text": "for you to use in your applications.",
        "start": 608.245,
        "duration": 1.895
    },
    {
        "text": "Thank so much for watching.",
        "start": 610.14,
        "duration": 1.02
    },
    {
        "text": "We'll see you next time. Take care.",
        "start": 611.16,
        "duration": 2.0
    }
]