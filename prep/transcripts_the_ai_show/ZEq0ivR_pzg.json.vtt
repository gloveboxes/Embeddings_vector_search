[
    {
        "text": ">> You're not going to want to miss this episode of the AI Show.",
        "start": 0.0,
        "duration": 3.09
    },
    {
        "text": "We have Andreas Muller or Andy because now we're bffs,",
        "start": 3.09,
        "duration": 3.15
    },
    {
        "text": "talk about Scikit-Learn, machine learning",
        "start": 6.24,
        "duration": 2.445
    },
    {
        "text": "and he's got a cool new project up his sleeve.",
        "start": 8.685,
        "duration": 2.805
    },
    {
        "text": "You're not going to want to miss it. Make sure you tune in.",
        "start": 11.49,
        "duration": 1.83
    },
    {
        "text": "[MUSIC].",
        "start": 13.32,
        "duration": 8.13
    },
    {
        "text": ">> Hello and welcome to this special edition of",
        "start": 21.45,
        "duration": 1.86
    },
    {
        "text": "the AI Show where we've got a special guest Andreas Muller.",
        "start": 23.31,
        "duration": 3.055
    },
    {
        "text": "He said, I could call him Andy,",
        "start": 26.365,
        "duration": 2.135
    },
    {
        "text": "so now we're actually bffs. How you doing my friend?",
        "start": 28.5,
        "duration": 3.36
    },
    {
        "text": ">> I'm great. How are you doing?",
        "start": 31.86,
        "duration": 1.62
    },
    {
        "text": ">> Fantastic. So tell us who you are and what you do.",
        "start": 33.48,
        "duration": 2.79
    },
    {
        "text": ">> So I recently joined Microsoft two months ago",
        "start": 36.43,
        "duration": 5.29
    },
    {
        "text": "as a Principal Research SDE,",
        "start": 41.72,
        "duration": 4.66
    },
    {
        "text": "I think it's the official name, it's a bit long.",
        "start": 46.38,
        "duration": 3.22
    },
    {
        "text": "I worked a lot on software for machine learning,",
        "start": 50.39,
        "duration": 3.54
    },
    {
        "text": "in particular on Scikit-Learn,",
        "start": 53.93,
        "duration": 1.68
    },
    {
        "text": "so I've been a core developer on that project for a while now.",
        "start": 55.61,
        "duration": 3.285
    },
    {
        "text": "I also have some other projects like",
        "start": 58.895,
        "duration": 2.52
    },
    {
        "text": "dabl and I have a book on machine learning,",
        "start": 61.415,
        "duration": 3.66
    },
    {
        "text": "introduction to machine learning with Python.",
        "start": 65.075,
        "duration": 2.43
    },
    {
        "text": "So I'm trying to",
        "start": 67.505,
        "duration": 2.215
    },
    {
        "text": "make it easier for people to use",
        "start": 69.72,
        "duration": 1.57
    },
    {
        "text": "machine learning in Python mostly.",
        "start": 71.29,
        "duration": 1.35
    },
    {
        "text": ">> So let's start all the way at the beginning if you don't mind,",
        "start": 72.64,
        "duration": 2.82
    },
    {
        "text": "I'd love to get a sense for how you got into machine learning,",
        "start": 75.46,
        "duration": 3.405
    },
    {
        "text": "how you started getting into some of",
        "start": 78.865,
        "duration": 1.305
    },
    {
        "text": "the projects that you were doing,",
        "start": 80.17,
        "duration": 1.635
    },
    {
        "text": "and what the overall goal is for people.",
        "start": 81.805,
        "duration": 2.145
    },
    {
        "text": "Because personally I love Scikit-Learn,",
        "start": 83.95,
        "duration": 2.03
    },
    {
        "text": "I feel like we talk about deep learning a lot in the field,",
        "start": 85.98,
        "duration": 2.56
    },
    {
        "text": "but I'd love to get a sense for",
        "start": 88.54,
        "duration": 1.59
    },
    {
        "text": "what Scikit-Learn is and why it's important.",
        "start": 90.13,
        "duration": 2.265
    },
    {
        "text": "So let's start with all of those things.",
        "start": 92.395,
        "duration": 2.04
    },
    {
        "text": "There's so many because I have",
        "start": 94.435,
        "duration": 1.215
    },
    {
        "text": "so many questions for you. How did you get started?",
        "start": 95.65,
        "duration": 1.83
    },
    {
        "text": ">> All right. So how did I get started?",
        "start": 97.48,
        "duration": 1.35
    },
    {
        "text": "So my background is actually in pure math.",
        "start": 98.83,
        "duration": 2.64
    },
    {
        "text": "But then after I graduated with a master's degree,",
        "start": 101.47,
        "duration": 4.85
    },
    {
        "text": "I was like okay, so what I'm I going to do next,",
        "start": 106.32,
        "duration": 2.095
    },
    {
        "text": "and then I saw an article about some people",
        "start": 108.415,
        "duration": 2.115
    },
    {
        "text": "in the same town doing robot soccer and I was like,",
        "start": 110.53,
        "duration": 4.53
    },
    {
        "text": "oh my god, robots,",
        "start": 115.06,
        "duration": 1.11
    },
    {
        "text": "they seem really cool.",
        "start": 116.17,
        "duration": 1.41
    },
    {
        "text": "So I started my PhD in that group.",
        "start": 117.58,
        "duration": 2.925
    },
    {
        "text": "But I ended up not working on robots,",
        "start": 120.505,
        "duration": 1.785
    },
    {
        "text": "but actually ended up working on machine learning for",
        "start": 122.29,
        "duration": 3.48
    },
    {
        "text": "some deep learning and then",
        "start": 125.77,
        "duration": 1.26
    },
    {
        "text": "some computer vision structure prediction and so on.",
        "start": 127.03,
        "duration": 2.925
    },
    {
        "text": "So during that time in my PhD,",
        "start": 129.955,
        "duration": 2.01
    },
    {
        "text": "I started contributing to open source,",
        "start": 131.965,
        "duration": 1.635
    },
    {
        "text": "I started playing around with Scikit-Learn and then yeah,",
        "start": 133.6,
        "duration": 3.96
    },
    {
        "text": "became a contributor there.",
        "start": 137.56,
        "duration": 1.285
    },
    {
        "text": ">> So how does one become a contributor to",
        "start": 138.845,
        "duration": 2.075
    },
    {
        "text": "a project like that, like Scikit-Learn?",
        "start": 140.92,
        "duration": 3.445
    },
    {
        "text": ">> Back then it was quite a bit smaller and less popular,",
        "start": 144.365,
        "duration": 4.385
    },
    {
        "text": "I guess, and it was a smaller community.",
        "start": 148.75,
        "duration": 2.639
    },
    {
        "text": "But generally, now, as then,",
        "start": 151.389,
        "duration": 4.346
    },
    {
        "text": "you start becoming a developer by",
        "start": 155.735,
        "duration": 1.575
    },
    {
        "text": "contributing like it's on GitHub.",
        "start": 157.31,
        "duration": 1.965
    },
    {
        "text": "Like any other community open source project,",
        "start": 159.275,
        "duration": 2.145
    },
    {
        "text": "you can just start making pull requests.",
        "start": 161.42,
        "duration": 2.64
    },
    {
        "text": "My first pull requests were fixing typos in",
        "start": 164.06,
        "duration": 2.43
    },
    {
        "text": "the documentation or clarifying things in the documentation.",
        "start": 166.49,
        "duration": 3.93
    },
    {
        "text": "So even small stuff, it's really appreciated.",
        "start": 170.42,
        "duration": 2.985
    },
    {
        "text": "Actually often small stuff is much easier to get into",
        "start": 173.405,
        "duration": 2.715
    },
    {
        "text": "a project than huge new things.",
        "start": 176.12,
        "duration": 2.61
    },
    {
        "text": "So just start contributing, start small,",
        "start": 178.73,
        "duration": 3.93
    },
    {
        "text": "and then engage in a conversation with the project to what,",
        "start": 182.66,
        "duration": 3.495
    },
    {
        "text": "where things are going.",
        "start": 186.155,
        "duration": 1.125
    },
    {
        "text": ">> So for those that are new to",
        "start": 187.28,
        "duration": 1.95
    },
    {
        "text": "machine learning are super excited to get started.",
        "start": 189.23,
        "duration": 2.52
    },
    {
        "text": "Can you frame for us",
        "start": 191.75,
        "duration": 1.68
    },
    {
        "text": "what's the difference between the goals of something",
        "start": 193.43,
        "duration": 2.37
    },
    {
        "text": "like a Scikit-Learn versus a thing like a PyTorch or a TensorFlow.",
        "start": 195.8,
        "duration": 4.62
    },
    {
        "text": "Are they the same thing?",
        "start": 200.42,
        "duration": 1.86
    },
    {
        "text": "How are they different? What do you say?",
        "start": 202.28,
        "duration": 2.92
    },
    {
        "text": ">> I think there's two main differences.",
        "start": 205.85,
        "duration": 4.18
    },
    {
        "text": "Scikit-learn, this may be little bit more",
        "start": 211.19,
        "duration": 2.37
    },
    {
        "text": "comparable to in the deep learning space,",
        "start": 213.56,
        "duration": 3.66
    },
    {
        "text": "fast AI or maybe Keras,",
        "start": 217.22,
        "duration": 2.22
    },
    {
        "text": "which is more like batteries included.",
        "start": 219.44,
        "duration": 3.314
    },
    {
        "text": "So Scikit-Learn really gives you full algorithms and tools",
        "start": 222.754,
        "duration": 4.696
    },
    {
        "text": "to trying the models to validate the models and so on.",
        "start": 227.45,
        "duration": 4.935
    },
    {
        "text": "Whereas PyTorch and TensorFlow are both much more low level,",
        "start": 232.385,
        "duration": 3.965
    },
    {
        "text": "so they allow you to really tweak what model you're using.",
        "start": 236.35,
        "duration": 4.725
    },
    {
        "text": "They give you a lot of flexibility,",
        "start": 241.075,
        "duration": 3.14
    },
    {
        "text": "but also they require you to do a lot of work,",
        "start": 244.215,
        "duration": 2.93
    },
    {
        "text": "whereas Scikit-Learn really has a fixed,",
        "start": 247.145,
        "duration": 5.045
    },
    {
        "text": "like a toolbox of models",
        "start": 252.19,
        "duration": 2.705
    },
    {
        "text": "and you can pick which model you want from",
        "start": 254.895,
        "duration": 2.345
    },
    {
        "text": "this toolbox and you have to do very little work",
        "start": 257.24,
        "duration": 3.15
    },
    {
        "text": "to use them but there's also like",
        "start": 260.39,
        "duration": 1.5
    },
    {
        "text": "a limited amount of customization.",
        "start": 261.89,
        "duration": 2.36
    },
    {
        "text": "Then the other maybe more obvious thing is domain,",
        "start": 264.25,
        "duration": 5.435
    },
    {
        "text": "which is; TensorFlow, PyTorch,",
        "start": 269.685,
        "duration": 3.12
    },
    {
        "text": "[inaudible] they're all for deep learning",
        "start": 272.805,
        "duration": 3.26
    },
    {
        "text": "where Scikit-Learn is what is",
        "start": 276.065,
        "duration": 1.635
    },
    {
        "text": "now called traditional machine learning,",
        "start": 277.7,
        "duration": 1.86
    },
    {
        "text": "which is actually newer than deep learning.",
        "start": 279.56,
        "duration": 3.015
    },
    {
        "text": ">> So tell me about that, tell me about",
        "start": 282.575,
        "duration": 2.625
    },
    {
        "text": "how traditional machine learning is newer,",
        "start": 285.2,
        "duration": 2.34
    },
    {
        "text": "look, I went to grad school when",
        "start": 287.54,
        "duration": 1.59
    },
    {
        "text": "sump's were all the rage and I'm like you,",
        "start": 289.13,
        "duration": 2.13
    },
    {
        "text": "I'm a math wonk and I just loved how SVMs have like",
        "start": 291.26,
        "duration": 3.51
    },
    {
        "text": "this perfect mathematical structure and",
        "start": 294.77,
        "duration": 2.19
    },
    {
        "text": "optimization and I always gravitated toward those algorithms.",
        "start": 296.96,
        "duration": 3.585
    },
    {
        "text": "Tell us about that.",
        "start": 300.545,
        "duration": 3.335
    },
    {
        "text": ">> That's actually also what I did during my PhD.",
        "start": 303.88,
        "duration": 2.71
    },
    {
        "text": "So my advisor actually was like",
        "start": 306.59,
        "duration": 1.56
    },
    {
        "text": "super gung-ho about neural networks,",
        "start": 308.15,
        "duration": 2.355
    },
    {
        "text": "that was before ImageNet happened.",
        "start": 310.505,
        "duration": 2.445
    },
    {
        "text": "I was like, no, this is not working and then I",
        "start": 312.95,
        "duration": 2.07
    },
    {
        "text": "was much more going to the optimization direction.",
        "start": 315.02,
        "duration": 2.775
    },
    {
        "text": "But it turns out actually",
        "start": 317.795,
        "duration": 2.85
    },
    {
        "text": "like neural networks were just on",
        "start": 320.645,
        "duration": 1.515
    },
    {
        "text": "the cusp of becoming much more important.",
        "start": 322.16,
        "duration": 2.475
    },
    {
        "text": "But so a lot of the technology is from the 90s.",
        "start": 324.635,
        "duration": 5.875
    },
    {
        "text": "The math is like mostly from the 90s.",
        "start": 330.51,
        "duration": 1.8
    },
    {
        "text": "there's been some couple of very important innovations like",
        "start": 332.31,
        "duration": 3.935
    },
    {
        "text": "different learning strategies and residual networks and so on,",
        "start": 336.245,
        "duration": 7.3
    },
    {
        "text": "and obviously transformers now,",
        "start": 343.545,
        "duration": 2.015
    },
    {
        "text": "but a lot of the stuff that people use in deep learning",
        "start": 345.56,
        "duration": 3.015
    },
    {
        "text": "is very similar to what Yann Lecun has in his 1989 paper.",
        "start": 348.575,
        "duration": 6.85
    },
    {
        "text": "Whereas in 1989, random forests did not exist at all.",
        "start": 355.425,
        "duration": 5.07
    },
    {
        "text": ">> No it didn't.",
        "start": 360.495,
        "duration": 1.59
    },
    {
        "text": ">> Random forests have, I don't want to misquote the year,",
        "start": 362.085,
        "duration": 7.035
    },
    {
        "text": "so I'd rather not,",
        "start": 369.12,
        "duration": 1.995
    },
    {
        "text": "but they're newer than",
        "start": 371.115,
        "duration": 2.495
    },
    {
        "text": "convolutional neural networks by quite a bit.",
        "start": 373.61,
        "duration": 3.64
    },
    {
        "text": ">> It feels like as we look at what's",
        "start": 377.81,
        "duration": 3.15
    },
    {
        "text": "actually the cool things in machine learning,",
        "start": 380.96,
        "duration": 3.615
    },
    {
        "text": "people tend to gravitate towards deep learning.",
        "start": 384.575,
        "duration": 3.57
    },
    {
        "text": "Do you think we've over-indexed on",
        "start": 388.145,
        "duration": 2.325
    },
    {
        "text": "that side of the house as opposed to some of the other things in",
        "start": 390.47,
        "duration": 2.88
    },
    {
        "text": "Scikit-Learn or the newer machine learning",
        "start": 393.35,
        "duration": 2.925
    },
    {
        "text": "approaches that are not deep learning.",
        "start": 396.275,
        "duration": 2.25
    },
    {
        "text": "Do you think we've over-indexed?",
        "start": 398.525,
        "duration": 1.745
    },
    {
        "text": ">> It depends a lot",
        "start": 400.27,
        "duration": 2.23
    },
    {
        "text": "on what your application is and what your goal is.",
        "start": 402.5,
        "duration": 3.33
    },
    {
        "text": "So in terms of research,",
        "start": 405.83,
        "duration": 1.499
    },
    {
        "text": "there's so much really,",
        "start": 407.329,
        "duration": 1.531
    },
    {
        "text": "really amazing research going on in deep learning,",
        "start": 408.86,
        "duration": 2.295
    },
    {
        "text": "whereas instead of the traditional stuff,",
        "start": 411.155,
        "duration": 2.64
    },
    {
        "text": "the innovations that are relevant for",
        "start": 413.795,
        "duration": 2.085
    },
    {
        "text": "practice are relatively small.",
        "start": 415.88,
        "duration": 2.19
    },
    {
        "text": "So people love gradient boosting,",
        "start": 418.07,
        "duration": 1.83
    },
    {
        "text": "people have loved gradient boosting for the last 5-10 years.",
        "start": 419.9,
        "duration": 3.885
    },
    {
        "text": "This is really the thing that people really go to.",
        "start": 423.785,
        "duration": 3.98
    },
    {
        "text": "Whereas in deep learning,",
        "start": 427.765,
        "duration": 2.075
    },
    {
        "text": "you have some major innovations every year",
        "start": 429.84,
        "duration": 3.56
    },
    {
        "text": "happening that are important innovations.",
        "start": 433.4,
        "duration": 3.81
    },
    {
        "text": "So in terms of research,",
        "start": 437.21,
        "duration": 1.05
    },
    {
        "text": "I think it makes lot of sense.",
        "start": 438.26,
        "duration": 2.115
    },
    {
        "text": "In terms of applications,",
        "start": 440.375,
        "duration": 2.155
    },
    {
        "text": "it depends a lot on two things.",
        "start": 442.53,
        "duration": 4.74
    },
    {
        "text": "A is what's your trade",
        "start": 447.27,
        "duration": 2.96
    },
    {
        "text": "off between the work you put in and the accuracy?",
        "start": 450.23,
        "duration": 3.58
    },
    {
        "text": "The second thing is,",
        "start": 453.97,
        "duration": 2.68
    },
    {
        "text": "what is your modality?",
        "start": 456.65,
        "duration": 2.28
    },
    {
        "text": "Let me maybe talk about the second thing first.",
        "start": 458.93,
        "duration": 2.745
    },
    {
        "text": "So if you're working on image data,",
        "start": 461.675,
        "duration": 2.19
    },
    {
        "text": "video data, sound data,",
        "start": 463.865,
        "duration": 1.635
    },
    {
        "text": "you'd need to do deep learning,",
        "start": 465.5,
        "duration": 2.1
    },
    {
        "text": "there's no point in not doing deep learning.",
        "start": 467.6,
        "duration": 4.09
    },
    {
        "text": "Did I say text data? Text data,",
        "start": 474.03,
        "duration": 2.44
    },
    {
        "text": "probably these days, it depends a little bit,",
        "start": 476.47,
        "duration": 3.165
    },
    {
        "text": "but mostly, you also want to deep learning.",
        "start": 479.635,
        "duration": 2.46
    },
    {
        "text": "If you have tabular data or potentially text data,",
        "start": 482.095,
        "duration": 4.455
    },
    {
        "text": "then actually traditional stuff often fares a little bit better,",
        "start": 486.55,
        "duration": 4.68
    },
    {
        "text": "but that might also change.",
        "start": 491.23,
        "duration": 1.89
    },
    {
        "text": "But here, really the trade off",
        "start": 493.12,
        "duration": 1.725
    },
    {
        "text": "is the work you have to put in versus the accuracy.",
        "start": 494.845,
        "duration": 4.105
    },
    {
        "text": "I worked for a while at Amazon and even at a company",
        "start": 499.95,
        "duration": 3.79
    },
    {
        "text": "that we perceive as a very high-tech company,",
        "start": 503.74,
        "duration": 2.865
    },
    {
        "text": "there were a lot of places where they",
        "start": 506.605,
        "duration": 1.425
    },
    {
        "text": "could use machine learning, but they didn't.",
        "start": 508.03,
        "duration": 2.83
    },
    {
        "text": "Really, the big improvement comes from going from",
        "start": 510.86,
        "duration": 3.4
    },
    {
        "text": "a manual process to a principle data-driven,",
        "start": 514.26,
        "duration": 3.705
    },
    {
        "text": "potentially machine learning process,",
        "start": 517.965,
        "duration": 1.889
    },
    {
        "text": "and so the hard work is going from",
        "start": 519.854,
        "duration": 2.461
    },
    {
        "text": "zero to that or from manual to that,",
        "start": 522.315,
        "duration": 3.445
    },
    {
        "text": "and you can do that with logistic regression.",
        "start": 525.76,
        "duration": 3.34
    },
    {
        "text": "If it's really important for you to get the best possible results,",
        "start": 529.47,
        "duration": 5.305
    },
    {
        "text": "you can then do more and more complex models,",
        "start": 534.775,
        "duration": 2.775
    },
    {
        "text": "and maybe deep learning,",
        "start": 537.55,
        "duration": 1.035
    },
    {
        "text": "even though tabular data will give you a bit more performance.",
        "start": 538.585,
        "duration": 3.224
    },
    {
        "text": "But you'll have to spend a lot of time on that.",
        "start": 541.809,
        "duration": 2.851
    },
    {
        "text": "I would argue that in many contexts,",
        "start": 544.66,
        "duration": 2.64
    },
    {
        "text": "it might be better for you to move on to the next place where",
        "start": 547.3,
        "duration": 5.39
    },
    {
        "text": "your company is still at zero and go from",
        "start": 552.69,
        "duration": 3.24
    },
    {
        "text": "zero to 90 percent accuracy instead of going from 90 to 95.",
        "start": 555.93,
        "duration": 4.32
    },
    {
        "text": ">> I see.",
        "start": 560.25,
        "duration": 1.715
    },
    {
        "text": ">> There are some applications where office like,",
        "start": 561.965,
        "duration": 2.435
    },
    {
        "text": "if you're doing ad click prediction for Google,",
        "start": 564.4,
        "duration": 2.64
    },
    {
        "text": "every smallest percentage point is millions of dollars.",
        "start": 567.04,
        "duration": 3.9
    },
    {
        "text": "So clearly, you want to really optimize everything out of it.",
        "start": 570.94,
        "duration": 3.39
    },
    {
        "text": "But I think these applications are actually quite rare.",
        "start": 574.33,
        "duration": 3.21
    },
    {
        "text": ">> What I'm hearing from you, and this is",
        "start": 577.54,
        "duration": 1.8
    },
    {
        "text": "an interesting take and one that I agree with,",
        "start": 579.34,
        "duration": 2.4
    },
    {
        "text": "is you're saying instead of trying to",
        "start": 581.74,
        "duration": 2.55
    },
    {
        "text": "shave a percentage off of the error,",
        "start": 584.29,
        "duration": 3.57
    },
    {
        "text": "like a tiny bit, do something that moves",
        "start": 587.86,
        "duration": 2.79
    },
    {
        "text": "your business forward in",
        "start": 590.65,
        "duration": 1.11
    },
    {
        "text": "a significant way without shaving a little bit.",
        "start": 591.76,
        "duration": 2.415
    },
    {
        "text": "This is the question I have for you because look,",
        "start": 594.175,
        "duration": 2.16
    },
    {
        "text": "I was trained as a machine learning person.",
        "start": 596.335,
        "duration": 2.265
    },
    {
        "text": "I went to school, the University of Utah,",
        "start": 598.6,
        "duration": 1.71
    },
    {
        "text": "and I'm familiar with the math,",
        "start": 600.31,
        "duration": 1.23
    },
    {
        "text": "and the models, and such.",
        "start": 601.54,
        "duration": 1.545
    },
    {
        "text": "But I don't have the horse sense",
        "start": 603.085,
        "duration": 2.16
    },
    {
        "text": "of a data scientist that goes out and looks at a problem.",
        "start": 605.245,
        "duration": 3.864
    },
    {
        "text": "When you're advising people with machine learning problems,",
        "start": 609.109,
        "duration": 4.121
    },
    {
        "text": "is there a specific path that you give them?",
        "start": 613.23,
        "duration": 3.15
    },
    {
        "text": "You gave us a little bit of that with like, \"Hey,",
        "start": 616.38,
        "duration": 2.37
    },
    {
        "text": "if it's a table, you should probably not do deep learning.\"",
        "start": 618.75,
        "duration": 3.07
    },
    {
        "text": "What's the path that you follow",
        "start": 621.82,
        "duration": 2.16
    },
    {
        "text": "for solving machine learning problems?",
        "start": 623.98,
        "duration": 2.55
    },
    {
        "text": "Obviously, you're not going to try everything at once,",
        "start": 626.53,
        "duration": 1.56
    },
    {
        "text": "but what's your path? Does that make sense?",
        "start": 628.09,
        "duration": 2.79
    },
    {
        "text": ">> Yeah. The thing",
        "start": 630.88,
        "duration": 3.75
    },
    {
        "text": "that I start with in both my lecture series",
        "start": 634.63,
        "duration": 2.7
    },
    {
        "text": "and the all the workshops I give,",
        "start": 637.33,
        "duration": 1.11
    },
    {
        "text": "is that you should really start",
        "start": 638.44,
        "duration": 1.5
    },
    {
        "text": "with thinking about your objective.",
        "start": 639.94,
        "duration": 2.82
    },
    {
        "text": "What is your overall business objective?",
        "start": 642.76,
        "duration": 2.43
    },
    {
        "text": "Then how can you measure this?",
        "start": 645.19,
        "duration": 3.97
    },
    {
        "text": "Or what is a good measure for this?",
        "start": 649.17,
        "duration": 3.475
    },
    {
        "text": "Then collecting data to measure it.",
        "start": 652.645,
        "duration": 2.52
    },
    {
        "text": "I think before you start thinking",
        "start": 655.165,
        "duration": 2.445
    },
    {
        "text": "about doing machine learning, you should think about,",
        "start": 657.61,
        "duration": 3.33
    },
    {
        "text": "let's say I do the perfect algorithm to solve this problem.",
        "start": 660.94,
        "duration": 6.15
    },
    {
        "text": "What will the actual business impact",
        "start": 667.09,
        "duration": 1.65
    },
    {
        "text": "be and how can I measure this?",
        "start": 668.74,
        "duration": 2.265
    },
    {
        "text": "Then I start from a very simple baseline,",
        "start": 671.005,
        "duration": 3.765
    },
    {
        "text": "like if I always give answer one or if I use this very simple if,",
        "start": 674.77,
        "duration": 6.66
    },
    {
        "text": "how far can I get to the maximum business impact that I can get?",
        "start": 681.43,
        "duration": 5.17
    },
    {
        "text": "This is actually all of the things that I just said are really,",
        "start": 686.79,
        "duration": 3.94
    },
    {
        "text": "really hard problems because very often,",
        "start": 690.73,
        "duration": 1.98
    },
    {
        "text": "the problem you're currently trying to solve",
        "start": 692.71,
        "duration": 2.655
    },
    {
        "text": "doesn't necessarily directly translate to your business objective.",
        "start": 695.365,
        "duration": 4.635
    },
    {
        "text": "I know several years ago,",
        "start": 700.0,
        "duration": 3.465
    },
    {
        "text": "Spotify use Scikit-Learn to make their artist radio.",
        "start": 703.465,
        "duration": 3.54
    },
    {
        "text": "Spotify as a company obviously wants to",
        "start": 707.005,
        "duration": 2.325
    },
    {
        "text": "maximize subscription because that's how they get money.",
        "start": 709.33,
        "duration": 2.355
    },
    {
        "text": "But how do you relate that to",
        "start": 711.685,
        "duration": 2.505
    },
    {
        "text": "what songs you recommend in the artist radio?",
        "start": 714.19,
        "duration": 6.435
    },
    {
        "text": "This is a super indirect thing,",
        "start": 720.625,
        "duration": 2.655
    },
    {
        "text": "and this is the same in most applications,",
        "start": 723.28,
        "duration": 2.91
    },
    {
        "text": "and so you have to have a a proxy that's say,",
        "start": 726.19,
        "duration": 2.535
    },
    {
        "text": "well, how long did they listen to this playlist or something?",
        "start": 728.725,
        "duration": 2.685
    },
    {
        "text": "But then you need to think about,",
        "start": 731.41,
        "duration": 3.57
    },
    {
        "text": "how does the proxy that I've found relate to my overarching goal?",
        "start": 734.98,
        "duration": 5.86
    },
    {
        "text": "Do I have the data to measure that proxy?",
        "start": 740.85,
        "duration": 3.68
    },
    {
        "text": ">> If I'm understanding you right, and let me",
        "start": 744.53,
        "duration": 2.65
    },
    {
        "text": "say because a baseline I think is super important.",
        "start": 747.18,
        "duration": 2.52
    },
    {
        "text": "You say start with a business objective, number 1,",
        "start": 749.7,
        "duration": 2.685
    },
    {
        "text": "find a baseline thing like ran.next less than 0.5 or something,",
        "start": 752.385,
        "duration": 6.91
    },
    {
        "text": "if I were to just use a column in my database to predict.",
        "start": 759.295,
        "duration": 3.57
    },
    {
        "text": "Then what you do is you find",
        "start": 762.865,
        "duration": 1.965
    },
    {
        "text": "a measurement that maximizes whatever your objective is,",
        "start": 764.83,
        "duration": 4.68
    },
    {
        "text": "and sometimes you can't find that,",
        "start": 769.51,
        "duration": 1.11
    },
    {
        "text": "so you find a proxy, and then you use",
        "start": 770.62,
        "duration": 1.83
    },
    {
        "text": "the baseline together with the proxy to",
        "start": 772.45,
        "duration": 2.76
    },
    {
        "text": "see if the machine learning outcomes you're using are",
        "start": 775.21,
        "duration": 2.16
    },
    {
        "text": "actually helping you for that. Did I get that right?",
        "start": 777.37,
        "duration": 3.15
    },
    {
        "text": ">> Yes, I think so.",
        "start": 780.52,
        "duration": 1.74
    },
    {
        "text": ">> The question that I have for you following this is,",
        "start": 782.26,
        "duration": 3.435
    },
    {
        "text": "how has Scikit-Learn evolved to help with these problems?",
        "start": 785.695,
        "duration": 6.055
    },
    {
        "text": ">> Scikit-learn comes from a much more scientific perspective,",
        "start": 792.93,
        "duration": 4.24
    },
    {
        "text": "and so it really focuses on",
        "start": 797.17,
        "duration": 2.67
    },
    {
        "text": "the modeling aspect and",
        "start": 799.84,
        "duration": 2.535
    },
    {
        "text": "not on the workflow that's all around this.",
        "start": 802.375,
        "duration": 2.88
    },
    {
        "text": "I think it's very hard to try to solve many of",
        "start": 805.255,
        "duration": 2.625
    },
    {
        "text": "these problems with software",
        "start": 807.88,
        "duration": 1.29
    },
    {
        "text": "because they are not software problems,",
        "start": 809.17,
        "duration": 1.5
    },
    {
        "text": "they are business problems.",
        "start": 810.67,
        "duration": 1.485
    },
    {
        "text": "As programmers, we always like to have technical tools,",
        "start": 812.155,
        "duration": 3.585
    },
    {
        "text": "and often, that's not the right solution.",
        "start": 815.74,
        "duration": 3.81
    },
    {
        "text": "What Scikit-Learn does is,",
        "start": 819.55,
        "duration": 2.805
    },
    {
        "text": "let's say I have the data, I want to use machine learning.",
        "start": 822.355,
        "duration": 4.305
    },
    {
        "text": "I know what the effect of this is",
        "start": 826.66,
        "duration": 1.47
    },
    {
        "text": "going to be on my overall process.",
        "start": 828.13,
        "duration": 1.785
    },
    {
        "text": "Now I want to use logistic regression, it's three lines in Python.",
        "start": 829.915,
        "duration": 3.06
    },
    {
        "text": "I want to use random force.",
        "start": 832.975,
        "duration": 1.395
    },
    {
        "text": "I changed this one line and then I have random force.",
        "start": 834.37,
        "duration": 2.25
    },
    {
        "text": "I changed this one line again and I have gradient boosting.",
        "start": 836.62,
        "duration": 2.625
    },
    {
        "text": "That here is this code to",
        "start": 839.245,
        "duration": 2.355
    },
    {
        "text": "plot all the metrics that are relevant for this.",
        "start": 841.6,
        "duration": 2.49
    },
    {
        "text": ">> I think that's cool because I",
        "start": 844.09,
        "duration": 2.37
    },
    {
        "text": "saw at the beginning, you're like, well,",
        "start": 846.46,
        "duration": 1.74
    },
    {
        "text": "Scikit-Learn isn't designed to actually solve the hard one.",
        "start": 848.2,
        "duration": 4.785
    },
    {
        "text": "But the way you described the code is it lets",
        "start": 852.985,
        "duration": 2.715
    },
    {
        "text": "you experiment quickly against",
        "start": 855.7,
        "duration": 2.76
    },
    {
        "text": "the baseline to show whether or",
        "start": 858.46,
        "duration": 2.34
    },
    {
        "text": "not you're actually driving change.",
        "start": 860.8,
        "duration": 3.09
    },
    {
        "text": "That's the thing that I like about Scikit-Learn,",
        "start": 863.89,
        "duration": 1.995
    },
    {
        "text": "specifically how it treats models and how it treats optimization,",
        "start": 865.885,
        "duration": 3.555
    },
    {
        "text": "and it treats them in a uniform way across models.",
        "start": 869.44,
        "duration": 3.735
    },
    {
        "text": "Maybe that's just my limited thinking of it.",
        "start": 873.175,
        "duration": 2.61
    },
    {
        "text": "What do you think about it?",
        "start": 875.785,
        "duration": 1.425
    },
    {
        "text": "Is there a philosophy with how you present models",
        "start": 877.21,
        "duration": 2.73
    },
    {
        "text": "and optimization in Scikit-Learn that's important?",
        "start": 879.94,
        "duration": 3.76
    },
    {
        "text": ">> First, I want to do a comment that's slightly tangential,",
        "start": 884.28,
        "duration": 5.59
    },
    {
        "text": "which is exactly the thing you just said,",
        "start": 889.87,
        "duration": 2.01
    },
    {
        "text": "having nice tooling helps you iterate on the overall process.",
        "start": 891.88,
        "duration": 4.709
    },
    {
        "text": "This is my pitch for my new project Dabble,",
        "start": 896.589,
        "duration": 3.001
    },
    {
        "text": "which is trying to make it even easier.",
        "start": 899.59,
        "duration": 3.255
    },
    {
        "text": "Just allows you to focus really on the big picture,",
        "start": 902.845,
        "duration": 3.435
    },
    {
        "text": "that was the idea of Dabble.",
        "start": 906.28,
        "duration": 2.38
    },
    {
        "text": ">> The question is, is there a general philosophy?",
        "start": 911.61,
        "duration": 2.83
    },
    {
        "text": "Now that you've introduced Dabble,",
        "start": 914.44,
        "duration": 1.845
    },
    {
        "text": "we're not going to leave that,",
        "start": 916.285,
        "duration": 1.545
    },
    {
        "text": "but I'm going to leave that for a little bit later.",
        "start": 917.83,
        "duration": 1.665
    },
    {
        "text": "The question I have is,",
        "start": 919.495,
        "duration": 1.68
    },
    {
        "text": "is there a general philosophy with Scikit-Learn because some of",
        "start": 921.175,
        "duration": 2.805
    },
    {
        "text": "the models that are in there are radically",
        "start": 923.98,
        "duration": 1.62
    },
    {
        "text": "different in terms of shape.",
        "start": 925.6,
        "duration": 1.41
    },
    {
        "text": "An SVM and a decision tree,",
        "start": 927.01,
        "duration": 2.04
    },
    {
        "text": "they're not the same things at all,",
        "start": 929.05,
        "duration": 2.34
    },
    {
        "text": "but it feels like they're treated in a similar way.",
        "start": 931.39,
        "duration": 2.97
    },
    {
        "text": "Is there an underlying philosophy with",
        "start": 934.36,
        "duration": 2.16
    },
    {
        "text": "Scikit-Learn that lets you do this kind of approach.",
        "start": 936.52,
        "duration": 3.46
    },
    {
        "text": ">> If you ask me, I would say that",
        "start": 940.2,
        "duration": 2.68
    },
    {
        "text": "our interface is actually super inconsistent in some ways,",
        "start": 942.88,
        "duration": 4.74
    },
    {
        "text": "which is mostly for historical reasons.",
        "start": 947.62,
        "duration": 2.115
    },
    {
        "text": "We have a lot of users right now,",
        "start": 949.735,
        "duration": 1.725
    },
    {
        "text": "so changing anything is super-hard.",
        "start": 951.46,
        "duration": 2.8
    },
    {
        "text": "The underlying philosophies is make things easy for the user,",
        "start": 954.54,
        "duration": 4.6
    },
    {
        "text": "think about what is the code the user has to write to use",
        "start": 959.14,
        "duration": 2.73
    },
    {
        "text": "this and use as few concepts as possible.",
        "start": 961.87,
        "duration": 3.69
    },
    {
        "text": "Whenever a programmer introduces a concept,",
        "start": 965.56,
        "duration": 1.74
    },
    {
        "text": "he or she has to explain the concept",
        "start": 967.3,
        "duration": 3.074
    },
    {
        "text": "to the user and that's the hardest part in programming,",
        "start": 970.374,
        "duration": 3.736
    },
    {
        "text": "is having the user understand",
        "start": 974.11,
        "duration": 1.709
    },
    {
        "text": "all the constructs you had in your head.",
        "start": 975.819,
        "duration": 1.816
    },
    {
        "text": "We try to have not too many of those.",
        "start": 977.635,
        "duration": 2.205
    },
    {
        "text": ">> I see. But is there a philosophy?",
        "start": 979.84,
        "duration": 2.76
    },
    {
        "text": "Look, for me personally,",
        "start": 982.6,
        "duration": 1.92
    },
    {
        "text": "the thing I've liked about Scikit-Learn in general is that for me,",
        "start": 984.52,
        "duration": 4.065
    },
    {
        "text": "a model, because look,",
        "start": 988.585,
        "duration": 1.155
    },
    {
        "text": "I was a programmer for like a decade",
        "start": 989.74,
        "duration": 1.5
    },
    {
        "text": "and then I went to grad school,",
        "start": 991.24,
        "duration": 1.455
    },
    {
        "text": "I think of models as functions that we don't write,",
        "start": 992.695,
        "duration": 3.66
    },
    {
        "text": "we just lazily write with data.",
        "start": 996.355,
        "duration": 2.67
    },
    {
        "text": "The way that you separate all the models out and you show what",
        "start": 999.025,
        "duration": 3.345
    },
    {
        "text": "they are and this concept of fitting data to it,",
        "start": 1002.37,
        "duration": 2.985
    },
    {
        "text": "to me, is super-interesting.",
        "start": 1005.355,
        "duration": 1.575
    },
    {
        "text": "Are those same concepts, the same across all of the models?",
        "start": 1006.93,
        "duration": 2.955
    },
    {
        "text": "Obviously, there's differences between them.",
        "start": 1009.885,
        "duration": 3.135
    },
    {
        "text": ">> The API is completely consistent across all of the models.",
        "start": 1013.02,
        "duration": 4.39
    },
    {
        "text": "I recently had a paper rejected about how you",
        "start": 1018.5,
        "duration": 2.77
    },
    {
        "text": "can frame these concepts,",
        "start": 1021.27,
        "duration": 3.03
    },
    {
        "text": "which is there's basically two ways to think about it.",
        "start": 1024.3,
        "duration": 3.105
    },
    {
        "text": "One is you have",
        "start": 1027.405,
        "duration": 2.01
    },
    {
        "text": "the stateful object that",
        "start": 1029.415,
        "duration": 2.595
    },
    {
        "text": "consumes the data and then changes the internal state.",
        "start": 1032.01,
        "duration": 3.66
    },
    {
        "text": "If I rewrite Scikit-Learn now,",
        "start": 1035.67,
        "duration": 2.295
    },
    {
        "text": "I might change using a different concept,",
        "start": 1037.965,
        "duration": 2.475
    },
    {
        "text": "which is that you",
        "start": 1040.44,
        "duration": 1.97
    },
    {
        "text": "create a stateless object, it does a prediction in.",
        "start": 1042.41,
        "duration": 2.805
    },
    {
        "text": "You have one function that creates",
        "start": 1045.215,
        "duration": 1.785
    },
    {
        "text": "an object and this object is a prediction object.",
        "start": 1047.0,
        "duration": 3.105
    },
    {
        "text": "Because actually if you look at applications,",
        "start": 1050.105,
        "duration": 2.995
    },
    {
        "text": "in the deployment setting,",
        "start": 1053.36,
        "duration": 2.095
    },
    {
        "text": "you usually care about shipping the prediction function,",
        "start": 1055.455,
        "duration": 2.85
    },
    {
        "text": "and so Scikit-Learn marries",
        "start": 1058.305,
        "duration": 1.665
    },
    {
        "text": "the training and the prediction very closely together,",
        "start": 1059.97,
        "duration": 2.865
    },
    {
        "text": "which is very nice from",
        "start": 1062.835,
        "duration": 1.695
    },
    {
        "text": "a teaching perspective and",
        "start": 1064.53,
        "duration": 1.44
    },
    {
        "text": "from I have everything in my notebook perspective,",
        "start": 1065.97,
        "duration": 2.28
    },
    {
        "text": "but actually from a deployment infrastructure perspective,",
        "start": 1068.25,
        "duration": 3.03
    },
    {
        "text": "it's a little bit annoying.",
        "start": 1071.28,
        "duration": 1.605
    },
    {
        "text": ">> That's cool. I wrote a machine learning library in C#,",
        "start": 1072.885,
        "duration": 3.66
    },
    {
        "text": "when I was a C# programmer,",
        "start": 1076.545,
        "duration": 1.485
    },
    {
        "text": "and I had the concept of",
        "start": 1078.03,
        "duration": 1.29
    },
    {
        "text": "an AI trainer and an AI model which are interfaces.",
        "start": 1079.32,
        "duration": 3.12
    },
    {
        "text": "Because the reality of the matter is,",
        "start": 1082.44,
        "duration": 1.41
    },
    {
        "text": "is that the true business value of these things is",
        "start": 1083.85,
        "duration": 2.58
    },
    {
        "text": "putting these models out into production.",
        "start": 1086.43,
        "duration": 2.759
    },
    {
        "text": "Does Scikit-Learn have a facility to do that?",
        "start": 1089.189,
        "duration": 2.341
    },
    {
        "text": "I know there's a lot of pickling going on.",
        "start": 1091.53,
        "duration": 1.92
    },
    {
        "text": "How does that work with Scikit-Learn?",
        "start": 1093.45,
        "duration": 1.8
    },
    {
        "text": ">> Basically, you can use joplib or pickle that will always work.",
        "start": 1095.25,
        "duration": 5.205
    },
    {
        "text": "But has the two caveats that basically you need",
        "start": 1100.455,
        "duration": 2.895
    },
    {
        "text": "to have a container with exactly the same version of everything,",
        "start": 1103.35,
        "duration": 3.78
    },
    {
        "text": "which is not that nice.",
        "start": 1107.13,
        "duration": 2.265
    },
    {
        "text": "The other version is using ONNX.",
        "start": 1109.395,
        "duration": 5.385
    },
    {
        "text": "ONNX, I'm not sure if everybody is familiar with it.",
        "start": 1114.78,
        "duration": 2.985
    },
    {
        "text": "It's a serialization format that",
        "start": 1117.765,
        "duration": 2.64
    },
    {
        "text": "Microsoft and Nvidia and a",
        "start": 1120.405,
        "duration": 1.365
    },
    {
        "text": "couple of other companies are working on,",
        "start": 1121.77,
        "duration": 1.725
    },
    {
        "text": "that basically allows you to serialize",
        "start": 1123.495,
        "duration": 2.85
    },
    {
        "text": "arbitrary machine learning models and then run",
        "start": 1126.345,
        "duration": 3.315
    },
    {
        "text": "them, there's the runtimes.",
        "start": 1129.66,
        "duration": 3.705
    },
    {
        "text": "There's Microsoft Scikit-Learn converter for ONNX so you can take",
        "start": 1133.365,
        "duration": 5.745
    },
    {
        "text": "the model and convert it to ONNX and",
        "start": 1139.11,
        "duration": 2.565
    },
    {
        "text": "ONNX only encapsulates the prediction function.",
        "start": 1141.675,
        "duration": 3.18
    },
    {
        "text": "ONNX doesn't know about training models,",
        "start": 1144.855,
        "duration": 1.905
    },
    {
        "text": "ONNX says given data,",
        "start": 1146.76,
        "duration": 1.935
    },
    {
        "text": "this is how you make a prediction with this blob.",
        "start": 1148.695,
        "duration": 2.175
    },
    {
        "text": "But this blob is now completely self-contained,",
        "start": 1150.87,
        "duration": 3.345
    },
    {
        "text": "which a pickle file is not.",
        "start": 1154.215,
        "duration": 2.205
    },
    {
        "text": ">> That's interesting, I had not heard because I thought of",
        "start": 1156.42,
        "duration": 3.585
    },
    {
        "text": "ONNX as like the PDF for machine learning inference.",
        "start": 1160.005,
        "duration": 3.645
    },
    {
        "text": "But I didn't know it extended to",
        "start": 1163.65,
        "duration": 2.085
    },
    {
        "text": "models such as those in Scikit-Learn.",
        "start": 1165.735,
        "duration": 2.865
    },
    {
        "text": "Is this a new thing? How long has this been out?",
        "start": 1168.6,
        "duration": 2.875
    },
    {
        "text": ">> I think it's at least a year or something",
        "start": 1171.475,
        "duration": 3.865
    },
    {
        "text": "since the Scikit-Learn converters have been launched,",
        "start": 1175.34,
        "duration": 6.1
    },
    {
        "text": "maybe a bit longer.",
        "start": 1181.44,
        "duration": 2.43
    },
    {
        "text": "I'm not sure how",
        "start": 1183.87,
        "duration": 1.95
    },
    {
        "text": "intensively they're used right now, but it's probably,",
        "start": 1185.82,
        "duration": 3.795
    },
    {
        "text": "it's the best solution that is not pickles and",
        "start": 1189.615,
        "duration": 3.615
    },
    {
        "text": "the best solution that is platform-agnostic",
        "start": 1193.23,
        "duration": 2.19
    },
    {
        "text": "and version-independent.",
        "start": 1195.42,
        "duration": 2.655
    },
    {
        "text": "ONNX was originally made more for deep learning models,",
        "start": 1198.075,
        "duration": 3.585
    },
    {
        "text": "but they can certainly also now",
        "start": 1201.66,
        "duration": 2.46
    },
    {
        "text": "support random forests and things like this.",
        "start": 1204.12,
        "duration": 4.425
    },
    {
        "text": "I think it's pretty feature complete",
        "start": 1208.545,
        "duration": 1.935
    },
    {
        "text": "and that it can support most of Scikit-Learn, I think.",
        "start": 1210.48,
        "duration": 2.85
    },
    {
        "text": ">> That's cool. I hadn't of heard that.",
        "start": 1213.33,
        "duration": 1.95
    },
    {
        "text": "I'm excited to look into it.",
        "start": 1215.28,
        "duration": 1.26
    },
    {
        "text": "Now, before we get into Dabble,",
        "start": 1216.54,
        "duration": 2.82
    },
    {
        "text": "do you have anything to show us to give people",
        "start": 1219.36,
        "duration": 1.95
    },
    {
        "text": "a sense for if they've never seen Scikit-Learn,",
        "start": 1221.31,
        "duration": 2.535
    },
    {
        "text": "how it works and how one would go about building something.",
        "start": 1223.845,
        "duration": 3.06
    },
    {
        "text": ">> Sure. Totally. It's even better, I can do this.",
        "start": 1226.905,
        "duration": 3.15
    },
    {
        "text": "Then I live code all of the same stuff in Dabble in a single line.",
        "start": 1230.055,
        "duration": 5.22
    },
    {
        "text": ">> Let's do the Scikit-Learn thing first and then we'll come back,",
        "start": 1235.275,
        "duration": 3.705
    },
    {
        "text": "and then we'll talk about Dabble and then we'll come back",
        "start": 1238.98,
        "duration": 1.68
    },
    {
        "text": "and see how it's better. Let's do that.",
        "start": 1240.66,
        "duration": 2.28
    },
    {
        "text": ">> What you see here is",
        "start": 1242.94,
        "duration": 2.61
    },
    {
        "text": "a Jupyter Notebook that's running on Azure Machine Learning,",
        "start": 1245.55,
        "duration": 3.285
    },
    {
        "text": "so you could just run the same Notebook",
        "start": 1248.835,
        "duration": 1.755
    },
    {
        "text": "locally in your Jupyter or Jupyter lab.",
        "start": 1250.59,
        "duration": 2.31
    },
    {
        "text": "But here I'm just running it on",
        "start": 1252.9,
        "duration": 1.5
    },
    {
        "text": "Azure Machine Learning on a remote compute instance.",
        "start": 1254.4,
        "duration": 3.22
    },
    {
        "text": "I'm going to use Scikit-Learn here",
        "start": 1258.23,
        "duration": 3.115
    },
    {
        "text": "to do a simple binary classification problem.",
        "start": 1261.345,
        "duration": 3.165
    },
    {
        "text": "I start by loading the data,",
        "start": 1264.51,
        "duration": 1.5
    },
    {
        "text": "I'm using pandas to read a CSV file.",
        "start": 1266.01,
        "duration": 2.625
    },
    {
        "text": "This is a classical machine learning data set,",
        "start": 1268.635,
        "duration": 3.255
    },
    {
        "text": "which is the adult census dataset,",
        "start": 1271.89,
        "duration": 1.95
    },
    {
        "text": "which has census data from",
        "start": 1273.84,
        "duration": 2.31
    },
    {
        "text": "around 1990 and some of the census properties of people.",
        "start": 1276.15,
        "duration": 4.365
    },
    {
        "text": "The goal is to predict whether their income",
        "start": 1280.515,
        "duration": 1.845
    },
    {
        "text": "will be less than 50k a year or more.",
        "start": 1282.36,
        "duration": 3.22
    },
    {
        "text": "So Scikit-Learn usually separates the features or say,",
        "start": 1285.8,
        "duration": 7.315
    },
    {
        "text": "independent variables from the target into",
        "start": 1293.115,
        "duration": 3.405
    },
    {
        "text": "two different [inaudible] frames or not [inaudible].",
        "start": 1296.52,
        "duration": 3.0
    },
    {
        "text": "Here, income will be",
        "start": 1299.52,
        "duration": 1.74
    },
    {
        "text": "the target column and data features will be all the other columns,",
        "start": 1301.26,
        "duration": 3.24
    },
    {
        "text": "which will be the input features.",
        "start": 1304.5,
        "duration": 2.38
    },
    {
        "text": "Then I'm actually going to do just slightly more",
        "start": 1308.87,
        "duration": 3.7
    },
    {
        "text": "advanced Scikit-Learn way of doing it,",
        "start": 1312.57,
        "duration": 3.09
    },
    {
        "text": "which is using pipelines and column transformers.",
        "start": 1315.66,
        "duration": 2.58
    },
    {
        "text": "This allow you to encapsulate all of your machine learning",
        "start": 1318.24,
        "duration": 2.88
    },
    {
        "text": "workflow in a single Python object,",
        "start": 1321.12,
        "duration": 2.91
    },
    {
        "text": "which you could then pickle and store or send somewhere.",
        "start": 1324.03,
        "duration": 5.325
    },
    {
        "text": "Here, I start off by splitting my data into training a test set,",
        "start": 1329.355,
        "duration": 4.725
    },
    {
        "text": "to build and evaluate the model.",
        "start": 1334.08,
        "duration": 3.075
    },
    {
        "text": "The column transformer here is something that",
        "start": 1337.155,
        "duration": 4.245
    },
    {
        "text": "allows you to apply different transformations to",
        "start": 1341.4,
        "duration": 2.13
    },
    {
        "text": "different parts of your data set.",
        "start": 1343.53,
        "duration": 2.715
    },
    {
        "text": "I will apply OneHotEncoder to",
        "start": 1346.245,
        "duration": 3.525
    },
    {
        "text": "the categorical variables and the",
        "start": 1349.77,
        "duration": 1.5
    },
    {
        "text": "StandardScaler to continuous variables.",
        "start": 1351.27,
        "duration": 2.79
    },
    {
        "text": "The way I'm selecting this is I say, well,",
        "start": 1354.06,
        "duration": 3.705
    },
    {
        "text": "make a column selector and select city type object and make",
        "start": 1357.765,
        "duration": 2.595
    },
    {
        "text": "a column selector that selects everything but the dtype objects.",
        "start": 1360.36,
        "duration": 3.075
    },
    {
        "text": "The dtype object are going to be interpreted as",
        "start": 1363.435,
        "duration": 2.655
    },
    {
        "text": "categorical and the rest are going to",
        "start": 1366.09,
        "duration": 1.59
    },
    {
        "text": "be interpreted as continuous.",
        "start": 1367.68,
        "duration": 2.535
    },
    {
        "text": "This is my preprocessing and then I",
        "start": 1370.215,
        "duration": 2.475
    },
    {
        "text": "pipeline this together with logistic regression models,",
        "start": 1372.69,
        "duration": 2.4
    },
    {
        "text": "so this is a simple binary classification model here.",
        "start": 1375.09,
        "duration": 3.12
    },
    {
        "text": "This basically declares the model.",
        "start": 1378.21,
        "duration": 2.85
    },
    {
        "text": "Another thing I wanted to briefly show,",
        "start": 1381.06,
        "duration": 2.16
    },
    {
        "text": "so this is text representation of the model,",
        "start": 1383.22,
        "duration": 2.595
    },
    {
        "text": "the thing that we've recently built in.",
        "start": 1385.815,
        "duration": 1.53
    },
    {
        "text": "If you set this sklearn.set_config diagram is you get",
        "start": 1387.345,
        "duration": 3.375
    },
    {
        "text": "some nice HTML representation that shows you the modeling,",
        "start": 1390.72,
        "duration": 3.9
    },
    {
        "text": "you click on the \"Parameters\" and so on.",
        "start": 1394.62,
        "duration": 2.97
    },
    {
        "text": ">> That's cool.",
        "start": 1397.59,
        "duration": 1.32
    },
    {
        "text": ">> That's kind of new, so I wanted to show this off.",
        "start": 1398.91,
        "duration": 2.76
    },
    {
        "text": "Then whenever you have a model,",
        "start": 1401.67,
        "duration": 2.31
    },
    {
        "text": "usually you want to tune parameters and",
        "start": 1403.98,
        "duration": 2.28
    },
    {
        "text": "so logistic regression is penalized in Scikit-Learn.",
        "start": 1406.26,
        "duration": 4.095
    },
    {
        "text": "Here I'm defining a parameter space for",
        "start": 1410.355,
        "duration": 3.615
    },
    {
        "text": "logistic regression to tune",
        "start": 1413.97,
        "duration": 1.8
    },
    {
        "text": "the regularization parameter and then running grid search.",
        "start": 1415.77,
        "duration": 4.75
    },
    {
        "text": "This is where actual fitting will take place.",
        "start": 1421.52,
        "duration": 3.235
    },
    {
        "text": "It will run cross-validation and",
        "start": 1424.755,
        "duration": 2.925
    },
    {
        "text": "for each possible value of",
        "start": 1427.68,
        "duration": 1.65
    },
    {
        "text": "the regularization parameter as specified here.",
        "start": 1429.33,
        "duration": 2.595
    },
    {
        "text": "Then at the end, it will evaluate",
        "start": 1431.925,
        "duration": 2.115
    },
    {
        "text": "the best model it found on the test set.",
        "start": 1434.04,
        "duration": 1.845
    },
    {
        "text": ">> I see. You're actually running multiple models",
        "start": 1435.885,
        "duration": 2.505
    },
    {
        "text": "using the parameterization for regularization there.",
        "start": 1438.39,
        "duration": 3.42
    },
    {
        "text": ">> Yeah.",
        "start": 1441.81,
        "duration": 1.045
    },
    {
        "text": ">> Okay. What is your hybrid parameter that you're putting in?",
        "start": 1442.855,
        "duration": 4.06
    },
    {
        "text": ">> C, that's the autoregularization. Yeah.",
        "start": 1446.915,
        "duration": 4.4
    },
    {
        "text": ">> That's cool. Then it just goes ahead and goes through all of",
        "start": 1451.315,
        "duration": 3.395
    },
    {
        "text": "those things and finds the best model",
        "start": 1454.71,
        "duration": 2.01
    },
    {
        "text": "with that regularization parameter.",
        "start": 1456.72,
        "duration": 2.625
    },
    {
        "text": ">> Yeah, so it does. Right now,",
        "start": 1459.345,
        "duration": 2.925
    },
    {
        "text": "so there are seven parameters.",
        "start": 1462.27,
        "duration": 4.44
    },
    {
        "text": "For each of them, it has five-fold cross-validation.",
        "start": 1466.71,
        "duration": 3.1
    },
    {
        "text": "So it trains 35 models for that,",
        "start": 1472.52,
        "duration": 6.775
    },
    {
        "text": "and then it finds the best parameter using cross-validation,",
        "start": 1479.295,
        "duration": 4.305
    },
    {
        "text": "and then it retrains the model on the full training dataset.",
        "start": 1483.6,
        "duration": 2.4
    },
    {
        "text": "So in total we trained 36 models,",
        "start": 1486.0,
        "duration": 2.445
    },
    {
        "text": "and then evaluated the last model on the test set.",
        "start": 1488.445,
        "duration": 3.195
    },
    {
        "text": ">> That's cool. So all of that and just,",
        "start": 1491.64,
        "duration": 2.61
    },
    {
        "text": "I think it's seven different cells, basically.",
        "start": 1494.25,
        "duration": 3.975
    },
    {
        "text": ">> Yeah.",
        "start": 1498.225,
        "duration": 0.795
    },
    {
        "text": ">> That's cool.",
        "start": 1499.02,
        "duration": 1.305
    },
    {
        "text": ">> This is a relatively sophisticated example where I show",
        "start": 1500.325,
        "duration": 3.885
    },
    {
        "text": "off all the different parts and",
        "start": 1504.21,
        "duration": 1.59
    },
    {
        "text": "how you can ideally put them together.",
        "start": 1505.8,
        "duration": 2.235
    },
    {
        "text": "You can obviously also just instantiate",
        "start": 1508.035,
        "duration": 2.445
    },
    {
        "text": "logistic regression call fit and call score,",
        "start": 1510.48,
        "duration": 2.49
    },
    {
        "text": "and then you fit your Scikit-Learn model on",
        "start": 1512.97,
        "duration": 1.47
    },
    {
        "text": "your pre-processed data or something.",
        "start": 1514.44,
        "duration": 1.635
    },
    {
        "text": ">> I see. That's cool.",
        "start": 1516.075,
        "duration": 2.055
    },
    {
        "text": "So tell me about dabl.",
        "start": 1518.13,
        "duration": 2.55
    },
    {
        "text": "For example, you mentioned a little bit about dabl.",
        "start": 1520.68,
        "duration": 2.46
    },
    {
        "text": "Because I hadn't heard that before,",
        "start": 1523.14,
        "duration": 1.59
    },
    {
        "text": "but it's something you're working on?",
        "start": 1524.73,
        "duration": 1.605
    },
    {
        "text": ">> Obviously, I love Scikit-Learn.",
        "start": 1526.335,
        "duration": 2.64
    },
    {
        "text": "But the thing is that Scikit-Learn asks you to be very,",
        "start": 1528.975,
        "duration": 4.245
    },
    {
        "text": "very explicit about things.",
        "start": 1533.22,
        "duration": 1.965
    },
    {
        "text": "For example, for the pre-processing we had up here, you say,",
        "start": 1535.185,
        "duration": 3.48
    },
    {
        "text": "\"Well, I want to scale my data,",
        "start": 1538.665,
        "duration": 1.575
    },
    {
        "text": "I want to encode my data.\"",
        "start": 1540.24,
        "duration": 1.815
    },
    {
        "text": "If I had missing values,",
        "start": 1542.055,
        "duration": 1.485
    },
    {
        "text": "I would need to specify how to impute them and then I have to say,",
        "start": 1543.54,
        "duration": 3.57
    },
    {
        "text": "\"Specifically these are the parameters I want to tune,",
        "start": 1547.11,
        "duration": 2.25
    },
    {
        "text": "and this is how I want to tune them.\"",
        "start": 1549.36,
        "duration": 2.26
    },
    {
        "text": "Scikit-learn is not opinionated at all.",
        "start": 1551.9,
        "duration": 3.415
    },
    {
        "text": "Scikit-learn requires you to be really,",
        "start": 1555.315,
        "duration": 3.435
    },
    {
        "text": "really precise in what you're doing,",
        "start": 1558.75,
        "duration": 1.65
    },
    {
        "text": "which is great for some settings,",
        "start": 1560.4,
        "duration": 1.44
    },
    {
        "text": "like in a production setting, you want to",
        "start": 1561.84,
        "duration": 1.26
    },
    {
        "text": "be precise in what you're doing.",
        "start": 1563.1,
        "duration": 1.335
    },
    {
        "text": "You want to make sure you understand",
        "start": 1564.435,
        "duration": 1.455
    },
    {
        "text": "exactly what your model is doing.",
        "start": 1565.89,
        "duration": 1.485
    },
    {
        "text": "But maybe if you want to iterate quickly",
        "start": 1567.375,
        "duration": 3.525
    },
    {
        "text": "or maybe there's a default that often works,",
        "start": 1570.9,
        "duration": 4.005
    },
    {
        "text": "it might be nice to have something that's a",
        "start": 1574.905,
        "duration": 1.575
    },
    {
        "text": "bit more opinionated that",
        "start": 1576.48,
        "duration": 1.62
    },
    {
        "text": "can give you some results quickly",
        "start": 1578.1,
        "duration": 1.575
    },
    {
        "text": "and allows you to iterate really quickly.",
        "start": 1579.675,
        "duration": 2.575
    },
    {
        "text": "Dabl basically just wraps Scikit-Learn",
        "start": 1583.25,
        "duration": 3.19
    },
    {
        "text": "and does most of the cells in this automatically.",
        "start": 1586.44,
        "duration": 5.29
    },
    {
        "text": "There's a couple of things in dabl,",
        "start": 1598.52,
        "duration": 2.86
    },
    {
        "text": "but if I want to do what I just did above,",
        "start": 1601.38,
        "duration": 1.53
    },
    {
        "text": "then it would be something like.",
        "start": 1602.91,
        "duration": 2.2
    },
    {
        "text": "Basically what this does is,",
        "start": 1608.42,
        "duration": 2.17
    },
    {
        "text": "so there's basically three things or four things in dabl.",
        "start": 1610.59,
        "duration": 3.12
    },
    {
        "text": "The simple classifier, basically detects what the data types are,",
        "start": 1613.71,
        "duration": 4.735
    },
    {
        "text": "automatically detects what to scale and",
        "start": 1618.445,
        "duration": 2.815
    },
    {
        "text": "if there's an index that it should drop.",
        "start": 1621.26,
        "duration": 3.29
    },
    {
        "text": "You can also give it a data frame",
        "start": 1624.55,
        "duration": 2.18
    },
    {
        "text": "and say this is the target column,",
        "start": 1626.73,
        "duration": 1.59
    },
    {
        "text": "and then it does all the scaling and everything automatically,",
        "start": 1628.32,
        "duration": 2.655
    },
    {
        "text": "then it does cross-validation and it runs a bunch",
        "start": 1630.975,
        "duration": 2.115
    },
    {
        "text": "of the simple classifiers like you can see here.",
        "start": 1633.09,
        "duration": 1.95
    },
    {
        "text": "Dummy classifier, Gaussian Naive Bayes,",
        "start": 1635.04,
        "duration": 1.47
    },
    {
        "text": "multinomial decision tree, logistic",
        "start": 1636.51,
        "duration": 1.47
    },
    {
        "text": "regression with different organization variants.",
        "start": 1637.98,
        "duration": 2.43
    },
    {
        "text": "Now we have, basically this is here is",
        "start": 1640.41,
        "duration": 1.86
    },
    {
        "text": "the same result that we had head above.",
        "start": 1642.27,
        "duration": 2.985
    },
    {
        "text": ">> Interesting.",
        "start": 1645.255,
        "duration": 1.41
    },
    {
        "text": ">> Only that I only had to write a single line.",
        "start": 1646.665,
        "duration": 2.235
    },
    {
        "text": "Well, I used to train split from above. It's two lines.",
        "start": 1648.9,
        "duration": 5.775
    },
    {
        "text": "There's another thing it can do,",
        "start": 1654.675,
        "duration": 4.425
    },
    {
        "text": "which is plotting, which I probably should have done before.",
        "start": 1659.1,
        "duration": 3.43
    },
    {
        "text": "It doesn't work that well, well it kind of",
        "start": 1670.34,
        "duration": 2.89
    },
    {
        "text": "works simply well, on this data set.",
        "start": 1673.23,
        "duration": 2.7
    },
    {
        "text": "So it gives you a visual summary.",
        "start": 1675.93,
        "duration": 1.5
    },
    {
        "text": "In machine learning, we often have very high dimensional datasets.",
        "start": 1677.43,
        "duration": 2.775
    },
    {
        "text": "So there's actually no plotting library that's",
        "start": 1680.205,
        "duration": 2.955
    },
    {
        "text": "really targeted as doing visualizations for machine learning.",
        "start": 1683.16,
        "duration": 3.585
    },
    {
        "text": "So here starts like it gives you a distribution of the target,",
        "start": 1686.745,
        "duration": 3.54
    },
    {
        "text": "then it gives you, there's like two continuous variables,",
        "start": 1690.285,
        "duration": 2.685
    },
    {
        "text": "age and capital-gain and it gives you a pair plot for this,",
        "start": 1692.97,
        "duration": 3.93
    },
    {
        "text": "it gives you a PCA plot,",
        "start": 1696.9,
        "duration": 1.86
    },
    {
        "text": "it gives you linear discriminant.",
        "start": 1698.76,
        "duration": 2.295
    },
    {
        "text": "Then for categorical variables,",
        "start": 1701.055,
        "duration": 1.905
    },
    {
        "text": "it gives you a mosaic plot that shows you,",
        "start": 1702.96,
        "duration": 4.215
    },
    {
        "text": "I'm sorry, I don't know how to deal with this,",
        "start": 1707.175,
        "duration": 2.955
    },
    {
        "text": "how that's popping up.",
        "start": 1710.13,
        "duration": 1.62
    },
    {
        "text": ">> Escape. There you go.",
        "start": 1711.75,
        "duration": 1.35
    },
    {
        "text": ">> Yeah. It says, well,",
        "start": 1713.1,
        "duration": 2.07
    },
    {
        "text": "relationship status was actually the most important,",
        "start": 1715.17,
        "duration": 2.895
    },
    {
        "text": "and it shows for the categorical variables in this mosaic plot,",
        "start": 1718.065,
        "duration": 3.96
    },
    {
        "text": "both with the most common relationships are,",
        "start": 1722.025,
        "duration": 2.805
    },
    {
        "text": "but then also the cost balance in each of them.",
        "start": 1724.83,
        "duration": 2.61
    },
    {
        "text": ">> That's really cool. How were the couple of lines?",
        "start": 1727.44,
        "duration": 4.08
    },
    {
        "text": ">> This was one line also, again.",
        "start": 1731.52,
        "duration": 2.71
    },
    {
        "text": "You can do this for regression as well.",
        "start": 1736.01,
        "duration": 2.92
    },
    {
        "text": "It does some type and friends and then it tries to figure out",
        "start": 1738.93,
        "duration": 2.52
    },
    {
        "text": "what are the most interesting plots to show you.",
        "start": 1741.45,
        "duration": 3.06
    },
    {
        "text": "Then to give you a very,",
        "start": 1744.51,
        "duration": 2.04
    },
    {
        "text": "very quick idea of what's happening in your data.",
        "start": 1746.55,
        "duration": 5.17
    },
    {
        "text": ">> This is now really cool.",
        "start": 1752.06,
        "duration": 2.95
    },
    {
        "text": "I'm excited, you were saying and then there's more stuff,",
        "start": 1755.01,
        "duration": 2.985
    },
    {
        "text": "like there's more and that's cool.",
        "start": 1757.995,
        "duration": 1.72
    },
    {
        "text": ">> Yeah. Like these two things work reasonably well, I think.",
        "start": 1759.715,
        "duration": 5.47
    },
    {
        "text": "There's two more things that are",
        "start": 1765.185,
        "duration": 1.755
    },
    {
        "text": "more experimental like all of this is experimental.",
        "start": 1766.94,
        "duration": 2.04
    },
    {
        "text": "But there are even more experimental and that's",
        "start": 1768.98,
        "duration": 2.31
    },
    {
        "text": "basically one is that there's a thing called any classifier,",
        "start": 1771.29,
        "duration": 4.84
    },
    {
        "text": "which does some fancy optimization between all different models.",
        "start": 1776.13,
        "duration": 5.235
    },
    {
        "text": "So it tries out different gradient boosting random forest,",
        "start": 1781.365,
        "duration": 3.69
    },
    {
        "text": "support vector machine and uses",
        "start": 1785.055,
        "duration": 2.01
    },
    {
        "text": "successive huffing and a fixed portfolio and does",
        "start": 1787.065,
        "duration": 2.85
    },
    {
        "text": "some things that should give you the simplest version of RML,",
        "start": 1789.915,
        "duration": 6.135
    },
    {
        "text": "but it should work reasonably well.",
        "start": 1796.05,
        "duration": 3.46
    },
    {
        "text": "Then there's another one which is,",
        "start": 1799.58,
        "duration": 2.83
    },
    {
        "text": "and it also again does all the pre-processing for you.",
        "start": 1802.41,
        "duration": 2.58
    },
    {
        "text": "Then the last thing is there's an explained function that is there",
        "start": 1804.99,
        "duration": 3.3
    },
    {
        "text": "to give you-all the metrics and interpretation of your model.",
        "start": 1808.29,
        "duration": 3.795
    },
    {
        "text": "So it gives you feature importances and",
        "start": 1812.085,
        "duration": 2.235
    },
    {
        "text": "ROC curves and all of this kind of stuff.",
        "start": 1814.32,
        "duration": 2.55
    },
    {
        "text": ">> This is all super cool.",
        "start": 1816.87,
        "duration": 2.205
    },
    {
        "text": "I just have a couple more questions just to",
        "start": 1819.075,
        "duration": 2.235
    },
    {
        "text": "finish up because I know I've taken a lot of your time.",
        "start": 1821.31,
        "duration": 2.625
    },
    {
        "text": "The first question I have, and I think",
        "start": 1823.935,
        "duration": 1.755
    },
    {
        "text": "you've pointed it out a little bit,",
        "start": 1825.69,
        "duration": 2.01
    },
    {
        "text": "where do you see machine learning going from here?",
        "start": 1827.7,
        "duration": 3.09
    },
    {
        "text": "It looks like a lot of those opinions",
        "start": 1830.79,
        "duration": 2.04
    },
    {
        "text": "were influenced what went into dabl?",
        "start": 1832.83,
        "duration": 3.51
    },
    {
        "text": ">> Yes, definitely. I was",
        "start": 1836.34,
        "duration": 4.47
    },
    {
        "text": "thinking about what is the next best tool",
        "start": 1840.81,
        "duration": 2.13
    },
    {
        "text": "that I can build that will help people?",
        "start": 1842.94,
        "duration": 2.44
    },
    {
        "text": "That was my motivation for dabl.",
        "start": 1845.96,
        "duration": 3.92
    },
    {
        "text": "Dabl is really for the data scientist,",
        "start": 1851.09,
        "duration": 4.12
    },
    {
        "text": "dabbling with the data,",
        "start": 1855.21,
        "duration": 1.425
    },
    {
        "text": "playing around, iterating quickly.",
        "start": 1856.635,
        "duration": 2.1
    },
    {
        "text": "The other part that I think it's going to be",
        "start": 1858.735,
        "duration": 2.355
    },
    {
        "text": "important is like more interpretability,",
        "start": 1861.09,
        "duration": 2.85
    },
    {
        "text": "also potentially looking at fairness and other ethical concerns,",
        "start": 1863.94,
        "duration": 5.34
    },
    {
        "text": "and having infrastructure for machine learning so that you can",
        "start": 1869.28,
        "duration": 6.33
    },
    {
        "text": "have an experimental repository and a unified way to access data.",
        "start": 1875.61,
        "duration": 7.065
    },
    {
        "text": "I think some of the big companies have,",
        "start": 1882.675,
        "duration": 5.065
    },
    {
        "text": "I noticed, at least Facebook and Google,",
        "start": 1889.28,
        "duration": 2.68
    },
    {
        "text": "they have centralized ways to do experiments,",
        "start": 1891.96,
        "duration": 2.25
    },
    {
        "text": "to do machine learning experiments or",
        "start": 1894.21,
        "duration": 1.2
    },
    {
        "text": "other drive data of experiments,",
        "start": 1895.41,
        "duration": 1.44
    },
    {
        "text": "where people can go in and launch their own trials,",
        "start": 1896.85,
        "duration": 3.51
    },
    {
        "text": "and this really gives them a big advantage.",
        "start": 1900.36,
        "duration": 2.91
    },
    {
        "text": "But this is not something that most companies do.",
        "start": 1903.27,
        "duration": 2.67
    },
    {
        "text": "So really doing this right is",
        "start": 1905.94,
        "duration": 2.46
    },
    {
        "text": "probably one of the next things and there's a bunch of things,",
        "start": 1908.4,
        "duration": 2.67
    },
    {
        "text": "like Azure machine learning has some tools to solve this problem.",
        "start": 1911.07,
        "duration": 5.175
    },
    {
        "text": "Data pre-access tools will help this problem.",
        "start": 1916.245,
        "duration": 2.46
    },
    {
        "text": "There's some Kubeflow and there's a bunch of other things,",
        "start": 1918.705,
        "duration": 4.785
    },
    {
        "text": "but this is a space where I think we'll",
        "start": 1923.49,
        "duration": 2.1
    },
    {
        "text": "see a lot of",
        "start": 1925.59,
        "duration": 2.67
    },
    {
        "text": "interesting things happening for machine learning now.",
        "start": 1928.26,
        "duration": 2.58
    },
    {
        "text": "As I said, going from zero to something is the hardest part.",
        "start": 1930.84,
        "duration": 5.19
    },
    {
        "text": "I think making this part easier from",
        "start": 1936.03,
        "duration": 2.43
    },
    {
        "text": "the infrastructure side is going to be an important piece.",
        "start": 1938.46,
        "duration": 3.645
    },
    {
        "text": ">> Well, this has been amazing.",
        "start": 1942.105,
        "duration": 2.22
    },
    {
        "text": "Where can people go to find out more about Scikit-Learn and dabl?",
        "start": 1944.325,
        "duration": 4.075
    },
    {
        "text": ">> Well, dabl.github.io for dabl.",
        "start": 1950.03,
        "duration": 4.135
    },
    {
        "text": "You can obviously find me on Twitter as like Andreas Muller ML.",
        "start": 1954.165,
        "duration": 4.14
    },
    {
        "text": "The Scikit-Learn website has so much documentation,",
        "start": 1958.305,
        "duration": 3.945
    },
    {
        "text": "so definitely check that out.",
        "start": 1962.25,
        "duration": 1.245
    },
    {
        "text": "If you want, you can also find",
        "start": 1963.495,
        "duration": 2.205
    },
    {
        "text": "my lecture series I did at",
        "start": 1965.7,
        "duration": 1.98
    },
    {
        "text": "Columbia on applied machine learning on YouTube.",
        "start": 1967.68,
        "duration": 2.91
    },
    {
        "text": "That's youtube.com/AndreasMuller or something,",
        "start": 1970.59,
        "duration": 4.575
    },
    {
        "text": "you can probably find it.",
        "start": 1975.165,
        "duration": 1.815
    },
    {
        "text": "That's a semester long lecture that goes over",
        "start": 1976.98,
        "duration": 3.285
    },
    {
        "text": "Scikit-Learn and Keras and some other stuff.",
        "start": 1980.265,
        "duration": 4.08
    },
    {
        "text": ">> Well, this has been amazing.",
        "start": 1984.345,
        "duration": 1.845
    },
    {
        "text": "Thank you so much for spending some time with us Andreas,",
        "start": 1986.19,
        "duration": 3.15
    },
    {
        "text": "Andy, because now we're BFFs forever.",
        "start": 1989.34,
        "duration": 2.625
    },
    {
        "text": "Again, thank you for watching.",
        "start": 1991.965,
        "duration": 1.665
    },
    {
        "text": "It's been glorious spending some time with you.",
        "start": 1993.63,
        "duration": 1.995
    },
    {
        "text": "Hopefully you've learned a lot. I know I have.",
        "start": 1995.625,
        "duration": 1.545
    },
    {
        "text": "Thank you so much for watching and we'll see you next time.",
        "start": 1997.17,
        "duration": 1.95
    },
    {
        "text": "Take care.",
        "start": 1999.12,
        "duration": 0.39
    },
    {
        "text": "[MUSIC]",
        "start": 1999.51,
        "duration": 14.49
    }
]