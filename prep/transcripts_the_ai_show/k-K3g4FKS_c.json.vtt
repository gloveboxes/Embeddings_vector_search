[
    {
        "text": ">> Hi, my name is Micheleen Harris.",
        "start": 1.47,
        "duration": 5.92
    },
    {
        "text": "I come from a acquisition actually",
        "start": 7.39,
        "duration": 2.985
    },
    {
        "text": "from Microsoft acquiring Revolution Analytics.",
        "start": 10.375,
        "duration": 2.995
    },
    {
        "text": "I use \"R\" from a,",
        "start": 13.37,
        "duration": 1.68
    },
    {
        "text": "from a very long time and,",
        "start": 15.05,
        "duration": 2.195
    },
    {
        "text": "and now I'm moving into",
        "start": 17.245,
        "duration": 2.415
    },
    {
        "text": "the Python realm hence my \"twitter handle IR Python\".",
        "start": 19.66,
        "duration": 3.86
    },
    {
        "text": "And I'm now part",
        "start": 23.52,
        "duration": 3.11
    },
    {
        "text": "of Microsoft in commercial software engineering.",
        "start": 26.63,
        "duration": 2.255
    },
    {
        "text": ">> Excellent, and I'm from New Zealand which",
        "start": 28.885,
        "duration": 3.525
    },
    {
        "text": "is the birthplace of",
        "start": 32.41,
        "duration": 1.29
    },
    {
        "text": "revolution are out of the University of Auckland.",
        "start": 33.7,
        "duration": 2.22
    },
    {
        "text": "So, we were just discussing",
        "start": 35.92,
        "duration": 1.555
    },
    {
        "text": "two degrees of separation already.",
        "start": 37.475,
        "duration": 2.125
    },
    {
        "text": "And I work as a software engineer across Asia.",
        "start": 39.6,
        "duration": 3.645
    },
    {
        "text": "And we've been here this week together working on",
        "start": 43.245,
        "duration": 3.245
    },
    {
        "text": "an open heck for computer vision and machine learning.",
        "start": 46.49,
        "duration": 3.31
    },
    {
        "text": "And one of the things that came",
        "start": 49.8,
        "duration": 1.47
    },
    {
        "text": "up during the presentation,",
        "start": 51.27,
        "duration": 1.53
    },
    {
        "text": "was there's this idea around what is machine learning?",
        "start": 52.8,
        "duration": 3.32
    },
    {
        "text": "What is deep learning?",
        "start": 56.12,
        "duration": 1.295
    },
    {
        "text": "And how do these concepts all come together?",
        "start": 57.415,
        "duration": 2.57
    },
    {
        "text": "And I spent a bit of time demystifying",
        "start": 59.985,
        "duration": 2.435
    },
    {
        "text": "this concept and sharing it",
        "start": 62.42,
        "duration": 1.45
    },
    {
        "text": "amongst the group that I was working within.",
        "start": 63.87,
        "duration": 1.91
    },
    {
        "text": "And we thought it would be",
        "start": 65.78,
        "duration": 1.01
    },
    {
        "text": "great to bring it to the studio to",
        "start": 66.79,
        "duration": 1.38
    },
    {
        "text": "share with more people and all of you out here.",
        "start": 68.17,
        "duration": 3.495
    },
    {
        "text": "So where we start?",
        "start": 71.665,
        "duration": 2.015
    },
    {
        "text": "I studied Computer Vision at University",
        "start": 73.68,
        "duration": 2.13
    },
    {
        "text": "20 years ago and",
        "start": 75.81,
        "duration": 1.655
    },
    {
        "text": "things in computer vision were quite different back then.",
        "start": 77.465,
        "duration": 2.325
    },
    {
        "text": "They weren't necessarily what we have",
        "start": 79.79,
        "duration": 1.85
    },
    {
        "text": "today but there are a lot of",
        "start": 81.64,
        "duration": 1.29
    },
    {
        "text": "concepts and things that were quite similar.",
        "start": 82.93,
        "duration": 2.03
    },
    {
        "text": "And so when we think about computer",
        "start": 84.96,
        "duration": 1.71
    },
    {
        "text": "vision that really is,",
        "start": 86.67,
        "duration": 1.24
    },
    {
        "text": "4 main areas that we approach.",
        "start": 87.91,
        "duration": 2.49
    },
    {
        "text": "The first one being image classification.",
        "start": 90.4,
        "duration": 2.185
    },
    {
        "text": "This is, is there a deer in the image.",
        "start": 92.585,
        "duration": 2.115
    },
    {
        "text": "If you've seen, Silicon Valley",
        "start": 94.7,
        "duration": 1.54
    },
    {
        "text": "you know hot dog not hot dog.",
        "start": 96.24,
        "duration": 1.76
    },
    {
        "text": ">> Yup.",
        "start": 98.0,
        "duration": 0.295
    },
    {
        "text": ">> Concept. And this is where the computer is determining",
        "start": 98.295,
        "duration": 4.265
    },
    {
        "text": "if a particular object exists within",
        "start": 102.56,
        "duration": 2.27
    },
    {
        "text": "a photo within an image. Object detection.",
        "start": 104.83,
        "duration": 3.205
    },
    {
        "text": "It's the way it is the deer in the image.",
        "start": 108.035,
        "duration": 2.465
    },
    {
        "text": "So it's not just is it here?",
        "start": 110.5,
        "duration": 1.545
    },
    {
        "text": "Can you find that? Can you put a box around it?",
        "start": 112.045,
        "duration": 2.78
    },
    {
        "text": "Image segmentation.",
        "start": 114.825,
        "duration": 1.995
    },
    {
        "text": "Where exactly is the deer?",
        "start": 116.82,
        "duration": 1.6
    },
    {
        "text": "What are the pixels?",
        "start": 118.42,
        "duration": 1.225
    },
    {
        "text": "And this is the tight outline around",
        "start": 119.645,
        "duration": 1.815
    },
    {
        "text": "that particular object that we've identified.",
        "start": 121.46,
        "duration": 2.89
    },
    {
        "text": "And then image similarity.",
        "start": 124.35,
        "duration": 2.11
    },
    {
        "text": "Which images are similar to the query image.",
        "start": 126.46,
        "duration": 2.3
    },
    {
        "text": "So you may have seen",
        "start": 128.76,
        "duration": 1.53
    },
    {
        "text": "examples where we do an image search and bang",
        "start": 130.29,
        "duration": 3.315
    },
    {
        "text": "and it does a reverse look up or it",
        "start": 133.605,
        "duration": 2.975
    },
    {
        "text": "uses a photo to find either a similar type images.",
        "start": 136.58,
        "duration": 3.115
    },
    {
        "text": ">> Yeah that's actually one of our cognitive services.",
        "start": 139.695,
        "duration": 2.54
    },
    {
        "text": "It's a Bing Image Search. I love using that.",
        "start": 142.235,
        "duration": 3.985
    },
    {
        "text": ">> And a length max search as well, where you can.",
        "start": 146.22,
        "duration": 2.15
    },
    {
        "text": ">> Yes.",
        "start": 148.37,
        "duration": 0.21
    },
    {
        "text": ">> look at the building and get a response back to you.",
        "start": 148.58,
        "duration": 2.2
    },
    {
        "text": ">> Yeah.",
        "start": 150.78,
        "duration": 0.35
    },
    {
        "text": ">> And so.",
        "start": 151.13,
        "duration": 2.08
    },
    {
        "text": "When we talk about AI machine learning, deep learning,",
        "start": 153.21,
        "duration": 3.89
    },
    {
        "text": "the way I like to think about it is",
        "start": 157.1,
        "duration": 2.355
    },
    {
        "text": "traditional supervised machine learning really",
        "start": 159.455,
        "duration": 2.775
    },
    {
        "text": "has a domain expert or a data science or",
        "start": 162.23,
        "duration": 2.11
    },
    {
        "text": "a person involved that has an expertise in the field.",
        "start": 164.34,
        "duration": 3.365
    },
    {
        "text": "So they look for",
        "start": 167.705,
        "duration": 1.8
    },
    {
        "text": "the elements that are",
        "start": 169.505,
        "duration": 1.325
    },
    {
        "text": "important and they call these the features",
        "start": 170.83,
        "duration": 2.2
    },
    {
        "text": "and they extract these",
        "start": 173.03,
        "duration": 1.44
    },
    {
        "text": "and they put weights and preferences on",
        "start": 174.47,
        "duration": 2.01
    },
    {
        "text": "them and then they put them through",
        "start": 176.48,
        "duration": 1.66
    },
    {
        "text": "some form of algorithm to classify,",
        "start": 178.14,
        "duration": 2.15
    },
    {
        "text": "to come out with the answer.",
        "start": 180.29,
        "duration": 1.355
    },
    {
        "text": "So in this example is there a dog?",
        "start": 181.645,
        "duration": 2.115
    },
    {
        "text": "And it will go through this traditional approach of",
        "start": 183.76,
        "duration": 2.63
    },
    {
        "text": "what's the feature's important to determine a dog?",
        "start": 186.39,
        "duration": 2.655
    },
    {
        "text": "And then the outcome would be yes,",
        "start": 189.045,
        "duration": 2.155
    },
    {
        "text": "no, it is, it isn't.",
        "start": 191.2,
        "duration": 2.31
    },
    {
        "text": ">> That's actually like a really nice introduction",
        "start": 193.51,
        "duration": 3.73
    },
    {
        "text": "because we all know we can't do two data science",
        "start": 197.24,
        "duration": 2.71
    },
    {
        "text": "without data and also data",
        "start": 199.95,
        "duration": 3.015
    },
    {
        "text": "in large quantities is very helpful",
        "start": 202.965,
        "duration": 2.345
    },
    {
        "text": "so the data scientists can spend a lot of time working",
        "start": 205.31,
        "duration": 3.08
    },
    {
        "text": "with the data and that can actually",
        "start": 208.39,
        "duration": 1.465
    },
    {
        "text": "end up being quite fun to do, too.",
        "start": 209.855,
        "duration": 1.78
    },
    {
        "text": ">> Absolutely.",
        "start": 211.635,
        "duration": 1.055
    },
    {
        "text": ">> Yeah.",
        "start": 212.69,
        "duration": 0.49
    },
    {
        "text": ">> And in deep networks.",
        "start": 213.18,
        "duration": 2.075
    },
    {
        "text": "This concept of Deep Learning or Neural Networks.",
        "start": 215.255,
        "duration": 3.645
    },
    {
        "text": "They have this concept of",
        "start": 218.9,
        "duration": 1.88
    },
    {
        "text": "Convolutional Neural Networks which is really we're.",
        "start": 220.78,
        "duration": 3.195
    },
    {
        "text": "These different steps inside a network that determine",
        "start": 223.975,
        "duration": 2.98
    },
    {
        "text": "and do the feature extraction",
        "start": 226.955,
        "duration": 1.385
    },
    {
        "text": "and classification themselves.",
        "start": 228.34,
        "duration": 1.61
    },
    {
        "text": "So a person isn't involved,",
        "start": 229.95,
        "duration": 1.855
    },
    {
        "text": "and the network itself is",
        "start": 231.805,
        "duration": 1.915
    },
    {
        "text": "determining aspects of the image,",
        "start": 233.72,
        "duration": 2.38
    },
    {
        "text": "aspects of the picture and then at the end that brings it",
        "start": 236.1,
        "duration": 3.71
    },
    {
        "text": "back together to answer",
        "start": 239.81,
        "duration": 1.92
    },
    {
        "text": "the question that you posed of it,",
        "start": 241.73,
        "duration": 1.8
    },
    {
        "text": "was is this a dog?",
        "start": 243.53,
        "duration": 1.07
    },
    {
        "text": "Or is it a cat? Or is it a car??",
        "start": 244.6,
        "duration": 1.535
    },
    {
        "text": "And that's called the unconnected layers at",
        "start": 246.135,
        "duration": 2.585
    },
    {
        "text": "the end where it brings the information back.",
        "start": 248.72,
        "duration": 2.515
    },
    {
        "text": "So if we wanted to see an example of this,",
        "start": 251.235,
        "duration": 2.155
    },
    {
        "text": "this would be a deep neural network for computer vision.",
        "start": 253.39,
        "duration": 2.88
    },
    {
        "text": "And the first, the outcome is,",
        "start": 256.27,
        "duration": 3.42
    },
    {
        "text": "is it a cat? Is it a dog?",
        "start": 259.69,
        "duration": 1.68
    },
    {
        "text": "Is it a car? And it's actually got the answer",
        "start": 261.37,
        "duration": 2.21
    },
    {
        "text": "wrong because that's my dog",
        "start": 263.58,
        "duration": 1.01
    },
    {
        "text": "Lottie and it's saying it's a cat.",
        "start": 264.59,
        "duration": 1.405
    },
    {
        "text": "So, it's not focused on",
        "start": 265.995,
        "duration": 1.635
    },
    {
        "text": "the accuracy of this particular Neural Network.",
        "start": 267.63,
        "duration": 2.64
    },
    {
        "text": "And here are",
        "start": 270.27,
        "duration": 1.72
    },
    {
        "text": "the Convolutional Layers that we talked about.",
        "start": 271.99,
        "duration": 2.425
    },
    {
        "text": "The first stage of the network is",
        "start": 274.415,
        "duration": 2.545
    },
    {
        "text": "really around finding the low-level features.",
        "start": 276.96,
        "duration": 2.68
    },
    {
        "text": "So these are the things that are quite obvious.",
        "start": 279.64,
        "duration": 1.76
    },
    {
        "text": "So it could be the edges of the image, the lines,",
        "start": 281.4,
        "duration": 3.57
    },
    {
        "text": "specific colors,",
        "start": 284.97,
        "duration": 2.615
    },
    {
        "text": "the obvious patterns and",
        "start": 287.585,
        "duration": 3.245
    },
    {
        "text": "things that you find in the image.",
        "start": 290.83,
        "duration": 1.56
    },
    {
        "text": ">> Yeah. I like to point",
        "start": 292.39,
        "duration": 2.03
    },
    {
        "text": "out you have a lovely diagram with a.",
        "start": 294.42,
        "duration": 2.57
    },
    {
        "text": "It's almost like a flashlight is being shown",
        "start": 296.99,
        "duration": 2.64
    },
    {
        "text": "on the image and each flashlight is like a filter.",
        "start": 299.63,
        "duration": 3.33
    },
    {
        "text": ">> Yes yes.",
        "start": 302.96,
        "duration": 1.32
    },
    {
        "text": ">> And we have these filters and the filters are like",
        "start": 304.28,
        "duration": 2.385
    },
    {
        "text": "these parts that recognize like a patterns right?",
        "start": 306.665,
        "duration": 3.195
    },
    {
        "text": ">> Yeah?",
        "start": 309.86,
        "duration": 0.56
    },
    {
        "text": ">> Something like that? Yeah, yeah?",
        "start": 310.42,
        "duration": 1.105
    },
    {
        "text": ">> And then the next stage.",
        "start": 311.525,
        "duration": 1.625
    },
    {
        "text": "And the high-level features.",
        "start": 313.15,
        "duration": 1.71
    },
    {
        "text": "So this is things like corners, simple shapes, circles,",
        "start": 314.86,
        "duration": 3.4
    },
    {
        "text": "and contours that you might see and these are things that",
        "start": 318.26,
        "duration": 3.44
    },
    {
        "text": "stand out not just within",
        "start": 321.7,
        "duration": 1.73
    },
    {
        "text": "the image itself, the whole image.",
        "start": 323.43,
        "duration": 1.81
    },
    {
        "text": "It could be components of the image.",
        "start": 325.24,
        "duration": 1.77
    },
    {
        "text": "So it could be a section of the image",
        "start": 327.01,
        "duration": 1.92
    },
    {
        "text": "has some of these features within it.",
        "start": 328.93,
        "duration": 2.585
    },
    {
        "text": "And then the next stage and as we get deeper",
        "start": 331.515,
        "duration": 2.855
    },
    {
        "text": "into the network it's really around parts of the image.",
        "start": 334.37,
        "duration": 2.71
    },
    {
        "text": "It's finding faces,",
        "start": 337.08,
        "duration": 2.275
    },
    {
        "text": "it's finding windows, it's finding wheels,",
        "start": 339.355,
        "duration": 2.315
    },
    {
        "text": "it's finding these kind of",
        "start": 341.67,
        "duration": 1.305
    },
    {
        "text": "common aspects of the images that we have.",
        "start": 342.975,
        "duration": 3.465
    },
    {
        "text": ">> Right.",
        "start": 346.44,
        "duration": 1.13
    },
    {
        "text": ">> And once it's done all of this work",
        "start": 347.57,
        "duration": 1.68
    },
    {
        "text": "it kind of works a bit like the brain where each",
        "start": 349.25,
        "duration": 1.94
    },
    {
        "text": "of the independent neurons",
        "start": 351.19,
        "duration": 2.39
    },
    {
        "text": "is solving a different part of the problem.",
        "start": 353.58,
        "duration": 2.965
    },
    {
        "text": ">> Right.",
        "start": 356.545,
        "duration": 0.705
    },
    {
        "text": ">> And then it's bringing back all of",
        "start": 357.25,
        "duration": 1.735
    },
    {
        "text": "that information together at these final layers or",
        "start": 358.985,
        "duration": 2.625
    },
    {
        "text": "these connected layers where it's",
        "start": 361.61,
        "duration": 2.29
    },
    {
        "text": "passing all of those using some kind of",
        "start": 363.9,
        "duration": 2.82
    },
    {
        "text": "activation function that can bring it into",
        "start": 366.72,
        "duration": 3.085
    },
    {
        "text": "a single view to solve a more complicated problem,",
        "start": 369.805,
        "duration": 3.445
    },
    {
        "text": "such as is it a dog",
        "start": 373.25,
        "duration": 1.45
    },
    {
        "text": "or is it a sunset or some other particular photo.",
        "start": 374.7,
        "duration": 4.81
    },
    {
        "text": "So the complex objects are really",
        "start": 379.51,
        "duration": 1.93
    },
    {
        "text": "the scenes are things like people, animals, beaches.",
        "start": 381.44,
        "duration": 3.235
    },
    {
        "text": "The things that we understand that this human level,",
        "start": 384.675,
        "duration": 2.765
    },
    {
        "text": "based on all of this work that's gone before it.",
        "start": 387.44,
        "duration": 2.975
    },
    {
        "text": ">> And I encourage the listeners too if you hear a term",
        "start": 390.415,
        "duration": 4.275
    },
    {
        "text": "that you don't recognize or that's new to you,",
        "start": 394.69,
        "duration": 4.435
    },
    {
        "text": "don't worry, like this is the high-level primer.",
        "start": 399.125,
        "duration": 2.78
    },
    {
        "text": ">> Absolutely.",
        "start": 401.905,
        "duration": 0.995
    },
    {
        "text": ">> And you can explore that term later on",
        "start": 402.9,
        "duration": 1.88
    },
    {
        "text": "on your own or in future videos.",
        "start": 404.78,
        "duration": 2.345
    },
    {
        "text": ">> And although I called it a",
        "start": 407.125,
        "duration": 1.705
    },
    {
        "text": "Convolutional Neural Network and you",
        "start": 408.83,
        "duration": 2.16
    },
    {
        "text": "probably only see it referred to as a CNN?",
        "start": 410.99,
        "duration": 2.8
    },
    {
        "text": "And people will start talking about CNN's and at",
        "start": 413.79,
        "duration": 4.2
    },
    {
        "text": "that stage that's what this",
        "start": 417.99,
        "duration": 1.93
    },
    {
        "text": "actually means, Convolutional Neural Network.",
        "start": 419.92,
        "duration": 3.0
    },
    {
        "text": "And this idea of using",
        "start": 422.92,
        "duration": 1.82
    },
    {
        "text": "a Pretrained Convolutional Neural",
        "start": 424.74,
        "duration": 1.845
    },
    {
        "text": "Network is a feature ISA.",
        "start": 426.585,
        "duration": 1.425
    },
    {
        "text": "This is a concept which we call transfer learning.",
        "start": 428.01,
        "duration": 3.845
    },
    {
        "text": "Whereas you've got these",
        "start": 431.855,
        "duration": 3.095
    },
    {
        "text": "pre-built information's from a general task.",
        "start": 434.95,
        "duration": 2.625
    },
    {
        "text": "So this could be a massive amount of images that",
        "start": 437.575,
        "duration": 3.145
    },
    {
        "text": "the network is trained on and",
        "start": 440.72,
        "duration": 1.57
    },
    {
        "text": "spent a lot of time learning about.",
        "start": 442.29,
        "duration": 2.14
    },
    {
        "text": "And then you've got the output layer which",
        "start": 444.43,
        "duration": 2.55
    },
    {
        "text": "defines are you looking for a dog in the image?",
        "start": 446.98,
        "duration": 2.94
    },
    {
        "text": "And you may want to solve a different problem.",
        "start": 449.92,
        "duration": 2.57
    },
    {
        "text": "So you might instead of wanting to",
        "start": 452.49,
        "duration": 1.68
    },
    {
        "text": "define a dog you might want to say is this a deer.",
        "start": 454.17,
        "duration": 2.71
    },
    {
        "text": "And this network hasn't been trained",
        "start": 456.88,
        "duration": 3.02
    },
    {
        "text": "to identify deers and it's never seen a deer before.",
        "start": 459.9,
        "duration": 3.33
    },
    {
        "text": "So using the approaches of pre-trained network,",
        "start": 463.23,
        "duration": 3.565
    },
    {
        "text": "you could actually say take off",
        "start": 466.795,
        "duration": 2.485
    },
    {
        "text": "the output layer which used to define whether it was",
        "start": 469.28,
        "duration": 3.1
    },
    {
        "text": "a cat or a dog and actually replace that",
        "start": 472.38,
        "duration": 3.295
    },
    {
        "text": "with a new layer which can look and identify deer.",
        "start": 475.675,
        "duration": 4.745
    },
    {
        "text": "So this is really outputs or the penultimate layer.",
        "start": 480.42,
        "duration": 2.4
    },
    {
        "text": "We call it the penultimate layer because",
        "start": 482.82,
        "duration": 1.86
    },
    {
        "text": "the second to last layer and the network.",
        "start": 484.68,
        "duration": 2.61
    },
    {
        "text": "I think there's other terms so I can.",
        "start": 487.29,
        "duration": 2.517
    },
    {
        "text": "What is it? The Bootstrap?",
        "start": 489.807,
        "duration": 3.003
    },
    {
        "text": "The Bootstrap terms as well,",
        "start": 492.81,
        "duration": 2.49
    },
    {
        "text": "and with transfer learning",
        "start": 495.3,
        "duration": 3.035
    },
    {
        "text": "the models can achieve you know,",
        "start": 498.335,
        "duration": 1.55
    },
    {
        "text": "with thousands of labeled images instead of millions.",
        "start": 499.885,
        "duration": 3.01
    },
    {
        "text": "So you might train your original network",
        "start": 502.895,
        "duration": 2.965
    },
    {
        "text": "with millions of photos,",
        "start": 505.86,
        "duration": 1.65
    },
    {
        "text": "but you can take all of the benefit of",
        "start": 507.51,
        "duration": 1.795
    },
    {
        "text": "that work and you can just try it with",
        "start": 509.305,
        "duration": 1.9
    },
    {
        "text": "a few thousand images to refactor the solution.",
        "start": 511.205,
        "duration": 4.21
    },
    {
        "text": ">> Yeah we even have cognitive services",
        "start": 515.415,
        "duration": 1.995
    },
    {
        "text": "that are built on transfer learning right?",
        "start": 517.41,
        "duration": 2.705
    },
    {
        "text": ">> \"Custom vision A.I\".",
        "start": 520.115,
        "duration": 0.71
    },
    {
        "text": ">> \"Custom vision A.I\" you only have to provide",
        "start": 520.825,
        "duration": 3.315
    },
    {
        "text": "a about 30 to 50 images to",
        "start": 524.14,
        "duration": 2.745
    },
    {
        "text": "that because it uses exactly that concept.",
        "start": 526.885,
        "duration": 2.85
    },
    {
        "text": ">> And if you do use \"Custom Vision",
        "start": 529.735,
        "duration": 2.575
    },
    {
        "text": "A.I\" you'll notice there's a question which sees,",
        "start": 532.31,
        "duration": 3.265
    },
    {
        "text": "which is the base model you want to",
        "start": 535.575,
        "duration": 1.835
    },
    {
        "text": "use and it doesn't use it in those terms it says,",
        "start": 537.41,
        "duration": 2.195
    },
    {
        "text": "is this a general image problem,",
        "start": 539.605,
        "duration": 2.215
    },
    {
        "text": "is this a food image problem,",
        "start": 541.82,
        "duration": 1.75
    },
    {
        "text": "is this a landscape image problem?",
        "start": 543.57,
        "duration": 2.29
    },
    {
        "text": "And that's because those",
        "start": 545.86,
        "duration": 1.935
    },
    {
        "text": "are the base models they're talking from like,",
        "start": 547.795,
        "duration": 1.79
    },
    {
        "text": "ones that have been trained in",
        "start": 549.585,
        "duration": 1.24
    },
    {
        "text": "those particular data sets.",
        "start": 550.825,
        "duration": 1.605
    },
    {
        "text": "And so therefore if your problem is similar to those,",
        "start": 552.43,
        "duration": 3.75
    },
    {
        "text": "it may offer better results.",
        "start": 556.18,
        "duration": 3.155
    },
    {
        "text": "And then there's a new output layer which is created,",
        "start": 559.335,
        "duration": 3.18
    },
    {
        "text": "which is now, is it a deer?",
        "start": 562.515,
        "duration": 2.045
    },
    {
        "text": "And so that in itself,",
        "start": 564.56,
        "duration": 2.225
    },
    {
        "text": "is you training one or more layers than the network,",
        "start": 566.785,
        "duration": 1.8
    },
    {
        "text": "you're not retraining the whole network.",
        "start": 568.585,
        "duration": 1.74
    },
    {
        "text": "So it may take eight hours,",
        "start": 570.325,
        "duration": 1.81
    },
    {
        "text": "ten hours to train the original neural net,",
        "start": 572.135,
        "duration": 3.025
    },
    {
        "text": "it may only take 15 minutes",
        "start": 575.16,
        "duration": 2.645
    },
    {
        "text": "to retrain where the new problem space.",
        "start": 577.805,
        "duration": 3.255
    },
    {
        "text": "And we, and you may wonder like,",
        "start": 581.06,
        "duration": 2.185
    },
    {
        "text": "where do these protein networks come from?",
        "start": 583.245,
        "duration": 2.28
    },
    {
        "text": "Well there's a site called \"ImageNet\" which is really",
        "start": 585.525,
        "duration": 2.78
    },
    {
        "text": "the world's largest collection of labeled images.",
        "start": 588.305,
        "duration": 3.045
    },
    {
        "text": "It's millions and millions of labeled images,",
        "start": 591.35,
        "duration": 2.795
    },
    {
        "text": "defining a whole range of different topics.",
        "start": 594.145,
        "duration": 2.89
    },
    {
        "text": "It's come from Stanford University.",
        "start": 597.035,
        "duration": 1.49
    },
    {
        "text": ">> Yeah.",
        "start": 598.525,
        "duration": 0.49
    },
    {
        "text": ">> And so here's an example here looking inside",
        "start": 599.015,
        "duration": 4.0
    },
    {
        "text": "the person area of ImageNet and finding leaders,",
        "start": 603.015,
        "duration": 4.175
    },
    {
        "text": "and then within leaders,",
        "start": 607.19,
        "duration": 1.44
    },
    {
        "text": "there's different types of leaders,",
        "start": 608.63,
        "duration": 1.875
    },
    {
        "text": "spiritual leaders,",
        "start": 610.505,
        "duration": 1.575
    },
    {
        "text": "military leaders and then examples of each one of those.",
        "start": 612.08,
        "duration": 4.315
    },
    {
        "text": "So it's a massive data set with a whole bunch",
        "start": 616.395,
        "duration": 2.05
    },
    {
        "text": "of contexts assigned within it.",
        "start": 618.445,
        "duration": 2.27
    },
    {
        "text": "And so we, when you see",
        "start": 620.715,
        "duration": 1.7
    },
    {
        "text": "an image classification a lot of it comes",
        "start": 622.415,
        "duration": 2.43
    },
    {
        "text": "from this particular data",
        "start": 624.845,
        "duration": 2.68
    },
    {
        "text": "set or training across this particular data set.",
        "start": 627.525,
        "duration": 2.43
    },
    {
        "text": ">> There are actually a lot of sort",
        "start": 629.955,
        "duration": 2.92
    },
    {
        "text": "of competitions right?",
        "start": 632.875,
        "duration": 1.31
    },
    {
        "text": ">> Yes.",
        "start": 634.185,
        "duration": 0.63
    },
    {
        "text": ">> Yearly competitions that",
        "start": 634.815,
        "duration": 1.835
    },
    {
        "text": "occur amongst worldwide universities,",
        "start": 636.65,
        "duration": 3.485
    },
    {
        "text": "companies et cetera to",
        "start": 640.135,
        "duration": 2.12
    },
    {
        "text": "do better and better on this ImageNet data set.",
        "start": 642.255,
        "duration": 2.13
    },
    {
        "text": ">> Absolutely.",
        "start": 644.385,
        "duration": 1.01
    },
    {
        "text": "So one of the grand competitions is",
        "start": 645.395,
        "duration": 2.84
    },
    {
        "text": "this ImageNet Large Scale visual recognition challenge",
        "start": 648.235,
        "duration": 3.7
    },
    {
        "text": "also known as ILSVRC for short.",
        "start": 651.935,
        "duration": 4.685
    },
    {
        "text": "Now this started in 2012 and the winner,",
        "start": 656.62,
        "duration": 5.195
    },
    {
        "text": "I don't know if it started in 2012",
        "start": 661.815,
        "duration": 1.76
    },
    {
        "text": "but that's where I'm going to start the conversation.",
        "start": 663.575,
        "duration": 1.81
    },
    {
        "text": "> It did. Yeah, you're right.",
        "start": 665.385,
        "duration": 1.78
    },
    {
        "text": ">> And back then the idea of",
        "start": 667.165,
        "duration": 2.51
    },
    {
        "text": "a deep Neural Network was really about eight layers deep.",
        "start": 669.675,
        "duration": 3.54
    },
    {
        "text": "So we talk about these hidden layers",
        "start": 673.215,
        "duration": 1.55
    },
    {
        "text": "being in the middle of the Neural Network,",
        "start": 674.765,
        "duration": 1.76
    },
    {
        "text": "and the solution that won",
        "start": 676.525,
        "duration": 2.05
    },
    {
        "text": "2012 was Alex Net named after its founder.",
        "start": 678.575,
        "duration": 3.81
    },
    {
        "text": "It was an eight layer Convolutional Neural Network,",
        "start": 682.385,
        "duration": 4.77
    },
    {
        "text": "and in 2014 you see we move up to 19 layers for VGG?",
        "start": 687.155,
        "duration": 5.235
    },
    {
        "text": ">> Yeah.",
        "start": 692.39,
        "duration": 1.3
    },
    {
        "text": ">> And then also in 2014,",
        "start": 693.69,
        "duration": 2.245
    },
    {
        "text": "Google Net came out",
        "start": 695.935,
        "duration": 2.63
    },
    {
        "text": "and took out a number of categories in",
        "start": 698.565,
        "duration": 1.49
    },
    {
        "text": "the competition using its 22 layer network.",
        "start": 700.055,
        "duration": 4.375
    },
    {
        "text": "But the difference with Google net solution,",
        "start": 704.43,
        "duration": 2.2
    },
    {
        "text": "is it was kind of like encyption which became the name",
        "start": 706.63,
        "duration": 2.945
    },
    {
        "text": "of the future networks where it learnt,",
        "start": 709.575,
        "duration": 3.28
    },
    {
        "text": "it looked back into itself",
        "start": 712.855,
        "duration": 1.73
    },
    {
        "text": "recursively as stages through the process well so,",
        "start": 714.585,
        "duration": 3.285
    },
    {
        "text": "it had that South feedback look.",
        "start": 717.87,
        "duration": 2.83
    },
    {
        "text": ">> Feedback look, yeah yeah yeah.",
        "start": 720.7,
        "duration": 2.53
    },
    {
        "text": ">> And then in 2015 Microsoft research took out",
        "start": 723.23,
        "duration": 7.66
    },
    {
        "text": "their competition with Res Net which was",
        "start": 730.89,
        "duration": 3.04
    },
    {
        "text": "152 hidden layer Convolutional Neural Network.",
        "start": 733.93,
        "duration": 5.425
    },
    {
        "text": ">> And this was even in the computer vision space.",
        "start": 739.355,
        "duration": 2.33
    },
    {
        "text": ">> In the computer vision space, absolutely.",
        "start": 741.685,
        "duration": 2.305
    },
    {
        "text": "And this came out of the research team",
        "start": 743.99,
        "duration": 1.655
    },
    {
        "text": "in China in Beijing.",
        "start": 745.645,
        "duration": 1.685
    },
    {
        "text": "And when I read an interview with",
        "start": 747.33,
        "duration": 2.835
    },
    {
        "text": "the researcher who was involved in this process,",
        "start": 750.165,
        "duration": 2.695
    },
    {
        "text": "he said at the time all the common thinking was",
        "start": 752.86,
        "duration": 2.575
    },
    {
        "text": "that a neuro-network couldn't go too deep.",
        "start": 755.435,
        "duration": 2.73
    },
    {
        "text": "Because each of the filters",
        "start": 758.165,
        "duration": 3.35
    },
    {
        "text": "would get to a point where they were,",
        "start": 761.515,
        "duration": 2.7
    },
    {
        "text": "there was like faint.",
        "start": 764.215,
        "duration": 1.665
    },
    {
        "text": "The feedback from the neurons became too faint.",
        "start": 765.88,
        "duration": 3.555
    },
    {
        "text": ">> Yeah, and then the parameter space.",
        "start": 769.435,
        "duration": 4.055
    },
    {
        "text": ">> Yeah.",
        "start": 773.49,
        "duration": 0.335
    },
    {
        "text": ">> Right.",
        "start": 773.825,
        "duration": 0.755
    },
    {
        "text": ">> And it would be impossible",
        "start": 774.58,
        "duration": 1.305
    },
    {
        "text": "to actually bring it all back",
        "start": 775.885,
        "duration": 1.615
    },
    {
        "text": "at those output layers to have good result.",
        "start": 777.5,
        "duration": 4.11
    },
    {
        "text": "And the techniques that they used",
        "start": 781.61,
        "duration": 2.195
    },
    {
        "text": "kind of proof that that wasn't the case and",
        "start": 783.805,
        "duration": 2.16
    },
    {
        "text": "that became the new benchmark on how to",
        "start": 785.965,
        "duration": 2.13
    },
    {
        "text": "do image recognition in 2015.",
        "start": 788.095,
        "duration": 4.52
    },
    {
        "text": "And so unfortunately, ILSVRC is no",
        "start": 792.615,
        "duration": 5.04
    },
    {
        "text": "more I think the 2017 competition",
        "start": 797.655,
        "duration": 2.81
    },
    {
        "text": "was the last and they are moving that over on to Kaggle.",
        "start": 800.465,
        "duration": 3.205
    },
    {
        "text": "But the domain is moved a little bit more",
        "start": 803.67,
        "duration": 2.61
    },
    {
        "text": "into this area of \"Coco\".",
        "start": 806.28,
        "duration": 2.865
    },
    {
        "text": "So Microsoft \"Coco\" is common objects and context,",
        "start": 809.145,
        "duration": 3.975
    },
    {
        "text": "and this is more of a segmentation challenge",
        "start": 813.12,
        "duration": 2.735
    },
    {
        "text": "than a classification challenge.",
        "start": 815.855,
        "duration": 2.625
    },
    {
        "text": "And so in this example in this data set you'll",
        "start": 818.48,
        "duration": 2.775
    },
    {
        "text": "notice that I'm looking for people and dogs,",
        "start": 821.255,
        "duration": 3.47
    },
    {
        "text": "and it's identifying images",
        "start": 824.725,
        "duration": 2.77
    },
    {
        "text": "which have a person and a dog in that,",
        "start": 827.495,
        "duration": 1.825
    },
    {
        "text": "and the exact pixels of",
        "start": 829.32,
        "duration": 1.335
    },
    {
        "text": "where that person and dog is located.",
        "start": 830.655,
        "duration": 1.48
    },
    {
        "text": ">> Right.",
        "start": 832.135,
        "duration": 0.48
    },
    {
        "text": ">> And so in 2016 Google took out the Coco challenge",
        "start": 832.615,
        "duration": 7.705
    },
    {
        "text": "and using a combination",
        "start": 840.32,
        "duration": 3.41
    },
    {
        "text": "of encyption which was the engine and Microsoft Res Net.",
        "start": 843.73,
        "duration": 5.14
    },
    {
        "text": "So they call it an encyption \"ResNet V2\".",
        "start": 848.87,
        "duration": 4.095
    },
    {
        "text": ">> So it's an ensemble.",
        "start": 852.965,
        "duration": 1.57
    },
    {
        "text": ">> An ensemble of",
        "start": 854.535,
        "duration": 1.485
    },
    {
        "text": "multiple Neural Network solutions, yeah.",
        "start": 856.02,
        "duration": 2.96
    },
    {
        "text": "And this little diagram on the right",
        "start": 858.98,
        "duration": 1.865
    },
    {
        "text": "is just a visualization",
        "start": 860.845,
        "duration": 1.3
    },
    {
        "text": "of the \"encyption resnet V2\".",
        "start": 862.145,
        "duration": 4.79
    },
    {
        "text": "And when you sort of see this over time this is building",
        "start": 866.935,
        "duration": 3.37
    },
    {
        "text": "up to the Google coco 2016,",
        "start": 870.305,
        "duration": 3.305
    },
    {
        "text": "and you'll notice the progress that's been",
        "start": 873.61,
        "duration": 2.745
    },
    {
        "text": "made in a very short period of",
        "start": 876.355,
        "duration": 1.09
    },
    {
        "text": "time because this is on the left here,",
        "start": 877.445,
        "duration": 1.64
    },
    {
        "text": "it's like August 2016 up until this was the you know,",
        "start": 879.085,
        "duration": 5.48
    },
    {
        "text": "near the end of 2016 when they achieve this.",
        "start": 884.565,
        "duration": 2.975
    },
    {
        "text": "And you look here the previous winner",
        "start": 887.54,
        "duration": 1.995
    },
    {
        "text": "was Microsoft research",
        "start": 889.535,
        "duration": 1.835
    },
    {
        "text": "based in 2015 with a \"Res Net\" isolution.",
        "start": 891.37,
        "duration": 5.035
    },
    {
        "text": "So there's a movement now towards this idea",
        "start": 896.405,
        "duration": 2.935
    },
    {
        "text": "of multiple Neural Network actually",
        "start": 899.34,
        "duration": 3.765
    },
    {
        "text": "feeding back into themselves",
        "start": 903.105,
        "duration": 2.555
    },
    {
        "text": "because we're almost hitting the limit of what",
        "start": 905.66,
        "duration": 2.17
    },
    {
        "text": "the individual neuron networks can achieve,",
        "start": 907.83,
        "duration": 1.95
    },
    {
        "text": "so it makes sense to then increase the Neural Nets.",
        "start": 909.78,
        "duration": 4.795
    },
    {
        "text": ">> The ensemble you mean.",
        "start": 914.575,
        "duration": 1.77
    },
    {
        "text": ">> Yeah the ensemble, sorry.",
        "start": 916.345,
        "duration": 1.045
    },
    {
        "text": ">> For sure.",
        "start": 917.39,
        "duration": 1.727
    },
    {
        "text": ">> And this technique is being",
        "start": 919.117,
        "duration": 2.743
    },
    {
        "text": "used in a number of places.",
        "start": 921.86,
        "duration": 1.78
    },
    {
        "text": "So kaggle.com is a website for",
        "start": 923.64,
        "duration": 4.01
    },
    {
        "text": "crowd sourcing solutions for",
        "start": 927.65,
        "duration": 2.3
    },
    {
        "text": "machine learning and data science.",
        "start": 929.95,
        "duration": 2.725
    },
    {
        "text": "And the Kaggle Data Science Bowl 2017 was",
        "start": 932.675,
        "duration": 3.375
    },
    {
        "text": "a challenge from a series of photos to",
        "start": 936.05,
        "duration": 2.12
    },
    {
        "text": "determine whether a patient has lung cancer or not.",
        "start": 938.17,
        "duration": 2.615
    },
    {
        "text": "And the winning solution was",
        "start": 940.785,
        "duration": 2.495
    },
    {
        "text": "actually a transfer learning solution that used",
        "start": 943.28,
        "duration": 2.905
    },
    {
        "text": "the Microsoft ResNet CNN",
        "start": 946.185,
        "duration": 4.315
    },
    {
        "text": "and it took a ResNet that was trained",
        "start": 950.5,
        "duration": 2.375
    },
    {
        "text": "off a general image dataset from",
        "start": 952.875,
        "duration": 2.055
    },
    {
        "text": "ImageNet and stripped off the penultimate layer.",
        "start": 954.93,
        "duration": 5.14
    },
    {
        "text": "It then used Microsoft Cognitive Toolkit to",
        "start": 960.07,
        "duration": 4.27
    },
    {
        "text": "retrain the model and retrain",
        "start": 964.34,
        "duration": 2.46
    },
    {
        "text": "the penultimate layer with the k batch of images,",
        "start": 966.8,
        "duration": 3.29
    },
    {
        "text": "and that took 53 minutes.",
        "start": 970.09,
        "duration": 1.845
    },
    {
        "text": "And then, it used a product called",
        "start": 971.935,
        "duration": 1.895
    },
    {
        "text": "LightGBM to extract the features for the final stage,",
        "start": 973.83,
        "duration": 3.98
    },
    {
        "text": "and submit that as the solution to the problem.",
        "start": 977.81,
        "duration": 2.26
    },
    {
        "text": "So in less than an hour,",
        "start": 980.07,
        "duration": 1.745
    },
    {
        "text": "using the Azure solution,",
        "start": 981.815,
        "duration": 1.545
    },
    {
        "text": "they were able to apply transfer learning and win",
        "start": 983.36,
        "duration": 2.11
    },
    {
        "text": "the competition for detecting",
        "start": 985.47,
        "duration": 1.79
    },
    {
        "text": "if the patient had lung cancer or not.",
        "start": 987.26,
        "duration": 1.38
    },
    {
        "text": ">> Some classification.",
        "start": 988.64,
        "duration": 0.93
    },
    {
        "text": ">> Yeah.",
        "start": 989.57,
        "duration": 0.435
    },
    {
        "text": ">> That's interesting, that's almost",
        "start": 990.005,
        "duration": 1.445
    },
    {
        "text": "like another ensemble.",
        "start": 991.45,
        "duration": 1.22
    },
    {
        "text": ">> Yes.",
        "start": 992.67,
        "duration": 0.59
    },
    {
        "text": ">> Yes, it is.",
        "start": 993.26,
        "duration": 0.63
    },
    {
        "text": ">> There you go,",
        "start": 993.89,
        "duration": 1.095
    },
    {
        "text": "a lot of this type of learning.",
        "start": 994.985,
        "duration": 2.055
    },
    {
        "text": ">> And we've talked a lot",
        "start": 997.04,
        "duration": 2.28
    },
    {
        "text": "about Deep Convolutional Neural Networks in",
        "start": 999.32,
        "duration": 3.71
    },
    {
        "text": "this focus because the focus",
        "start": 1003.03,
        "duration": 1.72
    },
    {
        "text": "of the heck was computer vision",
        "start": 1004.75,
        "duration": 1.55
    },
    {
        "text": "and the focus of this content as computer vision.",
        "start": 1006.3,
        "duration": 3.38
    },
    {
        "text": "But there are other and also,",
        "start": 1009.68,
        "duration": 3.0
    },
    {
        "text": "CNNs are used for,",
        "start": 1012.68,
        "duration": 1.77
    },
    {
        "text": "like we use it inside of Skype translator.",
        "start": 1014.45,
        "duration": 1.845
    },
    {
        "text": "So, it's not just vision tasks,",
        "start": 1016.295,
        "duration": 2.86
    },
    {
        "text": "but what tends to happen is,",
        "start": 1019.155,
        "duration": 1.445
    },
    {
        "text": "in other complicated domains,",
        "start": 1020.6,
        "duration": 1.945
    },
    {
        "text": "we will turn the data into image data to",
        "start": 1022.545,
        "duration": 2.715
    },
    {
        "text": "use a CNN even if it's not an image problem.",
        "start": 1025.26,
        "duration": 3.31
    },
    {
        "text": ">> They do this with sound as well?",
        "start": 1028.57,
        "duration": 1.4
    },
    {
        "text": ">> Yes.",
        "start": 1029.97,
        "duration": 0.21
    },
    {
        "text": ">> Yes.",
        "start": 1030.18,
        "duration": 0.36
    },
    {
        "text": ">> Yeah, which is crazy",
        "start": 1030.54,
        "duration": 1.43
    },
    {
        "text": "when you think about it like if you're",
        "start": 1031.97,
        "duration": 1.22
    },
    {
        "text": "trying to determine which is",
        "start": 1033.19,
        "duration": 1.37
    },
    {
        "text": "the shorter queue in the supermarket.",
        "start": 1034.56,
        "duration": 1.675
    },
    {
        "text": "I know, let's turn it into images and put it in a CNN.",
        "start": 1036.235,
        "duration": 2.585
    },
    {
        "text": ">> Yeah. Why not?",
        "start": 1038.82,
        "duration": 2.995
    },
    {
        "text": ">> But there are",
        "start": 1041.815,
        "duration": 1.325
    },
    {
        "text": "other Neural Networks that are used for other tasks.",
        "start": 1043.14,
        "duration": 2.94
    },
    {
        "text": "So Recurrent Neural Network",
        "start": 1046.08,
        "duration": 2.21
    },
    {
        "text": "for Natural Language Processing is very strong,",
        "start": 1048.29,
        "duration": 2.785
    },
    {
        "text": "and Deep Belief Neural Networks for Speech and Music,",
        "start": 1051.075,
        "duration": 2.83
    },
    {
        "text": "and Deep Reinforcement Learning",
        "start": 1053.905,
        "duration": 1.915
    },
    {
        "text": "for things like gamification and",
        "start": 1055.82,
        "duration": 2.645
    },
    {
        "text": "determining reward and is quite common in",
        "start": 1058.465,
        "duration": 2.485
    },
    {
        "text": "the gaming environment for determining user behavior.",
        "start": 1060.95,
        "duration": 3.375
    },
    {
        "text": ">> Wow.",
        "start": 1064.325,
        "duration": 0.875
    },
    {
        "text": ">> And then, CNNs are everywhere.",
        "start": 1065.2,
        "duration": 5.215
    },
    {
        "text": "We have at Microsoft Cognitive Services Face API which is",
        "start": 1070.415,
        "duration": 4.585
    },
    {
        "text": "a service that identifies",
        "start": 1075.0,
        "duration": 2.195
    },
    {
        "text": "people from elements to their face,",
        "start": 1077.195,
        "duration": 2.65
    },
    {
        "text": "fingerprint on their face, and then,",
        "start": 1079.845,
        "duration": 1.845
    },
    {
        "text": "can determine things like estimated age and gender,",
        "start": 1081.69,
        "duration": 3.06
    },
    {
        "text": "and that is using",
        "start": 1084.75,
        "duration": 3.285
    },
    {
        "text": "a trained as seen into perform that task.",
        "start": 1088.035,
        "duration": 3.69
    },
    {
        "text": ">> Yeah. Can even like discover",
        "start": 1091.725,
        "duration": 2.205
    },
    {
        "text": "if people are wearing glasses or not with that.",
        "start": 1093.93,
        "duration": 2.725
    },
    {
        "text": ">> Yes.",
        "start": 1096.655,
        "duration": 0.735
    },
    {
        "text": ">> Yeah. Anyway.",
        "start": 1097.39,
        "duration": 0.835
    },
    {
        "text": ">> And you see them everywhere,",
        "start": 1098.225,
        "duration": 1.69
    },
    {
        "text": "you see them in Facebook,",
        "start": 1099.915,
        "duration": 1.265
    },
    {
        "text": "you see them in image search,",
        "start": 1101.18,
        "duration": 1.855
    },
    {
        "text": "and lots of different places.",
        "start": 1103.035,
        "duration": 1.925
    },
    {
        "text": "And we talked a little bit about Custom Vision AI.",
        "start": 1104.96,
        "duration": 2.985
    },
    {
        "text": "This is just a demonstration of what it's actually doing.",
        "start": 1107.945,
        "duration": 2.83
    },
    {
        "text": "It's taking the custom vision model",
        "start": 1110.775,
        "duration": 3.515
    },
    {
        "text": "as the classifier in the cloud and then,",
        "start": 1114.29,
        "duration": 3.22
    },
    {
        "text": "it's effectively retraining that.",
        "start": 1117.51,
        "duration": 2.13
    },
    {
        "text": "So you don't need a lot of experience in",
        "start": 1119.64,
        "duration": 2.42
    },
    {
        "text": "Computer Vision or deep learning to use the solution,",
        "start": 1122.06,
        "duration": 2.59
    },
    {
        "text": "you essentially just need to retrain",
        "start": 1124.65,
        "duration": 2.35
    },
    {
        "text": "it and then extract or publish that model.",
        "start": 1127.0,
        "duration": 2.52
    },
    {
        "text": "And one thing I would say",
        "start": 1129.52,
        "duration": 2.06
    },
    {
        "text": "is that it's actually really important if",
        "start": 1131.58,
        "duration": 1.84
    },
    {
        "text": "you're using Custom Vision AI",
        "start": 1133.42,
        "duration": 1.695
    },
    {
        "text": "to understand about preparation",
        "start": 1135.115,
        "duration": 2.915
    },
    {
        "text": "for your image data like it's tempting for",
        "start": 1138.03,
        "duration": 2.26
    },
    {
        "text": "people to take a really high resolution photo,",
        "start": 1140.29,
        "duration": 2.46
    },
    {
        "text": "three megabits and then, applied",
        "start": 1142.75,
        "duration": 1.43
    },
    {
        "text": "it to the service endpoint.",
        "start": 1144.18,
        "duration": 1.22
    },
    {
        "text": ">> Yeah.",
        "start": 1145.4,
        "duration": 0.81
    },
    {
        "text": ">> But really, for this to work and",
        "start": 1146.21,
        "duration": 2.57
    },
    {
        "text": "it's better to have consistently sized images and",
        "start": 1148.78,
        "duration": 2.91
    },
    {
        "text": "normalized images when you actually",
        "start": 1151.69,
        "duration": 2.88
    },
    {
        "text": "create your model originally and then performing",
        "start": 1154.57,
        "duration": 3.02
    },
    {
        "text": "the same pre-processing steps when you",
        "start": 1157.59,
        "duration": 1.8
    },
    {
        "text": "actually upload those images to the service",
        "start": 1159.39,
        "duration": 2.09
    },
    {
        "text": "because a lot of engineers that get involved on",
        "start": 1161.48,
        "duration": 2.52
    },
    {
        "text": "this don't have that concept,",
        "start": 1164.0,
        "duration": 2.795
    },
    {
        "text": "and then they come back and say, well,",
        "start": 1166.795,
        "duration": 1.325
    },
    {
        "text": "the model is not very effective.",
        "start": 1168.12,
        "duration": 2.09
    },
    {
        "text": ">> Yeah, that's actually a really good point.",
        "start": 1170.21,
        "duration": 2.05
    },
    {
        "text": "They even in the documentation",
        "start": 1172.26,
        "duration": 1.44
    },
    {
        "text": "have a great blurb on that,",
        "start": 1173.7,
        "duration": 1.83
    },
    {
        "text": "but the concept of",
        "start": 1175.53,
        "duration": 1.395
    },
    {
        "text": "a representative dataset but also the model will",
        "start": 1176.925,
        "duration": 3.175
    },
    {
        "text": "not be able to do well on",
        "start": 1180.1,
        "duration": 2.08
    },
    {
        "text": "things that it really hasn't seen and been trained on.",
        "start": 1182.18,
        "duration": 2.44
    },
    {
        "text": ">> Yes.",
        "start": 1184.62,
        "duration": 0.97
    },
    {
        "text": ">> It's actually, yeah, that's a really good point.",
        "start": 1185.59,
        "duration": 2.39
    },
    {
        "text": ">> And we, as humans are like the high resolution,",
        "start": 1187.98,
        "duration": 2.88
    },
    {
        "text": "the sharper the image, the better, right?",
        "start": 1190.86,
        "duration": 2.305
    },
    {
        "text": "But for a computer, it's like there's",
        "start": 1193.165,
        "duration": 2.705
    },
    {
        "text": "too much information and high detailed image,",
        "start": 1195.87,
        "duration": 3.42
    },
    {
        "text": "and it's finding too much on those pixels,",
        "start": 1199.29,
        "duration": 2.01
    },
    {
        "text": "and so it really needs to refine it and reduce it.",
        "start": 1201.3,
        "duration": 3.755
    },
    {
        "text": "And Before Deep Learning,",
        "start": 1205.055,
        "duration": 2.83
    },
    {
        "text": "I mentioned 20 years ago I",
        "start": 1207.885,
        "duration": 1.615
    },
    {
        "text": "was doing some study in this area,",
        "start": 1209.5,
        "duration": 1.755
    },
    {
        "text": "and there are a lot of",
        "start": 1211.255,
        "duration": 2.175
    },
    {
        "text": "traditional approaches that have been",
        "start": 1213.43,
        "duration": 1.29
    },
    {
        "text": "used that is still really relevant today.",
        "start": 1214.72,
        "duration": 2.255
    },
    {
        "text": "So, some problems don't require",
        "start": 1216.975,
        "duration": 1.905
    },
    {
        "text": "a neural net and they may not come up with",
        "start": 1218.88,
        "duration": 2.03
    },
    {
        "text": "the best solutions and things like",
        "start": 1220.91,
        "duration": 1.9
    },
    {
        "text": "very fast OpenCV or SVM classifiers still are",
        "start": 1222.81,
        "duration": 4.41
    },
    {
        "text": "very good for determining",
        "start": 1227.22,
        "duration": 1.93
    },
    {
        "text": "handwriting in digits and things like that.",
        "start": 1229.15,
        "duration": 4.99
    },
    {
        "text": "So just because there's a new kid in town,",
        "start": 1234.14,
        "duration": 3.1
    },
    {
        "text": "doesn't mean that's the right tool for everything.",
        "start": 1237.24,
        "duration": 1.98
    },
    {
        "text": "There are still times when you might use",
        "start": 1239.22,
        "duration": 1.47
    },
    {
        "text": "some of the traditional approaches.",
        "start": 1240.69,
        "duration": 1.52
    },
    {
        "text": ">> Absolutely. Yeah.",
        "start": 1242.21,
        "duration": 1.875
    },
    {
        "text": ">> Excellent.",
        "start": 1244.085,
        "duration": 1.615
    },
    {
        "text": "I hope you enjoyed the primer and we'll put",
        "start": 1245.7,
        "duration": 3.9
    },
    {
        "text": "some show notes together with",
        "start": 1249.6,
        "duration": 1.69
    },
    {
        "text": "some additional links to learn",
        "start": 1251.29,
        "duration": 1.49
    },
    {
        "text": "more and to go deeper on some of the concepts.",
        "start": 1252.78,
        "duration": 2.315
    },
    {
        "text": "And as Micheleen saying,",
        "start": 1255.095,
        "duration": 1.625
    },
    {
        "text": "there's going to be more videos to come as well.",
        "start": 1256.72,
        "duration": 2.66
    },
    {
        "text": "And just before we close off,",
        "start": 1259.38,
        "duration": 1.73
    },
    {
        "text": "I thought I'd show you what it looks like",
        "start": 1261.11,
        "duration": 2.62
    },
    {
        "text": "inside of a neural net because we talked a lot about it,",
        "start": 1263.73,
        "duration": 3.015
    },
    {
        "text": "but this is an example here,",
        "start": 1266.745,
        "duration": 1.91
    },
    {
        "text": "we are at playground.tensorflow.org.",
        "start": 1268.655,
        "duration": 3.07
    },
    {
        "text": "You can actually start to solve",
        "start": 1271.725,
        "duration": 2.035
    },
    {
        "text": "some computer vision problems",
        "start": 1273.76,
        "duration": 2.27
    },
    {
        "text": "like identifying a particular shape here by",
        "start": 1276.03,
        "duration": 2.55
    },
    {
        "text": "creating a neural net with",
        "start": 1278.58,
        "duration": 2.66
    },
    {
        "text": "a number of feature extraction layers at the start.",
        "start": 1281.24,
        "duration": 4.66
    },
    {
        "text": "And then, you can increase the depth,",
        "start": 1285.9,
        "duration": 1.9
    },
    {
        "text": "so I can increase the number of hidden layers that I've",
        "start": 1287.8,
        "duration": 2.515
    },
    {
        "text": "got and for increase the number of neurons.",
        "start": 1290.315,
        "duration": 4.445
    },
    {
        "text": "And then, having that generate the output.",
        "start": 1294.76,
        "duration": 4.93
    },
    {
        "text": "If I press \"Play\" here,",
        "start": 1299.69,
        "duration": 1.295
    },
    {
        "text": "what that's happening over here is it's",
        "start": 1300.985,
        "duration": 2.245
    },
    {
        "text": "actually training and learning as it goes,",
        "start": 1303.23,
        "duration": 2.6
    },
    {
        "text": "and you can see each of the neurons doing their thing,",
        "start": 1305.83,
        "duration": 3.05
    },
    {
        "text": "looking for the particular features",
        "start": 1308.88,
        "duration": 1.71
    },
    {
        "text": "that they've been trying to do.",
        "start": 1310.59,
        "duration": 1.08
    },
    {
        "text": "And you'll see them change over",
        "start": 1311.67,
        "duration": 1.53
    },
    {
        "text": "time as I hover over them as it",
        "start": 1313.2,
        "duration": 2.14
    },
    {
        "text": "starts to try and solve",
        "start": 1315.34,
        "duration": 1.16
    },
    {
        "text": "this problem of getting this shape up over here.",
        "start": 1316.5,
        "duration": 2.78
    },
    {
        "text": ">> Yeah, this is an excellent tool to just explore",
        "start": 1319.28,
        "duration": 4.195
    },
    {
        "text": "different concepts even of Neural Network,",
        "start": 1323.475,
        "duration": 4.955
    },
    {
        "text": "a Tanh's Neural Network to do classification.",
        "start": 1328.43,
        "duration": 3.735
    },
    {
        "text": ">> And we didn't talk in this talk",
        "start": 1332.165,
        "duration": 1.625
    },
    {
        "text": "about activation functions.",
        "start": 1333.79,
        "duration": 1.635
    },
    {
        "text": "And there are different types",
        "start": 1335.425,
        "duration": 2.195
    },
    {
        "text": "of activation functions that are popular.",
        "start": 1337.62,
        "duration": 2.015
    },
    {
        "text": "Right now, Tanh seems to be",
        "start": 1339.635,
        "duration": 1.525
    },
    {
        "text": "the most popular one that people are using but there's",
        "start": 1341.16,
        "duration": 2.47
    },
    {
        "text": "also ReLu and Sigmoid as the traditional linear.",
        "start": 1343.63,
        "duration": 4.74
    },
    {
        "text": "Quite familiar with linear regression and that approach.",
        "start": 1348.37,
        "duration": 3.735
    },
    {
        "text": "If I change the activation function to ReLu here,",
        "start": 1352.105,
        "duration": 3.075
    },
    {
        "text": "it's actually performs in a different way,",
        "start": 1355.18,
        "duration": 3.3
    },
    {
        "text": "and you'll see different process",
        "start": 1358.48,
        "duration": 2.44
    },
    {
        "text": "and path through the network.",
        "start": 1360.92,
        "duration": 1.82
    },
    {
        "text": "We can talk about that in later sessions.",
        "start": 1362.74,
        "duration": 3.89
    },
    {
        "text": "The other thing, the learning rate",
        "start": 1366.63,
        "duration": 1.41
    },
    {
        "text": "and think of this as if",
        "start": 1368.04,
        "duration": 1.27
    },
    {
        "text": "you're looking for you being in the snow,",
        "start": 1369.31,
        "duration": 3.425
    },
    {
        "text": "in a whiteout, and",
        "start": 1372.735,
        "duration": 1.63
    },
    {
        "text": "you don't know which way is up or down.",
        "start": 1374.365,
        "duration": 1.835
    },
    {
        "text": "So you kind of inch forward a little",
        "start": 1376.2,
        "duration": 1.86
    },
    {
        "text": "bit and then you have to gauge,",
        "start": 1378.06,
        "duration": 1.77
    },
    {
        "text": "are you going upward? Are you going down?",
        "start": 1379.83,
        "duration": 1.7
    },
    {
        "text": "To try and find the bottom of the hill,",
        "start": 1381.53,
        "duration": 1.985
    },
    {
        "text": "that's what the learning rate is doing,",
        "start": 1383.515,
        "duration": 1.975
    },
    {
        "text": "it's really looking around itself.",
        "start": 1385.49,
        "duration": 1.49
    },
    {
        "text": "And if it's too big, it might miss the hill,",
        "start": 1386.98,
        "duration": 1.9
    },
    {
        "text": "it might skip right over it.",
        "start": 1388.88,
        "duration": 1.42
    },
    {
        "text": "And if it's too small, it might take too",
        "start": 1390.3,
        "duration": 1.62
    },
    {
        "text": "long because it's working really, really slowly.",
        "start": 1391.92,
        "duration": 3.04
    },
    {
        "text": ">> Right.",
        "start": 1394.96,
        "duration": 0.28
    },
    {
        "text": ">> So that's kind of the way to",
        "start": 1395.24,
        "duration": 1.74
    },
    {
        "text": "think what's happening with the learning rate there.",
        "start": 1396.98,
        "duration": 2.63
    },
    {
        "text": "And it looks like ReLu wasn't as good",
        "start": 1399.61,
        "duration": 2.33
    },
    {
        "text": "as tanh at solving in that particular problem.",
        "start": 1401.94,
        "duration": 3.085
    },
    {
        "text": "But we can see that and we can see the example.",
        "start": 1405.025,
        "duration": 3.695
    },
    {
        "text": "And the other thing is it's",
        "start": 1408.72,
        "duration": 1.61
    },
    {
        "text": "calculating whites so what it's really doing is",
        "start": 1410.33,
        "duration": 2.23
    },
    {
        "text": "it's looking at a particular feature and determining",
        "start": 1412.56,
        "duration": 2.505
    },
    {
        "text": "how important is this particular thing",
        "start": 1415.065,
        "duration": 2.285
    },
    {
        "text": "in solving this problem.",
        "start": 1417.35,
        "duration": 1.13
    },
    {
        "text": "And as it's calculating and going through,",
        "start": 1418.48,
        "duration": 3.4
    },
    {
        "text": "it's either increasing the",
        "start": 1421.88,
        "duration": 1.05
    },
    {
        "text": "weight or decreasing the weight,",
        "start": 1422.93,
        "duration": 1.25
    },
    {
        "text": "depending on how it",
        "start": 1424.18,
        "duration": 2.23
    },
    {
        "text": "feels that is significant to the problem state.",
        "start": 1426.41,
        "duration": 2.43
    },
    {
        "text": ">> Those tasks.",
        "start": 1428.84,
        "duration": 0.48
    },
    {
        "text": ">> Yeah.",
        "start": 1429.32,
        "duration": 0.43
    },
    {
        "text": ">> Yeah, in the whiteout.",
        "start": 1429.75,
        "duration": 0.81
    },
    {
        "text": ">> Yes, absolutely.",
        "start": 1430.56,
        "duration": 0.95
    },
    {
        "text": ">> In the air, yeah.",
        "start": 1431.51,
        "duration": 1.255
    },
    {
        "text": ">> And just to miss with it,",
        "start": 1432.765,
        "duration": 1.935
    },
    {
        "text": "you can actually come in here and you could",
        "start": 1434.7,
        "duration": 2.16
    },
    {
        "text": "change those weights so you",
        "start": 1436.86,
        "duration": 1.38
    },
    {
        "text": "could say actually, you are wrong.",
        "start": 1438.24,
        "duration": 2.605
    },
    {
        "text": "I think this neuron is more important.",
        "start": 1440.845,
        "duration": 4.2
    },
    {
        "text": "You are saying it's a negative",
        "start": 1445.045,
        "duration": 1.175
    },
    {
        "text": "80 percent and negative 0.3,",
        "start": 1446.22,
        "duration": 2.085
    },
    {
        "text": "I'm saying it's actually 0.8.",
        "start": 1448.305,
        "duration": 2.09
    },
    {
        "text": "And by making a change,",
        "start": 1450.395,
        "duration": 2.765
    },
    {
        "text": "you're forcing more of",
        "start": 1453.16,
        "duration": 2.315
    },
    {
        "text": "the process through that particular neuron.",
        "start": 1455.475,
        "duration": 3.615
    },
    {
        "text": "And over time it may pick that up and say,",
        "start": 1459.09,
        "duration": 3.66
    },
    {
        "text": "actually that doesn't look right and",
        "start": 1462.75,
        "duration": 1.41
    },
    {
        "text": "adjusted and take a path",
        "start": 1464.16,
        "duration": 1.815
    },
    {
        "text": "because ultimately it knows better than we do.",
        "start": 1465.975,
        "duration": 1.85
    },
    {
        "text": ">> It's got a lot more matrix calculation",
        "start": 1467.825,
        "duration": 4.385
    },
    {
        "text": "going on in it than I do for sure.",
        "start": 1472.21,
        "duration": 1.86
    },
    {
        "text": ">> Absolutely. Excellent. So thanks",
        "start": 1474.07,
        "duration": 3.75
    },
    {
        "text": "for the time and thanks for listening.",
        "start": 1477.82,
        "duration": 3.04
    },
    {
        "text": "And as I mentioned before,",
        "start": 1480.86,
        "duration": 1.36
    },
    {
        "text": "we'll have some more show notes",
        "start": 1482.22,
        "duration": 1.03
    },
    {
        "text": "at the end of this session.",
        "start": 1483.25,
        "duration": 0.98
    },
    {
        "text": ">> Thank you so much.",
        "start": 1484.23,
        "duration": 1.25
    },
    {
        "text": ">> Thanks a lot. Bye.",
        "start": 1485.48,
        "duration": 2.01
    }
]