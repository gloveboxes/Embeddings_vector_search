[
    {
        "text": ">> You're not going to want to miss this episode of",
        "start": 0.0,
        "duration": 1.98
    },
    {
        "text": "The AI Show where we talk all about what's new",
        "start": 1.98,
        "duration": 2.175
    },
    {
        "text": "in Azure Machine Learning Automated ML",
        "start": 4.155,
        "duration": 2.855
    },
    {
        "text": "with my good friend Cesar make sure you tune in.",
        "start": 7.01,
        "duration": 6.432
    },
    {
        "text": ">> [MUSIC]",
        "start": 13.442,
        "duration": 3.088
    },
    {
        "text": ">> Hello and welcome to this episode of the AI show,",
        "start": 16.53,
        "duration": 2.28
    },
    {
        "text": "where we're talking all about what's new in",
        "start": 18.81,
        "duration": 1.89
    },
    {
        "text": "Azure Machine Learning Automated ML with my good friend.",
        "start": 20.7,
        "duration": 3.14
    },
    {
        "text": "Cesar. Cesar, I want you introduce yourself?",
        "start": 23.84,
        "duration": 1.69
    },
    {
        "text": "Tell us who you are and what you do.",
        "start": 25.53,
        "duration": 1.665
    },
    {
        "text": ">> Yeah, my name is Cesar De la Torre.",
        "start": 27.195,
        "duration": 1.815
    },
    {
        "text": "I work in the Azure Machine Learning Team",
        "start": 29.01,
        "duration": 2.97
    },
    {
        "text": "as Principal Program Manager.",
        "start": 31.98,
        "duration": 1.905
    },
    {
        "text": ">> Fantastic. We've had a lot of",
        "start": 33.885,
        "duration": 2.835
    },
    {
        "text": "shows on Automated Machine Learning.",
        "start": 36.72,
        "duration": 2.85
    },
    {
        "text": "Can you tell us what it is for",
        "start": 39.57,
        "duration": 1.53
    },
    {
        "text": "those that maybe haven't heard about it yet?",
        "start": 41.1,
        "duration": 2.22
    },
    {
        "text": ">> Yeah. AutoML is part of the Azure Machine Learning product.",
        "start": 43.32,
        "duration": 5.235
    },
    {
        "text": "Basically, it allows you to have more productivity,",
        "start": 48.555,
        "duration": 3.315
    },
    {
        "text": "so instead of having to know",
        "start": 51.87,
        "duration": 2.37
    },
    {
        "text": "all the algorithms and how to create a model,",
        "start": 54.24,
        "duration": 2.52
    },
    {
        "text": "you can just provide data.",
        "start": 56.76,
        "duration": 1.95
    },
    {
        "text": "What machine learning tasks you want to do, like classification,",
        "start": 58.71,
        "duration": 3.44
    },
    {
        "text": "progression for time serials and then what you want to predict.",
        "start": 62.15,
        "duration": 3.28
    },
    {
        "text": "Then will do a bunch of different trainings with different models,",
        "start": 65.43,
        "duration": 3.45
    },
    {
        "text": "comparing one to the other and finally,",
        "start": 68.88,
        "duration": 3.0
    },
    {
        "text": "let's say we train 50 or 100 models,",
        "start": 71.88,
        "duration": 2.745
    },
    {
        "text": "we give you the best one and then you can just deploy and use",
        "start": 74.625,
        "duration": 3.525
    },
    {
        "text": "the model and something",
        "start": 78.15,
        "duration": 1.95
    },
    {
        "text": "new that I'm going to talk later about cogeneration.",
        "start": 80.1,
        "duration": 2.23
    },
    {
        "text": ">> That's actually really cool because I remember",
        "start": 82.33,
        "duration": 2.54
    },
    {
        "text": "describing this to data scientists",
        "start": 84.87,
        "duration": 2.16
    },
    {
        "text": "and they were like wait a minute Seth,",
        "start": 87.03,
        "duration": 1.755
    },
    {
        "text": "this is something that we needed really.",
        "start": 88.785,
        "duration": 2.04
    },
    {
        "text": "Like the boring part of machine learning is going through",
        "start": 90.825,
        "duration": 2.565
    },
    {
        "text": "all the first models and this takes that away and honestly,",
        "start": 93.39,
        "duration": 4.86
    },
    {
        "text": "I think it's great.",
        "start": 98.25,
        "duration": 1.35
    },
    {
        "text": "Question for you says are what's new?",
        "start": 99.6,
        "duration": 2.625
    },
    {
        "text": "What should people be looking out for?",
        "start": 102.225,
        "duration": 1.545
    },
    {
        "text": ">> Yeah. One thing that's new",
        "start": 103.77,
        "duration": 2.28
    },
    {
        "text": "and you can use it today is public preview",
        "start": 106.05,
        "duration": 3.45
    },
    {
        "text": "in with SDK 1 or even from the UI and it is cogeneration.",
        "start": 109.5,
        "duration": 5.515
    },
    {
        "text": "Basically, we are creating a white box with total amount,",
        "start": 115.015,
        "duration": 6.235
    },
    {
        "text": "so instead of like until now AutoML was,",
        "start": 121.25,
        "duration": 3.205
    },
    {
        "text": "some people could say it's a black box because I provide the data,",
        "start": 124.455,
        "duration": 3.945
    },
    {
        "text": "you give me a model,",
        "start": 128.4,
        "duration": 1.14
    },
    {
        "text": "but then with the model I can just deploy it and use it.",
        "start": 129.54,
        "duration": 3.3
    },
    {
        "text": "But we got feedback from customers saying that, hey,",
        "start": 132.84,
        "duration": 3.93
    },
    {
        "text": "even I have regulations and",
        "start": 136.77,
        "duration": 3.93
    },
    {
        "text": "policies and because of the laws sometimes that I",
        "start": 140.7,
        "duration": 3.45
    },
    {
        "text": "need to have the real training code of the model that I'm going to",
        "start": 144.15,
        "duration": 4.29
    },
    {
        "text": "deploy into production and",
        "start": 148.44,
        "duration": 2.73
    },
    {
        "text": "also want to have deterministic reproducibility,",
        "start": 151.17,
        "duration": 2.57
    },
    {
        "text": "so this is the code for that model.",
        "start": 153.74,
        "duration": 1.57
    },
    {
        "text": "If I get new data,",
        "start": 155.31,
        "duration": 1.215
    },
    {
        "text": "it'll train exactly the same way.",
        "start": 156.525,
        "duration": 2.445
    },
    {
        "text": "Finally, there are also some data scientists that they say, hey,",
        "start": 158.97,
        "duration": 5.52
    },
    {
        "text": "but I want full control of the training code and I also",
        "start": 164.49,
        "duration": 4.29
    },
    {
        "text": "even want to tweak the hyper parameters of the model and,",
        "start": 168.78,
        "duration": 5.04
    },
    {
        "text": "work at lower level of what everyone will get.",
        "start": 173.82,
        "duration": 4.635
    },
    {
        "text": "That's provided with cogeneration.",
        "start": 178.455,
        "duration": 2.415
    },
    {
        "text": "It's like the real training code of",
        "start": 180.87,
        "duration": 3.75
    },
    {
        "text": "the model that we provided with AutoML and it can be any,",
        "start": 184.62,
        "duration": 3.9
    },
    {
        "text": "you can pick the best one or you can get any other model,",
        "start": 188.52,
        "duration": 3.24
    },
    {
        "text": "trial models on the way and you",
        "start": 191.76,
        "duration": 2.64
    },
    {
        "text": "can see the training code for that particular model.",
        "start": 194.4,
        "duration": 3.24
    },
    {
        "text": ">> That's actually really cool because I know it",
        "start": 197.64,
        "duration": 3.72
    },
    {
        "text": "used to make the model and then",
        "start": 201.36,
        "duration": 1.8
    },
    {
        "text": "you would just get it and it would be wonderful.",
        "start": 203.16,
        "duration": 1.995
    },
    {
        "text": "But now you just don't get the model file.",
        "start": 205.155,
        "duration": 2.775
    },
    {
        "text": "I should say it's a pickle file because it's,",
        "start": 207.93,
        "duration": 1.98
    },
    {
        "text": "maybe it's a hard model or something,",
        "start": 209.91,
        "duration": 1.905
    },
    {
        "text": "but now you actually get the code",
        "start": 211.815,
        "duration": 2.13
    },
    {
        "text": "that you would have written if you would have done it.",
        "start": 213.945,
        "duration": 2.085
    },
    {
        "text": "Because I'm guessing there's a lot of",
        "start": 216.03,
        "duration": 1.35
    },
    {
        "text": "different settings that go and are",
        "start": 217.38,
        "duration": 1.86
    },
    {
        "text": "involved with building these models like feature risers,",
        "start": 219.24,
        "duration": 4.165
    },
    {
        "text": "model hyper parameters, etc.",
        "start": 223.405,
        "duration": 2.45
    },
    {
        "text": ">> Yeah, exactly. If I go to the next slide.",
        "start": 225.855,
        "duration": 4.495
    },
    {
        "text": "Basically, you could go to the UI",
        "start": 231.56,
        "duration": 3.53
    },
    {
        "text": "also from basic but like from the UI is pretty clear.",
        "start": 235.09,
        "duration": 3.06
    },
    {
        "text": "You select any model from AutoML from a particular experiment say",
        "start": 238.15,
        "duration": 4.89
    },
    {
        "text": "this one XGBoostClassifier and then you can see the script.py,",
        "start": 243.04,
        "duration": 7.62
    },
    {
        "text": "which is the training code of",
        "start": 250.66,
        "duration": 1.32
    },
    {
        "text": "that particular model in this case and shown",
        "start": 251.98,
        "duration": 2.85
    },
    {
        "text": "here shows the algorithm I could",
        "start": 254.83,
        "duration": 2.16
    },
    {
        "text": "learn XGBoostClssifier with happy the parameters.",
        "start": 256.99,
        "duration": 2.61
    },
    {
        "text": "But even before the training,",
        "start": 259.6,
        "duration": 2.759
    },
    {
        "text": "we are also generating the featurization of the data.",
        "start": 262.359,
        "duration": 3.706
    },
    {
        "text": "What transformations are happening on each of the columns?",
        "start": 266.065,
        "duration": 4.155
    },
    {
        "text": "It's the end-to-end processes.",
        "start": 270.22,
        "duration": 2.31
    },
    {
        "text": "We upload the data",
        "start": 272.53,
        "duration": 1.635
    },
    {
        "text": "until the model is trained and you can see it's like",
        "start": 274.165,
        "duration": 2.655
    },
    {
        "text": "we are using a secular pipeline fit and",
        "start": 276.82,
        "duration": 2.19
    },
    {
        "text": "this is training your model.",
        "start": 279.01,
        "duration": 2.87
    },
    {
        "text": ">> That's cool. How do you set these up?",
        "start": 281.88,
        "duration": 6.785
    },
    {
        "text": "Can you only just do it in the UI.",
        "start": 288.665,
        "duration": 1.655
    },
    {
        "text": "You have to give it data or there are multiple ways to do this?",
        "start": 290.32,
        "duration": 2.63
    },
    {
        "text": ">> There are multiple ways I can do a demo if you want.",
        "start": 292.95,
        "duration": 3.695
    },
    {
        "text": ">> Yeah. Let's take a look.",
        "start": 296.645,
        "duration": 1.205
    },
    {
        "text": ">> Let's look at it.",
        "start": 297.85,
        "duration": 6.125
    },
    {
        "text": "Basically, the way you",
        "start": 303.975,
        "duration": 2.97
    },
    {
        "text": "can trigger CodeGen is like it's going to happen by default.",
        "start": 306.945,
        "duration": 3.445
    },
    {
        "text": "Like, you don't need to do something special.",
        "start": 310.39,
        "duration": 2.345
    },
    {
        "text": "You could just, you know,",
        "start": 312.735,
        "duration": 1.655
    },
    {
        "text": "like create AutoML experiment from the UI,",
        "start": 314.39,
        "duration": 3.915
    },
    {
        "text": "so data set the typical workflow",
        "start": 318.305,
        "duration": 4.755
    },
    {
        "text": "with AutoML or you can also create the experiment with how",
        "start": 323.06,
        "duration": 4.02
    },
    {
        "text": "to I'm like a regular AutoMLConfig with",
        "start": 327.08,
        "duration": 2.655
    },
    {
        "text": "basically one in this case what you want to do like",
        "start": 329.735,
        "duration": 3.345
    },
    {
        "text": "the task and so on and then we have",
        "start": 333.08,
        "duration": 2.49
    },
    {
        "text": "just one particular property",
        "start": 335.57,
        "duration": 3.45
    },
    {
        "text": "which is for enabling or disabling code generation.",
        "start": 339.02,
        "duration": 3.975
    },
    {
        "text": "By default. It's now going to be generated into code,",
        "start": 342.995,
        "duration": 4.795
    },
    {
        "text": "so even if you don't put it is going to be working,",
        "start": 347.79,
        "duration": 2.45
    },
    {
        "text": "but you could disable CodeGen.",
        "start": 350.24,
        "duration": 2.775
    },
    {
        "text": "Basically, it's a regular training,",
        "start": 353.015,
        "duration": 6.655
    },
    {
        "text": "so when you launch that AutoML training,",
        "start": 359.67,
        "duration": 5.67
    },
    {
        "text": "you will see always different models",
        "start": 365.34,
        "duration": 3.86
    },
    {
        "text": "that have been trained with AutoML.",
        "start": 369.2,
        "duration": 3.075
    },
    {
        "text": "This is the best one.",
        "start": 372.275,
        "duration": 1.86
    },
    {
        "text": "Let's say I want to see hey for I'd like to see what's",
        "start": 374.135,
        "duration": 3.465
    },
    {
        "text": "the training code for this particular model XGBoostClassifier.",
        "start": 377.6,
        "duration": 4.09
    },
    {
        "text": "If you can select here and click on view generated code",
        "start": 381.69,
        "duration": 3.47
    },
    {
        "text": "or I can also get into the models page I can click now.",
        "start": 385.16,
        "duration": 5.17
    },
    {
        "text": "There's also something that we ought to look",
        "start": 391.64,
        "duration": 2.59
    },
    {
        "text": "at a few months already for",
        "start": 394.23,
        "duration": 1.865
    },
    {
        "text": "visibilities you'll get a model",
        "start": 396.095,
        "duration": 2.355
    },
    {
        "text": "but you can see that you can just apply,",
        "start": 398.45,
        "duration": 2.22
    },
    {
        "text": "download it, explain it.",
        "start": 400.67,
        "duration": 2.115
    },
    {
        "text": "We also had added you can use the hyper parameters",
        "start": 402.785,
        "duration": 3.42
    },
    {
        "text": "for this particular model and these are right hyper parameters.",
        "start": 406.205,
        "duration": 3.78
    },
    {
        "text": "But that was not enough,",
        "start": 409.985,
        "duration": 1.335
    },
    {
        "text": "because if you want to create the training code for this model,",
        "start": 411.32,
        "duration": 5.13
    },
    {
        "text": "then you need to do a reverse engineer",
        "start": 416.45,
        "duration": 2.685
    },
    {
        "text": "or the feature session that can be complex.",
        "start": 419.135,
        "duration": 3.6
    },
    {
        "text": "We made it super simple.",
        "start": 422.735,
        "duration": 1.605
    },
    {
        "text": "You just click here on view generated code for",
        "start": 424.34,
        "duration": 3.12
    },
    {
        "text": "this particular model and then we're going to copy like two files,",
        "start": 427.46,
        "duration": 4.62
    },
    {
        "text": "basically one that's a convenient notebook to",
        "start": 432.08,
        "duration": 4.08
    },
    {
        "text": "run that training code",
        "start": 436.16,
        "duration": 2.1
    },
    {
        "text": "and then the training code which is py file.",
        "start": 438.26,
        "duration": 3.7
    },
    {
        "text": "This is a convenient notebook,",
        "start": 443.9,
        "duration": 3.05
    },
    {
        "text": "but at this point, this is not our roadmap anymore.",
        "start": 446.95,
        "duration": 2.895
    },
    {
        "text": "It's just using Azure Machine Learning as the key,",
        "start": 449.845,
        "duration": 3.99
    },
    {
        "text": "where it's specified the cluster",
        "start": 453.835,
        "duration": 5.405
    },
    {
        "text": "where you can run that training code or that particular model",
        "start": 459.24,
        "duration": 4.29
    },
    {
        "text": "and also something interesting is we are",
        "start": 463.53,
        "duration": 2.955
    },
    {
        "text": "using the dark environment that was used when training,",
        "start": 466.485,
        "duration": 7.115
    },
    {
        "text": "so you have all the dependencies.",
        "start": 473.6,
        "duration": 1.66
    },
    {
        "text": "But then it's a very simple code is just using",
        "start": 475.26,
        "duration": 5.58
    },
    {
        "text": "ScriptRunConfig pointing to the",
        "start": 480.84,
        "duration": 4.155
    },
    {
        "text": "script.py which is the training code.",
        "start": 484.995,
        "duration": 4.545
    },
    {
        "text": "This is just a way to run a script.py in the Cloud.",
        "start": 489.54,
        "duration": 4.2
    },
    {
        "text": "But then this is the interesting code script.py.",
        "start": 493.74,
        "duration": 4.84
    },
    {
        "text": "Here is where you can see how we load the data.",
        "start": 499.76,
        "duration": 5.45
    },
    {
        "text": ">> I'm going to go to the interesting part,",
        "start": 507.71,
        "duration": 2.38
    },
    {
        "text": "but you can see the loaded data, speed data sets.",
        "start": 510.09,
        "duration": 3.09
    },
    {
        "text": "Then there are some code for preparing the data.",
        "start": 513.18,
        "duration": 4.2
    },
    {
        "text": ">> It's everything that you would do",
        "start": 517.38,
        "duration": 1.92
    },
    {
        "text": "if you were to writing this thing that you-",
        "start": 519.3,
        "duration": 1.605
    },
    {
        "text": ">> Exactly. Here you can see the columns featurization.",
        "start": 520.905,
        "duration": 5.295
    },
    {
        "text": "This is a data set with 50 columns and you can see that I'm doing",
        "start": 526.2,
        "duration": 4.35
    },
    {
        "text": "the same featurization for a group of",
        "start": 530.55,
        "duration": 2.37
    },
    {
        "text": "columns and then another featurization for another group.",
        "start": 532.92,
        "duration": 2.955
    },
    {
        "text": "This is optimized.",
        "start": 535.875,
        "duration": 2.22
    },
    {
        "text": "Then this is the interesting code.",
        "start": 538.095,
        "duration": 1.845
    },
    {
        "text": "You can see we are using x equals",
        "start": 539.94,
        "duration": 2.4
    },
    {
        "text": "classifier all the hyper parameters for this particular model.",
        "start": 542.34,
        "duration": 3.57
    },
    {
        "text": "You could tweak any of these type of parameters.",
        "start": 545.91,
        "duration": 2.685
    },
    {
        "text": "Finally, you can see here",
        "start": 548.595,
        "duration": 1.725
    },
    {
        "text": "the circular pipeline for the steps featurization,",
        "start": 550.32,
        "duration": 4.56
    },
    {
        "text": "preprocessing and the model training and then when",
        "start": 554.88,
        "duration": 3.3
    },
    {
        "text": "you call here fit.",
        "start": 558.18,
        "duration": 5.32
    },
    {
        "text": "Then is training.",
        "start": 563.51,
        "duration": 2.485
    },
    {
        "text": "You could even take this code,",
        "start": 565.995,
        "duration": 2.94
    },
    {
        "text": "change the way you are loading the data",
        "start": 568.935,
        "duration": 2.745
    },
    {
        "text": "set and run it anywhere, even in premises.",
        "start": 571.68,
        "duration": 2.925
    },
    {
        "text": "But of course, we made that notebook.",
        "start": 574.605,
        "duration": 2.85
    },
    {
        "text": "That is going to make you just",
        "start": 577.455,
        "duration": 2.865
    },
    {
        "text": "super easy to run these training code, just running that node.",
        "start": 580.32,
        "duration": 3.465
    },
    {
        "text": ">> What's cool is it's not like,",
        "start": 583.785,
        "duration": 2.535
    },
    {
        "text": "I was looking at the code, it's like, oh,",
        "start": 586.32,
        "duration": 1.815
    },
    {
        "text": "this is just regular code that I would run",
        "start": 588.135,
        "duration": 2.04
    },
    {
        "text": "if I was doing this myself.",
        "start": 590.175,
        "duration": 2.205
    },
    {
        "text": "But it turns out that",
        "start": 592.38,
        "duration": 1.14
    },
    {
        "text": "the automated machine learning thing",
        "start": 593.52,
        "duration": 2.01
    },
    {
        "text": "went through a whole bunch of them to try stuff out.",
        "start": 595.53,
        "duration": 2.295
    },
    {
        "text": ">> Yeah. Because this code is using,",
        "start": 597.825,
        "duration": 3.495
    },
    {
        "text": "just like in this case. I could learn.",
        "start": 601.32,
        "duration": 2.64
    },
    {
        "text": "Then there are a few libraries that we are providing",
        "start": 603.96,
        "duration": 2.745
    },
    {
        "text": "as decouple libraries as well or",
        "start": 606.705,
        "duration": 2.13
    },
    {
        "text": "things for like some featurization steps",
        "start": 608.835,
        "duration": 4.29
    },
    {
        "text": "or maybe related to assembly.",
        "start": 613.125,
        "duration": 3.225
    },
    {
        "text": "But most of the code we wanted to use directly",
        "start": 616.35,
        "duration": 3.75
    },
    {
        "text": "the open source process like in",
        "start": 620.1,
        "duration": 2.16
    },
    {
        "text": "this case [inaudible] was classified.",
        "start": 622.26,
        "duration": 2.64
    },
    {
        "text": ">> That was really cool. It was cool to see how the thing ran,",
        "start": 624.9,
        "duration": 4.53
    },
    {
        "text": "but it wasn't some hidden thing.",
        "start": 629.43,
        "duration": 1.8
    },
    {
        "text": "You actually had the code for the notebook",
        "start": 631.23,
        "duration": 1.845
    },
    {
        "text": "to run it and then you actually had",
        "start": 633.075,
        "duration": 1.575
    },
    {
        "text": "the code for the actual model featurization, all that stuff.",
        "start": 634.65,
        "duration": 5.16
    },
    {
        "text": "Anything else that's new?",
        "start": 639.81,
        "duration": 1.71
    },
    {
        "text": ">> Yeah. The other area that I like to",
        "start": 641.52,
        "duration": 2.4
    },
    {
        "text": "highlight is precisely a link.",
        "start": 643.92,
        "duration": 2.79
    },
    {
        "text": "Now, in Build we are releasing a new version of",
        "start": 646.71,
        "duration": 4.86
    },
    {
        "text": "the development platform and",
        "start": 651.57,
        "duration": 3.18
    },
    {
        "text": "then AutoML is part of this new version v2,",
        "start": 654.75,
        "duration": 3.33
    },
    {
        "text": "so then previously in v1 there was",
        "start": 658.08,
        "duration": 4.41
    },
    {
        "text": "a CLI for actual machine learning but not for AutoML.",
        "start": 662.49,
        "duration": 5.715
    },
    {
        "text": "This is completely new supporting CLI for AutoML.",
        "start": 668.205,
        "duration": 4.245
    },
    {
        "text": "Basically that means that you can write in a YAML file",
        "start": 672.45,
        "duration": 4.185
    },
    {
        "text": "all the AutoML experiment properties",
        "start": 676.635,
        "duration": 3.24
    },
    {
        "text": "like what task, what's your data,",
        "start": 679.875,
        "duration": 2.295
    },
    {
        "text": "what's the time out and so on and then run or trigger that",
        "start": 682.17,
        "duration": 4.14
    },
    {
        "text": "training run directly from",
        "start": 686.31,
        "duration": 2.625
    },
    {
        "text": "a single line of command pointing to the YAML.",
        "start": 688.935,
        "duration": 3.675
    },
    {
        "text": "Why would you want to do that?",
        "start": 692.61,
        "duration": 2.295
    },
    {
        "text": "It's great for MLOps operations.",
        "start": 694.905,
        "duration": 2.715
    },
    {
        "text": "Basically you can trigger training in your CICD,",
        "start": 697.62,
        "duration": 6.345
    },
    {
        "text": "but for models from GitHub actions or from",
        "start": 703.965,
        "duration": 4.755
    },
    {
        "text": "actual DevOps and then I find myself it's super",
        "start": 708.72,
        "duration": 3.93
    },
    {
        "text": "easy to test again the same run,",
        "start": 712.65,
        "duration": 3.51
    },
    {
        "text": "but just tweaking one property",
        "start": 716.16,
        "duration": 1.89
    },
    {
        "text": "and then run it again quickly from this YAML.",
        "start": 718.05,
        "duration": 2.895
    },
    {
        "text": "Then of course we also have support for",
        "start": 720.945,
        "duration": 3.465
    },
    {
        "text": "Python SDK because when you are working with the data,",
        "start": 724.41,
        "duration": 3.825
    },
    {
        "text": "transforming the data, exploring the data for DOD,",
        "start": 728.235,
        "duration": 4.77
    },
    {
        "text": "like using a notebook is a lot more flexible.",
        "start": 733.005,
        "duration": 3.975
    },
    {
        "text": "We also have DOD in v2,",
        "start": 736.98,
        "duration": 2.13
    },
    {
        "text": "but then we improve the code because in v1,",
        "start": 739.11,
        "duration": 4.05
    },
    {
        "text": "the AutoML comfort class has a very long list of properties,",
        "start": 743.16,
        "duration": 3.254
    },
    {
        "text": "possible properties and now we simplified the signature,",
        "start": 746.414,
        "duration": 3.856
    },
    {
        "text": "so it's just a short release for what's come",
        "start": 750.27,
        "duration": 3.24
    },
    {
        "text": "on and then optional sections later,",
        "start": 753.51,
        "duration": 3.33
    },
    {
        "text": "so it's a cleaner code.",
        "start": 756.84,
        "duration": 1.32
    },
    {
        "text": "Let me do a demo first of all about the CLI.",
        "start": 758.16,
        "duration": 5.265
    },
    {
        "text": "As I mentioned, you write",
        "start": 763.425,
        "duration": 3.845
    },
    {
        "text": "the properties of your AutoML job in YAML,",
        "start": 767.27,
        "duration": 3.495
    },
    {
        "text": "for instance, I can see here the experiment name,",
        "start": 770.765,
        "duration": 2.295
    },
    {
        "text": "the task specification, what's the target column name and so on.",
        "start": 773.06,
        "duration": 5.215
    },
    {
        "text": "The cool thing is that because I'm using",
        "start": 778.275,
        "duration": 3.625
    },
    {
        "text": "VS code is [inaudible] code",
        "start": 781.97,
        "duration": 2.785
    },
    {
        "text": "and because I'm putting here the schema,",
        "start": 784.755,
        "duration": 2.88
    },
    {
        "text": "then we also have IntelliSense.",
        "start": 787.635,
        "duration": 1.8
    },
    {
        "text": "For instance, because the task is classification,",
        "start": 789.435,
        "duration": 3.765
    },
    {
        "text": "the prime metrics are different that if",
        "start": 793.2,
        "duration": 2.325
    },
    {
        "text": "the task was regression or forecasting.",
        "start": 795.525,
        "duration": 3.12
    },
    {
        "text": "If I delete and then Control space,",
        "start": 798.645,
        "duration": 5.625
    },
    {
        "text": "we should have here",
        "start": 804.27,
        "duration": 2.19
    },
    {
        "text": "the multiple possibilities for classification primary metrics.",
        "start": 806.46,
        "duration": 5.625
    },
    {
        "text": "In this case, I select the area under the curve.",
        "start": 812.085,
        "duration": 4.26
    },
    {
        "text": "Once you have all the properties in the YAML,",
        "start": 816.345,
        "duration": 3.96
    },
    {
        "text": "then you just simply go to the CLI",
        "start": 820.305,
        "duration": 4.539
    },
    {
        "text": "and you just use the extension with the Azure CLI.",
        "start": 824.844,
        "duration": 8.531
    },
    {
        "text": "In this case this is AC machine learning job",
        "start": 833.375,
        "duration": 4.435
    },
    {
        "text": "create and then I'm providing here that YAML file and of course,",
        "start": 837.81,
        "duration": 6.46
    },
    {
        "text": "where I'm going to run it like workspace,",
        "start": 844.31,
        "duration": 3.31
    },
    {
        "text": "research group and so on.",
        "start": 847.62,
        "duration": 1.05
    },
    {
        "text": "You can put all these except the file,",
        "start": 848.67,
        "duration": 3.315
    },
    {
        "text": "I can by default values,",
        "start": 851.985,
        "duration": 1.8
    },
    {
        "text": "but it's also flexible to change it here.",
        "start": 853.785,
        "duration": 3.015
    },
    {
        "text": "Then just hit \"Enter\" and in",
        "start": 856.8,
        "duration": 3.63
    },
    {
        "text": "just a few seconds it will trigger asynchronously a run.",
        "start": 860.43,
        "duration": 5.01
    },
    {
        "text": ">> That's really cool. Basically, with the seal ICommand,",
        "start": 865.44,
        "duration": 3.72
    },
    {
        "text": "what you're doing is you're giving it instructions",
        "start": 869.16,
        "duration": 2.07
    },
    {
        "text": "in the YAML that has some auto completions",
        "start": 871.23,
        "duration": 2.129
    },
    {
        "text": "that tell it to run an automated machine",
        "start": 873.359,
        "duration": 2.19
    },
    {
        "text": "learning job and that just runs it in the Cloud.",
        "start": 875.549,
        "duration": 2.761
    },
    {
        "text": ">> Right. At the end of the day,",
        "start": 878.31,
        "duration": 1.68
    },
    {
        "text": "it's exactly the same action",
        "start": 879.99,
        "duration": 2.46
    },
    {
        "text": "that if you trigger that from from Python.",
        "start": 882.45,
        "duration": 2.88
    },
    {
        "text": "At the end, I have this run and then it's going",
        "start": 885.33,
        "duration": 3.54
    },
    {
        "text": "to run multiple chyrons for different model trainings,",
        "start": 888.87,
        "duration": 3.45
    },
    {
        "text": "but it's exactly the same.",
        "start": 892.32,
        "duration": 1.26
    },
    {
        "text": "In this case, it was trigger from the CLI.",
        "start": 893.58,
        "duration": 2.625
    },
    {
        "text": "In other cases, it can be trigger from the Python SDK,",
        "start": 896.205,
        "duration": 5.01
    },
    {
        "text": "which is what I'm going to show you now.",
        "start": 901.215,
        "duration": 2.235
    },
    {
        "text": "In this case, I have this notebook",
        "start": 903.45,
        "duration": 3.585
    },
    {
        "text": "with the new Python SDK from Azure Machine Learning,",
        "start": 907.035,
        "duration": 4.425
    },
    {
        "text": "and you can see that we have these new functions.",
        "start": 911.46,
        "duration": 4.725
    },
    {
        "text": "We call them our factory functions.",
        "start": 916.185,
        "duration": 2.085
    },
    {
        "text": "This is for classification.",
        "start": 918.27,
        "duration": 3.45
    },
    {
        "text": "This is one difference.",
        "start": 921.72,
        "duration": 1.725
    },
    {
        "text": "Now with AutoML,",
        "start": 923.445,
        "duration": 2.025
    },
    {
        "text": "we have 10 different tasks.",
        "start": 925.47,
        "duration": 1.875
    },
    {
        "text": "It's not just classification,",
        "start": 927.345,
        "duration": 1.695
    },
    {
        "text": "regression and time series,",
        "start": 929.04,
        "duration": 1.29
    },
    {
        "text": "but also for related to images,",
        "start": 930.33,
        "duration": 4.05
    },
    {
        "text": "computer vision, object detection and also",
        "start": 934.38,
        "duration": 2.94
    },
    {
        "text": "NLP for text classification and so on.",
        "start": 937.32,
        "duration": 2.73
    },
    {
        "text": "Basically what we're doing is that we are",
        "start": 940.05,
        "duration": 3.24
    },
    {
        "text": "having 10 different factory functions.",
        "start": 943.29,
        "duration": 3.915
    },
    {
        "text": "In this case, I'm using here for the classification example",
        "start": 947.205,
        "duration": 3.765
    },
    {
        "text": "that we were discussing and",
        "start": 950.97,
        "duration": 1.59
    },
    {
        "text": "then we have a first level properties,",
        "start": 952.56,
        "duration": 2.565
    },
    {
        "text": "which ones are the most common and",
        "start": 955.125,
        "duration": 4.185
    },
    {
        "text": "with this would be enough because then",
        "start": 959.31,
        "duration": 1.77
    },
    {
        "text": "the rest are by default values.",
        "start": 961.08,
        "duration": 2.505
    },
    {
        "text": "But then if you want to add",
        "start": 963.585,
        "duration": 2.775
    },
    {
        "text": "additional properties like limits or timeouts or,",
        "start": 966.36,
        "duration": 4.875
    },
    {
        "text": "I want to block some algorithms or",
        "start": 971.235,
        "duration": 3.105
    },
    {
        "text": "even additional properties related to assembly and so on.",
        "start": 974.34,
        "duration": 4.29
    },
    {
        "text": "Then we have these additional setters.",
        "start": 978.63,
        "duration": 3.315
    },
    {
        "text": "It's a lot more clearer",
        "start": 981.945,
        "duration": 3.6
    },
    {
        "text": "instead of having a very long list of",
        "start": 985.545,
        "duration": 2.415
    },
    {
        "text": "properties on the [inaudible].",
        "start": 987.96,
        "duration": 2.22
    },
    {
        "text": "Then once you we have this job configure,",
        "start": 990.18,
        "duration": 4.665
    },
    {
        "text": "then we use the same function launcher",
        "start": 994.845,
        "duration": 5.549
    },
    {
        "text": "in natural machine learning to create a job,",
        "start": 1000.394,
        "duration": 2.671
    },
    {
        "text": "so create or update and then we provide",
        "start": 1003.065,
        "duration": 2.775
    },
    {
        "text": "our justification job and then again the same thing.",
        "start": 1005.84,
        "duration": 3.96
    },
    {
        "text": "But now these runs",
        "start": 1009.8,
        "duration": 4.324
    },
    {
        "text": "or this experiment is created with from the SDK.",
        "start": 1014.124,
        "duration": 4.981
    },
    {
        "text": ">> Yeah. I mean, this is really cool.",
        "start": 1019.105,
        "duration": 3.115
    },
    {
        "text": "To summarize, if I'm understanding this, we have the new stuff.",
        "start": 1022.22,
        "duration": 3.4
    },
    {
        "text": "We have the CodeGen, which I thought was was really cool.",
        "start": 1025.62,
        "duration": 3.105
    },
    {
        "text": "We have the New CLI with some YAML descriptions,",
        "start": 1028.725,
        "duration": 4.485
    },
    {
        "text": "autocomplete inside of Visual Studio code and then we",
        "start": 1033.21,
        "duration": 3.53
    },
    {
        "text": "have the new SDK that has some simplification,",
        "start": 1036.74,
        "duration": 3.7
    },
    {
        "text": "some factory methods, and some setters which make",
        "start": 1040.44,
        "duration": 2.79
    },
    {
        "text": "it all a whole lot easier. Am I getting this right?",
        "start": 1043.23,
        "duration": 3.39
    },
    {
        "text": ">> Yeah, that's right.",
        "start": 1046.62,
        "duration": 2.695
    },
    {
        "text": ">> Go ahead. Sorry",
        "start": 1049.315,
        "duration": 1.805
    },
    {
        "text": ">> The only thing that I wanted to add as well,",
        "start": 1051.12,
        "duration": 2.49
    },
    {
        "text": "although I'm not copying these today and",
        "start": 1053.61,
        "duration": 2.52
    },
    {
        "text": "I think you also did other shows for this.",
        "start": 1056.13,
        "duration": 3.12
    },
    {
        "text": "New things in YAML is precisely AutoML for images.",
        "start": 1059.25,
        "duration": 4.155
    },
    {
        "text": ">> That's right.",
        "start": 1063.405,
        "duration": 0.42
    },
    {
        "text": ">> These classification,",
        "start": 1063.825,
        "duration": 1.83
    },
    {
        "text": "object detection, image segmentation,",
        "start": 1065.655,
        "duration": 2.655
    },
    {
        "text": "and then also NLP for text classification and so on,",
        "start": 1068.31,
        "duration": 3.06
    },
    {
        "text": "and some improvements about forecasting and parakeets.",
        "start": 1071.37,
        "duration": 3.945
    },
    {
        "text": "But this is also in preview and really exciting because now we",
        "start": 1075.315,
        "duration": 5.145
    },
    {
        "text": "are getting AutoML into",
        "start": 1080.46,
        "duration": 3.15
    },
    {
        "text": "the world of deep learning with these new tasks as well.",
        "start": 1083.61,
        "duration": 4.175
    },
    {
        "text": ">> Well, this has been really cool.",
        "start": 1087.785,
        "duration": 2.485
    },
    {
        "text": "Just a little link here.",
        "start": 1090.27,
        "duration": 1.02
    },
    {
        "text": "If you want to learn more about CodeGen,",
        "start": 1091.29,
        "duration": 1.56
    },
    {
        "text": "we got a little link just down there for you.",
        "start": 1092.85,
        "duration": 2.07
    },
    {
        "text": "This has been really awesome.",
        "start": 1094.92,
        "duration": 1.35
    },
    {
        "text": "Thank you so much for being with us, my friend.",
        "start": 1096.27,
        "duration": 1.98
    },
    {
        "text": ">> Thank you. Appreciate it.",
        "start": 1098.25,
        "duration": 1.635
    },
    {
        "text": ">> All right. We've been learning all about what's new in",
        "start": 1099.885,
        "duration": 2.475
    },
    {
        "text": "Azure Machine Learning automated ML here on the show.",
        "start": 1102.36,
        "duration": 3.06
    },
    {
        "text": "Thank you so much for watching and",
        "start": 1105.42,
        "duration": 1.02
    },
    {
        "text": "hopefully we'll see you next time. Take care.",
        "start": 1106.44,
        "duration": 1.53
    },
    {
        "text": "[MUSIC].",
        "start": 1107.97,
        "duration": 10.347
    }
]