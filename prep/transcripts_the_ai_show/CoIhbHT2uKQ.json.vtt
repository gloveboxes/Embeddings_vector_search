[
    {
        "text": "you're not gonna want to miss this",
        "start": 0.0,
        "duration": 3.81
    },
    {
        "text": "episode of the AI show where may who",
        "start": 1.8,
        "duration": 3.72
    },
    {
        "text": "program manager on the Azure machine",
        "start": 3.81,
        "duration": 4.01
    },
    {
        "text": "learning service team talks all about",
        "start": 5.52,
        "duration": 5.039
    },
    {
        "text": "datasets not only does she explain what",
        "start": 7.82,
        "duration": 4.87
    },
    {
        "text": "they are but also how to use them in a",
        "start": 10.559,
        "duration": 4.651
    },
    {
        "text": "distributed way all wrapped in a really",
        "start": 12.69,
        "duration": 5.04
    },
    {
        "text": "cool demo interesting data set make sure",
        "start": 15.21,
        "duration": 12.75
    },
    {
        "text": "you tune in my name is Mei I'm a program",
        "start": 17.73,
        "duration": 11.699
    },
    {
        "text": "manager working on our machine learning",
        "start": 27.96,
        "duration": 4.08
    },
    {
        "text": "service in today's session we will talk",
        "start": 29.429,
        "duration": 4.771
    },
    {
        "text": "about how to do distributed data",
        "start": 32.04,
        "duration": 3.9
    },
    {
        "text": "pre-processing using Azure machine",
        "start": 34.2,
        "duration": 4.679
    },
    {
        "text": "learning platform the agenda for the",
        "start": 35.94,
        "duration": 5.549
    },
    {
        "text": "session will start with an overview for",
        "start": 38.879,
        "duration": 5.011
    },
    {
        "text": "our machine learning data set what it is",
        "start": 41.489,
        "duration": 4.651
    },
    {
        "text": "how it can help you achieve your machine",
        "start": 43.89,
        "duration": 4.98
    },
    {
        "text": "learning workflows then we will do a",
        "start": 46.14,
        "duration": 5.43
    },
    {
        "text": "live demo to showcase how to use data",
        "start": 48.87,
        "duration": 5.13
    },
    {
        "text": "set with parallel run in automation and",
        "start": 51.57,
        "duration": 5.219
    },
    {
        "text": "in pipelines to help to distributed data",
        "start": 54.0,
        "duration": 6.93
    },
    {
        "text": "pre-processing our machine learning data",
        "start": 56.789,
        "duration": 7.02
    },
    {
        "text": "sets connect to your storage service and",
        "start": 60.93,
        "duration": 5.28
    },
    {
        "text": "help deliver data from the storage",
        "start": 63.809,
        "duration": 4.92
    },
    {
        "text": "service to your computer target on the",
        "start": 66.21,
        "duration": 5.67
    },
    {
        "text": "cloud you can mount download or load the",
        "start": 68.729,
        "duration": 6.241
    },
    {
        "text": "data into common data frames like pandas",
        "start": 71.88,
        "duration": 5.97
    },
    {
        "text": "spark or Python for data preparation",
        "start": 74.97,
        "duration": 4.86
    },
    {
        "text": "training and inferencing",
        "start": 77.85,
        "duration": 5.1
    },
    {
        "text": "this set also come with built-in lineage",
        "start": 79.83,
        "duration": 5.82
    },
    {
        "text": "support to help track your data in your",
        "start": 82.95,
        "duration": 4.41
    },
    {
        "text": "machine learning workflow for",
        "start": 85.65,
        "duration": 6.929
    },
    {
        "text": "reproducibility and auditability our",
        "start": 87.36,
        "duration": 7.619
    },
    {
        "text": "machine learning help accelerate your",
        "start": 92.579,
        "duration": 5.701
    },
    {
        "text": "big big data preparation by scaling out",
        "start": 94.979,
        "duration": 6.241
    },
    {
        "text": "the process out-of-the-box in this demo",
        "start": 98.28,
        "duration": 3.87
    },
    {
        "text": "we will use",
        "start": 101.22,
        "duration": 3.179
    },
    {
        "text": "kovita knighting open research datasets",
        "start": 102.15,
        "duration": 6.149
    },
    {
        "text": "which is made of 47,000 scholar articles",
        "start": 104.399,
        "duration": 7.171
    },
    {
        "text": "in json format we will first distribute",
        "start": 108.299,
        "duration": 5.491
    },
    {
        "text": "the full datasets across five different",
        "start": 111.57,
        "duration": 5.07
    },
    {
        "text": "notes and all these notes will run the",
        "start": 113.79,
        "duration": 4.8
    },
    {
        "text": "same preparation script which is",
        "start": 116.64,
        "duration": 4.079
    },
    {
        "text": "basically to parse the json files",
        "start": 118.59,
        "duration": 4.62
    },
    {
        "text": "process the sentence and writes the",
        "start": 120.719,
        "duration": 5.491
    },
    {
        "text": "output into data frames at the end of",
        "start": 123.21,
        "duration": 5.909
    },
    {
        "text": "the distributed data preparation we will",
        "start": 126.21,
        "duration": 5.91
    },
    {
        "text": "append the rows into one big data frames",
        "start": 129.119,
        "duration": 4.651
    },
    {
        "text": "which will then be read",
        "start": 132.12,
        "duration": 4.92
    },
    {
        "text": "for exploratory data analysis report or",
        "start": 133.77,
        "duration": 6.33
    },
    {
        "text": "NLP training to answer kovat questions",
        "start": 137.04,
        "duration": 6.09
    },
    {
        "text": "from this literature review with that",
        "start": 140.1,
        "duration": 9.06
    },
    {
        "text": "let's go into the demo here is a sample",
        "start": 143.13,
        "duration": 8.07
    },
    {
        "text": "notebook that showcase how to do",
        "start": 149.16,
        "duration": 4.29
    },
    {
        "text": "distributed data preparation using Azure",
        "start": 151.2,
        "duration": 4.98
    },
    {
        "text": "machine learning SDK to start an",
        "start": 153.45,
        "duration": 4.68
    },
    {
        "text": "experiment you first need to load your",
        "start": 156.18,
        "duration": 3.27
    },
    {
        "text": "machine on your workspace to the",
        "start": 158.13,
        "duration": 5.85
    },
    {
        "text": "notebook and here we are connecting to",
        "start": 159.45,
        "duration": 7.71
    },
    {
        "text": "the agile blog container hosted by agile",
        "start": 163.98,
        "duration": 7.32
    },
    {
        "text": "open data storage and create two",
        "start": 167.16,
        "duration": 6.69
    },
    {
        "text": "datasets from the files in the blob",
        "start": 171.3,
        "duration": 5.19
    },
    {
        "text": "container one thing to note here is that",
        "start": 173.85,
        "duration": 5.88
    },
    {
        "text": "by creating these datasets you we are",
        "start": 176.49,
        "duration": 6.03
    },
    {
        "text": "not creating an extra data copy which",
        "start": 179.73,
        "duration": 4.74
    },
    {
        "text": "means no extra storage cost will",
        "start": 182.52,
        "duration": 4.01
    },
    {
        "text": "incurred and you will always be able to",
        "start": 184.47,
        "duration": 5.07
    },
    {
        "text": "manage your data in your storage service",
        "start": 186.53,
        "duration": 5.74
    },
    {
        "text": "as a single source of truth the two the",
        "start": 189.54,
        "duration": 4.89
    },
    {
        "text": "two dataset we are creating here is one",
        "start": 192.27,
        "duration": 5.1
    },
    {
        "text": "is for the metadata the other one kovat",
        "start": 194.43,
        "duration": 5.1
    },
    {
        "text": "TS points to all the J's and files",
        "start": 197.37,
        "duration": 5.85
    },
    {
        "text": "hosted in this blob container and this",
        "start": 199.53,
        "duration": 5.67
    },
    {
        "text": "JSON files are basically those research",
        "start": 203.22,
        "duration": 5.76
    },
    {
        "text": "articles about it and by registered",
        "start": 205.2,
        "duration": 6.33
    },
    {
        "text": "these two datasets you will be able to",
        "start": 208.98,
        "duration": 5.43
    },
    {
        "text": "go to your machine learning studios and",
        "start": 211.53,
        "duration": 5.72
    },
    {
        "text": "find these two datasets being registered",
        "start": 214.41,
        "duration": 9.24
    },
    {
        "text": "with your workspace now we are ready for",
        "start": 217.25,
        "duration": 9.64
    },
    {
        "text": "some data exploration these two paths",
        "start": 223.65,
        "duration": 5.97
    },
    {
        "text": "methods will list all the files being",
        "start": 226.89,
        "duration": 7.46
    },
    {
        "text": "referenced by this kovat TS data set",
        "start": 229.62,
        "duration": 4.73
    },
    {
        "text": "so these are order JSON files that's",
        "start": 243.739,
        "duration": 6.34
    },
    {
        "text": "been referenced by Cobie ideas and then",
        "start": 246.719,
        "duration": 5.85
    },
    {
        "text": "we will mount the data set onto our",
        "start": 250.079,
        "duration": 7.65
    },
    {
        "text": "compute instance after mounting the data",
        "start": 252.569,
        "duration": 7.98
    },
    {
        "text": "set you you will then be able to read",
        "start": 257.729,
        "duration": 6.151
    },
    {
        "text": "the files like a local path and here we",
        "start": 260.549,
        "duration": 7.611
    },
    {
        "text": "will read one random JSON from this Oh",
        "start": 263.88,
        "duration": 11.43
    },
    {
        "text": "disco VDS to print first row you'll be",
        "start": 268.16,
        "duration": 9.87
    },
    {
        "text": "able to see",
        "start": 275.31,
        "duration": 2.72
    },
    {
        "text": "you will be able to see the content of",
        "start": 295.19,
        "duration": 7.33
    },
    {
        "text": "the article now we are ready for dinner",
        "start": 297.93,
        "duration": 7.5
    },
    {
        "text": "preparation so here we will first define",
        "start": 302.52,
        "duration": 5.67
    },
    {
        "text": "which is the computer target I want to",
        "start": 305.43,
        "duration": 5.88
    },
    {
        "text": "run my experiments on and then here is",
        "start": 308.19,
        "duration": 7.05
    },
    {
        "text": "my script which basically to pass those",
        "start": 311.31,
        "duration": 7.11
    },
    {
        "text": "Jason's and process the sentence and",
        "start": 315.24,
        "duration": 6.02
    },
    {
        "text": "writes the outputs into data frame and",
        "start": 318.42,
        "duration": 6.05
    },
    {
        "text": "here I'm defining the output data as",
        "start": 321.26,
        "duration": 8.17
    },
    {
        "text": "prepared data and our setup my",
        "start": 324.47,
        "duration": 6.94
    },
    {
        "text": "environment install the necessary",
        "start": 329.43,
        "duration": 5.61
    },
    {
        "text": "packages and now I'm ready to configure",
        "start": 331.41,
        "duration": 6.84
    },
    {
        "text": "my parallel run here are a few things to",
        "start": 335.04,
        "duration": 5.16
    },
    {
        "text": "note this mini batch size basically",
        "start": 338.25,
        "duration": 5.79
    },
    {
        "text": "means there will be my each of my node",
        "start": 340.2,
        "duration": 6.24
    },
    {
        "text": "will process a hundred files each time",
        "start": 344.04,
        "duration": 6.87
    },
    {
        "text": "and for the outputs at the end of the",
        "start": 346.44,
        "duration": 6.51
    },
    {
        "text": "distributed data preparation we will",
        "start": 350.91,
        "duration": 5.76
    },
    {
        "text": "append the result from each node into a",
        "start": 352.95,
        "duration": 6.51
    },
    {
        "text": "big data frame and I'm doing my",
        "start": 356.67,
        "duration": 5.61
    },
    {
        "text": "distributed data preparation across five",
        "start": 359.46,
        "duration": 7.41
    },
    {
        "text": "nodes and then here I'm ready to",
        "start": 362.28,
        "duration": 7.2
    },
    {
        "text": "authorize my pipeline so parallel run",
        "start": 366.87,
        "duration": 5.58
    },
    {
        "text": "step using the parallel run config that",
        "start": 369.48,
        "duration": 5.63
    },
    {
        "text": "we just defined in the previous step and",
        "start": 372.45,
        "duration": 7.76
    },
    {
        "text": "using this code VDS as the inputs",
        "start": 375.11,
        "duration": 5.1
    },
    {
        "text": "that's all I'm ready to submit the",
        "start": 382.04,
        "duration": 8.77
    },
    {
        "text": "experiments for the sake of time we will",
        "start": 384.69,
        "duration": 8.01
    },
    {
        "text": "not wait for the pipeline to finish",
        "start": 390.81,
        "duration": 4.25
    },
    {
        "text": "running so this is the output from my",
        "start": 392.7,
        "duration": 4.92
    },
    {
        "text": "previous room which successfully",
        "start": 395.06,
        "duration": 6.34
    },
    {
        "text": "finished and I can also explore the",
        "start": 397.62,
        "duration": 7.11
    },
    {
        "text": "output from the pipeline result pipeline",
        "start": 401.4,
        "duration": 8.7
    },
    {
        "text": "run and here is printout of how the",
        "start": 404.73,
        "duration": 8.76
    },
    {
        "text": "propelled data looks like so we prepare",
        "start": 410.1,
        "duration": 6.17
    },
    {
        "text": "we have parsed the JSON files and",
        "start": 413.49,
        "duration": 5.88
    },
    {
        "text": "process those sentence and into a big",
        "start": 416.27,
        "duration": 5.86
    },
    {
        "text": "data frames that's ready for reports",
        "start": 419.37,
        "duration": 5.13
    },
    {
        "text": "exploratory data analysis or NLP",
        "start": 422.13,
        "duration": 2.79
    },
    {
        "text": "training",
        "start": 424.5,
        "duration": 3.27
    },
    {
        "text": "in order to answer those codes",
        "start": 424.92,
        "duration": 4.619
    },
    {
        "text": "questions from this literature review",
        "start": 427.77,
        "duration": 4.14
    },
    {
        "text": "with that let's switch back to our",
        "start": 429.539,
        "duration": 12.81
    },
    {
        "text": "slides so you can download the demo",
        "start": 431.91,
        "duration": 14.099
    },
    {
        "text": "notebook at AKMs slash build - data set",
        "start": 442.349,
        "duration": 7.5
    },
    {
        "text": "and here are some reference links where",
        "start": 446.009,
        "duration": 5.791
    },
    {
        "text": "to help you get started with Azure",
        "start": 449.849,
        "duration": 6.121
    },
    {
        "text": "machine learning or give feedbacks with",
        "start": 451.8,
        "duration": 6.51
    },
    {
        "text": "that I will end this session thank you",
        "start": 455.97,
        "duration": 5.96
    },
    {
        "text": "or thank you all for your attention",
        "start": 458.31,
        "duration": 12.639
    },
    {
        "text": "[Music]",
        "start": 461.93,
        "duration": 9.019
    }
]