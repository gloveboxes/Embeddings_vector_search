[
    {
        "text": ">> All right. Why am I starting with all, right?",
        "start": 0.0,
        "duration": 2.3
    },
    {
        "text": "It sounds weird. I mean but it is all right.",
        "start": 2.3,
        "duration": 3.325
    },
    {
        "text": "It's all right.",
        "start": 5.625,
        "duration": 5.705
    },
    {
        "text": "Welcome to this episode of the AI Show",
        "start": 11.33,
        "duration": 2.56
    },
    {
        "text": "where we're going to be looking at",
        "start": 13.89,
        "duration": 1.61
    },
    {
        "text": "the entire AI process using animal services,",
        "start": 15.5,
        "duration": 3.09
    },
    {
        "text": "here with Parashar Sha, did I say it right?",
        "start": 18.59,
        "duration": 2.35
    },
    {
        "text": ">> Fantastic. How are you doing, my friend?",
        "start": 20.94,
        "duration": 1.63
    },
    {
        "text": ">> I'm doing great. How are you?",
        "start": 22.57,
        "duration": 1.09
    },
    {
        "text": ">> Good. Why don't you tell us",
        "start": 23.66,
        "duration": 1.02
    },
    {
        "text": "a little overview what were you talking about?",
        "start": 24.68,
        "duration": 1.575
    },
    {
        "text": ">> Okay, sure. So today,",
        "start": 26.255,
        "duration": 1.865
    },
    {
        "text": "I'm going to talk about",
        "start": 28.12,
        "duration": 1.745
    },
    {
        "text": "the Azure Machine Learning Services,",
        "start": 29.865,
        "duration": 2.015
    },
    {
        "text": "which are currently in public preview,",
        "start": 31.88,
        "duration": 1.97
    },
    {
        "text": "and we're going to walk to",
        "start": 33.85,
        "duration": 1.78
    },
    {
        "text": "an entire experiment where we are going to predict",
        "start": 35.63,
        "duration": 2.47
    },
    {
        "text": "the income of a particular person",
        "start": 38.1,
        "duration": 2.52
    },
    {
        "text": "where you provide inputs based",
        "start": 40.62,
        "duration": 2.04
    },
    {
        "text": "on the US government census data.",
        "start": 42.66,
        "duration": 1.8
    },
    {
        "text": "We are going to use a",
        "start": 44.46,
        "duration": 1.34
    },
    {
        "text": "classical machine learning approach,",
        "start": 45.8,
        "duration": 1.625
    },
    {
        "text": "but the idea is to showcase that how far",
        "start": 47.425,
        "duration": 3.365
    },
    {
        "text": "for that Azure Machine Learning Services",
        "start": 50.79,
        "duration": 1.7
    },
    {
        "text": "are and what you do with it.",
        "start": 52.49,
        "duration": 1.64
    },
    {
        "text": ">> This has a soup to nuts.",
        "start": 54.13,
        "duration": 3.47
    },
    {
        "text": "Has a soup to nuts from beginning to end, all of our MLs,",
        "start": 63.26,
        "duration": 5.89
    },
    {
        "text": "our Azure ML services,",
        "start": 69.15,
        "duration": 1.49
    },
    {
        "text": "how you use them, why you would",
        "start": 70.64,
        "duration": 1.42
    },
    {
        "text": "use them, and what we can provide.",
        "start": 72.06,
        "duration": 1.34
    },
    {
        "text": ">> Perfect.",
        "start": 73.4,
        "duration": 0.555
    },
    {
        "text": ">> Fantastic. All right. Let's see what we got.",
        "start": 73.955,
        "duration": 1.45
    },
    {
        "text": ">> Okay. So let's start with",
        "start": 75.405,
        "duration": 2.275
    },
    {
        "text": "the Microsoft AI platform basically.",
        "start": 77.68,
        "duration": 2.84
    },
    {
        "text": "So the Microsoft the platform,",
        "start": 80.52,
        "duration": 2.82
    },
    {
        "text": "if I can say there are three particular components to it.",
        "start": 83.34,
        "duration": 3.865
    },
    {
        "text": "One is the AI services,",
        "start": 87.205,
        "duration": 1.55
    },
    {
        "text": "now there is the AI infrastructure,",
        "start": 88.755,
        "duration": 1.785
    },
    {
        "text": "and the third part is the AI tools.",
        "start": 90.54,
        "duration": 1.745
    },
    {
        "text": "Now, we have tried to see",
        "start": 92.285,
        "duration": 1.685
    },
    {
        "text": "different needs from different customers.",
        "start": 93.97,
        "duration": 3.535
    },
    {
        "text": "Everything can be satisfied.",
        "start": 97.505,
        "duration": 1.22
    },
    {
        "text": "So the AI services allow you to use",
        "start": 98.725,
        "duration": 3.165
    },
    {
        "text": "our pass based services be it in terms of",
        "start": 101.89,
        "duration": 2.42
    },
    {
        "text": "the cognitive services the API slight cost of vision,",
        "start": 104.31,
        "duration": 3.125
    },
    {
        "text": "speech, and things like that,",
        "start": 107.435,
        "duration": 1.545
    },
    {
        "text": "or if you are to create bar stand,",
        "start": 108.98,
        "duration": 1.91
    },
    {
        "text": "then you can use the back framework and things like that.",
        "start": 110.89,
        "duration": 2.235
    },
    {
        "text": "And the third part is the custom machine learning.",
        "start": 113.125,
        "duration": 2.74
    },
    {
        "text": "So a lot of enterprises, our customers,",
        "start": 115.865,
        "duration": 2.25
    },
    {
        "text": "would want to create",
        "start": 118.115,
        "duration": 1.66
    },
    {
        "text": "their own machine model",
        "start": 119.775,
        "duration": 1.795
    },
    {
        "text": "and then deployed in cloud on there.",
        "start": 121.57,
        "duration": 2.415
    },
    {
        "text": "So that's what we",
        "start": 123.985,
        "duration": 1.435
    },
    {
        "text": "call is Azure Machine Learning Services,",
        "start": 125.42,
        "duration": 1.72
    },
    {
        "text": "and that is what I'm going to talk to about today.",
        "start": 127.14,
        "duration": 1.55
    },
    {
        "text": ">> Fantastic. And so we've got a bunch of things",
        "start": 128.69,
        "duration": 2.68
    },
    {
        "text": "that people don't want to",
        "start": 131.37,
        "duration": 1.4
    },
    {
        "text": "build their own and use them services,",
        "start": 132.77,
        "duration": 1.945
    },
    {
        "text": "and they want to do conversational",
        "start": 134.715,
        "duration": 1.245
    },
    {
        "text": "type things about framework.",
        "start": 135.96,
        "duration": 1.53
    },
    {
        "text": "If you could focus on",
        "start": 137.49,
        "duration": 1.82
    },
    {
        "text": "what we're going to be focusing on today,",
        "start": 139.31,
        "duration": 2.18
    },
    {
        "text": "what are the elements of",
        "start": 141.49,
        "duration": 1.77
    },
    {
        "text": "the AI platform that we're going to talking about today?",
        "start": 143.26,
        "duration": 1.61
    },
    {
        "text": ">> Sure. So today,",
        "start": 144.87,
        "duration": 1.625
    },
    {
        "text": "I'm going to walk you through",
        "start": 146.495,
        "duration": 1.505
    },
    {
        "text": "an actual demo where we are building an application.",
        "start": 148.0,
        "duration": 3.17
    },
    {
        "text": "And we are using a remote.",
        "start": 151.17,
        "duration": 1.655
    },
    {
        "text": "Think of it this way.",
        "start": 152.825,
        "duration": 2.815
    },
    {
        "text": "Data scientists, what they normally do is they",
        "start": 155.64,
        "duration": 3.425
    },
    {
        "text": "train on a particular machine",
        "start": 159.065,
        "duration": 1.79
    },
    {
        "text": "and they will start it with a sample data set.",
        "start": 160.855,
        "duration": 2.045
    },
    {
        "text": "They would explore the data,",
        "start": 162.9,
        "duration": 1.285
    },
    {
        "text": "and then they want to scale it out",
        "start": 164.185,
        "duration": 1.67
    },
    {
        "text": "and that's where the power of cloud comes in.",
        "start": 165.855,
        "duration": 2.045
    },
    {
        "text": "Once they are happy with",
        "start": 167.9,
        "duration": 1.35
    },
    {
        "text": "the particular machine model,",
        "start": 169.25,
        "duration": 1.49
    },
    {
        "text": "they actually wanted to deploy.",
        "start": 170.74,
        "duration": 1.275
    },
    {
        "text": "And that will be another thing. So this",
        "start": 172.015,
        "duration": 2.535
    },
    {
        "text": "will be the actual process I'll walk you through,",
        "start": 174.55,
        "duration": 2.0
    },
    {
        "text": "that you start training on your local machine,",
        "start": 176.55,
        "duration": 5.005
    },
    {
        "text": "then actually scale it out using",
        "start": 181.555,
        "duration": 2.175
    },
    {
        "text": "a data sense virtual machine which has a GPU.",
        "start": 183.73,
        "duration": 2.735
    },
    {
        "text": "And then once you're happy with the model,",
        "start": 186.465,
        "duration": 2.115
    },
    {
        "text": "then you'd deploy it in the cloud in a cluster.",
        "start": 188.58,
        "duration": 2.255
    },
    {
        "text": ">> I see, does this includes services for,",
        "start": 190.835,
        "duration": 2.84
    },
    {
        "text": "not only just like deploying and having out of the cloud,",
        "start": 193.675,
        "duration": 2.675
    },
    {
        "text": "but also for training and",
        "start": 196.35,
        "duration": 1.33
    },
    {
        "text": "for how to actually run the entire experiment.",
        "start": 197.68,
        "duration": 2.05
    },
    {
        "text": ">> That's right. And the good thing is",
        "start": 199.73,
        "duration": 1.78
    },
    {
        "text": "you'll be only based on your usage,",
        "start": 201.51,
        "duration": 2.07
    },
    {
        "text": "so the pricing would be similar to what you",
        "start": 203.58,
        "duration": 2.63
    },
    {
        "text": "would pay for spinning up a regular virtual machine.",
        "start": 206.21,
        "duration": 3.005
    },
    {
        "text": ">> Awesome. So show us how it started.",
        "start": 209.215,
        "duration": 2.045
    },
    {
        "text": ">> Perfect. So let's look at",
        "start": 211.26,
        "duration": 2.78
    },
    {
        "text": "the AI development life cycle",
        "start": 214.04,
        "duration": 2.09
    },
    {
        "text": "and where does Azure Machine Learning Services.",
        "start": 216.13,
        "duration": 1.78
    },
    {
        "text": "So anytime you want",
        "start": 217.91,
        "duration": 2.21
    },
    {
        "text": "to create a machinery based application,",
        "start": 220.12,
        "duration": 2.48
    },
    {
        "text": "you would have your data somewhere.",
        "start": 222.6,
        "duration": 1.605
    },
    {
        "text": "Now either that data is coming in",
        "start": 224.205,
        "duration": 1.675
    },
    {
        "text": "real time or it has been stored somewhere.",
        "start": 225.88,
        "duration": 2.37
    },
    {
        "text": "So once you have that data,",
        "start": 228.25,
        "duration": 1.63
    },
    {
        "text": "you want to actually start creating features out",
        "start": 229.88,
        "duration": 3.28
    },
    {
        "text": "of it because that's what",
        "start": 233.16,
        "duration": 1.96
    },
    {
        "text": "is needed for machine learning experiments.",
        "start": 235.12,
        "duration": 1.745
    },
    {
        "text": "So that is what we call a data preparation part of it.",
        "start": 236.865,
        "duration": 3.73
    },
    {
        "text": "And then once you have created those features,",
        "start": 240.595,
        "duration": 3.01
    },
    {
        "text": "you want to train",
        "start": 243.605,
        "duration": 1.57
    },
    {
        "text": "a machine learning model on top of that.",
        "start": 245.175,
        "duration": 2.4
    },
    {
        "text": "So that's the prep and clean part",
        "start": 247.575,
        "duration": 3.36
    },
    {
        "text": "and you can use different compute,",
        "start": 250.935,
        "duration": 2.33
    },
    {
        "text": "different storage options in this.",
        "start": 253.265,
        "duration": 2.05
    },
    {
        "text": "And then once you're happy with that,",
        "start": 255.315,
        "duration": 1.575
    },
    {
        "text": "you actually create the model and you use it for so.",
        "start": 256.89,
        "duration": 2.495
    },
    {
        "text": "So that is the area where",
        "start": 259.385,
        "duration": 1.67
    },
    {
        "text": "Azure machine and new services fits in.",
        "start": 261.055,
        "duration": 2.73
    },
    {
        "text": "And let's look at the capabilities which are now there.",
        "start": 263.785,
        "duration": 4.0
    },
    {
        "text": "So we already have an Azure Machine Learning studio.",
        "start": 267.785,
        "duration": 4.995
    },
    {
        "text": "As you know, it's been there from 2014.",
        "start": 272.78,
        "duration": 1.905
    },
    {
        "text": "And then we got feedback",
        "start": 274.685,
        "duration": 1.505
    },
    {
        "text": "from the customers that we want more,",
        "start": 276.19,
        "duration": 1.455
    },
    {
        "text": "\"We want to use different computer options.",
        "start": 277.645,
        "duration": 3.545
    },
    {
        "text": "We want to use different frameworks.\"",
        "start": 281.19,
        "duration": 1.49
    },
    {
        "text": "And that's where we launched our new capabilities",
        "start": 282.68,
        "duration": 2.12
    },
    {
        "text": "in September during our Ignite event.",
        "start": 284.8,
        "duration": 2.43
    },
    {
        "text": "So now, what we allow users",
        "start": 287.23,
        "duration": 2.39
    },
    {
        "text": "is whatever IDE you are using,",
        "start": 289.62,
        "duration": 3.155
    },
    {
        "text": "whatever framework you are using, you can use that,",
        "start": 292.775,
        "duration": 3.07
    },
    {
        "text": "you can trim your model,",
        "start": 295.845,
        "duration": 1.64
    },
    {
        "text": "and then once you're ready,",
        "start": 297.485,
        "duration": 1.285
    },
    {
        "text": "you can deploy it, be it in the cloud.",
        "start": 298.77,
        "duration": 2.445
    },
    {
        "text": "You can even deploy it on Prime",
        "start": 301.215,
        "duration": 1.555
    },
    {
        "text": "or you can even deploy it on IoT Edge.",
        "start": 302.77,
        "duration": 2.03
    },
    {
        "text": ">> So there's just a lot more options",
        "start": 304.8,
        "duration": 2.6
    },
    {
        "text": "on what you want to do, we can help you with that.",
        "start": 307.4,
        "duration": 2.26
    },
    {
        "text": ">> That's right, a lot of flexibility.",
        "start": 309.66,
        "duration": 1.86
    },
    {
        "text": "So now, in the demo,",
        "start": 311.52,
        "duration": 3.405
    },
    {
        "text": "what I'm going to walk you through is",
        "start": 314.925,
        "duration": 1.945
    },
    {
        "text": "this entire process of how you would actually",
        "start": 316.87,
        "duration": 3.525
    },
    {
        "text": "use a Jupiter notebook and then deploy",
        "start": 320.395,
        "duration": 3.65
    },
    {
        "text": "training using all these like I said",
        "start": 324.045,
        "duration": 2.115
    },
    {
        "text": "and then deploy it in the cloud.",
        "start": 326.16,
        "duration": 2.26
    },
    {
        "text": ">> So let us start from the very beginning.",
        "start": 328.42,
        "duration": 1.96
    },
    {
        "text": "Let's just say first time",
        "start": 330.38,
        "duration": 1.685
    },
    {
        "text": "I'm looking at Azure ML and I want to start with this,",
        "start": 332.065,
        "duration": 2.14
    },
    {
        "text": "how do you get that service started?",
        "start": 334.205,
        "duration": 1.78
    },
    {
        "text": ">> Sure. So for the set up part,",
        "start": 335.985,
        "duration": 2.135
    },
    {
        "text": "we have any user would",
        "start": 338.12,
        "duration": 1.97
    },
    {
        "text": "need at least three things to start.",
        "start": 340.09,
        "duration": 2.375
    },
    {
        "text": "One is an experimentation account.",
        "start": 342.465,
        "duration": 2.59
    },
    {
        "text": "Now, this experimentation account is actually maintaining",
        "start": 345.055,
        "duration": 3.335
    },
    {
        "text": "all your RAM histories because",
        "start": 348.39,
        "duration": 1.795
    },
    {
        "text": "that is how normal data scientists would go after.",
        "start": 350.185,
        "duration": 2.005
    },
    {
        "text": "He would do might to put it on some to figure it out.",
        "start": 352.19,
        "duration": 1.925
    },
    {
        "text": "So we moved in that history.",
        "start": 354.115,
        "duration": 1.635
    },
    {
        "text": "So anytime you wanted to go back",
        "start": 355.75,
        "duration": 1.645
    },
    {
        "text": "in time and look at something, you can do that.",
        "start": 357.395,
        "duration": 1.835
    },
    {
        "text": "Now, that thing is also batching",
        "start": 359.23,
        "duration": 1.66
    },
    {
        "text": "different remote compute targets.",
        "start": 360.89,
        "duration": 1.755
    },
    {
        "text": "So you could use, like I said,",
        "start": 362.645,
        "duration": 2.305
    },
    {
        "text": "single vertical machine, like Data Science VM",
        "start": 364.95,
        "duration": 2.41
    },
    {
        "text": "or you could even scale it out with spark-based.",
        "start": 367.36,
        "duration": 2.52
    },
    {
        "text": "So actually, you need some spark or something.",
        "start": 369.88,
        "duration": 2.205
    },
    {
        "text": "The other part is the model management part.",
        "start": 372.085,
        "duration": 2.475
    },
    {
        "text": "So once you had the model,",
        "start": 374.56,
        "duration": 1.54
    },
    {
        "text": "you can actually deploy it,",
        "start": 376.1,
        "duration": 1.955
    },
    {
        "text": "and that is the model management part.",
        "start": 378.055,
        "duration": 2.665
    },
    {
        "text": "So you have to create these two,",
        "start": 380.72,
        "duration": 1.625
    },
    {
        "text": "if you could use the portal or you could use the CLI.",
        "start": 382.345,
        "duration": 2.71
    },
    {
        "text": "And the third thing you would need is to install an ID.",
        "start": 385.055,
        "duration": 3.835
    },
    {
        "text": "Now, the ID part is optional, whatever,",
        "start": 388.89,
        "duration": 2.16
    },
    {
        "text": "I am going to show you, because you couldn't",
        "start": 391.05,
        "duration": 1.83
    },
    {
        "text": "use your ID and still use these two.",
        "start": 392.88,
        "duration": 2.325
    },
    {
        "text": ">> Alright. Visuals to your code has tools for AI.",
        "start": 395.205,
        "duration": 2.275
    },
    {
        "text": ">> That's right. That's what we have.",
        "start": 397.48,
        "duration": 1.825
    },
    {
        "text": "So let's go to the portal right now.",
        "start": 399.305,
        "duration": 2.915
    },
    {
        "text": "And I already have a screen loaded, but essentially,",
        "start": 402.22,
        "duration": 2.9
    },
    {
        "text": "the way you would do it is just do",
        "start": 405.12,
        "duration": 1.6
    },
    {
        "text": "what it creates resource,",
        "start": 406.72,
        "duration": 2.505
    },
    {
        "text": "then select the AI plus Cognitive Services.",
        "start": 409.225,
        "duration": 2.835
    },
    {
        "text": "Once you are in there, you can see on the top you",
        "start": 412.06,
        "duration": 1.91
    },
    {
        "text": "have experimentation service online on management.",
        "start": 413.97,
        "duration": 2.255
    },
    {
        "text": "Now, this is normally a one time thing,",
        "start": 416.225,
        "duration": 2.555
    },
    {
        "text": "so it's not that a data scientist would need to do that.",
        "start": 418.78,
        "duration": 3.84
    },
    {
        "text": "So it could be like account admin",
        "start": 422.62,
        "duration": 2.155
    },
    {
        "text": "would set it up once and then,",
        "start": 424.775,
        "duration": 1.29
    },
    {
        "text": "it would be shared by multiple data service.",
        "start": 426.065,
        "duration": 1.93
    },
    {
        "text": ">> And the reason why you would have",
        "start": 427.995,
        "duration": 1.315
    },
    {
        "text": "an experimentation service is for example,",
        "start": 429.31,
        "duration": 2.515
    },
    {
        "text": "let's just say you're trying",
        "start": 431.825,
        "duration": 2.745
    },
    {
        "text": "to figure out hyperparameters for a particular model.",
        "start": 434.57,
        "duration": 2.19
    },
    {
        "text": "If you use the experimentation service right,",
        "start": 436.76,
        "duration": 1.945
    },
    {
        "text": "you'd actually be able to see the history of what you've",
        "start": 438.705,
        "duration": 2.305
    },
    {
        "text": "already tried sort of Sally, data scientist,",
        "start": 441.01,
        "duration": 2.27
    },
    {
        "text": "comes in, she won't be trying what",
        "start": 443.28,
        "duration": 1.805
    },
    {
        "text": "Bob did a year ago and it didn't work,",
        "start": 445.085,
        "duration": 2.025
    },
    {
        "text": "and it's just a way of keeping track",
        "start": 447.11,
        "duration": 1.45
    },
    {
        "text": "of the work that has happened with the modeling.",
        "start": 448.56,
        "duration": 2.335
    },
    {
        "text": ">> That's right.",
        "start": 450.895,
        "duration": 0.685
    },
    {
        "text": ">> That's fantastic. It's the way you",
        "start": 451.58,
        "duration": 1.77
    },
    {
        "text": "set it up just like any anything else on it.",
        "start": 453.35,
        "duration": 1.68
    },
    {
        "text": ">> That's right. Yeah. You just provide the name,",
        "start": 455.03,
        "duration": 2.595
    },
    {
        "text": "select the subscription, the",
        "start": 457.625,
        "duration": 1.595
    },
    {
        "text": "resource group and how many seats you have.",
        "start": 459.22,
        "duration": 2.22
    },
    {
        "text": "So the first two seats are free, but if you want more,",
        "start": 461.44,
        "duration": 2.43
    },
    {
        "text": "then you have to pay based on the contract you had.",
        "start": 463.87,
        "duration": 3.215
    },
    {
        "text": "And then when you created the experimentation service,",
        "start": 467.085,
        "duration": 3.265
    },
    {
        "text": "we give you the option to create",
        "start": 470.35,
        "duration": 1.37
    },
    {
        "text": "the modern management to have an account right away.",
        "start": 471.72,
        "duration": 2.345
    },
    {
        "text": "So you don't have to go to a separate.",
        "start": 474.065,
        "duration": 1.41
    },
    {
        "text": ">> And you get the model management is to store",
        "start": 475.475,
        "duration": 2.425
    },
    {
        "text": "the actual output of",
        "start": 477.9,
        "duration": 1.16
    },
    {
        "text": "the training, which is the actual model.",
        "start": 479.06,
        "duration": 1.49
    },
    {
        "text": "Let's just say it's the weights of a deep learning model",
        "start": 480.55,
        "duration": 2.14
    },
    {
        "text": "or the decision tree or whatever,",
        "start": 482.69,
        "duration": 2.84
    },
    {
        "text": "as you say you're using something else.",
        "start": 485.53,
        "duration": 1.78
    },
    {
        "text": "It's just the numbers that you can do inferencing with.",
        "start": 487.31,
        "duration": 2.99
    },
    {
        "text": ">> That's right.",
        "start": 490.3,
        "duration": 0.56
    },
    {
        "text": ">> Okay.",
        "start": 490.86,
        "duration": 0.22
    },
    {
        "text": ">> So that's the particle HTTP API,",
        "start": 491.08,
        "duration": 2.53
    },
    {
        "text": "which you can invoke in",
        "start": 493.61,
        "duration": 1.66
    },
    {
        "text": "an application and whatever you want.",
        "start": 495.27,
        "duration": 1.64
    },
    {
        "text": ">> I see some experimentation is for when",
        "start": 496.91,
        "duration": 1.91
    },
    {
        "text": "you're trying to figure out the best model.",
        "start": 498.82,
        "duration": 2.16
    },
    {
        "text": "Model management is for when you have",
        "start": 500.98,
        "duration": 1.755
    },
    {
        "text": "a model or maybe multiple models and",
        "start": 502.735,
        "duration": 2.22
    },
    {
        "text": "that model gets better because the data gets out date or",
        "start": 504.955,
        "duration": 2.515
    },
    {
        "text": "stay a model and you",
        "start": 507.47,
        "duration": 1.26
    },
    {
        "text": "can just use the model measure for that.",
        "start": 508.73,
        "duration": 1.325
    },
    {
        "text": ">> Yes, and track everything they come in and",
        "start": 510.055,
        "duration": 2.125
    },
    {
        "text": "requests are coming home and",
        "start": 512.18,
        "duration": 1.03
    },
    {
        "text": "the responses you are getting at least.",
        "start": 513.21,
        "duration": 1.31
    },
    {
        "text": ">> Awesome. And the third thing you mentioned was",
        "start": 514.52,
        "duration": 2.02
    },
    {
        "text": "the actual infrastructure where",
        "start": 516.54,
        "duration": 1.45
    },
    {
        "text": "you run the experimentation,",
        "start": 517.99,
        "duration": 1.355
    },
    {
        "text": "which is let's just say you don't have",
        "start": 519.345,
        "duration": 1.775
    },
    {
        "text": "a huge GPU or you want to",
        "start": 521.12,
        "duration": 1.67
    },
    {
        "text": "be able to have a lot of RAM, for example.",
        "start": 522.79,
        "duration": 1.99
    },
    {
        "text": "So that's when you would use like",
        "start": 524.78,
        "duration": 1.73
    },
    {
        "text": "a Data Science VM to run that stuff.",
        "start": 526.51,
        "duration": 2.03
    },
    {
        "text": ">> That's right. And probably,",
        "start": 528.54,
        "duration": 1.57
    },
    {
        "text": "I can show it to you right now.",
        "start": 530.11,
        "duration": 1.88
    },
    {
        "text": "You just",
        "start": 531.99,
        "duration": 4.43
    },
    {
        "text": "select the size.",
        "start": 536.42,
        "duration": 8.54
    },
    {
        "text": "I do multiple options.",
        "start": 544.96,
        "duration": 1.145
    },
    {
        "text": "In this case, you can pick up the Linux.",
        "start": 546.105,
        "duration": 1.765
    },
    {
        "text": "It comes screen starting with",
        "start": 547.87,
        "duration": 1.1
    },
    {
        "text": "all the frameworks and libraries.",
        "start": 548.97,
        "duration": 1.725
    },
    {
        "text": "And then you charge based",
        "start": 550.695,
        "duration": 1.365
    },
    {
        "text": "on the type of computer you select.",
        "start": 552.06,
        "duration": 1.51
    },
    {
        "text": "So you can associate a GPU or CPU [inaudible].",
        "start": 553.57,
        "duration": 2.31
    },
    {
        "text": ">> So this, the purpose of",
        "start": 555.88,
        "duration": 1.88
    },
    {
        "text": "the Data Science VM is because, I don't know about you,",
        "start": 557.76,
        "duration": 3.04
    },
    {
        "text": "but when I set up my environment",
        "start": 560.8,
        "duration": 2.53
    },
    {
        "text": "for doing Machine Learning",
        "start": 563.33,
        "duration": 1.4
    },
    {
        "text": "or Data Science the first time,",
        "start": 564.73,
        "duration": 1.36
    },
    {
        "text": "I'm looking at selling a ton of things.",
        "start": 566.09,
        "duration": 2.34
    },
    {
        "text": "And then like if I forget what I",
        "start": 568.43,
        "duration": 2.23
    },
    {
        "text": "install and on the target machine,",
        "start": 570.66,
        "duration": 1.9
    },
    {
        "text": "it's suing the inferencing, it's not there.",
        "start": 572.56,
        "duration": 1.95
    },
    {
        "text": "I guess what this creates",
        "start": 574.51,
        "duration": 1.545
    },
    {
        "text": "a standard environment",
        "start": 576.055,
        "duration": 1.145
    },
    {
        "text": "where everything can happen.",
        "start": 577.2,
        "duration": 1.175
    },
    {
        "text": ">> That's right. And we have tested all the",
        "start": 578.375,
        "duration": 1.44
    },
    {
        "text": "interoperably of the libraries",
        "start": 579.815,
        "duration": 2.235
    },
    {
        "text": "they're made it easy for you.",
        "start": 582.05,
        "duration": 1.26
    },
    {
        "text": ">> Fantastic. So that's the set up.",
        "start": 583.31,
        "duration": 2.03
    },
    {
        "text": "Is there anything else you need",
        "start": 585.34,
        "duration": 1.03
    },
    {
        "text": "to do to get everything going?",
        "start": 586.37,
        "duration": 1.02
    },
    {
        "text": ">> No, not for this except that, like I said,",
        "start": 587.39,
        "duration": 3.105
    },
    {
        "text": "you could use your own ID or you could install of an ID,",
        "start": 590.495,
        "duration": 3.37
    },
    {
        "text": "which comes with Azure Machine Learning operation.",
        "start": 593.865,
        "duration": 1.655
    },
    {
        "text": ">> Fantastic. So this again is",
        "start": 595.52,
        "duration": 1.86
    },
    {
        "text": "just a really quick overview",
        "start": 597.38,
        "duration": 1.95
    },
    {
        "text": "of what you do in the Data Science process.",
        "start": 599.33,
        "duration": 2.63
    },
    {
        "text": "How we can help with services,",
        "start": 601.96,
        "duration": 1.32
    },
    {
        "text": "we talked about three experimentation: Model,",
        "start": 603.28,
        "duration": 2.24
    },
    {
        "text": "Management, and DSVMs, Data Science VMs,",
        "start": 605.52,
        "duration": 2.54
    },
    {
        "text": "if you want to set those up.",
        "start": 608.06,
        "duration": 1.595
    },
    {
        "text": "Honestly, I don't know how you",
        "start": 609.655,
        "duration": 2.2
    },
    {
        "text": "couldn't use something like",
        "start": 611.855,
        "duration": 1.925
    },
    {
        "text": "an experimentation service and",
        "start": 613.78,
        "duration": 1.49
    },
    {
        "text": "have models that come out better every time,",
        "start": 615.27,
        "duration": 2.375
    },
    {
        "text": "like if there's no way to do that,",
        "start": 617.645,
        "duration": 1.655
    },
    {
        "text": "and I love the idea of actually",
        "start": 619.3,
        "duration": 1.62
    },
    {
        "text": "keeping track of all of the models that you have",
        "start": 620.92,
        "duration": 2.47
    },
    {
        "text": "and making sure that if a model goes",
        "start": 623.39,
        "duration": 2.85
    },
    {
        "text": "stale that you put another one up",
        "start": 626.24,
        "duration": 1.37
    },
    {
        "text": "there and then the services sort of catch up.",
        "start": 627.61,
        "duration": 1.675
    },
    {
        "text": "It's awesome. The set up is pretty easy.",
        "start": 629.285,
        "duration": 1.97
    },
    {
        "text": ">> Yes.",
        "start": 631.255,
        "duration": 0.57
    },
    {
        "text": ">> It's awesome. So in the next",
        "start": 631.825,
        "duration": 1.255
    },
    {
        "text": "in the next installment of this,",
        "start": 633.08,
        "duration": 1.34
    },
    {
        "text": "we're going to be talking about once",
        "start": 634.42,
        "duration": 1.84
    },
    {
        "text": "you have all that set up,",
        "start": 636.26,
        "duration": 1.175
    },
    {
        "text": "what do you actually do? Does that work?",
        "start": 637.435,
        "duration": 1.41
    },
    {
        "text": ">> Yes.",
        "start": 638.845,
        "duration": 0.445
    },
    {
        "text": ">> All right. We'll see you then.",
        "start": 639.29,
        "duration": 2.27
    },
    {
        "text": ">> Yeah.",
        "start": 641.56,
        "duration": 2.14
    }
]