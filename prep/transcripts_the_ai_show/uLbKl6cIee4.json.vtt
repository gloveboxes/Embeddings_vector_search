[
    {
        "text": ">> You're not going to want to miss this episode of the AI Show.",
        "start": 0.0,
        "duration": 2.79
    },
    {
        "text": "We talk about AML Compute,",
        "start": 2.79,
        "duration": 2.58
    },
    {
        "text": "how to save money,",
        "start": 5.37,
        "duration": 1.215
    },
    {
        "text": "how to have good enterprise features,",
        "start": 6.585,
        "duration": 1.86
    },
    {
        "text": "how to be a data scientists without being an IT pro,",
        "start": 8.445,
        "duration": 2.76
    },
    {
        "text": "all of this and more in the next episode. Make sure you tune it.",
        "start": 11.205,
        "duration": 2.865
    },
    {
        "text": "[MUSIC]",
        "start": 14.07,
        "duration": 4.35
    },
    {
        "text": ">> Hello and welcome to this episode of the AI show.",
        "start": 18.42,
        "duration": 2.01
    },
    {
        "text": "I've got a special guest.",
        "start": 20.43,
        "duration": 1.18
    },
    {
        "text": "Shank, why don't you introduce yourself?",
        "start": 21.61,
        "duration": 1.355
    },
    {
        "text": ">> Hey, Seth. I am Shank.",
        "start": 22.965,
        "duration": 1.515
    },
    {
        "text": "I work on the Azure Machine Learning Team",
        "start": 24.48,
        "duration": 1.47
    },
    {
        "text": "specifically on Azure Machine Learning Compute.",
        "start": 25.95,
        "duration": 2.04
    },
    {
        "text": ">> Fantastic. So I just want to throw this out there,",
        "start": 27.99,
        "duration": 2.7
    },
    {
        "text": "when it comes to machine learning,",
        "start": 30.69,
        "duration": 1.66
    },
    {
        "text": "it's the compute where all of the actual work happens.",
        "start": 32.35,
        "duration": 3.91
    },
    {
        "text": ">> Yes.",
        "start": 36.26,
        "duration": 0.375
    },
    {
        "text": ">> So I've heard this new term AML Compute.",
        "start": 36.635,
        "duration": 2.245
    },
    {
        "text": "Why don't you describe what it is and why it's so-called?",
        "start": 38.88,
        "duration": 2.015
    },
    {
        "text": ">> Yeah. So AML Compute is",
        "start": 40.895,
        "duration": 1.365
    },
    {
        "text": "the manage compute offering from Azure Machine Learning.",
        "start": 42.26,
        "duration": 2.55
    },
    {
        "text": "The advantage that we wanted to give this was a wrapper over",
        "start": 44.81,
        "duration": 2.85
    },
    {
        "text": "the underlying Azure infrastructure so",
        "start": 47.66,
        "duration": 1.77
    },
    {
        "text": "that you are able to spin up your compute,",
        "start": 49.43,
        "duration": 1.78
    },
    {
        "text": "are able to easily scale up clusters,",
        "start": 51.21,
        "duration": 2.15
    },
    {
        "text": "are able to just send your job,",
        "start": 53.36,
        "duration": 1.83
    },
    {
        "text": "and we take care of the rest which is managing your resources,",
        "start": 55.19,
        "duration": 3.165
    },
    {
        "text": "making sure that all the costs are taken care of,",
        "start": 58.355,
        "duration": 2.545
    },
    {
        "text": "and making sure that all of",
        "start": 60.9,
        "duration": 1.4
    },
    {
        "text": "your logs and metrics are being streamed back,",
        "start": 62.3,
        "duration": 2.39
    },
    {
        "text": "and all of that is just taken care of by AML Compute.",
        "start": 64.69,
        "duration": 2.32
    },
    {
        "text": ">> That's awesome because, basically,",
        "start": 67.01,
        "duration": 2.85
    },
    {
        "text": "there's a VM somewhere running your things?",
        "start": 69.86,
        "duration": 2.16
    },
    {
        "text": ">> Yeah.",
        "start": 72.02,
        "duration": 0.36
    },
    {
        "text": ">> I don't like doing VME kinds of things, right?",
        "start": 72.38,
        "duration": 3.3
    },
    {
        "text": ">> Yeah.",
        "start": 75.68,
        "duration": 0.16
    },
    {
        "text": ">> So when we're talking about AML compute,",
        "start": 75.84,
        "duration": 1.825
    },
    {
        "text": "it's a wrapper around the VMs, is that right?",
        "start": 77.665,
        "duration": 2.38
    },
    {
        "text": ">> Yeah.",
        "start": 80.045,
        "duration": 0.675
    },
    {
        "text": ">> So can I ask a couple questions about that?",
        "start": 80.72,
        "duration": 1.48
    },
    {
        "text": "So what kind of VMs can we wrap around?",
        "start": 82.2,
        "duration": 3.095
    },
    {
        "text": ">> So essentially, we bring you the entire power of Azure Cloud,",
        "start": 85.295,
        "duration": 3.185
    },
    {
        "text": "which means all of the CPUs and GPUs that Azure supports",
        "start": 88.48,
        "duration": 2.665
    },
    {
        "text": "is something that you can use AML Compute cluster out off.",
        "start": 91.145,
        "duration": 3.32
    },
    {
        "text": "In addition, we also allow you to be easily",
        "start": 94.465,
        "duration": 2.605
    },
    {
        "text": "able to get dedicated and low clarity clusters,",
        "start": 97.07,
        "duration": 2.835
    },
    {
        "text": "something that our customers really care about",
        "start": 99.905,
        "duration": 2.155
    },
    {
        "text": "because there are times when their jobs are not high priority,",
        "start": 102.06,
        "duration": 2.375
    },
    {
        "text": "and they are spending up low clarity cluster and saving costs.",
        "start": 104.435,
        "duration": 3.665
    },
    {
        "text": ">> So here's another question.",
        "start": 108.1,
        "duration": 1.7
    },
    {
        "text": "Because when I was hearing this, I was like,",
        "start": 109.8,
        "duration": 2.52
    },
    {
        "text": "\"AML Compute represents a machine,\" but it could",
        "start": 112.32,
        "duration": 2.42
    },
    {
        "text": "also represent a cluster of machines, is that right?",
        "start": 114.74,
        "duration": 2.76
    },
    {
        "text": ">> Yeah. So there are a couple of ways to think about it.",
        "start": 117.5,
        "duration": 3.015
    },
    {
        "text": "If you're looking at a dev test workstation,",
        "start": 120.515,
        "duration": 1.545
    },
    {
        "text": "you use something like compute instance,",
        "start": 122.06,
        "duration": 1.53
    },
    {
        "text": "something that we recently announced with Ignite.",
        "start": 123.59,
        "duration": 1.965
    },
    {
        "text": "Then you could also be looking at",
        "start": 125.555,
        "duration": 1.515
    },
    {
        "text": "a training cluster which automatically scales",
        "start": 127.07,
        "duration": 1.68
    },
    {
        "text": "from one to say 100 nodes",
        "start": 128.75,
        "duration": 1.38
    },
    {
        "text": "and it can do distributed training for you.",
        "start": 130.13,
        "duration": 2.18
    },
    {
        "text": "All that you need to worry about is",
        "start": 132.31,
        "duration": 1.9
    },
    {
        "text": "how your training script is actually going",
        "start": 134.21,
        "duration": 1.35
    },
    {
        "text": "to use something like [inaudible]",
        "start": 135.56,
        "duration": 1.21
    },
    {
        "text": "to actually communicate between the nodes.",
        "start": 136.77,
        "duration": 1.83
    },
    {
        "text": "But then we are essentially going to go create a VM image,",
        "start": 138.6,
        "duration": 3.2
    },
    {
        "text": "we're going to go deploy the container,",
        "start": 141.8,
        "duration": 1.26
    },
    {
        "text": "and it will make sure that all of your data is inside",
        "start": 143.06,
        "duration": 1.83
    },
    {
        "text": "that container and spin off your job,",
        "start": 144.89,
        "duration": 2.315
    },
    {
        "text": "make sure that the communication is set up between those nodes,",
        "start": 147.205,
        "duration": 2.47
    },
    {
        "text": "and get the logs stream back into your Cloud storage.",
        "start": 149.675,
        "duration": 3.44
    },
    {
        "text": ">> So basically, I get to do all the fun things,",
        "start": 153.115,
        "duration": 2.745
    },
    {
        "text": "and you do all the housekeeping?",
        "start": 155.86,
        "duration": 1.665
    },
    {
        "text": ">> Yeah, that's it.",
        "start": 157.525,
        "duration": 0.465
    },
    {
        "text": ">> If I'm only interested in running",
        "start": 157.99,
        "duration": 1.03
    },
    {
        "text": "my Python training straight, right?",
        "start": 159.02,
        "duration": 1.95
    },
    {
        "text": ">> Yeah.",
        "start": 160.97,
        "duration": 0.96
    },
    {
        "text": ">> The other thing that I have a question about is,",
        "start": 161.93,
        "duration": 2.67
    },
    {
        "text": "whenever I'm talking to you about",
        "start": 164.6,
        "duration": 2.115
    },
    {
        "text": "standing up a VM and I'm in an enterprise,",
        "start": 166.715,
        "duration": 2.279
    },
    {
        "text": "there's always going to be someone that is going to be like,",
        "start": 168.994,
        "duration": 2.251
    },
    {
        "text": "\"Wait a minute, you can't just start up a VM.",
        "start": 171.245,
        "duration": 2.91
    },
    {
        "text": "There's some rules.\"",
        "start": 174.155,
        "duration": 1.335
    },
    {
        "text": "What enterprisee-like features do we",
        "start": 175.49,
        "duration": 2.37
    },
    {
        "text": "have that helps with the IT pro side of stuff?",
        "start": 177.86,
        "duration": 3.115
    },
    {
        "text": ">> Yeah. AML Compute has been",
        "start": 180.975,
        "duration": 1.37
    },
    {
        "text": "working towards enterprise readiness,",
        "start": 182.345,
        "duration": 1.515
    },
    {
        "text": "and there are a few things that",
        "start": 183.86,
        "duration": 1.56
    },
    {
        "text": "we know that enterprises really care about.",
        "start": 185.42,
        "duration": 1.665
    },
    {
        "text": "There are things like control,",
        "start": 187.085,
        "duration": 1.68
    },
    {
        "text": "there's a thing like monitoring,",
        "start": 188.765,
        "duration": 1.56
    },
    {
        "text": "and then there's also things that are on",
        "start": 190.325,
        "duration": 1.23
    },
    {
        "text": "security that enterprises are passionate about.",
        "start": 191.555,
        "duration": 2.295
    },
    {
        "text": "Today, I wanted to just show you",
        "start": 193.85,
        "duration": 1.53
    },
    {
        "text": "some of those updates that we've made to",
        "start": 195.38,
        "duration": 1.32
    },
    {
        "text": "the product and see how it resonates with our enterprise.",
        "start": 196.7,
        "duration": 3.51
    },
    {
        "text": ">> All right. Let's take a look.",
        "start": 200.21,
        "duration": 0.86
    },
    {
        "text": ">> Yeah. So yes,",
        "start": 201.07,
        "duration": 1.865
    },
    {
        "text": "here I am on the Azure portal.",
        "start": 202.935,
        "duration": 2.03
    },
    {
        "text": "I have my \"Compute\" tab open.",
        "start": 204.965,
        "duration": 1.59
    },
    {
        "text": "As you can see that I can go create a new compute if I wanted to.",
        "start": 206.555,
        "duration": 3.265
    },
    {
        "text": "Let's go try that.",
        "start": 209.82,
        "duration": 1.205
    },
    {
        "text": "I'm just going to spin up a test cluster.",
        "start": 211.025,
        "duration": 2.69
    },
    {
        "text": "As I do that, it gives me",
        "start": 213.715,
        "duration": 2.365
    },
    {
        "text": "a bunch of options that I can choose from.",
        "start": 216.08,
        "duration": 1.38
    },
    {
        "text": "So in this case, I'm going to go for machine learning compute,",
        "start": 217.46,
        "duration": 2.13
    },
    {
        "text": "which is AML Compute, and you automatically",
        "start": 219.59,
        "duration": 2.13
    },
    {
        "text": "see a bunch of options that you get to choose from.",
        "start": 221.72,
        "duration": 2.625
    },
    {
        "text": "There is a CPU and GPU support that we have.",
        "start": 224.345,
        "duration": 2.655
    },
    {
        "text": "You could choose from any of these.",
        "start": 227.0,
        "duration": 1.545
    },
    {
        "text": "In addition, we also started introducing things like",
        "start": 228.545,
        "duration": 3.365
    },
    {
        "text": "VNets that you can not set up in your cluster itself.",
        "start": 231.91,
        "duration": 3.07
    },
    {
        "text": "That's something that is really interesting for enterprises.",
        "start": 234.98,
        "duration": 2.67
    },
    {
        "text": "In addition, if you wanted to start",
        "start": 237.65,
        "duration": 1.59
    },
    {
        "text": "debugging something on a cluster,",
        "start": 239.24,
        "duration": 1.59
    },
    {
        "text": "you can also set up an SSH account which you can",
        "start": 240.83,
        "duration": 2.04
    },
    {
        "text": "now parse during the provisioning.",
        "start": 242.87,
        "duration": 2.535
    },
    {
        "text": "I, as an admin, has access to this account so",
        "start": 245.405,
        "duration": 2.415
    },
    {
        "text": "I can go into the nodes and actually see what's happening.",
        "start": 247.82,
        "duration": 2.09
    },
    {
        "text": "But as the rest of the data scientist,",
        "start": 249.91,
        "duration": 1.87
    },
    {
        "text": "if I wanted to control them from having SSE access,",
        "start": 251.78,
        "duration": 2.1
    },
    {
        "text": "they don't really have access to this.",
        "start": 253.88,
        "duration": 1.625
    },
    {
        "text": ">> That's nice because, for example,",
        "start": 255.505,
        "duration": 2.045
    },
    {
        "text": "VNet support is super",
        "start": 257.55,
        "duration": 1.07
    },
    {
        "text": "important because maybe I want to bring it in",
        "start": 258.62,
        "duration": 1.785
    },
    {
        "text": "the workload onto my on-premises locally, right?",
        "start": 260.405,
        "duration": 3.435
    },
    {
        "text": "Then I want to be able to map that together,",
        "start": 263.84,
        "duration": 1.955
    },
    {
        "text": "but what are some other advantages?",
        "start": 265.795,
        "duration": 1.655
    },
    {
        "text": "Because, look, let me just be honest with you.",
        "start": 267.45,
        "duration": 3.055
    },
    {
        "text": "Whenever I create a virtual machine,",
        "start": 270.505,
        "duration": 2.87
    },
    {
        "text": "there is an IP address,",
        "start": 273.375,
        "duration": 2.235
    },
    {
        "text": "and I don't want people to get to that machine.",
        "start": 275.61,
        "duration": 3.455
    },
    {
        "text": "What are we doing to help with that?",
        "start": 279.065,
        "duration": 1.395
    },
    {
        "text": ">> Yeah. So good question now, Seth.",
        "start": 280.46,
        "duration": 2.245
    },
    {
        "text": "We have heard feedback that customers do not want",
        "start": 282.705,
        "duration": 2.105
    },
    {
        "text": "a public IP both on instance or on the cluster,",
        "start": 284.81,
        "duration": 2.94
    },
    {
        "text": "and that's something that we're going to introduce",
        "start": 287.75,
        "duration": 1.695
    },
    {
        "text": "towards the end of the year.",
        "start": 289.445,
        "duration": 2.115
    },
    {
        "text": "This was a recent announcement from",
        "start": 291.56,
        "duration": 1.05
    },
    {
        "text": "Azure Services started supporting no public IP policy,",
        "start": 292.61,
        "duration": 3.81
    },
    {
        "text": "and that's something that's going to come out.",
        "start": 296.42,
        "duration": 1.02
    },
    {
        "text": "So we're really excited to work",
        "start": 297.44,
        "duration": 1.17
    },
    {
        "text": "on that and deliver it to our customers.",
        "start": 298.61,
        "duration": 1.35
    },
    {
        "text": ">> Fantastic. Just keep going. Sorry, I interrupted you up.",
        "start": 299.96,
        "duration": 1.98
    },
    {
        "text": ">> Yeah. So in addition,",
        "start": 301.94,
        "duration": 1.72
    },
    {
        "text": "what we started doing was if you're",
        "start": 303.66,
        "duration": 1.22
    },
    {
        "text": "deploying your cluster inside of VNet,",
        "start": 304.88,
        "duration": 1.8
    },
    {
        "text": "we'll automatically close the SSH port for you.",
        "start": 306.68,
        "duration": 2.475
    },
    {
        "text": "You can still SSH into it inside the VNet, but essentially,",
        "start": 309.155,
        "duration": 2.985
    },
    {
        "text": "for an enterprise standpoint,",
        "start": 312.14,
        "duration": 1.17
    },
    {
        "text": "we are not going to keep an open port for the Internet.",
        "start": 313.31,
        "duration": 3.57
    },
    {
        "text": "Additional things that you can start",
        "start": 316.88,
        "duration": 2.05
    },
    {
        "text": "doing is around monitoring, for example.",
        "start": 318.93,
        "duration": 2.43
    },
    {
        "text": "If you go into the \"Metrics\" tab,",
        "start": 321.36,
        "duration": 1.54
    },
    {
        "text": "now you can see alerts that you can set up.",
        "start": 322.9,
        "duration": 2.47
    },
    {
        "text": "I'm looking at my resource, which is a workspace,",
        "start": 325.37,
        "duration": 2.18
    },
    {
        "text": "and I'm going to say the metric",
        "start": 327.55,
        "duration": 2.41
    },
    {
        "text": "that I'm interested in this Active Cores.",
        "start": 329.96,
        "duration": 2.325
    },
    {
        "text": "I can just change the duration to say the last seven days,",
        "start": 332.285,
        "duration": 5.055
    },
    {
        "text": "and you'll see how easily I can plot",
        "start": 337.34,
        "duration": 2.97
    },
    {
        "text": "this Active Cores graph across the entire workspace,",
        "start": 340.31,
        "duration": 3.36
    },
    {
        "text": "across the various clusters that were there.",
        "start": 343.67,
        "duration": 1.455
    },
    {
        "text": "So these are things that enterprises",
        "start": 345.125,
        "duration": 1.365
    },
    {
        "text": "can now start using to set alerts",
        "start": 346.49,
        "duration": 1.435
    },
    {
        "text": "on to be able to monitor exactly how much usage is happening.",
        "start": 347.925,
        "duration": 3.305
    },
    {
        "text": "Is there someone who was abusing the clusters?",
        "start": 351.23,
        "duration": 2.385
    },
    {
        "text": "Are clusters lying idly,",
        "start": 353.615,
        "duration": 1.125
    },
    {
        "text": "its capacity being paid for but not being used, things like that?",
        "start": 354.74,
        "duration": 3.26
    },
    {
        "text": ">> This is really cool because",
        "start": 358.0,
        "duration": 2.05
    },
    {
        "text": "as I've looked at it as a data scientist,",
        "start": 360.05,
        "duration": 1.68
    },
    {
        "text": "I just want to run the thing,",
        "start": 361.73,
        "duration": 1.365
    },
    {
        "text": "but as IT professionals inside the organization,",
        "start": 363.095,
        "duration": 3.165
    },
    {
        "text": "especially during enterprises, you want to manage costs.",
        "start": 366.26,
        "duration": 2.49
    },
    {
        "text": "You want to manage to make sure that the machines aren't insecure,",
        "start": 368.75,
        "duration": 3.33
    },
    {
        "text": "and now we're adding a lot of features to let people do that.",
        "start": 372.08,
        "duration": 2.505
    },
    {
        "text": ">> Absolutely.",
        "start": 374.585,
        "duration": 0.525
    },
    {
        "text": ">> That's so cool.",
        "start": 375.11,
        "duration": 0.315
    },
    {
        "text": ">> Yeah. Let me show you a couple of other things also.",
        "start": 375.425,
        "duration": 2.7
    },
    {
        "text": "So now I'm using",
        "start": 378.125,
        "duration": 1.41
    },
    {
        "text": "our new workspace which",
        "start": 379.535,
        "duration": 2.415
    },
    {
        "text": "is a Data Scientist workspace we announced Studio at Ignite.",
        "start": 381.95,
        "duration": 2.675
    },
    {
        "text": "As you go here, I am again on the same cluster,",
        "start": 384.625,
        "duration": 2.705
    },
    {
        "text": "and now I can see what are the various states",
        "start": 387.33,
        "duration": 1.94
    },
    {
        "text": "of the nodes in that cluster itself,",
        "start": 389.27,
        "duration": 1.98
    },
    {
        "text": "but one of the more interesting things you'll see here is that now",
        "start": 391.25,
        "duration": 2.25
    },
    {
        "text": "I can actually start listing down the nodes on the cluster.",
        "start": 393.5,
        "duration": 2.43
    },
    {
        "text": "This is a five-node cluster,",
        "start": 395.93,
        "duration": 1.44
    },
    {
        "text": "but say it was a 20-node cluster,",
        "start": 397.37,
        "duration": 1.41
    },
    {
        "text": "I can easily see what is the state of each node,",
        "start": 398.78,
        "duration": 2.24
    },
    {
        "text": "what is the public and private IP address",
        "start": 401.02,
        "duration": 1.72
    },
    {
        "text": "if I wanted to SSH into it.",
        "start": 402.74,
        "duration": 1.18
    },
    {
        "text": "You could do that now. You can",
        "start": 403.92,
        "duration": 1.43
    },
    {
        "text": "list the actual runs that are coming on",
        "start": 405.35,
        "duration": 1.62
    },
    {
        "text": "cluster so you know exactly how many nodes",
        "start": 406.97,
        "duration": 2.1
    },
    {
        "text": "are being used for each run, things like that.",
        "start": 409.07,
        "duration": 1.5
    },
    {
        "text": ">> That's cool.",
        "start": 410.57,
        "duration": 0.815
    },
    {
        "text": ">> You go to the \"Runs\" tab.",
        "start": 411.385,
        "duration": 1.31
    },
    {
        "text": "Now you have a nice view of all the runs that are",
        "start": 412.695,
        "duration": 1.895
    },
    {
        "text": "either queued or running on this particular cluster.",
        "start": 414.59,
        "duration": 2.235
    },
    {
        "text": "So you just go through these views and you",
        "start": 416.825,
        "duration": 1.815
    },
    {
        "text": "actually know these other various runs that are there,",
        "start": 418.64,
        "duration": 2.595
    },
    {
        "text": "how many number of nodes are these runs actually taking,",
        "start": 421.235,
        "duration": 3.195
    },
    {
        "text": "when were they started,",
        "start": 424.43,
        "duration": 1.305
    },
    {
        "text": "other tags that you've set up on those runs.",
        "start": 425.735,
        "duration": 1.715
    },
    {
        "text": ">> That's amazing.",
        "start": 427.45,
        "duration": 1.07
    },
    {
        "text": ">> Yeah, and this view helps not only an admin to",
        "start": 428.52,
        "duration": 2.21
    },
    {
        "text": "understand exactly how the clusters being used,",
        "start": 430.73,
        "duration": 2.19
    },
    {
        "text": "but also for data scientists to know",
        "start": 432.92,
        "duration": 1.56
    },
    {
        "text": "exactly which cluster should I use to go submit my job on.",
        "start": 434.48,
        "duration": 2.75
    },
    {
        "text": "Because I got five clusters.",
        "start": 437.23,
        "duration": 1.39
    },
    {
        "text": "But which one is being utilized, which one is not,",
        "start": 438.62,
        "duration": 1.59
    },
    {
        "text": "those are things that I need to make a decision on.",
        "start": 440.21,
        "duration": 1.67
    },
    {
        "text": ">> It might be usually because you might",
        "start": 441.88,
        "duration": 1.45
    },
    {
        "text": "have a cluster with an ANSI 6,",
        "start": 443.33,
        "duration": 2.04
    },
    {
        "text": "and some with ANSI 12,",
        "start": 445.37,
        "duration": 1.395
    },
    {
        "text": "and if you look at the resource utilization,",
        "start": 446.765,
        "duration": 2.025
    },
    {
        "text": "maybe you don't need to spin up",
        "start": 448.79,
        "duration": 1.53
    },
    {
        "text": "that huge machine because you're not even using the ANSI 6.",
        "start": 450.32,
        "duration": 2.67
    },
    {
        "text": "It's just a good way to figure it out.",
        "start": 452.99,
        "duration": 1.365
    },
    {
        "text": ">> Yes. One of the things that we are",
        "start": 454.355,
        "duration": 1.275
    },
    {
        "text": "also adding as both counters here",
        "start": 455.63,
        "duration": 1.62
    },
    {
        "text": "which means that you'll be able to see your CPU",
        "start": 457.25,
        "duration": 1.44
    },
    {
        "text": "and GPU utilization very soon,",
        "start": 458.69,
        "duration": 1.49
    },
    {
        "text": "and you can do it for a job.",
        "start": 460.18,
        "duration": 1.435
    },
    {
        "text": "You can see it for the entire cluster if you are an admin trying",
        "start": 461.615,
        "duration": 2.025
    },
    {
        "text": "to understand how much of a cluster has been utilized.",
        "start": 463.64,
        "duration": 2.24
    },
    {
        "text": ">> That's cool because I could just thinking about this.",
        "start": 465.88,
        "duration": 2.705
    },
    {
        "text": "For example, I may have set up my estimator wrong,",
        "start": 468.585,
        "duration": 3.59
    },
    {
        "text": "and it's using only CPU even though",
        "start": 472.175,
        "duration": 2.805
    },
    {
        "text": "I've stood up a bunch of huge GPU machines.",
        "start": 474.98,
        "duration": 3.1
    },
    {
        "text": "You can be like, \"Hey,",
        "start": 478.08,
        "duration": 1.055
    },
    {
        "text": "we're not using the resources correctly.",
        "start": 479.135,
        "duration": 2.455
    },
    {
        "text": "You can go ahead and change that.\"",
        "start": 481.59,
        "duration": 1.215
    },
    {
        "text": ">> Yeah, and I'll put the icing on the cake.",
        "start": 482.805,
        "duration": 1.625
    },
    {
        "text": "We'll also be pushing all of this data",
        "start": 484.43,
        "duration": 1.56
    },
    {
        "text": "into Azure Monitor, the view that I just showed you.",
        "start": 485.99,
        "duration": 1.755
    },
    {
        "text": ">> That's cool.",
        "start": 487.745,
        "duration": 0.345
    },
    {
        "text": ">> Which means that you can now set up a load.",
        "start": 488.09,
        "duration": 1.35
    },
    {
        "text": "So as an admin, I can just rest and",
        "start": 489.44,
        "duration": 1.77
    },
    {
        "text": "assume that whenever somebody is not utilizing my GPU,",
        "start": 491.21,
        "duration": 2.04
    },
    {
        "text": "it's going to throw an alert, and I'll actually",
        "start": 493.25,
        "duration": 1.29
    },
    {
        "text": "know who's doing that.",
        "start": 494.54,
        "duration": 1.46
    },
    {
        "text": ">> That's awesome. So another question I have on",
        "start": 496.0,
        "duration": 1.9
    },
    {
        "text": "this is I've had this question",
        "start": 497.9,
        "duration": 1.98
    },
    {
        "text": "come up a lot is how do I grant access to a workspace?",
        "start": 499.88,
        "duration": 3.99
    },
    {
        "text": "I mean, I know that there's something called",
        "start": 503.87,
        "duration": 1.53
    },
    {
        "text": "role-based access security in Azure.",
        "start": 505.4,
        "duration": 1.76
    },
    {
        "text": "What does it look like here?",
        "start": 507.16,
        "duration": 1.09
    },
    {
        "text": ">> Cool. So when you go to",
        "start": 508.25,
        "duration": 1.65
    },
    {
        "text": "your workspace just like with any other Azure resource,",
        "start": 509.9,
        "duration": 2.52
    },
    {
        "text": "there's something called Identity and Access Management.",
        "start": 512.42,
        "duration": 2.055
    },
    {
        "text": "You click on this and you try to go give",
        "start": 514.475,
        "duration": 2.355
    },
    {
        "text": "access to someone on your workspace.",
        "start": 516.83,
        "duration": 2.475
    },
    {
        "text": "So in this case, I'm trying to make someone an owner.",
        "start": 519.305,
        "duration": 2.055
    },
    {
        "text": "Say, I want to make set an owner of this.",
        "start": 521.36,
        "duration": 2.94
    },
    {
        "text": "I'm not sure if I wanted to do that,",
        "start": 524.3,
        "duration": 1.86
    },
    {
        "text": "but just because we're doing this video, I'll try to do that.",
        "start": 526.16,
        "duration": 4.005
    },
    {
        "text": "So I'm trying to have Seth Juarez.",
        "start": 530.165,
        "duration": 2.76
    },
    {
        "text": ">> Let's do S-E.",
        "start": 532.925,
        "duration": 2.37
    },
    {
        "text": ">> S-E.",
        "start": 535.295,
        "duration": 0.915
    },
    {
        "text": ">> S-E-J-U-A.",
        "start": 536.21,
        "duration": 1.5
    },
    {
        "text": ">> J-U-A.",
        "start": 537.71,
        "duration": 0.615
    },
    {
        "text": ">> R-E.",
        "start": 538.325,
        "duration": 0.705
    },
    {
        "text": ">> R-E.",
        "start": 539.03,
        "duration": 0.69
    },
    {
        "text": ">> Let's see if I'm in there.",
        "start": 539.72,
        "duration": 1.94
    },
    {
        "text": "Maybe I've been fired.",
        "start": 541.66,
        "duration": 1.895
    },
    {
        "text": ">> Yeah. I wasn't expecting that.",
        "start": 543.555,
        "duration": 2.94
    },
    {
        "text": ">> That is embarrassing.",
        "start": 546.495,
        "duration": 1.215
    },
    {
        "text": ">> Yeah, let me just search for my name.",
        "start": 547.71,
        "duration": 1.76
    },
    {
        "text": "Maybe we are both in the same boat.",
        "start": 549.47,
        "duration": 1.5
    },
    {
        "text": "So this could be our last video.",
        "start": 550.97,
        "duration": 1.92
    },
    {
        "text": "Let's see if I am able to find myself. I am not.",
        "start": 552.89,
        "duration": 4.45
    },
    {
        "text": "In my case, I have already assigned the role to myself.",
        "start": 559.26,
        "duration": 3.46
    },
    {
        "text": "What I can do here is if I go to this portal now,",
        "start": 562.72,
        "duration": 4.35
    },
    {
        "text": "you will see that I",
        "start": 567.07,
        "duration": 2.13
    },
    {
        "text": "actually do not have access to creating compute.",
        "start": 569.2,
        "duration": 2.88
    },
    {
        "text": "Somebody has actually applied a role where I don't see a plus new.",
        "start": 572.08,
        "duration": 3.165
    },
    {
        "text": "This is something that is so powerful",
        "start": 575.245,
        "duration": 2.04
    },
    {
        "text": "for enterprises because they can apply a rule.",
        "start": 577.285,
        "duration": 2.085
    },
    {
        "text": "Now going forward, they do not need to be concerned with",
        "start": 579.37,
        "duration": 2.865
    },
    {
        "text": "our customers or their data scientists",
        "start": 582.235,
        "duration": 2.385
    },
    {
        "text": "about creating a compute by mistake.",
        "start": 584.62,
        "duration": 1.95
    },
    {
        "text": ">> That's cool. Let's go back to the portal.",
        "start": 586.57,
        "duration": 7.665
    },
    {
        "text": ">> Yeah. Let's go back.",
        "start": 594.235,
        "duration": 0.96
    },
    {
        "text": ">> In the access control,",
        "start": 595.195,
        "duration": 2.025
    },
    {
        "text": "you can basically say,",
        "start": 597.22,
        "duration": 1.44
    },
    {
        "text": "\"Here's a user and here's what",
        "start": 598.66,
        "duration": 1.5
    },
    {
        "text": "they can and can't do inside of the work space.\"",
        "start": 600.16,
        "duration": 1.62
    },
    {
        "text": ">> Exactly. Yeah. You can define custom roles.",
        "start": 601.78,
        "duration": 1.71
    },
    {
        "text": "You can say a user can do experiments,",
        "start": 603.49,
        "duration": 1.83
    },
    {
        "text": "but they cannot be doing deployments.",
        "start": 605.32,
        "duration": 2.1
    },
    {
        "text": "Those are all things that you can define",
        "start": 607.42,
        "duration": 1.485
    },
    {
        "text": "against a user in a work space,",
        "start": 608.905,
        "duration": 1.62
    },
    {
        "text": "so you can have a different identity between work spaces also.",
        "start": 610.525,
        "duration": 2.46
    },
    {
        "text": "But for a particular work space,",
        "start": 612.985,
        "duration": 1.785
    },
    {
        "text": "will now honor exactly what your role definition says and say,",
        "start": 614.77,
        "duration": 2.94
    },
    {
        "text": "prevent you from creating clusters.",
        "start": 617.71,
        "duration": 1.455
    },
    {
        "text": ">> That's awesome, because you don't want someone frivolously",
        "start": 619.165,
        "duration": 4.56
    },
    {
        "text": "spending up huge resources and then having to",
        "start": 623.725,
        "duration": 2.295
    },
    {
        "text": "be responsible for those particular costs,",
        "start": 626.02,
        "duration": 2.895
    },
    {
        "text": "which brings me to my next question.",
        "start": 628.915,
        "duration": 2.74
    },
    {
        "text": "These things can be quite expensive,",
        "start": 631.655,
        "duration": 2.485
    },
    {
        "text": "are we doing anything to help manage costs?",
        "start": 634.14,
        "duration": 1.71
    },
    {
        "text": ">> Yes. There are a few things that we're working towards.",
        "start": 635.85,
        "duration": 2.43
    },
    {
        "text": "One of the first things that we've already talked about",
        "start": 638.28,
        "duration": 2.73
    },
    {
        "text": "a little bit is that if",
        "start": 641.01,
        "duration": 1.41
    },
    {
        "text": "you are spending up an AML Compute cluster,",
        "start": 642.42,
        "duration": 1.5
    },
    {
        "text": "now I'll just switch to my notebook.",
        "start": 643.92,
        "duration": 1.845
    },
    {
        "text": "When you're spending up a cluster,",
        "start": 645.765,
        "duration": 1.44
    },
    {
        "text": "you actually are able to set in a min and a max node.",
        "start": 647.205,
        "duration": 2.46
    },
    {
        "text": "In this case, we just assume that the min node is zero.",
        "start": 649.665,
        "duration": 2.055
    },
    {
        "text": "So this auto-scaling automatically gives you cost savings.",
        "start": 651.72,
        "duration": 2.22
    },
    {
        "text": "As soon as the cluster has done its jobs,",
        "start": 653.94,
        "duration": 1.86
    },
    {
        "text": "it's automatically going to spend down.",
        "start": 655.8,
        "duration": 1.715
    },
    {
        "text": "We also allow you to",
        "start": 657.515,
        "duration": 1.655
    },
    {
        "text": "actually configure something called an idle timeout.",
        "start": 659.17,
        "duration": 2.625
    },
    {
        "text": "This is something that enterprises can use to say,",
        "start": 661.795,
        "duration": 2.775
    },
    {
        "text": "\"Hey my data scientists actually do a lot of depth test.\"",
        "start": 664.57,
        "duration": 3.075
    },
    {
        "text": "Which means that they keep iterating on",
        "start": 667.645,
        "duration": 1.575
    },
    {
        "text": "the training script before they submit the final script.",
        "start": 669.22,
        "duration": 2.13
    },
    {
        "text": "They don't want the data scientist to pay the cost of,",
        "start": 671.35,
        "duration": 2.115
    },
    {
        "text": "\"Hey the cluster went down, now it's scaling backup.\"",
        "start": 673.465,
        "duration": 2.025
    },
    {
        "text": "So give it that idle time mode where it will wait for",
        "start": 675.49,
        "duration": 2.1
    },
    {
        "text": "a new job for some time before it scales down.",
        "start": 677.59,
        "duration": 2.565
    },
    {
        "text": "In addition, we also have a parameter that you can use in",
        "start": 680.155,
        "duration": 3.645
    },
    {
        "text": "your training script itself which actually allows you to define.",
        "start": 683.8,
        "duration": 3.84
    },
    {
        "text": "I'm just trying to, there you go.",
        "start": 687.64,
        "duration": 2.4
    },
    {
        "text": "So you have a script run config,",
        "start": 690.04,
        "duration": 1.47
    },
    {
        "text": "which is a run configuration that gets used to define your run.",
        "start": 691.51,
        "duration": 3.885
    },
    {
        "text": "One of the parameters there is maximum duration seconds.",
        "start": 695.395,
        "duration": 2.445
    },
    {
        "text": "So you can say \"Hey I want to",
        "start": 697.84,
        "duration": 1.77
    },
    {
        "text": "limit this run to not go beyond 1,800 seconds,\" for example.",
        "start": 699.61,
        "duration": 2.955
    },
    {
        "text": "This is something that will also be introduced as a policy soon.",
        "start": 702.565,
        "duration": 2.775
    },
    {
        "text": "So as an admin, I can say I don't want",
        "start": 705.34,
        "duration": 1.95
    },
    {
        "text": "10 day jobs being run on",
        "start": 707.29,
        "duration": 1.05
    },
    {
        "text": "my clusters because they might be in a mistake,",
        "start": 708.34,
        "duration": 1.89
    },
    {
        "text": "but I'm pretty sure my data scientists are",
        "start": 710.23,
        "duration": 1.26
    },
    {
        "text": "not doing that on purpose.",
        "start": 711.49,
        "duration": 1.62
    },
    {
        "text": ">> That's also cool because look,",
        "start": 713.11,
        "duration": 3.12
    },
    {
        "text": "as data scientists I want the thing to run forever.",
        "start": 716.23,
        "duration": 2.85
    },
    {
        "text": "But if I'm smart,",
        "start": 719.08,
        "duration": 1.5
    },
    {
        "text": "I'm also check pointing my model as I go through",
        "start": 720.58,
        "duration": 2.205
    },
    {
        "text": "each epoch and it just might be, look,",
        "start": 722.785,
        "duration": 2.235
    },
    {
        "text": "the policy is you can only go for 10 hours and",
        "start": 725.02,
        "duration": 3.06
    },
    {
        "text": "then I'll just pull the best model out",
        "start": 728.08,
        "duration": 1.44
    },
    {
        "text": "that happens after 10 hours, which is cool.",
        "start": 729.52,
        "duration": 1.68
    },
    {
        "text": ">> In fact there are customers that we've talked to who have",
        "start": 731.2,
        "duration": 2.01
    },
    {
        "text": "scenarios where they want to stop their model training in between,",
        "start": 733.21,
        "duration": 2.865
    },
    {
        "text": "look at the performance of the model, update the hyperparameters,",
        "start": 736.075,
        "duration": 2.444
    },
    {
        "text": "and then again continue with the model training",
        "start": 738.519,
        "duration": 1.516
    },
    {
        "text": "or tweak something in the training script.",
        "start": 740.035,
        "duration": 1.86
    },
    {
        "text": "That's something that you can easily do",
        "start": 741.895,
        "duration": 1.905
    },
    {
        "text": "by just having parameters such as this",
        "start": 743.8,
        "duration": 1.89
    },
    {
        "text": "which allow you to control the job instead of",
        "start": 745.69,
        "duration": 1.5
    },
    {
        "text": "having to manually go into the job,",
        "start": 747.19,
        "duration": 1.92
    },
    {
        "text": "inspect it at all times.",
        "start": 749.11,
        "duration": 1.05
    },
    {
        "text": ">> That's awesome.",
        "start": 750.16,
        "duration": 0.6
    },
    {
        "text": ">> Yeah. Some other things that I did want to",
        "start": 750.76,
        "duration": 1.935
    },
    {
        "text": "mention were also that we have support for low-priority.",
        "start": 752.695,
        "duration": 2.625
    },
    {
        "text": "So in this, you can also use a parameter called VM",
        "start": 755.32,
        "duration": 2.82
    },
    {
        "text": "priority and you can pass it as either dedicated or low-priority.",
        "start": 758.14,
        "duration": 3.885
    },
    {
        "text": "In the case of low-priority,",
        "start": 762.025,
        "duration": 1.514
    },
    {
        "text": "what it allows you to do is use Azure's discounted capacity,",
        "start": 763.539,
        "duration": 4.711
    },
    {
        "text": "so all the excess capacity that Azure has,",
        "start": 768.25,
        "duration": 1.785
    },
    {
        "text": "you can get it at a preemptible rate",
        "start": 770.035,
        "duration": 1.545
    },
    {
        "text": "which is almost at a 70 percent discount.",
        "start": 771.58,
        "duration": 1.695
    },
    {
        "text": "So it's a steel for GPUs especially.",
        "start": 773.275,
        "duration": 2.79
    },
    {
        "text": "You can pretty much use it whenever you",
        "start": 776.065,
        "duration": 2.115
    },
    {
        "text": "want if there is excess capacity.",
        "start": 778.18,
        "duration": 1.92
    },
    {
        "text": "If a dedicated workload comes into Azure,",
        "start": 780.1,
        "duration": 2.865
    },
    {
        "text": "say a big customer spins up, say 1,000 GPUs,",
        "start": 782.965,
        "duration": 1.98
    },
    {
        "text": "your jobs will get preempted.",
        "start": 784.945,
        "duration": 1.605
    },
    {
        "text": "But when there is excess capacity,",
        "start": 786.55,
        "duration": 1.38
    },
    {
        "text": "you are automatically getting a cost discount.",
        "start": 787.93,
        "duration": 1.56
    },
    {
        "text": ">> That's cool because maybe you want to run it over the weekend,",
        "start": 789.49,
        "duration": 3.21
    },
    {
        "text": "like a Wednesday at 2:00 and",
        "start": 792.7,
        "duration": 1.47
    },
    {
        "text": "then you'll be able to save a lot of money.",
        "start": 794.17,
        "duration": 1.365
    },
    {
        "text": ">> Yeah. Azure also has this functionality",
        "start": 795.535,
        "duration": 1.545
    },
    {
        "text": "of reserved instances where you",
        "start": 797.08,
        "duration": 1.425
    },
    {
        "text": "come into Azure for say using a 1,000 GPUs over three years.",
        "start": 798.505,
        "duration": 3.255
    },
    {
        "text": "When you do that, you automatically get",
        "start": 801.76,
        "duration": 1.53
    },
    {
        "text": "about 60-70 percent discount.",
        "start": 803.29,
        "duration": 1.56
    },
    {
        "text": "That's a dedicated capacity,",
        "start": 804.85,
        "duration": 1.35
    },
    {
        "text": "not even paying low-priority price experience,",
        "start": 806.2,
        "duration": 2.61
    },
    {
        "text": "but now you are trying to save a lot of money by",
        "start": 808.81,
        "duration": 2.07
    },
    {
        "text": "just dedicatedly spending on Azure and committing it.",
        "start": 810.88,
        "duration": 3.525
    },
    {
        "text": ">> This is awesome. So just to summarize,",
        "start": 814.405,
        "duration": 2.07
    },
    {
        "text": "we've talked about ML compute,",
        "start": 816.475,
        "duration": 2.055
    },
    {
        "text": "we've talked about some of the enterprise",
        "start": 818.53,
        "duration": 1.86
    },
    {
        "text": "features around spending up these kind of resources,",
        "start": 820.39,
        "duration": 2.339
    },
    {
        "text": "we talked about how we're saving costs.",
        "start": 822.729,
        "duration": 2.011
    },
    {
        "text": "Is there anything else you'd like to add?",
        "start": 824.74,
        "duration": 1.35
    },
    {
        "text": ">> Yeah, just one more thing that we tried to introduce",
        "start": 826.09,
        "duration": 3.285
    },
    {
        "text": "recently was being able to easily",
        "start": 829.375,
        "duration": 1.77
    },
    {
        "text": "share resources between different work spaces.",
        "start": 831.145,
        "duration": 2.34
    },
    {
        "text": "So one of the experiences that our admins wanted was,",
        "start": 833.485,
        "duration": 3.75
    },
    {
        "text": "\"Hey I have these 20 work spaces.",
        "start": 837.235,
        "duration": 1.845
    },
    {
        "text": "I have data scientists spending up and",
        "start": 839.08,
        "duration": 1.23
    },
    {
        "text": "using clusters across these work spaces.",
        "start": 840.31,
        "duration": 1.665
    },
    {
        "text": "It's not easy for me to distribute this capacity.",
        "start": 841.975,
        "duration": 2.235
    },
    {
        "text": "Say I have a 1,000 cores. How do I fair share?",
        "start": 844.21,
        "duration": 2.1
    },
    {
        "text": "Or how do I give priority to a work space which is doing",
        "start": 846.31,
        "duration": 2.52
    },
    {
        "text": "research papers versus someone else who is",
        "start": 848.83,
        "duration": 1.53
    },
    {
        "text": "just doing some deftest experimentation?\"",
        "start": 850.36,
        "duration": 2.325
    },
    {
        "text": "For something like that, we introduce this expedience where",
        "start": 852.685,
        "duration": 3.195
    },
    {
        "text": "you can essentially come into the usage in quota bit,",
        "start": 855.88,
        "duration": 3.15
    },
    {
        "text": "and you can actually start seeing",
        "start": 859.03,
        "duration": 1.62
    },
    {
        "text": "the different usages across VM family.",
        "start": 860.65,
        "duration": 2.31
    },
    {
        "text": "So in this case. I have a work space",
        "start": 862.96,
        "duration": 1.53
    },
    {
        "text": "and you can see which cluster is using how much.",
        "start": 864.49,
        "duration": 2.775
    },
    {
        "text": "One of the added advantages here is that now you",
        "start": 867.265,
        "duration": 3.015
    },
    {
        "text": "can also start setting limits on this.",
        "start": 870.28,
        "duration": 2.79
    },
    {
        "text": "So I can say, \"Hey, this work space,",
        "start": 873.07,
        "duration": 2.04
    },
    {
        "text": "which is a flight delay demo,",
        "start": 875.11,
        "duration": 1.32
    },
    {
        "text": "is not supposed to go beyond a 50 core limit.",
        "start": 876.43,
        "duration": 2.745
    },
    {
        "text": "Once I do that, you will automatically be",
        "start": 879.175,
        "duration": 1.965
    },
    {
        "text": "limiting the work spaces user strict 50 cores.",
        "start": 881.14,
        "duration": 2.655
    },
    {
        "text": "This is an easy way for you to do something like capacity sharing,",
        "start": 883.795,
        "duration": 3.105
    },
    {
        "text": "governance, and cost management",
        "start": 886.9,
        "duration": 1.44
    },
    {
        "text": "and allocations across work spaces.",
        "start": 888.34,
        "duration": 1.695
    },
    {
        "text": ">> That's awesome. This is",
        "start": 890.035,
        "duration": 2.295
    },
    {
        "text": "the thing that I really like because there's",
        "start": 892.33,
        "duration": 1.8
    },
    {
        "text": "aspects of a data scientist's job that I just don't like doing.",
        "start": 894.13,
        "duration": 4.185
    },
    {
        "text": "I don't want to manage machine.",
        "start": 898.315,
        "duration": 1.29
    },
    {
        "text": "I don't want to worry how much this stuff costs.",
        "start": 899.605,
        "duration": 2.535
    },
    {
        "text": "I don't want to accidentally have a",
        "start": 902.14,
        "duration": 1.44
    },
    {
        "text": "$3,000 bill at the end of two months.",
        "start": 903.58,
        "duration": 2.55
    },
    {
        "text": "So it's really nice to be able to add this governance and",
        "start": 906.13,
        "duration": 2.7
    },
    {
        "text": "this enterprise flavor to these things.",
        "start": 908.83,
        "duration": 2.46
    },
    {
        "text": ">> Yeah. The whole point is that we want to take the IT out of",
        "start": 911.29,
        "duration": 2.7
    },
    {
        "text": "data science and leave it with the machine-learning compute.",
        "start": 913.99,
        "duration": 3.135
    },
    {
        "text": "What you focus on is actually",
        "start": 917.125,
        "duration": 1.665
    },
    {
        "text": "deftest experimentation and building your models.",
        "start": 918.79,
        "duration": 2.325
    },
    {
        "text": ">> Well, this has been awesome.",
        "start": 921.115,
        "duration": 1.125
    },
    {
        "text": "Thanks so much for spending some time with us.",
        "start": 922.24,
        "duration": 1.455
    },
    {
        "text": ">> Yeah. Thanks so much Seth, and we'll try",
        "start": 923.695,
        "duration": 1.395
    },
    {
        "text": "to find you back on sometimes.",
        "start": 925.09,
        "duration": 1.47
    },
    {
        "text": ">> Fantastic. We'll put some links",
        "start": 926.56,
        "duration": 1.38
    },
    {
        "text": "below on where you can find out more.",
        "start": 927.94,
        "duration": 1.725
    },
    {
        "text": "But again thanks for being with us. Thanks very much for watching.",
        "start": 929.665,
        "duration": 1.875
    },
    {
        "text": "We're learning all about AML Compute and all of",
        "start": 931.54,
        "duration": 2.49
    },
    {
        "text": "the amazing features that you",
        "start": 934.03,
        "duration": 1.53
    },
    {
        "text": "have now with Enterprise capabilities.",
        "start": 935.56,
        "duration": 2.16
    },
    {
        "text": "Thanks for watching. We'll see you next time. Take care.",
        "start": 937.72,
        "duration": 1.815
    },
    {
        "text": ">> Thanks for watching. See you.",
        "start": 939.535,
        "duration": 1.065
    },
    {
        "text": "[MUSIC]",
        "start": 940.6,
        "duration": 12.4
    }
]