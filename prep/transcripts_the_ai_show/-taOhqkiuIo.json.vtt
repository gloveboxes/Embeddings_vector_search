[
    {
        "text": ">> On this special build edition of the AI Show,",
        "start": 0.68,
        "duration": 3.31
    },
    {
        "text": "we'll get to hear from Scott Lundberg,",
        "start": 3.99,
        "duration": 1.71
    },
    {
        "text": "Senior Researcher on the Microsoft Research team.",
        "start": 5.7,
        "duration": 3.15
    },
    {
        "text": "It is definitely important to debug and",
        "start": 8.85,
        "duration": 1.44
    },
    {
        "text": "explain your machine learning models.",
        "start": 10.29,
        "duration": 2.1
    },
    {
        "text": "In this video, Scott will explain the science behind",
        "start": 12.39,
        "duration": 3.87
    },
    {
        "text": "SHAP values and how they can be used to",
        "start": 16.26,
        "duration": 1.86
    },
    {
        "text": "explain and debug your models. Make sure you tune in.",
        "start": 18.12,
        "duration": 3.21
    },
    {
        "text": "[MUSIC]",
        "start": 21.33,
        "duration": 9.029
    },
    {
        "text": ">> Hi, my name is Scott Lundberg.",
        "start": 30.359,
        "duration": 1.726
    },
    {
        "text": "I'm a Senior Researcher here at Microsoft Research AI,",
        "start": 32.085,
        "duration": 2.505
    },
    {
        "text": "and I look forward today to",
        "start": 34.59,
        "duration": 1.995
    },
    {
        "text": "diving into the background behind SHAP,",
        "start": 36.585,
        "duration": 2.325
    },
    {
        "text": "which is a tool in research",
        "start": 38.91,
        "duration": 3.23
    },
    {
        "text": "designed to use Shapley values from",
        "start": 42.14,
        "duration": 1.8
    },
    {
        "text": "game theory to explain machine learning models.",
        "start": 43.94,
        "duration": 2.79
    },
    {
        "text": "So to understand how this works,",
        "start": 46.73,
        "duration": 1.68
    },
    {
        "text": "let's start with a model that we're going to explain.",
        "start": 48.41,
        "duration": 2.37
    },
    {
        "text": "This model, let's imagine,",
        "start": 50.78,
        "duration": 1.2
    },
    {
        "text": "works at a bank and takes",
        "start": 51.98,
        "duration": 2.13
    },
    {
        "text": "information about customers like John and",
        "start": 54.11,
        "duration": 2.34
    },
    {
        "text": "outputs predictions about their likelihood",
        "start": 56.45,
        "duration": 2.55
    },
    {
        "text": "of having repayment problems if the bank were to give him a loan.",
        "start": 59.0,
        "duration": 3.17
    },
    {
        "text": "In this case, the repayment problem is a bit high,",
        "start": 62.17,
        "duration": 2.96
    },
    {
        "text": "so the banks unlikely to give him a loan.",
        "start": 65.13,
        "duration": 2.115
    },
    {
        "text": "As a data scientist responsible for building this model,",
        "start": 67.245,
        "duration": 3.11
    },
    {
        "text": "you may have used a whole variety",
        "start": 70.355,
        "duration": 2.355
    },
    {
        "text": "of different packages in the model development process.",
        "start": 72.71,
        "duration": 2.13
    },
    {
        "text": "Anything from Scikit-learn, or linear models,",
        "start": 74.84,
        "duration": 2.37
    },
    {
        "text": "or trees, gradient booster decision stuff,",
        "start": 77.21,
        "duration": 3.18
    },
    {
        "text": "deep networks, all in pursuit",
        "start": 80.39,
        "duration": 2.73
    },
    {
        "text": "of producing a good, accurate, high-quality model.",
        "start": 83.12,
        "duration": 3.39
    },
    {
        "text": "But in that process, a lot of these things are",
        "start": 86.51,
        "duration": 2.19
    },
    {
        "text": "very complicated and very opaque.",
        "start": 88.7,
        "duration": 2.52
    },
    {
        "text": "Which means in order to debug these things,",
        "start": 91.22,
        "duration": 3.81
    },
    {
        "text": "you need to be able to interpret them.",
        "start": 95.03,
        "duration": 1.44
    },
    {
        "text": "So that's one huge motivation for interpretability and",
        "start": 96.47,
        "duration": 2.25
    },
    {
        "text": "explainability is the ability to debug and understand your model.",
        "start": 98.72,
        "duration": 3.215
    },
    {
        "text": "Not just for the data scientists though,",
        "start": 101.935,
        "duration": 1.775
    },
    {
        "text": "it's also for customers.",
        "start": 103.71,
        "duration": 1.275
    },
    {
        "text": "There's even legal requirements in the finance domain.",
        "start": 104.985,
        "duration": 2.315
    },
    {
        "text": "But in many areas,",
        "start": 107.3,
        "duration": 1.08
    },
    {
        "text": "you need to be able to communicate to",
        "start": 108.38,
        "duration": 1.56
    },
    {
        "text": "a customer why a model is making decision about them.",
        "start": 109.94,
        "duration": 4.01
    },
    {
        "text": "Also for businesses, it would depend on these models.",
        "start": 113.95,
        "duration": 3.185
    },
    {
        "text": "Understanding how they work and, hence,",
        "start": 117.135,
        "duration": 1.845
    },
    {
        "text": "when they can break is extremely important in order",
        "start": 118.98,
        "duration": 3.5
    },
    {
        "text": "to manage the risk that is taken in these businesses for models.",
        "start": 122.48,
        "duration": 3.7
    },
    {
        "text": "All of these motivate how",
        "start": 126.18,
        "duration": 1.985
    },
    {
        "text": "important it is to have interpretability and explainability.",
        "start": 128.165,
        "duration": 2.85
    },
    {
        "text": "So how does SHAP help with this?",
        "start": 131.015,
        "duration": 1.665
    },
    {
        "text": "Well, if we go back to John,",
        "start": 132.68,
        "duration": 2.205
    },
    {
        "text": "it's important to understand that",
        "start": 134.885,
        "duration": 1.71
    },
    {
        "text": "whenever a model makes a prediction,",
        "start": 136.595,
        "duration": 1.485
    },
    {
        "text": "it's always got some prior in mind,",
        "start": 138.08,
        "duration": 2.55
    },
    {
        "text": "in the sense that there's always some base rate",
        "start": 140.63,
        "duration": 2.475
    },
    {
        "text": "that we would have predicted if we knew nothing about John.",
        "start": 143.105,
        "duration": 2.675
    },
    {
        "text": "In this case, it could be our average or",
        "start": 145.78,
        "duration": 2.35
    },
    {
        "text": "the training dataset of defaults,",
        "start": 148.13,
        "duration": 2.295
    },
    {
        "text": "or could be some test dataset that we have in mind,",
        "start": 150.425,
        "duration": 3.54
    },
    {
        "text": "or some particular group of people,",
        "start": 153.965,
        "duration": 2.445
    },
    {
        "text": "like all the people who got accepted.",
        "start": 156.41,
        "duration": 1.53
    },
    {
        "text": "Whatever that background prior knowledge is,",
        "start": 157.94,
        "duration": 2.775
    },
    {
        "text": "that's actually where we start when we don't",
        "start": 160.715,
        "duration": 2.115
    },
    {
        "text": "know anything about prediction.",
        "start": 162.83,
        "duration": 2.09
    },
    {
        "text": "But John didn't get predicted the base rate,",
        "start": 164.92,
        "duration": 2.26
    },
    {
        "text": "which in this case was 16 percent of our dataset.",
        "start": 167.18,
        "duration": 2.25
    },
    {
        "text": "That's just the expected value for our model's output.",
        "start": 169.43,
        "duration": 2.04
    },
    {
        "text": "He got predicted 22 percent.",
        "start": 171.47,
        "duration": 1.76
    },
    {
        "text": "So what SHAP does, it says, \"Hey look,",
        "start": 173.23,
        "duration": 2.435
    },
    {
        "text": "we need to explain not 22 percent from zero,",
        "start": 175.665,
        "duration": 3.645
    },
    {
        "text": "because zero is just an arbitrary number.",
        "start": 179.31,
        "duration": 1.61
    },
    {
        "text": "What we need to explain is how we",
        "start": 180.92,
        "duration": 1.62
    },
    {
        "text": "got from the base rate where we knew",
        "start": 182.54,
        "duration": 1.59
    },
    {
        "text": "nothing about John to the current prediction for John,",
        "start": 184.13,
        "duration": 3.69
    },
    {
        "text": "which is 22 percent.\"",
        "start": 187.82,
        "duration": 1.59
    },
    {
        "text": "How do we go about doing this?",
        "start": 189.41,
        "duration": 1.725
    },
    {
        "text": "Well, essentially, we can look at this expectation of",
        "start": 191.135,
        "duration": 2.535
    },
    {
        "text": "the model's prediction over our training dataset in this case,",
        "start": 193.67,
        "duration": 3.425
    },
    {
        "text": "and then we can fill out John's application one field at a time.",
        "start": 197.095,
        "duration": 4.825
    },
    {
        "text": "In this case, we're filling out that his income is not verified.",
        "start": 201.92,
        "duration": 4.055
    },
    {
        "text": "Now, what that does is it bumps up",
        "start": 205.975,
        "duration": 2.935
    },
    {
        "text": "the expected value of the model by 2.2 percent.",
        "start": 208.91,
        "duration": 2.31
    },
    {
        "text": "So we can say that 2.2 percent",
        "start": 211.22,
        "duration": 1.59
    },
    {
        "text": "must be attributable to",
        "start": 212.81,
        "duration": 2.16
    },
    {
        "text": "the fact that John didn't have his income verified.",
        "start": 214.97,
        "duration": 2.265
    },
    {
        "text": "So relative [inaudible] and training",
        "start": 217.235,
        "duration": 1.485
    },
    {
        "text": "dataset this increases his risk.",
        "start": 218.72,
        "duration": 2.085
    },
    {
        "text": "If we do the same thing for his debt-to-income ratio,",
        "start": 220.805,
        "duration": 2.85
    },
    {
        "text": "we see that that is at 30,",
        "start": 223.655,
        "duration": 1.515
    },
    {
        "text": "which bumps him up to 21 percent.",
        "start": 225.17,
        "duration": 2.135
    },
    {
        "text": "Then we see that he had a delinquent payment 10 months ago,",
        "start": 227.305,
        "duration": 3.055
    },
    {
        "text": "which further increases his risk up to 22.5 percent.",
        "start": 230.36,
        "duration": 3.095
    },
    {
        "text": "Again, we're filling out his application one entry at a time.",
        "start": 233.455,
        "duration": 4.255
    },
    {
        "text": "Then we throw out the fact that he had no recent account openings,",
        "start": 237.71,
        "duration": 3.27
    },
    {
        "text": "and this drops his risk significantly",
        "start": 240.98,
        "duration": 2.43
    },
    {
        "text": "because not applying for credit is a good sign.",
        "start": 243.41,
        "duration": 2.97
    },
    {
        "text": "But then finally, we fill in",
        "start": 246.38,
        "duration": 2.07
    },
    {
        "text": "the fact that he has 46 years of credit history,",
        "start": 248.45,
        "duration": 2.235
    },
    {
        "text": "which you would think would be a really good thing,",
        "start": 250.685,
        "duration": 2.22
    },
    {
        "text": "but ironically in this case,",
        "start": 252.905,
        "duration": 1.38
    },
    {
        "text": "it turns out that that hurts him",
        "start": 254.285,
        "duration": 1.515
    },
    {
        "text": "significantly and bumps his risk up to 22 percent.",
        "start": 255.8,
        "duration": 2.91
    },
    {
        "text": "So now what we've done is we've filled out his entire application",
        "start": 258.71,
        "duration": 3.134
    },
    {
        "text": "and we've arrived at the prediction of the model,",
        "start": 261.844,
        "duration": 3.366
    },
    {
        "text": "but we've done it piece by piece so that",
        "start": 265.21,
        "duration": 2.05
    },
    {
        "text": "we can attribute each piece to each feature.",
        "start": 267.26,
        "duration": 2.445
    },
    {
        "text": "Hence, explain how we got from when we knew",
        "start": 269.705,
        "duration": 2.565
    },
    {
        "text": "nothing about John to the model's final prediction.",
        "start": 272.27,
        "duration": 3.37
    },
    {
        "text": "Now, let's back up and see how this works for",
        "start": 275.64,
        "duration": 3.56
    },
    {
        "text": "a simple linear regression model from scikit-learn, for example.",
        "start": 279.2,
        "duration": 4.005
    },
    {
        "text": "So here's a model trained",
        "start": 283.205,
        "duration": 1.675
    },
    {
        "text": "on this lending dataset where it's a linear model,",
        "start": 284.88,
        "duration": 4.69
    },
    {
        "text": "and I'm showing you a straight line that",
        "start": 289.57,
        "duration": 1.93
    },
    {
        "text": "represents the partial dependence plot of that linear model.",
        "start": 291.5,
        "duration": 3.67
    },
    {
        "text": "What we can see also on x-axis we have the feature I'm explaining,",
        "start": 295.27,
        "duration": 6.07
    },
    {
        "text": "which in this case happens to be annual income.",
        "start": 301.34,
        "duration": 2.205
    },
    {
        "text": "Then on the y-axis, we just",
        "start": 303.545,
        "duration": 1.335
    },
    {
        "text": "have the axis for partial dependence plot,",
        "start": 304.88,
        "duration": 2.7
    },
    {
        "text": "which happens to be the expected value that models",
        "start": 307.58,
        "duration": 1.66
    },
    {
        "text": "output when we change one feature,",
        "start": 309.24,
        "duration": 2.225
    },
    {
        "text": "which for a linear model is a straight line.",
        "start": 311.465,
        "duration": 2.31
    },
    {
        "text": "What I want to highlight here is how easy it is for",
        "start": 313.775,
        "duration": 2.745
    },
    {
        "text": "a linear model to read off",
        "start": 316.52,
        "duration": 1.26
    },
    {
        "text": "the SHAP value from a partial dependence plot.",
        "start": 317.78,
        "duration": 2.145
    },
    {
        "text": "So the gray line here is just the average output of the model.",
        "start": 319.925,
        "duration": 2.475
    },
    {
        "text": "But that's the prior base rate we were talking about.",
        "start": 322.4,
        "duration": 2.48
    },
    {
        "text": "Then what we can see is that the SHAP value is just the difference",
        "start": 324.88,
        "duration": 4.9
    },
    {
        "text": "between that average and",
        "start": 329.78,
        "duration": 2.49
    },
    {
        "text": "the partial dependence plot for",
        "start": 332.27,
        "duration": 1.11
    },
    {
        "text": "the value of the feature we're interested in.",
        "start": 333.38,
        "duration": 1.62
    },
    {
        "text": "For a linear model,",
        "start": 335.0,
        "duration": 1.425
    },
    {
        "text": "we can simply look and say,",
        "start": 336.425,
        "duration": 2.705
    },
    {
        "text": "\"John has made $140,000.",
        "start": 339.13,
        "duration": 2.78
    },
    {
        "text": "That puts his partial dependence plot at a certain point.\"",
        "start": 341.91,
        "duration": 3.8
    },
    {
        "text": "Then we can just measure that height from the mean value,",
        "start": 345.71,
        "duration": 4.575
    },
    {
        "text": "which if it's higher than",
        "start": 350.285,
        "duration": 1.455
    },
    {
        "text": "the average, it's just going to be positive.",
        "start": 351.74,
        "duration": 1.365
    },
    {
        "text": "If it's lower than the average, it's going to be negative.",
        "start": 353.105,
        "duration": 2.45
    },
    {
        "text": "We can do the exact same thing for more complicated models like",
        "start": 355.555,
        "duration": 3.175
    },
    {
        "text": "generalized additive models such as whether an EVM package.",
        "start": 358.73,
        "duration": 4.455
    },
    {
        "text": "What happens there is now you don't have a straight line anymore.",
        "start": 363.185,
        "duration": 3.035
    },
    {
        "text": "You can have a much more flexible partial dependence plot.",
        "start": 366.22,
        "duration": 3.62
    },
    {
        "text": "But again, the SHAP values,",
        "start": 369.84,
        "duration": 1.58
    },
    {
        "text": "because there's no interaction effects going on,",
        "start": 371.42,
        "duration": 2.67
    },
    {
        "text": "we still have an additive model,",
        "start": 374.09,
        "duration": 1.41
    },
    {
        "text": "the SHAP values are again,",
        "start": 375.5,
        "duration": 1.455
    },
    {
        "text": "just exactly the difference between",
        "start": 376.955,
        "duration": 2.145
    },
    {
        "text": "the height of the partial dependence plot",
        "start": 379.1,
        "duration": 1.41
    },
    {
        "text": "and the expected value of the model.",
        "start": 380.51,
        "duration": 1.745
    },
    {
        "text": "So if you were to plot the SHAP values",
        "start": 382.255,
        "duration": 1.895
    },
    {
        "text": "for many different individuals,",
        "start": 384.15,
        "duration": 2.39
    },
    {
        "text": "you would get essentially a line,",
        "start": 386.54,
        "duration": 1.89
    },
    {
        "text": "and that line would be exactly",
        "start": 388.43,
        "duration": 1.455
    },
    {
        "text": "the mean centered partial dependence plot.",
        "start": 389.885,
        "duration": 2.55
    },
    {
        "text": "So more complicated models though,",
        "start": 392.435,
        "duration": 3.345
    },
    {
        "text": "or of course, where people are most",
        "start": 395.78,
        "duration": 1.17
    },
    {
        "text": "interested in this kind of stuff.",
        "start": 396.95,
        "duration": 1.13
    },
    {
        "text": "In that case, you can't just use a single order.",
        "start": 398.08,
        "duration": 3.55
    },
    {
        "text": "You can't just introduce features one at a time,",
        "start": 401.63,
        "duration": 2.16
    },
    {
        "text": "because it turns out that the orders",
        "start": 403.79,
        "duration": 1.17
    },
    {
        "text": "you introduced features matters.",
        "start": 404.96,
        "duration": 1.935
    },
    {
        "text": "If there's an and function or an or function,",
        "start": 406.895,
        "duration": 2.61
    },
    {
        "text": "the first or second one you introduce will get all the credit.",
        "start": 409.505,
        "duration": 2.685
    },
    {
        "text": "So here's an example on a real dataset where we",
        "start": 412.19,
        "duration": 2.355
    },
    {
        "text": "say no recent account openings in 46 years of credit history,",
        "start": 414.545,
        "duration": 2.925
    },
    {
        "text": "we've filled out account openings first and then credit history.",
        "start": 417.47,
        "duration": 2.865
    },
    {
        "text": "What if, in filling out this application we first",
        "start": 420.335,
        "duration": 1.875
    },
    {
        "text": "fill out credit history and then account openings?",
        "start": 422.21,
        "duration": 1.985
    },
    {
        "text": "Turns out, it makes a huge difference.",
        "start": 424.195,
        "duration": 1.61
    },
    {
        "text": "What that means is there's a strong interaction effect",
        "start": 425.805,
        "duration": 2.225
    },
    {
        "text": "between credit history and account openings.",
        "start": 428.03,
        "duration": 1.815
    },
    {
        "text": "That's where SHAP comes in to try and fairly",
        "start": 429.845,
        "duration": 3.585
    },
    {
        "text": "distribute the effects that are",
        "start": 433.43,
        "duration": 1.68
    },
    {
        "text": "going on in high level interactions.",
        "start": 435.11,
        "duration": 2.205
    },
    {
        "text": "You can say, \"How on earth are we going to do this?\"",
        "start": 437.315,
        "duration": 1.965
    },
    {
        "text": "Well, it turns out we can go back in the 1950s",
        "start": 439.28,
        "duration": 2.445
    },
    {
        "text": "and rely on some very solid theory and game theory",
        "start": 441.725,
        "duration": 3.435
    },
    {
        "text": "that is all about how to do this fairly in",
        "start": 445.16,
        "duration": 3.45
    },
    {
        "text": "complicated games with lots of",
        "start": 448.61,
        "duration": 1.29
    },
    {
        "text": "interacting players that have higher-order interaction effects.",
        "start": 449.9,
        "duration": 3.24
    },
    {
        "text": "How can we share those interaction effects fairly among all of",
        "start": 453.14,
        "duration": 3.3
    },
    {
        "text": "the players such that a set of basic axioms are satisfied?",
        "start": 456.44,
        "duration": 4.48
    },
    {
        "text": "It turns out there's only one way to do it.",
        "start": 460.92,
        "duration": 2.42
    },
    {
        "text": "It came from values that are now",
        "start": 463.34,
        "duration": 1.95
    },
    {
        "text": "called the Shapley values after Lloyd Shapley.",
        "start": 465.29,
        "duration": 2.37
    },
    {
        "text": "Lloyd Shapley did a lot of great work in",
        "start": 467.66,
        "duration": 1.83
    },
    {
        "text": "game theory and allocation and things like this,",
        "start": 469.49,
        "duration": 2.13
    },
    {
        "text": "and actually got a Nobel Prize in 2012.",
        "start": 471.62,
        "duration": 1.35
    },
    {
        "text": "So this is based on some solid math.",
        "start": 472.97,
        "duration": 2.795
    },
    {
        "text": "So going back to our data scientist,",
        "start": 475.765,
        "duration": 2.305
    },
    {
        "text": "you can say, \"That's great.",
        "start": 478.07,
        "duration": 1.575
    },
    {
        "text": "I'm really convinced by this.",
        "start": 479.645,
        "duration": 1.305
    },
    {
        "text": "I think I should use these values.",
        "start": 480.95,
        "duration": 1.56
    },
    {
        "text": "How do I compute them?\" Well, it turns",
        "start": 482.51,
        "duration": 1.87
    },
    {
        "text": "out that result from averaging,",
        "start": 484.38,
        "duration": 2.34
    },
    {
        "text": "just we did talk about before,",
        "start": 486.72,
        "duration": 1.19
    },
    {
        "text": "using a single ordering, but we have to do it over all orderings.",
        "start": 487.91,
        "duration": 2.915
    },
    {
        "text": "Because it's computationally intractable,",
        "start": 490.825,
        "duration": 1.805
    },
    {
        "text": "and it's even worse because it's",
        "start": 492.63,
        "duration": 1.13
    },
    {
        "text": "NP-hard, if you know what that means.",
        "start": 493.76,
        "duration": 2.415
    },
    {
        "text": "So that's where the real challenge in these values lie,",
        "start": 496.175,
        "duration": 4.335
    },
    {
        "text": "it's how to compute these things efficiently.",
        "start": 500.51,
        "duration": 2.24
    },
    {
        "text": "I'm not going to go into the algorithms that allow us to do that,",
        "start": 502.75,
        "duration": 2.41
    },
    {
        "text": "but that's at the heart of what is in",
        "start": 505.16,
        "duration": 1.44
    },
    {
        "text": "the SHAP package and the research behind it.",
        "start": 506.6,
        "duration": 2.435
    },
    {
        "text": "It is designed to enable us to compute",
        "start": 509.035,
        "duration": 2.8
    },
    {
        "text": "these very well-justified values",
        "start": 511.835,
        "duration": 2.925
    },
    {
        "text": "efficiently and effectively on real datasets.",
        "start": 514.76,
        "duration": 3.515
    },
    {
        "text": "If we do that for extra boost,",
        "start": 518.275,
        "duration": 1.645
    },
    {
        "text": "we can actually solve it in polynomial time very quickly, exactly.",
        "start": 519.92,
        "duration": 3.96
    },
    {
        "text": "Now we see that the SHAP values no longer exactly matched",
        "start": 523.88,
        "duration": 3.39
    },
    {
        "text": "the partial dependence plot because",
        "start": 527.27,
        "duration": 1.98
    },
    {
        "text": "they're accounting for these interaction effects.",
        "start": 529.25,
        "duration": 2.205
    },
    {
        "text": "Because when you look at a partial dependence plot,",
        "start": 531.455,
        "duration": 2.055
    },
    {
        "text": "you're losing all the higher-order interacting information",
        "start": 533.51,
        "duration": 3.645
    },
    {
        "text": "about ands and ors that your model may be doing.",
        "start": 537.155,
        "duration": 3.255
    },
    {
        "text": "But the SHAP values account for that and",
        "start": 540.41,
        "duration": 1.77
    },
    {
        "text": "then drop that credit down onto each feature.",
        "start": 542.18,
        "duration": 3.37
    },
    {
        "text": "So you'll see vertical dispersion when you",
        "start": 545.55,
        "duration": 2.15
    },
    {
        "text": "plot many people's SHAP values for a feature.",
        "start": 547.7,
        "duration": 3.0
    },
    {
        "text": "So let's do this for",
        "start": 550.7,
        "duration": 1.92
    },
    {
        "text": "a particular feature to dive into this credit history.",
        "start": 552.62,
        "duration": 3.33
    },
    {
        "text": "Because remember, it was a bit surprising that credit history",
        "start": 555.95,
        "duration": 2.145
    },
    {
        "text": "hurt John's credit score.",
        "start": 558.095,
        "duration": 3.69
    },
    {
        "text": "So if we plot credit history",
        "start": 561.785,
        "duration": 1.485
    },
    {
        "text": "versus the SHAP value for that credit history,",
        "start": 563.27,
        "duration": 2.07
    },
    {
        "text": "we get a dot for every person.",
        "start": 565.34,
        "duration": 1.92
    },
    {
        "text": "Again, a little bit of vertical dispersion",
        "start": 567.26,
        "duration": 1.5
    },
    {
        "text": "from the interaction effects.",
        "start": 568.76,
        "duration": 1.47
    },
    {
        "text": "Then if we look at John,",
        "start": 570.23,
        "duration": 1.29
    },
    {
        "text": "we'll see he's in this tail",
        "start": 571.52,
        "duration": 1.32
    },
    {
        "text": "here at the end where he's got a really,",
        "start": 572.84,
        "duration": 1.32
    },
    {
        "text": "really long credit history.",
        "start": 574.16,
        "duration": 1.685
    },
    {
        "text": "It doesn't take too long before you",
        "start": 575.845,
        "duration": 2.125
    },
    {
        "text": "realize that debugging was super important",
        "start": 577.97,
        "duration": 1.92
    },
    {
        "text": "because this model was actually",
        "start": 579.89,
        "duration": 1.31
    },
    {
        "text": "identifying retirement age individuals",
        "start": 581.2,
        "duration": 2.14
    },
    {
        "text": "based on their long credit histories and",
        "start": 583.34,
        "duration": 1.365
    },
    {
        "text": "increase the risk of default for them.",
        "start": 584.705,
        "duration": 2.63
    },
    {
        "text": "This is a big problem because age is a protected class.",
        "start": 587.335,
        "duration": 3.175
    },
    {
        "text": "So this essentially found",
        "start": 590.51,
        "duration": 1.74
    },
    {
        "text": "that credit history with a complicated model",
        "start": 592.25,
        "duration": 2.49
    },
    {
        "text": "was able to pull out credit history and use it as a proxy for age.",
        "start": 594.74,
        "duration": 4.955
    },
    {
        "text": "So it's really important to explain and debug your models.",
        "start": 599.695,
        "duration": 3.735
    },
    {
        "text": "So we've talked a little bit about",
        "start": 603.43,
        "duration": 2.02
    },
    {
        "text": "just one example of explainable AI in",
        "start": 605.45,
        "duration": 1.77
    },
    {
        "text": "practice and debugging and at model exploration.",
        "start": 607.22,
        "duration": 3.435
    },
    {
        "text": "But I'd like to highlight the fact",
        "start": 610.655,
        "duration": 1.515
    },
    {
        "text": "that there are so many other ways to",
        "start": 612.17,
        "duration": 1.29
    },
    {
        "text": "use these types of interpretability in your workflow.",
        "start": 613.46,
        "duration": 3.05
    },
    {
        "text": "You can monitor models by explaining their error over time.",
        "start": 616.51,
        "duration": 3.43
    },
    {
        "text": "You can encode prior beliefs about models and then",
        "start": 619.94,
        "duration": 3.12
    },
    {
        "text": "use explanations to actually control your model train process.",
        "start": 623.06,
        "duration": 3.465
    },
    {
        "text": "You can talk about customer retention by",
        "start": 626.525,
        "duration": 2.235
    },
    {
        "text": "supporting call centers by explaining why a churn model was done.",
        "start": 628.76,
        "duration": 7.17
    },
    {
        "text": "We've applied this in decision support for medical settings.",
        "start": 635.93,
        "duration": 3.93
    },
    {
        "text": "There's a lot of places where human risk oversight of",
        "start": 639.86,
        "duration": 2.58
    },
    {
        "text": "machine learning models is enhanced with explanations.",
        "start": 642.44,
        "duration": 2.685
    },
    {
        "text": "In regulatory compliance, there's a lot of need for",
        "start": 645.125,
        "duration": 3.24
    },
    {
        "text": "these type of transparency for consumer explanations.",
        "start": 648.365,
        "duration": 3.455
    },
    {
        "text": "It can help you better understand",
        "start": 651.82,
        "duration": 1.84
    },
    {
        "text": "anti-discrimination as we just showed an example of,",
        "start": 653.66,
        "duration": 3.0
    },
    {
        "text": "and of course, risk-management,",
        "start": 656.66,
        "duration": 1.74
    },
    {
        "text": "where you're understanding what your model will",
        "start": 658.4,
        "duration": 1.86
    },
    {
        "text": "do when economic conditions change.",
        "start": 660.26,
        "duration": 2.52
    },
    {
        "text": "All the more important right now.",
        "start": 662.78,
        "duration": 1.74
    },
    {
        "text": "Even in scientific discovery,",
        "start": 664.52,
        "duration": 1.875
    },
    {
        "text": "you can find that explanations can",
        "start": 666.395,
        "duration": 2.085
    },
    {
        "text": "help you better do population subtyping,",
        "start": 668.48,
        "duration": 2.985
    },
    {
        "text": "extremely helpful for pattern discovery and",
        "start": 671.465,
        "duration": 2.745
    },
    {
        "text": "even signal recovery of things inside, things like DNA.",
        "start": 674.21,
        "duration": 3.945
    },
    {
        "text": "All of these things are just tons of",
        "start": 678.155,
        "duration": 3.645
    },
    {
        "text": "downstream applications of interpretable ML",
        "start": 681.8,
        "duration": 3.165
    },
    {
        "text": "that's supported by these types of tools and research,",
        "start": 684.965,
        "duration": 2.295
    },
    {
        "text": "and I hope that this insight has given you a bit of a taste",
        "start": 687.26,
        "duration": 3.0
    },
    {
        "text": "and excitement for what can be done here. Thanks.",
        "start": 690.26,
        "duration": 4.05
    },
    {
        "text": "[MUSIC]",
        "start": 694.31,
        "duration": 12.2
    }
]