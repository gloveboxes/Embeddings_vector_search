[
    {
        "text": "you're not going to want to miss this",
        "start": 0.03,
        "duration": 3.389
    },
    {
        "text": "next episode of the AI show where you",
        "start": 1.02,
        "duration": 5.04
    },
    {
        "text": "and takes us to the next level of data",
        "start": 3.419,
        "duration": 4.861
    },
    {
        "text": "preparation and even shows us a little",
        "start": 6.06,
        "duration": 5.249
    },
    {
        "text": "GUI that is super slick make sure you",
        "start": 8.28,
        "duration": 5.359
    },
    {
        "text": "tune in",
        "start": 11.309,
        "duration": 2.33
    },
    {
        "text": "hello and welcome to this episode of the",
        "start": 18.64,
        "duration": 4.149
    },
    {
        "text": "AI show the third and final installment",
        "start": 20.93,
        "duration": 5.43
    },
    {
        "text": "of the series we're like you and flashed",
        "start": 22.789,
        "duration": 5.911
    },
    {
        "text": "up this GUI all out of nowhere and I",
        "start": 26.36,
        "duration": 3.78
    },
    {
        "text": "didn't have enough time to ask you just",
        "start": 28.7,
        "duration": 2.91
    },
    {
        "text": "moved on to this other thing",
        "start": 30.14,
        "duration": 3.75
    },
    {
        "text": "why don't you fill us in but we've been",
        "start": 31.61,
        "duration": 3.449
    },
    {
        "text": "talk about data preparation why don't",
        "start": 33.89,
        "duration": 2.61
    },
    {
        "text": "you summarize the last two things we've",
        "start": 35.059,
        "duration": 3.511
    },
    {
        "text": "talked about then get into this okay so",
        "start": 36.5,
        "duration": 3.3
    },
    {
        "text": "we started off and we talked about data",
        "start": 38.57,
        "duration": 3.0
    },
    {
        "text": "preparation just as a general problem in",
        "start": 39.8,
        "duration": 3.24
    },
    {
        "text": "data science and what makes it unique in",
        "start": 41.57,
        "duration": 3.6
    },
    {
        "text": "the data science and AI space from",
        "start": 43.04,
        "duration": 3.6
    },
    {
        "text": "perhaps the bi space or some other",
        "start": 45.17,
        "duration": 3.959
    },
    {
        "text": "places then we talked about specific",
        "start": 46.64,
        "duration": 4.559
    },
    {
        "text": "approaches to that and showed how it is",
        "start": 49.129,
        "duration": 4.021
    },
    {
        "text": "unique similar it's a little time",
        "start": 51.199,
        "duration": 3.57
    },
    {
        "text": "consuming a little experimental and so",
        "start": 53.15,
        "duration": 3.57
    },
    {
        "text": "then we showed some new stuff that we",
        "start": 54.769,
        "duration": 4.051
    },
    {
        "text": "brought out at ignite in preview to",
        "start": 56.72,
        "duration": 3.75
    },
    {
        "text": "allow you to simplify a job you'll be",
        "start": 58.82,
        "duration": 3.54
    },
    {
        "text": "more accurate move a little faster on a",
        "start": 60.47,
        "duration": 3.869
    },
    {
        "text": "few things make some things a lot",
        "start": 62.36,
        "duration": 3.21
    },
    {
        "text": "simpler like the ability to write single",
        "start": 64.339,
        "duration": 3.091
    },
    {
        "text": "code base at once cross-platform deal",
        "start": 65.57,
        "duration": 3.51
    },
    {
        "text": "with files which are bigger than memory",
        "start": 67.43,
        "duration": 3.39
    },
    {
        "text": "a whole bunch of stuff like that and I",
        "start": 69.08,
        "duration": 3.93
    },
    {
        "text": "did taunt you right - very yes I was",
        "start": 70.82,
        "duration": 4.95
    },
    {
        "text": "doing my super exciting API demos and",
        "start": 73.01,
        "duration": 4.2
    },
    {
        "text": "you were falling asleep on me so I just",
        "start": 75.77,
        "duration": 2.94
    },
    {
        "text": "slipped in a quick GUI there because I",
        "start": 77.21,
        "duration": 3.21
    },
    {
        "text": "know you're a GUI sort of guy flash that",
        "start": 78.71,
        "duration": 3.96
    },
    {
        "text": "you buy every man okay pretty good so",
        "start": 80.42,
        "duration": 4.26
    },
    {
        "text": "let's go chew even more good listener",
        "start": 82.67,
        "duration": 4.83
    },
    {
        "text": "yeah okay so this is the platform a",
        "start": 84.68,
        "duration": 4.86
    },
    {
        "text": "cross-platform client that runs on Mac",
        "start": 87.5,
        "duration": 3.99
    },
    {
        "text": "Windows Linux we're going to go through",
        "start": 89.54,
        "duration": 3.18
    },
    {
        "text": "the same exercise you went through with",
        "start": 91.49,
        "duration": 2.34
    },
    {
        "text": "the API but we'll do it with the GUI",
        "start": 92.72,
        "duration": 3.21
    },
    {
        "text": "cool so here I might say going to choose",
        "start": 93.83,
        "duration": 3.84
    },
    {
        "text": "the file type I want but you can see",
        "start": 95.93,
        "duration": 3.69
    },
    {
        "text": "here I've got a choice between CSV txt",
        "start": 97.67,
        "duration": 3.63
    },
    {
        "text": "Jason we don't make you choose those as",
        "start": 99.62,
        "duration": 3.96
    },
    {
        "text": "explicit types here I have a choice of",
        "start": 101.3,
        "duration": 4.98
    },
    {
        "text": "picky files locally blob data label and",
        "start": 103.58,
        "duration": 3.87
    },
    {
        "text": "I have the choice of choosing a file or",
        "start": 106.28,
        "duration": 3.39
    },
    {
        "text": "a directory so in this case because the",
        "start": 107.45,
        "duration": 4.14
    },
    {
        "text": "directory might have like a hundred of",
        "start": 109.67,
        "duration": 3.96
    },
    {
        "text": "the same file type for example you sir",
        "start": 111.59,
        "duration": 3.36
    },
    {
        "text": "are a genius you have earned your pay",
        "start": 113.63,
        "duration": 3.75
    },
    {
        "text": "for the day today yes let's go ahead and",
        "start": 114.95,
        "duration": 4.38
    },
    {
        "text": "take that deep data file that we're",
        "start": 117.38,
        "duration": 3.27
    },
    {
        "text": "looking at earlier and you notice this",
        "start": 119.33,
        "duration": 2.55
    },
    {
        "text": "is detecting up in the top right hand",
        "start": 120.65,
        "duration": 3.09
    },
    {
        "text": "corner that's just learning a program",
        "start": 121.88,
        "duration": 4.56
    },
    {
        "text": "about how to read the data just like you",
        "start": 123.74,
        "duration": 4.739
    },
    {
        "text": "saw that little pause in the API when I",
        "start": 126.44,
        "duration": 3.989
    },
    {
        "text": "was using it earlier so we're just using",
        "start": 128.479,
        "duration": 3.51
    },
    {
        "text": "the same approach is the API and so you",
        "start": 130.429,
        "duration": 3.571
    },
    {
        "text": "can see we've detected it's a delimited",
        "start": 131.989,
        "duration": 4.981
    },
    {
        "text": "file it has custom it's going to skip",
        "start": 134.0,
        "duration": 4.379
    },
    {
        "text": "the first three lines so all the same",
        "start": 136.97,
        "duration": 3.42
    },
    {
        "text": "stuff that you saw before here's what it",
        "start": 138.379,
        "duration": 3.811
    },
    {
        "text": "could have detected this as wasn't fixed",
        "start": 140.39,
        "duration": 3.209
    },
    {
        "text": "with wasn't plain text wasn't Jason so",
        "start": 142.19,
        "duration": 2.67
    },
    {
        "text": "we did that alter detection stuff you",
        "start": 143.599,
        "duration": 2.851
    },
    {
        "text": "saw we get a quick preview of the data",
        "start": 144.86,
        "duration": 3.419
    },
    {
        "text": "it's the same file as before believe me",
        "start": 146.45,
        "duration": 3.689
    },
    {
        "text": "you get to override the data type gases",
        "start": 148.279,
        "duration": 2.91
    },
    {
        "text": "that we make here you can see it's",
        "start": 150.139,
        "duration": 1.651
    },
    {
        "text": "mostly",
        "start": 151.189,
        "duration": 2.731
    },
    {
        "text": "strings numbers it's what we're seeing",
        "start": 151.79,
        "duration": 3.809
    },
    {
        "text": "and that's cool that you actually give",
        "start": 153.92,
        "duration": 4.349
    },
    {
        "text": "some examples to verify because one of",
        "start": 155.599,
        "duration": 4.14
    },
    {
        "text": "the things is like if this stuff is done",
        "start": 158.269,
        "duration": 3.511
    },
    {
        "text": "magically that's great but what I'm",
        "start": 159.739,
        "duration": 4.56
    },
    {
        "text": "looking at I'm like okay it got it right",
        "start": 161.78,
        "duration": 4.079
    },
    {
        "text": "it's like a little bit more common like",
        "start": 164.299,
        "duration": 3.66
    },
    {
        "text": "for example the date one might be wrong",
        "start": 165.859,
        "duration": 3.6
    },
    {
        "text": "but it's only because the format's kind",
        "start": 167.959,
        "duration": 4.081
    },
    {
        "text": "of off but it did a pretty good job yeah",
        "start": 169.459,
        "duration": 4.62
    },
    {
        "text": "it's generally pretty good and if",
        "start": 172.04,
        "duration": 4.11
    },
    {
        "text": "there's enough bad stuff in there then",
        "start": 174.079,
        "duration": 3.091
    },
    {
        "text": "it's gonna default to something like",
        "start": 176.15,
        "duration": 2.13
    },
    {
        "text": "string and then let you clean it up",
        "start": 177.17,
        "duration": 1.56
    },
    {
        "text": "later",
        "start": 178.28,
        "duration": 1.92
    },
    {
        "text": "you don't want stuff being auto fixed",
        "start": 178.73,
        "duration": 3.06
    },
    {
        "text": "you can't wanna know what what was going",
        "start": 180.2,
        "duration": 3.33
    },
    {
        "text": "on with it and the way through we added",
        "start": 181.79,
        "duration": 3.119
    },
    {
        "text": "this one extra column here called path",
        "start": 183.53,
        "duration": 3.39
    },
    {
        "text": "and that helps you if you're recurring",
        "start": 184.909,
        "duration": 4.05
    },
    {
        "text": "over directories because sometimes the",
        "start": 186.92,
        "duration": 4.11
    },
    {
        "text": "path to the file and the file name are",
        "start": 188.959,
        "duration": 3.661
    },
    {
        "text": "actually part of the data you ultimately",
        "start": 191.03,
        "duration": 3.45
    },
    {
        "text": "want so if you're doing IOT the device",
        "start": 192.62,
        "duration": 3.539
    },
    {
        "text": "ID is probably either in the file name",
        "start": 194.48,
        "duration": 3.659
    },
    {
        "text": "or in the path the day the month the",
        "start": 196.159,
        "duration": 4.05
    },
    {
        "text": "year the time I guess so you want to be",
        "start": 198.139,
        "duration": 4.35
    },
    {
        "text": "able to put that in as a column and then",
        "start": 200.209,
        "duration": 3.75
    },
    {
        "text": "you can use our extraction technology to",
        "start": 202.489,
        "duration": 3.06
    },
    {
        "text": "say well pull the month I pull a day out",
        "start": 203.959,
        "duration": 3.331
    },
    {
        "text": "we're all having to write some reg X",
        "start": 205.549,
        "duration": 3.181
    },
    {
        "text": "thing to pars where it came from we just",
        "start": 207.29,
        "duration": 3.3
    },
    {
        "text": "capture the fully qualified path to the",
        "start": 208.73,
        "duration": 3.659
    },
    {
        "text": "file whatever information is in there",
        "start": 210.59,
        "duration": 3.599
    },
    {
        "text": "you can then use normal data prep",
        "start": 212.389,
        "duration": 3.69
    },
    {
        "text": "techniques to get that data out this",
        "start": 214.189,
        "duration": 3.3
    },
    {
        "text": "makes sense when you're actually loading",
        "start": 216.079,
        "duration": 3.81
    },
    {
        "text": "up a folder of files because that file",
        "start": 217.489,
        "duration": 4.86
    },
    {
        "text": "name is part of the data exactly okay",
        "start": 219.889,
        "duration": 4.02
    },
    {
        "text": "well it's not I mean it can be nested",
        "start": 222.349,
        "duration": 3.0
    },
    {
        "text": "and levels deep in some of these cases",
        "start": 223.909,
        "duration": 3.061
    },
    {
        "text": "now here's one of the big things",
        "start": 225.349,
        "duration": 4.741
    },
    {
        "text": "although we can load much more data than",
        "start": 226.97,
        "duration": 4.049
    },
    {
        "text": "you would normally be able to do on a",
        "start": 230.09,
        "duration": 2.039
    },
    {
        "text": "desktop far bigger than memory",
        "start": 231.019,
        "duration": 3.241
    },
    {
        "text": "there's even when you're doing that",
        "start": 232.129,
        "duration": 3.6
    },
    {
        "text": "there's a performance responsiveness and",
        "start": 234.26,
        "duration": 2.219
    },
    {
        "text": "if you do this very iterative",
        "start": 235.729,
        "duration": 2.22
    },
    {
        "text": "interactive way of working with data",
        "start": 236.479,
        "duration": 3.271
    },
    {
        "text": "which people have in the data science",
        "start": 237.949,
        "duration": 3.331
    },
    {
        "text": "world I've gotten so used to with repple",
        "start": 239.75,
        "duration": 3.09
    },
    {
        "text": "environments definitely one of the big",
        "start": 241.28,
        "duration": 3.629
    },
    {
        "text": "changes from doing ETL or ELT where",
        "start": 242.84,
        "duration": 4.289
    },
    {
        "text": "you're not really interactive then you",
        "start": 244.909,
        "duration": 4.2
    },
    {
        "text": "know even if I've got a million rows I",
        "start": 247.129,
        "duration": 3.72
    },
    {
        "text": "might done sample it down to 50,000 so I",
        "start": 249.109,
        "duration": 3.511
    },
    {
        "text": "can just move fast right right so here",
        "start": 250.849,
        "duration": 2.941
    },
    {
        "text": "we allow you to create a sample will",
        "start": 252.62,
        "duration": 3.119
    },
    {
        "text": "default to top 10,000 and the trick we",
        "start": 253.79,
        "duration": 3.36
    },
    {
        "text": "do here is by default will give you the",
        "start": 255.739,
        "duration": 3.03
    },
    {
        "text": "top because we can just stream that",
        "start": 257.15,
        "duration": 2.85
    },
    {
        "text": "straight off the file and you can get",
        "start": 258.769,
        "duration": 3.06
    },
    {
        "text": "going super fast if you want a random",
        "start": 260.0,
        "duration": 3.78
    },
    {
        "text": "sample we have to make a pass over all",
        "start": 261.829,
        "duration": 3.691
    },
    {
        "text": "the data generally a truly random sample",
        "start": 263.78,
        "duration": 3.78
    },
    {
        "text": "so what we'll do here is we allow you to",
        "start": 265.52,
        "duration": 4.019
    },
    {
        "text": "create other samples here we'll say I",
        "start": 267.56,
        "duration": 4.139
    },
    {
        "text": "can have top I have random an R and a",
        "start": 269.539,
        "duration": 3.66
    },
    {
        "text": "percentage we're working on stratified",
        "start": 271.699,
        "duration": 3.75
    },
    {
        "text": "sampling take a different approach we'll",
        "start": 273.199,
        "duration": 4.291
    },
    {
        "text": "kick it off asynchronously so you still",
        "start": 275.449,
        "duration": 3.75
    },
    {
        "text": "get moving really quickly in the tool by",
        "start": 277.49,
        "duration": 3.78
    },
    {
        "text": "doing the top n but then we'll create",
        "start": 279.199,
        "duration": 3.421
    },
    {
        "text": "your other samples for you and you can",
        "start": 281.27,
        "duration": 3.42
    },
    {
        "text": "kick off like ten or twelve samples here",
        "start": 282.62,
        "duration": 2.96
    },
    {
        "text": "if you want to with differ",
        "start": 284.69,
        "duration": 2.569
    },
    {
        "text": "rules against them that works both",
        "start": 285.58,
        "duration": 3.329
    },
    {
        "text": "locally and remotely in the remote case",
        "start": 287.259,
        "duration": 2.88
    },
    {
        "text": "if I was reading this from blob storage",
        "start": 288.909,
        "duration": 3.57
    },
    {
        "text": "we'd kick off a bunch of Scala code on a",
        "start": 290.139,
        "duration": 3.631
    },
    {
        "text": "spark cluster that you'd have to tell us",
        "start": 292.479,
        "duration": 2.46
    },
    {
        "text": "which spark cluster you wanted to use",
        "start": 293.77,
        "duration": 2.91
    },
    {
        "text": "take off those asynchronous jobs they",
        "start": 294.939,
        "duration": 2.7
    },
    {
        "text": "would go ahead and generate everything",
        "start": 296.68,
        "duration": 3.03
    },
    {
        "text": "we pull it down we cache it then you can",
        "start": 297.639,
        "duration": 3.18
    },
    {
        "text": "just make use of in the UI and I'll show",
        "start": 299.71,
        "duration": 2.28
    },
    {
        "text": "you how to change samples in a second",
        "start": 300.819,
        "duration": 3.271
    },
    {
        "text": "that's cool because like generally like",
        "start": 301.99,
        "duration": 5.13
    },
    {
        "text": "I always do top stuff top end right",
        "start": 304.09,
        "duration": 5.25
    },
    {
        "text": "but I'm always worried that is this",
        "start": 307.12,
        "duration": 5.43
    },
    {
        "text": "sample indicative of the distribution or",
        "start": 309.34,
        "duration": 6.06
    },
    {
        "text": "the process that generates these cuts of",
        "start": 312.55,
        "duration": 4.44
    },
    {
        "text": "data and I worry that like if I'm only",
        "start": 315.4,
        "duration": 3.6
    },
    {
        "text": "look at the first 100 or 2000 I'm gonna",
        "start": 316.99,
        "duration": 3.54
    },
    {
        "text": "have a problem but this lets me look at",
        "start": 319.0,
        "duration": 3.18
    },
    {
        "text": "all sorts of different combinations yeah",
        "start": 320.53,
        "duration": 3.24
    },
    {
        "text": "and we're actually working on some tech",
        "start": 322.18,
        "duration": 3.66
    },
    {
        "text": "for the tool and for the API it's not",
        "start": 323.77,
        "duration": 2.67
    },
    {
        "text": "available right now",
        "start": 325.84,
        "duration": 2.85
    },
    {
        "text": "which allow you to diff your samples",
        "start": 326.44,
        "duration": 4.5
    },
    {
        "text": "from a statistical perspective and allow",
        "start": 328.69,
        "duration": 3.479
    },
    {
        "text": "you to take a look at one or two samples",
        "start": 330.94,
        "duration": 2.909
    },
    {
        "text": "and say okay you know this is the full",
        "start": 332.169,
        "duration": 3.481
    },
    {
        "text": "data set because in reality the most",
        "start": 333.849,
        "duration": 3.72
    },
    {
        "text": "important sample is full yeah because",
        "start": 335.65,
        "duration": 2.97
    },
    {
        "text": "you want to compare every one of your",
        "start": 337.569,
        "duration": 2.491
    },
    {
        "text": "samples against the full data set in the",
        "start": 338.62,
        "duration": 3.78
    },
    {
        "text": "cloud in a big data set case and almost",
        "start": 340.06,
        "duration": 3.27
    },
    {
        "text": "compare yourself against those who",
        "start": 342.4,
        "duration": 2.16
    },
    {
        "text": "always compare the different samples you",
        "start": 343.33,
        "duration": 3.059
    },
    {
        "text": "may want your samples to use different",
        "start": 344.56,
        "duration": 3.24
    },
    {
        "text": "distributions for a very specific reason",
        "start": 346.389,
        "duration": 3.511
    },
    {
        "text": "you may want them to follow along the",
        "start": 347.8,
        "duration": 2.729
    },
    {
        "text": "choice is yours",
        "start": 349.9,
        "duration": 2.31
    },
    {
        "text": "so provides some visual diffing tools",
        "start": 350.529,
        "duration": 3.091
    },
    {
        "text": "we're working with some folks at MSR and",
        "start": 352.21,
        "duration": 3.0
    },
    {
        "text": "some folks on our team are working on",
        "start": 353.62,
        "duration": 3.03
    },
    {
        "text": "some of us as well shewill to visually",
        "start": 355.21,
        "duration": 2.97
    },
    {
        "text": "take a look at your samples and then",
        "start": 356.65,
        "duration": 2.819
    },
    {
        "text": "look at the statistics about them and",
        "start": 358.18,
        "duration": 2.579
    },
    {
        "text": "determine if you have the right samples",
        "start": 359.469,
        "duration": 2.611
    },
    {
        "text": "you're working on and this is super",
        "start": 360.759,
        "duration": 3.301
    },
    {
        "text": "useful because like usually I'm running",
        "start": 362.08,
        "duration": 3.269
    },
    {
        "text": "these machine learning models and each",
        "start": 364.06,
        "duration": 3.96
    },
    {
        "text": "epoch takes like 12 hours but if I can",
        "start": 365.349,
        "duration": 4.56
    },
    {
        "text": "pull a sample that is indicative of the",
        "start": 368.02,
        "duration": 4.44
    },
    {
        "text": "overall over the over the overall",
        "start": 369.909,
        "duration": 3.75
    },
    {
        "text": "distribution I can actually run",
        "start": 372.46,
        "duration": 2.579
    },
    {
        "text": "experiments on something that",
        "start": 373.659,
        "duration": 3.6
    },
    {
        "text": "statistically is similar to the overall",
        "start": 375.039,
        "duration": 3.93
    },
    {
        "text": "thing yeah that means really cool the",
        "start": 377.259,
        "duration": 4.231
    },
    {
        "text": "workflow here would be generate 1 or n",
        "start": 378.969,
        "duration": 5.19
    },
    {
        "text": "samples evolved really quickly during",
        "start": 381.49,
        "duration": 4.38
    },
    {
        "text": "the day on those smaller samples Jun",
        "start": 384.159,
        "duration": 3.391
    },
    {
        "text": "which family of algorithms are you going",
        "start": 385.87,
        "duration": 3.659
    },
    {
        "text": "to use and which features are going to",
        "start": 387.55,
        "duration": 3.03
    },
    {
        "text": "use some of the stuff that we showed in",
        "start": 389.529,
        "duration": 2.431
    },
    {
        "text": "a Titanic data set a couple of episodes",
        "start": 390.58,
        "duration": 3.809
    },
    {
        "text": "ago you go decide which approach you're",
        "start": 391.96,
        "duration": 4.23
    },
    {
        "text": "taking right your hypothesis play around",
        "start": 394.389,
        "duration": 3.18
    },
    {
        "text": "with a bunch of that what's the range",
        "start": 396.19,
        "duration": 2.43
    },
    {
        "text": "that I want to pass for the",
        "start": 397.569,
        "duration": 2.371
    },
    {
        "text": "regularization rate to logistic",
        "start": 398.62,
        "duration": 2.639
    },
    {
        "text": "regression or something like that and",
        "start": 399.94,
        "duration": 4.11
    },
    {
        "text": "then run on the full data set overnight",
        "start": 401.259,
        "duration": 4.62
    },
    {
        "text": "but you're now much more informed our",
        "start": 404.05,
        "duration": 3.299
    },
    {
        "text": "hypothesis is much more likely to be",
        "start": 405.879,
        "duration": 3.811
    },
    {
        "text": "correct when you go spin that mm no to",
        "start": 407.349,
        "duration": 3.87
    },
    {
        "text": "cluster which is going to cost you a",
        "start": 409.69,
        "duration": 3.569
    },
    {
        "text": "couple of dollars yeah to be able to go",
        "start": 411.219,
        "duration": 5.76
    },
    {
        "text": "do it dollars love it ok so we're going",
        "start": 413.259,
        "duration": 4.71
    },
    {
        "text": "to do sampling we'll take the easy",
        "start": 416.979,
        "duration": 2.461
    },
    {
        "text": "example this for this and when",
        "start": 417.969,
        "duration": 2.881
    },
    {
        "text": "they include the path column but we",
        "start": 419.44,
        "duration": 2.49
    },
    {
        "text": "don't need it because it's a single file",
        "start": 420.85,
        "duration": 3.3
    },
    {
        "text": "and it's going to go ahead and drop us",
        "start": 421.93,
        "duration": 4.44
    },
    {
        "text": "in we get a sheet centric view but I can",
        "start": 424.15,
        "duration": 3.93
    },
    {
        "text": "also flip here and I can take a look at",
        "start": 426.37,
        "duration": 3.36
    },
    {
        "text": "the metrics but we call the metrics view",
        "start": 428.08,
        "duration": 3.21
    },
    {
        "text": "so here you can immediately see for",
        "start": 429.73,
        "duration": 3.18
    },
    {
        "text": "every single column which has now been",
        "start": 431.29,
        "duration": 3.21
    },
    {
        "text": "turned into a row I get all those",
        "start": 432.91,
        "duration": 3.45
    },
    {
        "text": "statistics that you saw from the API so",
        "start": 434.5,
        "duration": 3.96
    },
    {
        "text": "I can see Nan's and quartiles I can see",
        "start": 436.36,
        "duration": 3.78
    },
    {
        "text": "a default visualization for everything",
        "start": 438.46,
        "duration": 3.69
    },
    {
        "text": "so for all the string columns we get",
        "start": 440.14,
        "duration": 3.6
    },
    {
        "text": "frequency tables for number columns we",
        "start": 442.15,
        "duration": 3.42
    },
    {
        "text": "get histograms so the idea here is",
        "start": 443.74,
        "duration": 3.66
    },
    {
        "text": "develop an understanding help you",
        "start": 445.57,
        "duration": 3.75
    },
    {
        "text": "develop your hypothesis about the data",
        "start": 447.4,
        "duration": 4.38
    },
    {
        "text": "using visualization and statistics which",
        "start": 449.32,
        "duration": 3.33
    },
    {
        "text": "is something that I've talked about a",
        "start": 451.78,
        "duration": 2.73
    },
    {
        "text": "couple of times before and you can",
        "start": 452.65,
        "duration": 3.0
    },
    {
        "text": "choose which metrics you want and we're",
        "start": 454.51,
        "duration": 2.22
    },
    {
        "text": "constantly adding more metrics as",
        "start": 455.65,
        "duration": 2.91
    },
    {
        "text": "customers asked for them and it's",
        "start": 456.73,
        "duration": 3.06
    },
    {
        "text": "something that's fairly easy for us to",
        "start": 458.56,
        "duration": 2.7
    },
    {
        "text": "do so we'll go ahead and we'll flip back",
        "start": 459.79,
        "duration": 4.5
    },
    {
        "text": "so we flip back to the data here so here",
        "start": 461.26,
        "duration": 4.8
    },
    {
        "text": "we've got no real transformations of",
        "start": 464.29,
        "duration": 3.09
    },
    {
        "text": "data we just got the basic load these",
        "start": 466.06,
        "duration": 2.49
    },
    {
        "text": "are the building blocks at the load",
        "start": 467.38,
        "duration": 3.81
    },
    {
        "text": "let's go ahead and show off that derived",
        "start": 468.55,
        "duration": 4.74
    },
    {
        "text": "column by example that I showed at the",
        "start": 471.19,
        "duration": 4.38
    },
    {
        "text": "API level let's show a much more complex",
        "start": 473.29,
        "duration": 4.17
    },
    {
        "text": "one take a look at this founded column",
        "start": 475.57,
        "duration": 3.33
    },
    {
        "text": "here this is an actual table from",
        "start": 477.46,
        "duration": 3.96
    },
    {
        "text": "Wikipedia and it uses pretty much every",
        "start": 478.9,
        "duration": 4.35
    },
    {
        "text": "single date format you could think of",
        "start": 481.42,
        "duration": 3.3
    },
    {
        "text": "and that you probably couldn't think of",
        "start": 483.25,
        "duration": 4.08
    },
    {
        "text": "yeah all in the same table it's giving",
        "start": 484.72,
        "duration": 4.44
    },
    {
        "text": "me heartburn yeah okay so let's fall",
        "start": 487.33,
        "duration": 3.12
    },
    {
        "text": "solve your heartburn a little bit so",
        "start": 489.16,
        "duration": 2.58
    },
    {
        "text": "here we're just going to go derive : by",
        "start": 490.45,
        "duration": 4.11
    },
    {
        "text": "example I'm going to give an example we",
        "start": 491.74,
        "duration": 3.96
    },
    {
        "text": "do exactly the same thing that we did",
        "start": 494.56,
        "duration": 2.79
    },
    {
        "text": "from the API perspective except here I'm",
        "start": 495.7,
        "duration": 4.469
    },
    {
        "text": "gonna do fabric 21 of 1973 but it's",
        "start": 497.35,
        "duration": 4.53
    },
    {
        "text": "filling stuff out for you so we're",
        "start": 500.169,
        "duration": 3.301
    },
    {
        "text": "already able to understand the data",
        "start": 501.88,
        "duration": 2.97
    },
    {
        "text": "because we're looking at the data we're",
        "start": 503.47,
        "duration": 2.73
    },
    {
        "text": "looking for the format's we're looking",
        "start": 504.85,
        "duration": 2.73
    },
    {
        "text": "for what you might be headed towards as",
        "start": 506.2,
        "duration": 3.36
    },
    {
        "text": "a canonical format and so we can provide",
        "start": 507.58,
        "duration": 4.38
    },
    {
        "text": "data intellisense for you here so let's",
        "start": 509.56,
        "duration": 3.539
    },
    {
        "text": "go ahead and we'll select that as our",
        "start": 511.96,
        "duration": 2.25
    },
    {
        "text": "format so it's going to go off remember",
        "start": 513.099,
        "duration": 2.851
    },
    {
        "text": "generate a whole bunch of programs in",
        "start": 514.21,
        "duration": 3.69
    },
    {
        "text": "memory pick the best ones through",
        "start": 515.95,
        "duration": 3.48
    },
    {
        "text": "scoring and then apply it to the data",
        "start": 517.9,
        "duration": 3.3
    },
    {
        "text": "set now this time unlike being able to",
        "start": 519.43,
        "duration": 4.14
    },
    {
        "text": "determine that you're a mr. we weren't",
        "start": 521.2,
        "duration": 3.6
    },
    {
        "text": "able to get them all correctly the data",
        "start": 523.57,
        "duration": 3.93
    },
    {
        "text": "quality bar says you got 26 correct but",
        "start": 524.8,
        "duration": 4.23
    },
    {
        "text": "you've got 14 dolls in here we generate",
        "start": 527.5,
        "duration": 3.33
    },
    {
        "text": "a null if we can't generate a meaningful",
        "start": 529.03,
        "duration": 3.9
    },
    {
        "text": "program in this particular case so let",
        "start": 530.83,
        "duration": 3.36
    },
    {
        "text": "me just ignore land I thought I'd switch",
        "start": 532.93,
        "duration": 2.909
    },
    {
        "text": "that off you get a lot of technology so",
        "start": 534.19,
        "duration": 3.6
    },
    {
        "text": "what do we do now well what we do is we",
        "start": 535.839,
        "duration": 3.571
    },
    {
        "text": "give more examples this is just like",
        "start": 537.79,
        "duration": 3.09
    },
    {
        "text": "giving more data to an algorithm or",
        "start": 539.41,
        "duration": 3.45
    },
    {
        "text": "tuning and now what you're doing inside",
        "start": 540.88,
        "duration": 3.75
    },
    {
        "text": "the I space but we can be smarter than",
        "start": 542.86,
        "duration": 3.36
    },
    {
        "text": "that so we'll go into advanced mode here",
        "start": 544.63,
        "duration": 3.12
    },
    {
        "text": "and what we're able to do is show",
        "start": 546.22,
        "duration": 3.45
    },
    {
        "text": "suggested examples and what these are",
        "start": 547.75,
        "duration": 4.86
    },
    {
        "text": "are examples which represent a cluster",
        "start": 549.67,
        "duration": 3.54
    },
    {
        "text": "Oracle",
        "start": 552.61,
        "duration": 2.61
    },
    {
        "text": "of problem that we weren't able to",
        "start": 553.21,
        "duration": 3.81
    },
    {
        "text": "generate a program for we're basically",
        "start": 555.22,
        "duration": 3.93
    },
    {
        "text": "saying if you give me an example for",
        "start": 557.02,
        "duration": 5.25
    },
    {
        "text": "this case I will be able to fix in other",
        "start": 559.15,
        "duration": 5.67
    },
    {
        "text": "cases inside of the data start school so",
        "start": 562.27,
        "duration": 3.45
    },
    {
        "text": "we're using AI",
        "start": 564.82,
        "duration": 2.73
    },
    {
        "text": "to make the AI smarter to make your data",
        "start": 565.72,
        "duration": 5.01
    },
    {
        "text": "clean for AI that's a lot of AI going",
        "start": 567.55,
        "duration": 4.8
    },
    {
        "text": "everywhere I love it I think I need a",
        "start": 570.73,
        "duration": 3.66
    },
    {
        "text": "t-shirt with inception on it with Clippy",
        "start": 572.35,
        "duration": 3.15
    },
    {
        "text": "on it so let's go ahead and give another",
        "start": 574.39,
        "duration": 2.88
    },
    {
        "text": "example here and you can see if you look",
        "start": 575.5,
        "duration": 4.11
    },
    {
        "text": "at this format that the initial format",
        "start": 577.27,
        "duration": 4.47
    },
    {
        "text": "example I gave and this one is two input",
        "start": 579.61,
        "duration": 3.9
    },
    {
        "text": "variables they're far enough apart that",
        "start": 581.74,
        "duration": 3.09
    },
    {
        "text": "the algorithm may not be able to get the",
        "start": 583.51,
        "duration": 2.76
    },
    {
        "text": "right answer so let's go ahead we'll",
        "start": 584.83,
        "duration": 2.73
    },
    {
        "text": "select this one and we'll promote it to",
        "start": 586.27,
        "duration": 2.85
    },
    {
        "text": "be an actual example so now we're going",
        "start": 587.56,
        "duration": 3.96
    },
    {
        "text": "to go regenerate our program pick a",
        "start": 589.12,
        "duration": 3.72
    },
    {
        "text": "winner again and if you look at the data",
        "start": 591.52,
        "duration": 3.6
    },
    {
        "text": "quality bar we're now down to only 13",
        "start": 592.84,
        "duration": 4.59
    },
    {
        "text": "cases where we're generating a null so",
        "start": 595.12,
        "duration": 3.24
    },
    {
        "text": "we're getting better so I'm gonna",
        "start": 597.43,
        "duration": 2.31
    },
    {
        "text": "provide an example for this one here",
        "start": 598.36,
        "duration": 3.57
    },
    {
        "text": "which is January and this one it doesn't",
        "start": 599.74,
        "duration": 3.54
    },
    {
        "text": "actually able to do and tell sense cuz",
        "start": 601.93,
        "duration": 3.06
    },
    {
        "text": "it's like why is there a letter A at the",
        "start": 603.28,
        "duration": 4.62
    },
    {
        "text": "end I'm so confused and we'll do that",
        "start": 604.99,
        "duration": 7.2
    },
    {
        "text": "one and then now we're down to only 11",
        "start": 607.9,
        "duration": 6.15
    },
    {
        "text": "in this particular case so we've gone",
        "start": 612.19,
        "duration": 4.23
    },
    {
        "text": "from 40-plus incorrect examples down to",
        "start": 614.05,
        "duration": 3.81
    },
    {
        "text": "only 11 the thing that's interesting",
        "start": 616.42,
        "duration": 2.7
    },
    {
        "text": "about there was 11 if you look at the",
        "start": 617.86,
        "duration": 3.18
    },
    {
        "text": "suggested example is they're all cases",
        "start": 619.12,
        "duration": 4.35
    },
    {
        "text": "where there's a single digit year in",
        "start": 621.04,
        "duration": 4.32
    },
    {
        "text": "this particular case right and so from",
        "start": 623.47,
        "duration": 4.32
    },
    {
        "text": "that perspective Oh what do I want to do",
        "start": 625.36,
        "duration": 4.89
    },
    {
        "text": "with that data now I can do something",
        "start": 627.79,
        "duration": 4.89
    },
    {
        "text": "like 1st of January I put a sentinel",
        "start": 630.25,
        "duration": 4.5
    },
    {
        "text": "value in but if my data is the least bit",
        "start": 632.68,
        "duration": 4.14
    },
    {
        "text": "time series sensitive in any way shape",
        "start": 634.75,
        "duration": 3.63
    },
    {
        "text": "or form it could be a problem now I'm",
        "start": 636.82,
        "duration": 2.79
    },
    {
        "text": "actually going to be forcing a",
        "start": 638.38,
        "duration": 2.97
    },
    {
        "text": "distribution on my data that's not",
        "start": 639.61,
        "duration": 3.0
    },
    {
        "text": "actually something that I want to go",
        "start": 641.35,
        "duration": 3.48
    },
    {
        "text": "ahead and do so in this particular case",
        "start": 642.61,
        "duration": 3.9
    },
    {
        "text": "what I'm actually going to do is turn",
        "start": 644.83,
        "duration": 3.69
    },
    {
        "text": "round and say you know what I'm not",
        "start": 646.51,
        "duration": 3.93
    },
    {
        "text": "gonna take those nails because just",
        "start": 648.52,
        "duration": 3.84
    },
    {
        "text": "coalescing to null was a feature by",
        "start": 650.44,
        "duration": 3.39
    },
    {
        "text": "itself because otherwise if I had to do",
        "start": 652.36,
        "duration": 3.81
    },
    {
        "text": "either the look for a year only you know",
        "start": 653.83,
        "duration": 3.57
    },
    {
        "text": "write some expression that looked for a",
        "start": 656.17,
        "duration": 3.84
    },
    {
        "text": "year or do the old VB trick which is",
        "start": 657.4,
        "duration": 4.95
    },
    {
        "text": "trim string the date represented as a",
        "start": 660.01,
        "duration": 3.48
    },
    {
        "text": "string count the number of characters",
        "start": 662.35,
        "duration": 2.94
    },
    {
        "text": "and if there's only four in there then",
        "start": 663.49,
        "duration": 3.66
    },
    {
        "text": "it's a single year type approach to",
        "start": 665.29,
        "duration": 3.78
    },
    {
        "text": "write still works yeah but it's not",
        "start": 667.15,
        "duration": 3.36
    },
    {
        "text": "exactly the most scientific so in this",
        "start": 669.07,
        "duration": 4.05
    },
    {
        "text": "case we'll take the null and I'm just",
        "start": 670.51,
        "duration": 3.78
    },
    {
        "text": "going to pop up here a couple of",
        "start": 673.12,
        "duration": 2.88
    },
    {
        "text": "visualizations to show soups it's not",
        "start": 674.29,
        "duration": 3.81
    },
    {
        "text": "what I meant to do at all let's pop up a",
        "start": 676.0,
        "duration": 3.48
    },
    {
        "text": "couple of visualizations here to help us",
        "start": 678.1,
        "duration": 2.58
    },
    {
        "text": "understand what's going on with our data",
        "start": 679.48,
        "duration": 2.85
    },
    {
        "text": "so here I'm gonna bring up a histogram",
        "start": 680.68,
        "duration": 3.15
    },
    {
        "text": "of this column and will bring up a",
        "start": 682.33,
        "duration": 3.09
    },
    {
        "text": "histogram of this particular column over",
        "start": 683.83,
        "duration": 3.24
    },
    {
        "text": "here",
        "start": 685.42,
        "duration": 3.51
    },
    {
        "text": "okay so these are the two numeric",
        "start": 687.07,
        "duration": 3.42
    },
    {
        "text": "columns in this data set so now we're",
        "start": 688.93,
        "duration": 2.339
    },
    {
        "text": "going to do is I want to get rid of",
        "start": 690.49,
        "duration": 1.92
    },
    {
        "text": "those nulls because that's going to",
        "start": 691.269,
        "duration": 2.82
    },
    {
        "text": "freak out some algorithms so we'll",
        "start": 692.41,
        "duration": 3.27
    },
    {
        "text": "simply so a filter I could do a replace",
        "start": 694.089,
        "duration": 3.24
    },
    {
        "text": "when we filter in this case two values",
        "start": 695.68,
        "duration": 4.649
    },
    {
        "text": "which are not now so now if you take a",
        "start": 697.329,
        "duration": 4.62
    },
    {
        "text": "look at the histograms the histograms",
        "start": 700.329,
        "duration": 2.94
    },
    {
        "text": "have two colors on them they have a blue",
        "start": 701.949,
        "duration": 3.271
    },
    {
        "text": "and a gray the blue is the current value",
        "start": 703.269,
        "duration": 4.38
    },
    {
        "text": "the gray is the previous value before",
        "start": 705.22,
        "duration": 3.84
    },
    {
        "text": "the current state change we call this",
        "start": 707.649,
        "duration": 3.661
    },
    {
        "text": "the halo effect what you now get is",
        "start": 709.06,
        "duration": 4.829
    },
    {
        "text": "immediate feedback that the change you",
        "start": 711.31,
        "duration": 4.469
    },
    {
        "text": "made did make changes to the",
        "start": 713.889,
        "duration": 3.211
    },
    {
        "text": "distribution and you can see from this",
        "start": 715.779,
        "duration": 3.3
    },
    {
        "text": "data set I'm not too worried about the",
        "start": 717.1,
        "duration": 3.57
    },
    {
        "text": "change to my data I think my hypothesis",
        "start": 719.079,
        "duration": 3.421
    },
    {
        "text": "to eliminate nulls is actually a good",
        "start": 720.67,
        "duration": 4.289
    },
    {
        "text": "one in this particular case because the",
        "start": 722.5,
        "duration": 4.17
    },
    {
        "text": "data is still roughly the same shape as",
        "start": 724.959,
        "duration": 2.43
    },
    {
        "text": "it was before",
        "start": 726.67,
        "duration": 2.669
    },
    {
        "text": "I'm not horribly offended by it in this",
        "start": 727.389,
        "duration": 3.481
    },
    {
        "text": "particular case and that's actually",
        "start": 729.339,
        "duration": 4.081
    },
    {
        "text": "really cool because sometimes when",
        "start": 730.87,
        "duration": 4.5
    },
    {
        "text": "you're making these kinds of changes you",
        "start": 733.42,
        "duration": 4.229
    },
    {
        "text": "don't really have a sense for what did",
        "start": 735.37,
        "duration": 2.88
    },
    {
        "text": "it do",
        "start": 737.649,
        "duration": 2.67
    },
    {
        "text": "what I'm looking at these distributions",
        "start": 738.25,
        "duration": 4.35
    },
    {
        "text": "I can see that the histogram heights",
        "start": 740.319,
        "duration": 5.281
    },
    {
        "text": "have changed but they've changed equally",
        "start": 742.6,
        "duration": 5.429
    },
    {
        "text": "across the entire distribution so that",
        "start": 745.6,
        "duration": 4.53
    },
    {
        "text": "those particular samples that I removed",
        "start": 748.029,
        "duration": 4.951
    },
    {
        "text": "are not going to affect the distribution",
        "start": 750.13,
        "duration": 4.53
    },
    {
        "text": "of the phenomena that we're trying to",
        "start": 752.98,
        "duration": 3.06
    },
    {
        "text": "measure it's exactly that's pretty cool",
        "start": 754.66,
        "duration": 2.909
    },
    {
        "text": "and so this is all about the thing I",
        "start": 756.04,
        "duration": 2.76
    },
    {
        "text": "said in the very beginning of the first",
        "start": 757.569,
        "duration": 2.221
    },
    {
        "text": "of these three shows that we've done",
        "start": 758.8,
        "duration": 3.269
    },
    {
        "text": "which is data prep is an iterative",
        "start": 759.79,
        "duration": 4.89
    },
    {
        "text": "interactive hypothesis driven way to",
        "start": 762.069,
        "duration": 4.32
    },
    {
        "text": "solve problems I'm going to come up with",
        "start": 764.68,
        "duration": 3.029
    },
    {
        "text": "a hypothesis hey I should eliminate",
        "start": 766.389,
        "duration": 2.551
    },
    {
        "text": "these nulls yeah",
        "start": 767.709,
        "duration": 3.541
    },
    {
        "text": "like any scientific method I have to",
        "start": 768.94,
        "duration": 4.44
    },
    {
        "text": "evaluate my hypothesis you just",
        "start": 771.25,
        "duration": 3.81
    },
    {
        "text": "evaluated my hypothesis and gave me the",
        "start": 773.38,
        "duration": 3.48
    },
    {
        "text": "thumbs up that it was okay so I'm gonna",
        "start": 775.06,
        "duration": 3.45
    },
    {
        "text": "move on and do something else now with",
        "start": 776.86,
        "duration": 3.659
    },
    {
        "text": "my data but you could have turn around",
        "start": 778.51,
        "duration": 3.93
    },
    {
        "text": "and said I don't like a hypothesis you",
        "start": 780.519,
        "duration": 5.01
    },
    {
        "text": "and don't go back do not pass go and do",
        "start": 782.44,
        "duration": 5.129
    },
    {
        "text": "not get you $200 and I would simply go",
        "start": 785.529,
        "duration": 3.481
    },
    {
        "text": "over here and eliminate that filter",
        "start": 787.569,
        "duration": 3.12
    },
    {
        "text": "column I can edit it and go back and",
        "start": 789.01,
        "duration": 3.72
    },
    {
        "text": "change it if I want to that's cool and",
        "start": 790.689,
        "duration": 3.991
    },
    {
        "text": "so this is just the way data works and",
        "start": 792.73,
        "duration": 3.18
    },
    {
        "text": "we could do you know you've seen the",
        "start": 794.68,
        "duration": 2.94
    },
    {
        "text": "list of transforms which exist in manual",
        "start": 795.91,
        "duration": 3.33
    },
    {
        "text": "I'm not gonna go through all those what",
        "start": 797.62,
        "duration": 3.48
    },
    {
        "text": "we can just do that you apply you know",
        "start": 799.24,
        "duration": 3.39
    },
    {
        "text": "you attack a certain number of columns",
        "start": 801.1,
        "duration": 3.599
    },
    {
        "text": "at a time or one column at a time get",
        "start": 802.63,
        "duration": 3.209
    },
    {
        "text": "that into a state where you need it",
        "start": 804.699,
        "duration": 3.33
    },
    {
        "text": "apply some of the features that we saw",
        "start": 805.839,
        "duration": 3.93
    },
    {
        "text": "from the API or even that we saw when I",
        "start": 808.029,
        "duration": 3.571
    },
    {
        "text": "was doing the pure code centric approach",
        "start": 809.769,
        "duration": 3.031
    },
    {
        "text": "to the beginning all those are available",
        "start": 811.6,
        "duration": 2.52
    },
    {
        "text": "here you just keep running through these",
        "start": 812.8,
        "duration": 3.21
    },
    {
        "text": "and evolving things as you go forwards",
        "start": 814.12,
        "duration": 3.63
    },
    {
        "text": "over time but that essentially is the",
        "start": 816.01,
        "duration": 3.629
    },
    {
        "text": "way that the GUI works and it's all the",
        "start": 817.75,
        "duration": 3.45
    },
    {
        "text": "same capability that we have in the",
        "start": 819.639,
        "duration": 4.531
    },
    {
        "text": "but now I can take this if I want to I",
        "start": 821.2,
        "duration": 4.35
    },
    {
        "text": "can serialize it out to that deep rep",
        "start": 824.17,
        "duration": 3.27
    },
    {
        "text": "format that we saw in the last one and I",
        "start": 825.55,
        "duration": 3.21
    },
    {
        "text": "can go load it up on a spark cluster",
        "start": 827.44,
        "duration": 4.2
    },
    {
        "text": "just using that you know deep rep that",
        "start": 828.76,
        "duration": 5.91
    },
    {
        "text": "we saw in the API session and it will",
        "start": 831.64,
        "duration": 4.11
    },
    {
        "text": "generate the code remember the",
        "start": 834.67,
        "duration": 2.58
    },
    {
        "text": "architecture when I'm running here I'm",
        "start": 835.75,
        "duration": 2.88
    },
    {
        "text": "running on c-sharp course CLR when I'm",
        "start": 837.25,
        "duration": 2.88
    },
    {
        "text": "running up and SPARC I'm gonna generate",
        "start": 838.63,
        "duration": 3.72
    },
    {
        "text": "Scala code and it'll scale and if this",
        "start": 840.13,
        "duration": 3.51
    },
    {
        "text": "is a particular set of transformations",
        "start": 842.35,
        "duration": 3.27
    },
    {
        "text": "which will scale out it'll scale those",
        "start": 843.64,
        "duration": 4.32
    },
    {
        "text": "out and we're very careful about how we",
        "start": 845.62,
        "duration": 4.08
    },
    {
        "text": "actually build some of our",
        "start": 847.96,
        "duration": 3.3
    },
    {
        "text": "transformations for a long time for",
        "start": 849.7,
        "duration": 3.39
    },
    {
        "text": "example we didn't have a median in our",
        "start": 851.26,
        "duration": 4.68
    },
    {
        "text": "aggregator because well median is always",
        "start": 853.09,
        "duration": 4.89
    },
    {
        "text": "estimated in a distributed cluster like",
        "start": 855.94,
        "duration": 3.51
    },
    {
        "text": "a spark cluster and we didn't want to",
        "start": 857.98,
        "duration": 2.76
    },
    {
        "text": "catch people by surprise but we've",
        "start": 859.45,
        "duration": 2.34
    },
    {
        "text": "actually talked to a bunch of customers",
        "start": 860.74,
        "duration": 2.97
    },
    {
        "text": "like if you call it estimated median I",
        "start": 861.79,
        "duration": 3.93
    },
    {
        "text": "see in the drop-down would be okay with",
        "start": 863.71,
        "duration": 3.27
    },
    {
        "text": "using it but if you said you were able",
        "start": 865.72,
        "duration": 2.46
    },
    {
        "text": "to do a median and claimed you could do",
        "start": 866.98,
        "duration": 3.42
    },
    {
        "text": "a distributed median we would call you",
        "start": 868.18,
        "duration": 4.38
    },
    {
        "text": "on it because spark doesn't support at",
        "start": 870.4,
        "duration": 4.8
    },
    {
        "text": "actual 100% correct distributed median",
        "start": 872.56,
        "duration": 4.23
    },
    {
        "text": "in this particular case well house is",
        "start": 875.2,
        "duration": 3.93
    },
    {
        "text": "estimated right and so we've been very",
        "start": 876.79,
        "duration": 4.77
    },
    {
        "text": "careful to really optimize the way that",
        "start": 879.13,
        "duration": 4.92
    },
    {
        "text": "we do things so that that they only",
        "start": 881.56,
        "duration": 5.43
    },
    {
        "text": "really work when we can scale them up",
        "start": 884.05,
        "duration": 5.73
    },
    {
        "text": "and at Fantana let me show one other",
        "start": 886.99,
        "duration": 5.04
    },
    {
        "text": "thing here before we call up so this is",
        "start": 889.78,
        "duration": 3.39
    },
    {
        "text": "some technology from Microsoft Research",
        "start": 892.03,
        "duration": 3.96
    },
    {
        "text": "this is in this particular case a list",
        "start": 893.17,
        "duration": 3.93
    },
    {
        "text": "of cities so we'll go ahead and we'll",
        "start": 895.99,
        "duration": 2.49
    },
    {
        "text": "take a look at a value account here and",
        "start": 897.1,
        "duration": 3.63
    },
    {
        "text": "which is a frequency table and I know",
        "start": 898.48,
        "duration": 3.54
    },
    {
        "text": "that there I see more cases here what",
        "start": 900.73,
        "duration": 2.91
    },
    {
        "text": "you see at the minimum we have San",
        "start": 902.02,
        "duration": 3.33
    },
    {
        "text": "Francisco listed twice with different",
        "start": 903.64,
        "duration": 3.3
    },
    {
        "text": "cases in it let's go ahead and bump this",
        "start": 905.35,
        "duration": 5.82
    },
    {
        "text": "to 20 examples in here and by the way",
        "start": 906.94,
        "duration": 5.34
    },
    {
        "text": "any of these visualizations you want to",
        "start": 911.17,
        "duration": 2.34
    },
    {
        "text": "see them in more detail you simply bring",
        "start": 912.28,
        "duration": 2.64
    },
    {
        "text": "them up into the main view like this in",
        "start": 913.51,
        "duration": 2.64
    },
    {
        "text": "this case you have 20 and that little",
        "start": 914.92,
        "duration": 2.55
    },
    {
        "text": "thumbnail is not very useful you can see",
        "start": 916.15,
        "duration": 3.12
    },
    {
        "text": "here that we've got San Diego a couple",
        "start": 917.47,
        "duration": 3.27
    },
    {
        "text": "of times San Jose a couple times San",
        "start": 919.27,
        "duration": 2.97
    },
    {
        "text": "Francisco a couple times so this is a",
        "start": 920.74,
        "duration": 3.9
    },
    {
        "text": "pretty common problem that we see inside",
        "start": 922.24,
        "duration": 5.46
    },
    {
        "text": "of data sits slightly inconsistent you",
        "start": 924.64,
        "duration": 4.68
    },
    {
        "text": "know the strings are not right you use",
        "start": 927.7,
        "duration": 2.88
    },
    {
        "text": "uppercase because you like to show to",
        "start": 929.32,
        "duration": 4.2
    },
    {
        "text": "people or it'sh so I'm much more polite",
        "start": 930.58,
        "duration": 4.08
    },
    {
        "text": "than that I used to correct",
        "start": 933.52,
        "duration": 3.09
    },
    {
        "text": "capitalization and so let's take that",
        "start": 934.66,
        "duration": 4.38
    },
    {
        "text": "city column and we'll go ahead and we'll",
        "start": 936.61,
        "duration": 4.47
    },
    {
        "text": "apply a fuzzy grouping to it and so",
        "start": 939.04,
        "duration": 3.39
    },
    {
        "text": "fuzzy grouping in this particular case",
        "start": 941.08,
        "duration": 3.21
    },
    {
        "text": "is using a clustering technique and what",
        "start": 942.43,
        "duration": 3.03
    },
    {
        "text": "it's doing is trying to cluster the",
        "start": 944.29,
        "duration": 2.7
    },
    {
        "text": "values and so here we set it off on the",
        "start": 945.46,
        "duration": 3.48
    },
    {
        "text": "data set using statistics again of the",
        "start": 946.99,
        "duration": 3.21
    },
    {
        "text": "data I'm going to see if I'm four",
        "start": 948.94,
        "duration": 2.97
    },
    {
        "text": "clusters and this particular case is",
        "start": 950.2,
        "duration": 3.09
    },
    {
        "text": "okay there's four clusters one for each",
        "start": 951.91,
        "duration": 2.58
    },
    {
        "text": "of the cities and here's how",
        "start": 953.29,
        "duration": 3.39
    },
    {
        "text": "to map all the values into that now I",
        "start": 954.49,
        "duration": 3.75
    },
    {
        "text": "can take any one of these clusters and I",
        "start": 956.68,
        "duration": 3.06
    },
    {
        "text": "can remove it and then force it to",
        "start": 958.24,
        "duration": 3.719
    },
    {
        "text": "recompute the clusters I can change what",
        "start": 959.74,
        "duration": 3.719
    },
    {
        "text": "the centroid in the cluster is by just",
        "start": 961.959,
        "duration": 3.541
    },
    {
        "text": "renaming the string here I can take any",
        "start": 963.459,
        "duration": 3.511
    },
    {
        "text": "one of these individual entries and",
        "start": 965.5,
        "duration": 3.66
    },
    {
        "text": "remove it and from the cluster will add",
        "start": 966.97,
        "duration": 3.6
    },
    {
        "text": "the ability to manually move nodes",
        "start": 969.16,
        "duration": 2.82
    },
    {
        "text": "between clusters at some point I could",
        "start": 970.57,
        "duration": 2.88
    },
    {
        "text": "also change the similarity threshold",
        "start": 971.98,
        "duration": 2.729
    },
    {
        "text": "here and if I bump this down to 0.6",
        "start": 973.45,
        "duration": 3.24
    },
    {
        "text": "you'll see that the number of clusters",
        "start": 974.709,
        "duration": 4.411
    },
    {
        "text": "disappears and so Eric dropped from a",
        "start": 976.69,
        "duration": 3.81
    },
    {
        "text": "four to A two because we're changing how",
        "start": 979.12,
        "duration": 3.6
    },
    {
        "text": "accurate the the measurement has to be",
        "start": 980.5,
        "duration": 3.959
    },
    {
        "text": "in terms of the similarity we found that",
        "start": 982.72,
        "duration": 3.42
    },
    {
        "text": "somewhere in the point 7.8 region is a",
        "start": 984.459,
        "duration": 3.361
    },
    {
        "text": "good place to start and we'll say in",
        "start": 986.14,
        "duration": 3.18
    },
    {
        "text": "this particular case we'll do a point",
        "start": 987.82,
        "duration": 3.09
    },
    {
        "text": "eight so we'll go ahead and we'll simply",
        "start": 989.32,
        "duration": 5.01
    },
    {
        "text": "apply that and you'll see now we end up",
        "start": 990.91,
        "duration": 6.66
    },
    {
        "text": "with a second column over here which has",
        "start": 994.33,
        "duration": 5.34
    },
    {
        "text": "got the canonical values just with the",
        "start": 997.57,
        "duration": 4.139
    },
    {
        "text": "default name it's cool if I go ahead and",
        "start": 999.67,
        "duration": 4.919
    },
    {
        "text": "apply a frequency table to this one",
        "start": 1001.709,
        "duration": 4.831
    },
    {
        "text": "you'll see that we've brought it down to",
        "start": 1004.589,
        "duration": 3.81
    },
    {
        "text": "just the four from the twenty values",
        "start": 1006.54,
        "duration": 4.169
    },
    {
        "text": "that we had one mouse click supervised",
        "start": 1008.399,
        "duration": 4.711
    },
    {
        "text": "the action done then that'll work scaled",
        "start": 1010.709,
        "duration": 3.871
    },
    {
        "text": "out this because it running like k-means",
        "start": 1013.11,
        "duration": 3.51
    },
    {
        "text": "underneath or something we are way more",
        "start": 1014.58,
        "duration": 4.98
    },
    {
        "text": "sophisticated than that it's a jacquard",
        "start": 1016.62,
        "duration": 4.29
    },
    {
        "text": "similarity score is actually what's",
        "start": 1019.56,
        "duration": 2.96
    },
    {
        "text": "being calculated using a hierarchical",
        "start": 1020.91,
        "duration": 3.99
    },
    {
        "text": "clustering it's actually this technology",
        "start": 1022.52,
        "duration": 3.429
    },
    {
        "text": "Microsoft Research has had for a really",
        "start": 1024.9,
        "duration": 3.48
    },
    {
        "text": "long time or the team that build this a",
        "start": 1025.949,
        "duration": 3.841
    },
    {
        "text": "guy called surgery surgery in a guy",
        "start": 1028.38,
        "duration": 3.689
    },
    {
        "text": "called Vivek are two guys I've worked",
        "start": 1029.79,
        "duration": 3.24
    },
    {
        "text": "with from my days in the sequel server",
        "start": 1032.069,
        "duration": 2.911
    },
    {
        "text": "team I worked on sequel server 7 2000",
        "start": 1033.03,
        "duration": 3.779
    },
    {
        "text": "2005 2008 and it's actually part of",
        "start": 1034.98,
        "duration": 3.18
    },
    {
        "text": "sequel server integration services and",
        "start": 1036.809,
        "duration": 3.03
    },
    {
        "text": "some other tools at Microsoft but we",
        "start": 1038.16,
        "duration": 2.76
    },
    {
        "text": "worked with them and they were like hey",
        "start": 1039.839,
        "duration": 2.461
    },
    {
        "text": "we're thinking about maybe pushing the",
        "start": 1040.92,
        "duration": 2.82
    },
    {
        "text": "boundaries of the research little bit so",
        "start": 1042.3,
        "duration": 2.67
    },
    {
        "text": "they came up with a new algorithm and",
        "start": 1043.74,
        "duration": 2.01
    },
    {
        "text": "they've done a distributed",
        "start": 1044.97,
        "duration": 2.04
    },
    {
        "text": "implementation of some of this stuff as",
        "start": 1045.75,
        "duration": 3.45
    },
    {
        "text": "well which is hard to do hey this stuff",
        "start": 1047.01,
        "duration": 4.29
    },
    {
        "text": "is hard to do so it's using unsupervised",
        "start": 1049.2,
        "duration": 4.89
    },
    {
        "text": "learning to D dupe data that you're",
        "start": 1051.3,
        "duration": 5.91
    },
    {
        "text": "gonna be using for machine learning yeah",
        "start": 1054.09,
        "duration": 5.61
    },
    {
        "text": "so there's recurring theme here we used",
        "start": 1057.21,
        "duration": 4.86
    },
    {
        "text": "machine learning to read the files",
        "start": 1059.7,
        "duration": 4.38
    },
    {
        "text": "correctly we use machine learning to",
        "start": 1062.07,
        "duration": 3.96
    },
    {
        "text": "help the machine learning to do the",
        "start": 1064.08,
        "duration": 3.18
    },
    {
        "text": "drive : by example cuz we're",
        "start": 1066.03,
        "duration": 3.33
    },
    {
        "text": "recommending those values which have got",
        "start": 1067.26,
        "duration": 3.87
    },
    {
        "text": "the clusters associated with them and",
        "start": 1069.36,
        "duration": 4.17
    },
    {
        "text": "here we are again so the goal here is",
        "start": 1071.13,
        "duration": 3.99
    },
    {
        "text": "really to take as much of the smart",
        "start": 1073.53,
        "duration": 2.82
    },
    {
        "text": "technology that we're lucky enough to",
        "start": 1075.12,
        "duration": 3.51
    },
    {
        "text": "have kicking around in various parts of",
        "start": 1076.35,
        "duration": 4.74
    },
    {
        "text": "the Microsoft world put it into a single",
        "start": 1078.63,
        "duration": 4.59
    },
    {
        "text": "API put it into a single graphical tool",
        "start": 1081.09,
        "duration": 4.079
    },
    {
        "text": "and a lot of people to be much more",
        "start": 1083.22,
        "duration": 3.39
    },
    {
        "text": "efficient in terms of how they do their",
        "start": 1085.169,
        "duration": 3.271
    },
    {
        "text": "data prep and allow the smart",
        "start": 1086.61,
        "duration": 4.08
    },
    {
        "text": "HD guys to go focus on modeling and all",
        "start": 1088.44,
        "duration": 5.28
    },
    {
        "text": "the hyper parameters and shooting all",
        "start": 1090.69,
        "duration": 4.8
    },
    {
        "text": "that kind of stuff instead of messing",
        "start": 1093.72,
        "duration": 2.79
    },
    {
        "text": "around with dates which is what they",
        "start": 1095.49,
        "duration": 2.67
    },
    {
        "text": "spend too much time doing today I've",
        "start": 1096.51,
        "duration": 2.97
    },
    {
        "text": "been messing around with dates for ever",
        "start": 1098.16,
        "duration": 3.03
    },
    {
        "text": "in this kind of data sets thanks so much",
        "start": 1099.48,
        "duration": 3.0
    },
    {
        "text": "for your time my friend my pleasure",
        "start": 1101.19,
        "duration": 2.79
    },
    {
        "text": "thanks so much for watching we're",
        "start": 1102.48,
        "duration": 3.24
    },
    {
        "text": "learning all about data preparation and",
        "start": 1103.98,
        "duration": 3.09
    },
    {
        "text": "it's new tool what is this tool call by",
        "start": 1105.72,
        "duration": 2.97
    },
    {
        "text": "the way Microsoft data prep user",
        "start": 1107.07,
        "duration": 2.67
    },
    {
        "text": "interfaces its world calling for now",
        "start": 1108.69,
        "duration": 2.04
    },
    {
        "text": "we'll come up with something cool at",
        "start": 1109.74,
        "duration": 2.7
    },
    {
        "text": "some point in the future and we'll put a",
        "start": 1110.73,
        "duration": 3.21
    },
    {
        "text": "link below so you can go download it try",
        "start": 1112.44,
        "duration": 3.0
    },
    {
        "text": "it today he wants to get all the good",
        "start": 1113.94,
        "duration": 2.97
    },
    {
        "text": "feedback so make sure you send it over",
        "start": 1115.44,
        "duration": 3.03
    },
    {
        "text": "thanks so much for watching and we'll",
        "start": 1116.91,
        "duration": 2.89
    },
    {
        "text": "see you next time take care",
        "start": 1118.47,
        "duration": 10.41
    },
    {
        "text": "[Music]",
        "start": 1119.8,
        "duration": 9.08
    }
]