[
    {
        "text": "you're not going to want to miss this",
        "start": 0.03,
        "duration": 3.599
    },
    {
        "text": "episode of the AI show where Chris",
        "start": 1.5,
        "duration": 4.2
    },
    {
        "text": "Lauren takes us through how to do",
        "start": 3.629,
        "duration": 4.831
    },
    {
        "text": "experiments in AI using machine learning",
        "start": 5.7,
        "duration": 5.069
    },
    {
        "text": "inside of Azure machine learning service",
        "start": 8.46,
        "duration": 5.46
    },
    {
        "text": "using specifically visual studio code",
        "start": 10.769,
        "duration": 6.95
    },
    {
        "text": "tools for AI see that",
        "start": 13.92,
        "duration": 3.799
    },
    {
        "text": "welcome to this brand new and shiny",
        "start": 23.21,
        "duration": 4.6
    },
    {
        "text": "episode of the AI show we're actually",
        "start": 25.74,
        "duration": 3.84
    },
    {
        "text": "gonna do a machine learning problem",
        "start": 27.81,
        "duration": 4.02
    },
    {
        "text": "suite with some of the tools we talked",
        "start": 29.58,
        "duration": 3.78
    },
    {
        "text": "about in one of the previous shows so",
        "start": 31.83,
        "duration": 2.61
    },
    {
        "text": "make sure you check that one out too",
        "start": 33.36,
        "duration": 2.91
    },
    {
        "text": "I've got here my friend Chris Lauren how",
        "start": 34.44,
        "duration": 3.39
    },
    {
        "text": "you doing buddy good thanks for having",
        "start": 36.27,
        "duration": 3.81
    },
    {
        "text": "me fantastic so we talked a little about",
        "start": 37.83,
        "duration": 5.61
    },
    {
        "text": "our machine learning service we talked",
        "start": 40.08,
        "duration": 4.74
    },
    {
        "text": "about the workspace and all the good",
        "start": 43.44,
        "duration": 2.97
    },
    {
        "text": "doodads that were in there we also",
        "start": 44.82,
        "duration": 3.93
    },
    {
        "text": "talked about how vigil studio code tools",
        "start": 46.41,
        "duration": 4.469
    },
    {
        "text": "for AI allows you to do some stuff but I",
        "start": 48.75,
        "duration": 3.87
    },
    {
        "text": "thought I figured it would be better to",
        "start": 50.879,
        "duration": 3.78
    },
    {
        "text": "just like go through an actual problem",
        "start": 52.62,
        "duration": 4.59
    },
    {
        "text": "so as a data scientist let's pick a",
        "start": 54.659,
        "duration": 4.29
    },
    {
        "text": "random problem like the one we always",
        "start": 57.21,
        "duration": 3.419
    },
    {
        "text": "pick when we do these kind of demos yeah",
        "start": 58.949,
        "duration": 3.57
    },
    {
        "text": "it's completely random random like let's",
        "start": 60.629,
        "duration": 5.011
    },
    {
        "text": "do 10 digit recognition perfect you know",
        "start": 62.519,
        "duration": 4.771
    },
    {
        "text": "I feel like we can do that so it sounds",
        "start": 65.64,
        "duration": 2.82
    },
    {
        "text": "like a hard problem and no one's ever",
        "start": 67.29,
        "duration": 2.4
    },
    {
        "text": "done so long is it not my handwriting",
        "start": 68.46,
        "duration": 2.94
    },
    {
        "text": "that's right that's right so let's do",
        "start": 69.69,
        "duration": 3.69
    },
    {
        "text": "this how would you go about solving that",
        "start": 71.4,
        "duration": 4.2
    },
    {
        "text": "problem as a data scientist and then I",
        "start": 73.38,
        "duration": 4.23
    },
    {
        "text": "want you to show us how the tooling is",
        "start": 75.6,
        "duration": 3.809
    },
    {
        "text": "gonna help support that so how where",
        "start": 77.61,
        "duration": 2.25
    },
    {
        "text": "would you start",
        "start": 79.409,
        "duration": 1.89
    },
    {
        "text": "sure absolutely I'd start at the same",
        "start": 79.86,
        "duration": 3.27
    },
    {
        "text": "place everyone else starts because if",
        "start": 81.299,
        "duration": 3.061
    },
    {
        "text": "you look anywhere on the internet they",
        "start": 83.13,
        "duration": 3.06
    },
    {
        "text": "tell you to use Jupiter no of course",
        "start": 84.36,
        "duration": 4.26
    },
    {
        "text": "right so Jupiter notebooks are really",
        "start": 86.19,
        "duration": 4.71
    },
    {
        "text": "awesome you can both document exactly",
        "start": 88.62,
        "duration": 4.41
    },
    {
        "text": "all the steps that you're doing as well",
        "start": 90.9,
        "duration": 5.16
    },
    {
        "text": "as step through the code and share it",
        "start": 93.03,
        "duration": 5.25
    },
    {
        "text": "with others oh it's like a learning",
        "start": 96.06,
        "duration": 4.32
    },
    {
        "text": "environment yeah absolutely",
        "start": 98.28,
        "duration": 4.23
    },
    {
        "text": "so you can both document what you did as",
        "start": 100.38,
        "duration": 5.67
    },
    {
        "text": "well as do it and get quick visibility",
        "start": 102.51,
        "duration": 4.77
    },
    {
        "text": "into how things are going",
        "start": 106.05,
        "duration": 2.4
    },
    {
        "text": "which might be a thousand percent",
        "start": 107.28,
        "duration": 3.15
    },
    {
        "text": "onerous I'm basically using it to make",
        "start": 108.45,
        "duration": 3.87
    },
    {
        "text": "sure it's doing the right thing it's",
        "start": 110.43,
        "duration": 4.65
    },
    {
        "text": "like a poor man's unit test sort of sort",
        "start": 112.32,
        "duration": 4.2
    },
    {
        "text": "of it's much it's more than that for",
        "start": 115.08,
        "duration": 3.18
    },
    {
        "text": "data exploration and stuff too which is",
        "start": 116.52,
        "duration": 4.32
    },
    {
        "text": "pretty awesome however I'm going to show",
        "start": 118.26,
        "duration": 4.08
    },
    {
        "text": "you how to use Jupiter notebooks in a",
        "start": 120.84,
        "duration": 3.21
    },
    {
        "text": "way that you may have never seen before",
        "start": 122.34,
        "duration": 4.56
    },
    {
        "text": "inside my favorite code editor Visual",
        "start": 124.05,
        "duration": 5.67
    },
    {
        "text": "Studio code so the visual studio code",
        "start": 126.9,
        "duration": 5.699
    },
    {
        "text": "tools for AI has added functionality so",
        "start": 129.72,
        "duration": 4.739
    },
    {
        "text": "I can actually just open up Jupiter",
        "start": 132.599,
        "duration": 3.841
    },
    {
        "text": "notebooks right inside Visual Studio",
        "start": 134.459,
        "duration": 4.351
    },
    {
        "text": "code hey you know and that's important",
        "start": 136.44,
        "duration": 4.71
    },
    {
        "text": "because for me personally and a lot of",
        "start": 138.81,
        "duration": 4.38
    },
    {
        "text": "other data scientists I know well I",
        "start": 141.15,
        "duration": 4.02
    },
    {
        "text": "you start with Jupiter notebooks but",
        "start": 143.19,
        "duration": 4.109
    },
    {
        "text": "then take the code that works like once",
        "start": 145.17,
        "duration": 3.84
    },
    {
        "text": "I figured out oh yeah this experiments",
        "start": 147.299,
        "duration": 3.691
    },
    {
        "text": "really going to work so then I'll take",
        "start": 149.01,
        "duration": 3.74
    },
    {
        "text": "the code out put it in in",
        "start": 150.99,
        "duration": 4.31
    },
    {
        "text": "code I'll step through debug refactor",
        "start": 152.75,
        "duration": 4.2
    },
    {
        "text": "checking into source control all that",
        "start": 155.3,
        "duration": 5.04
    },
    {
        "text": "sort of stuff right and so this is fully",
        "start": 156.95,
        "duration": 5.34
    },
    {
        "text": "working Jupiter notebook we can step",
        "start": 160.34,
        "duration": 4.5
    },
    {
        "text": "through and run it inside vs code which",
        "start": 162.29,
        "duration": 5.25
    },
    {
        "text": "is awesome so it's a Jupiter server rut",
        "start": 164.84,
        "duration": 4.74
    },
    {
        "text": "where is it running on my local machine",
        "start": 167.54,
        "duration": 5.1
    },
    {
        "text": "okay so Visual Studio code creates the",
        "start": 169.58,
        "duration": 5.4
    },
    {
        "text": "Jupiter server for you and then it runs",
        "start": 172.64,
        "duration": 4.86
    },
    {
        "text": "it on okay cool that's right absolutely",
        "start": 174.98,
        "duration": 5.37
    },
    {
        "text": "now when you take your training script",
        "start": 177.5,
        "duration": 6.6
    },
    {
        "text": "out of the Jupiter notebook then again",
        "start": 180.35,
        "duration": 5.97
    },
    {
        "text": "this is you know any other Python code I",
        "start": 184.1,
        "duration": 4.23
    },
    {
        "text": "can step through I can debug on my local",
        "start": 186.32,
        "duration": 5.25
    },
    {
        "text": "machine which is great and to use this",
        "start": 188.33,
        "duration": 5.28
    },
    {
        "text": "with Azure machine learning then I",
        "start": 191.57,
        "duration": 3.84
    },
    {
        "text": "simply want to make sure and get a",
        "start": 193.61,
        "duration": 3.9
    },
    {
        "text": "handle to the Azure machine learning run",
        "start": 195.41,
        "duration": 5.52
    },
    {
        "text": "so if I step through on debug without",
        "start": 197.51,
        "duration": 4.949
    },
    {
        "text": "using Azure machine learning just for",
        "start": 200.93,
        "duration": 4.35
    },
    {
        "text": "maximum agility on my local machine then",
        "start": 202.459,
        "duration": 5.311
    },
    {
        "text": "I may not have a run context so I just",
        "start": 205.28,
        "duration": 4.2
    },
    {
        "text": "want to catch this error here right but",
        "start": 207.77,
        "duration": 4.77
    },
    {
        "text": "then if I do get a handle to a run then",
        "start": 209.48,
        "duration": 6.14
    },
    {
        "text": "I can use some of the AML Python SDK",
        "start": 212.54,
        "duration": 5.759
    },
    {
        "text": "functionality to like log metrics so",
        "start": 215.62,
        "duration": 4.48
    },
    {
        "text": "that we can see those fancy charts that",
        "start": 218.299,
        "duration": 2.761
    },
    {
        "text": "I showed you earlier",
        "start": 220.1,
        "duration": 2.609
    },
    {
        "text": "so let's list it let me let me see if I",
        "start": 221.06,
        "duration": 3.72
    },
    {
        "text": "can understand it so I've already had my",
        "start": 222.709,
        "duration": 4.951
    },
    {
        "text": "own training Python let's just say I'm",
        "start": 224.78,
        "duration": 5.31
    },
    {
        "text": "using I'm reading some crazy game that",
        "start": 227.66,
        "duration": 4.2
    },
    {
        "text": "generates images for example using PI",
        "start": 230.09,
        "duration": 4.26
    },
    {
        "text": "torch now this will basically be able to",
        "start": 231.86,
        "duration": 5.55
    },
    {
        "text": "run as is already yeah when I'm adding",
        "start": 234.35,
        "duration": 5.609
    },
    {
        "text": "this run stuff what it's doing is its",
        "start": 237.41,
        "duration": 4.62
    },
    {
        "text": "allowing me to produce even more",
        "start": 239.959,
        "duration": 4.771
    },
    {
        "text": "intelligent things on the output that",
        "start": 242.03,
        "duration": 4.62
    },
    {
        "text": "not only I can see but that others will",
        "start": 244.73,
        "duration": 3.21
    },
    {
        "text": "be able to see inside of the workspace",
        "start": 246.65,
        "duration": 3.66
    },
    {
        "text": "that's right absolutely because as you",
        "start": 247.94,
        "duration": 4.079
    },
    {
        "text": "can see while you were talking I went",
        "start": 250.31,
        "duration": 3.36
    },
    {
        "text": "ahead and just right clicked and ran the",
        "start": 252.019,
        "duration": 3.75
    },
    {
        "text": "python file and in terminal and you can",
        "start": 253.67,
        "duration": 4.67
    },
    {
        "text": "see locally here we can see the accuracy",
        "start": 255.769,
        "duration": 4.801
    },
    {
        "text": "while the models training which is",
        "start": 258.34,
        "duration": 4.42
    },
    {
        "text": "wonderful however nobody else on my team",
        "start": 260.57,
        "duration": 4.08
    },
    {
        "text": "is seeing this and I'm certainly not",
        "start": 262.76,
        "duration": 3.96
    },
    {
        "text": "keeping track of it so I can show my",
        "start": 264.65,
        "duration": 2.85
    },
    {
        "text": "boss later",
        "start": 266.72,
        "duration": 2.82
    },
    {
        "text": "you know how see how this one beat the",
        "start": 267.5,
        "duration": 3.99
    },
    {
        "text": "previous version and blah blah blah so",
        "start": 269.54,
        "duration": 2.67
    },
    {
        "text": "good question",
        "start": 271.49,
        "duration": 3.989
    },
    {
        "text": "usually I'm doing like print statements",
        "start": 272.21,
        "duration": 5.76
    },
    {
        "text": "in my Python script is just the standard",
        "start": 275.479,
        "duration": 4.201
    },
    {
        "text": "print statements being saved as well",
        "start": 277.97,
        "duration": 2.72
    },
    {
        "text": "when you're running an experiment",
        "start": 279.68,
        "duration": 3.69
    },
    {
        "text": "absolutely all of all the standard out",
        "start": 280.69,
        "duration": 5.06
    },
    {
        "text": "standard error all the logs get on",
        "start": 283.37,
        "duration": 4.87
    },
    {
        "text": "matically uploaded and anything that you",
        "start": 285.75,
        "duration": 5.34
    },
    {
        "text": "write into a folder called outputs in",
        "start": 288.24,
        "duration": 5.16
    },
    {
        "text": "your local directory as well so you can",
        "start": 291.09,
        "duration": 3.72
    },
    {
        "text": "see I just trained this tensor flow",
        "start": 293.4,
        "duration": 3.69
    },
    {
        "text": "model and then output this into this",
        "start": 294.81,
        "duration": 5.04
    },
    {
        "text": "local directory here and when running in",
        "start": 297.09,
        "duration": 4.14
    },
    {
        "text": "the context of Azure machine learning",
        "start": 299.85,
        "duration": 4.2
    },
    {
        "text": "then it'll automatically upload that to",
        "start": 301.23,
        "duration": 4.23
    },
    {
        "text": "the cloud as well and just keep tracking",
        "start": 304.05,
        "duration": 3.09
    },
    {
        "text": "I don't have to write any code to do",
        "start": 305.46,
        "duration": 3.3
    },
    {
        "text": "that awesome so the reason why you would",
        "start": 307.14,
        "duration": 4.89
    },
    {
        "text": "add this run little object is because",
        "start": 308.76,
        "duration": 4.74
    },
    {
        "text": "then you could get some even better",
        "start": 312.03,
        "duration": 3.24
    },
    {
        "text": "visualizations then you would just like",
        "start": 313.5,
        "duration": 3.6
    },
    {
        "text": "a log dump which is usually what we're",
        "start": 315.27,
        "duration": 3.57
    },
    {
        "text": "used to looking at this way you get",
        "start": 317.1,
        "duration": 3.69
    },
    {
        "text": "visual ations of accuracy there's a cost",
        "start": 318.84,
        "duration": 4.35
    },
    {
        "text": "function going down etc yeah that's",
        "start": 320.79,
        "duration": 4.98
    },
    {
        "text": "right and Azure machine learning fully",
        "start": 323.19,
        "duration": 3.84
    },
    {
        "text": "works with tensor board and other",
        "start": 325.77,
        "duration": 3.39
    },
    {
        "text": "visualizations as well but not all the",
        "start": 327.03,
        "duration": 3.42
    },
    {
        "text": "different machine learning frameworks",
        "start": 329.16,
        "duration": 3.42
    },
    {
        "text": "have some sort of visualizer so this is",
        "start": 330.45,
        "duration": 4.23
    },
    {
        "text": "a great way to get one in a standard way",
        "start": 332.58,
        "duration": 4.08
    },
    {
        "text": "across all of your different experiments",
        "start": 334.68,
        "duration": 3.44
    },
    {
        "text": "okay the other thing that wasn't",
        "start": 336.66,
        "duration": 4.26
    },
    {
        "text": "altogether clear to me is you ran this",
        "start": 338.12,
        "duration": 5.05
    },
    {
        "text": "locally I sure did and it was just",
        "start": 340.92,
        "duration": 4.38
    },
    {
        "text": "basically like any other run it running",
        "start": 343.17,
        "duration": 3.36
    },
    {
        "text": "on your local machine the only",
        "start": 345.3,
        "duration": 3.48
    },
    {
        "text": "difference is that you added some some a",
        "start": 346.53,
        "duration": 4.59
    },
    {
        "text": "ml or as machine learning logging out",
        "start": 348.78,
        "duration": 4.92
    },
    {
        "text": "and that's it that's all I added however",
        "start": 351.12,
        "duration": 4.95
    },
    {
        "text": "I did not run this using Azure machine",
        "start": 353.7,
        "duration": 5.34
    },
    {
        "text": "learning yet okay so let me show you how",
        "start": 356.07,
        "duration": 5.67
    },
    {
        "text": "to do that perfect so in order to use",
        "start": 359.04,
        "duration": 4.44
    },
    {
        "text": "Azure machine learning we click over to",
        "start": 361.74,
        "duration": 3.69
    },
    {
        "text": "the azure Activity bar right here and",
        "start": 363.48,
        "duration": 3.72
    },
    {
        "text": "you can see this Azure machine learning",
        "start": 365.43,
        "duration": 6.72
    },
    {
        "text": "workspace view in envious code you see",
        "start": 367.2,
        "duration": 6.93
    },
    {
        "text": "my team workspaces right here that we",
        "start": 372.15,
        "duration": 4.29
    },
    {
        "text": "talked about before and all of my",
        "start": 374.13,
        "duration": 4.08
    },
    {
        "text": "different experiments are under this",
        "start": 376.44,
        "duration": 5.31
    },
    {
        "text": "experiment node now to take this code",
        "start": 378.21,
        "duration": 5.61
    },
    {
        "text": "that's on my local machine and attach it",
        "start": 381.75,
        "duration": 4.38
    },
    {
        "text": "and use Azure machine learning then I",
        "start": 383.82,
        "duration": 4.5
    },
    {
        "text": "literally right click here and say",
        "start": 386.13,
        "duration": 4.56
    },
    {
        "text": "attach folder to experiment and when I",
        "start": 388.32,
        "duration": 4.08
    },
    {
        "text": "when I do that then I can select my",
        "start": 390.69,
        "duration": 4.65
    },
    {
        "text": "experiment my workspace in my experiment",
        "start": 392.4,
        "duration": 6.27
    },
    {
        "text": "name and this one's already attached so",
        "start": 395.34,
        "duration": 4.89
    },
    {
        "text": "it threw a little error and say hey",
        "start": 398.67,
        "duration": 3.33
    },
    {
        "text": "you're already attached to your good so",
        "start": 400.23,
        "duration": 3.09
    },
    {
        "text": "when you're running like let's just say",
        "start": 402.0,
        "duration": 2.76
    },
    {
        "text": "we didn't we weren't attached and we",
        "start": 403.32,
        "duration": 3.36
    },
    {
        "text": "didn't run it using address where are",
        "start": 404.76,
        "duration": 4.53
    },
    {
        "text": "these logs going to that they're just on",
        "start": 406.68,
        "duration": 3.93
    },
    {
        "text": "the local machine well just like any",
        "start": 409.29,
        "duration": 3.45
    },
    {
        "text": "other Python experiment inside this case",
        "start": 410.61,
        "duration": 6.24
    },
    {
        "text": "even if you're using the azure AML run",
        "start": 412.74,
        "duration": 6.899
    },
    {
        "text": "context correct because",
        "start": 416.85,
        "duration": 5.369
    },
    {
        "text": "it all I did is say try to get the",
        "start": 419.639,
        "duration": 4.8
    },
    {
        "text": "context but then it failed and it said",
        "start": 422.219,
        "duration": 5.04
    },
    {
        "text": "oh I didn't have a context but it I just",
        "start": 424.439,
        "duration": 4.47
    },
    {
        "text": "caught it and I wrote it out and saying",
        "start": 427.259,
        "duration": 4.081
    },
    {
        "text": "hey I'm not using AML right now so let",
        "start": 428.909,
        "duration": 4.861
    },
    {
        "text": "me show you how to use a okay so those",
        "start": 431.34,
        "duration": 4.02
    },
    {
        "text": "log statements weren't really doing",
        "start": 433.77,
        "duration": 5.13
    },
    {
        "text": "anything those are okay that's right so",
        "start": 435.36,
        "duration": 5.73
    },
    {
        "text": "in order to actually use Azure machine",
        "start": 438.9,
        "duration": 4.319
    },
    {
        "text": "learning with my local compute then we",
        "start": 441.09,
        "duration": 4.979
    },
    {
        "text": "have this notion of compute here where I",
        "start": 443.219,
        "duration": 5.25
    },
    {
        "text": "can create compute over in Azure and",
        "start": 446.069,
        "duration": 3.87
    },
    {
        "text": "that's super easy let me show you how to",
        "start": 448.469,
        "duration": 3.961
    },
    {
        "text": "do that real quick so I could create",
        "start": 449.939,
        "duration": 4.38
    },
    {
        "text": "compute I could create a batch ai",
        "start": 452.43,
        "duration": 5.94
    },
    {
        "text": "cluster I can give that a name and then",
        "start": 454.319,
        "duration": 8.041
    },
    {
        "text": "I can select a VM that has a type of GPU",
        "start": 458.37,
        "duration": 5.579
    },
    {
        "text": "and I'd like to to actually describe",
        "start": 462.36,
        "duration": 3.6
    },
    {
        "text": "them because I have had a bear of a time",
        "start": 463.949,
        "duration": 3.84
    },
    {
        "text": "with the names I don't know what's going",
        "start": 465.96,
        "duration": 3.15
    },
    {
        "text": "on so this is super helpful yeah",
        "start": 467.789,
        "duration": 2.19
    },
    {
        "text": "absolutely",
        "start": 469.11,
        "duration": 3.179
    },
    {
        "text": "so we can select one of these and then I",
        "start": 469.979,
        "duration": 4.74
    },
    {
        "text": "can specify how many of these machines",
        "start": 472.289,
        "duration": 5.13
    },
    {
        "text": "do I want in my cluster and notice again",
        "start": 474.719,
        "duration": 5.461
    },
    {
        "text": "the min count here is zero meaning that",
        "start": 477.419,
        "duration": 4.77
    },
    {
        "text": "when there's no jobs running the cluster",
        "start": 480.18,
        "duration": 3.87
    },
    {
        "text": "completely tears itself down and I'm not",
        "start": 482.189,
        "duration": 3.9
    },
    {
        "text": "paying for anything while I'm not using",
        "start": 484.05,
        "duration": 3.419
    },
    {
        "text": "that's pretty cool which is great",
        "start": 486.089,
        "duration": 4.411
    },
    {
        "text": "however I already have a cluster here",
        "start": 487.469,
        "duration": 5.611
    },
    {
        "text": "and for each one of these compute",
        "start": 490.5,
        "duration": 4.589
    },
    {
        "text": "contexts we need to create a run",
        "start": 493.08,
        "duration": 4.53
    },
    {
        "text": "configuration this keep track of which",
        "start": 495.089,
        "duration": 4.89
    },
    {
        "text": "script am i running what parameters am i",
        "start": 497.61,
        "duration": 4.649
    },
    {
        "text": "passing to it and if in a few other",
        "start": 499.979,
        "duration": 3.9
    },
    {
        "text": "things like that so I can repeat the",
        "start": 502.259,
        "duration": 3.481
    },
    {
        "text": "experiment over and over if I would like",
        "start": 503.879,
        "duration": 3.69
    },
    {
        "text": "to so if you're running the experiment",
        "start": 505.74,
        "duration": 4.229
    },
    {
        "text": "in the context of a run configuration",
        "start": 507.569,
        "duration": 4.981
    },
    {
        "text": "that's where the run object will start",
        "start": 509.969,
        "duration": 4.5
    },
    {
        "text": "to exist and do something that's exactly",
        "start": 512.55,
        "duration": 4.799
    },
    {
        "text": "right and so we can see when I attach my",
        "start": 514.469,
        "duration": 5.73
    },
    {
        "text": "folder to the to the workspace to the",
        "start": 517.349,
        "duration": 5.13
    },
    {
        "text": "experiment then it automatically created",
        "start": 520.199,
        "duration": 5.491
    },
    {
        "text": "a local run compute context config here",
        "start": 522.479,
        "duration": 5.161
    },
    {
        "text": "and I can just simply right click this",
        "start": 525.69,
        "duration": 4.589
    },
    {
        "text": "and I can say run experiment and when I",
        "start": 527.64,
        "duration": 4.77
    },
    {
        "text": "run experiment then now you would see",
        "start": 530.279,
        "duration": 4.5
    },
    {
        "text": "this is submitting the job instead of",
        "start": 532.41,
        "duration": 3.96
    },
    {
        "text": "just starting starting the tensorflow",
        "start": 534.779,
        "duration": 3.961
    },
    {
        "text": "job right away it says okay now",
        "start": 536.37,
        "duration": 4.44
    },
    {
        "text": "submitting job is succeeded now it's",
        "start": 538.74,
        "duration": 3.9
    },
    {
        "text": "submitting the job it's keep it's",
        "start": 540.81,
        "duration": 4.17
    },
    {
        "text": "getting that run context and then it's",
        "start": 542.64,
        "duration": 3.74
    },
    {
        "text": "actually running it on my local machine",
        "start": 544.98,
        "duration": 4.109
    },
    {
        "text": "so here's a question and this is because",
        "start": 546.38,
        "duration": 4.36
    },
    {
        "text": "usually when I'm setting these things up",
        "start": 549.089,
        "duration": 3.841
    },
    {
        "text": "I have a lot of Python files how does it",
        "start": 550.74,
        "duration": 2.58
    },
    {
        "text": "know",
        "start": 552.93,
        "duration": 3.18
    },
    {
        "text": "which file to run sure absolutely I'll",
        "start": 553.32,
        "duration": 4.56
    },
    {
        "text": "show you one second while it's running",
        "start": 556.11,
        "duration": 3.12
    },
    {
        "text": "but first I want to show you this little",
        "start": 557.88,
        "duration": 3.48
    },
    {
        "text": "toast notification okay so it said okay",
        "start": 559.23,
        "duration": 4.56
    },
    {
        "text": "the job is submitted and I can click",
        "start": 561.36,
        "duration": 5.07
    },
    {
        "text": "view experiment run and so when I click",
        "start": 563.79,
        "duration": 5.67
    },
    {
        "text": "this then this will open up the same",
        "start": 566.43,
        "duration": 5.49
    },
    {
        "text": "view of that Azure portal that I saw",
        "start": 569.46,
        "duration": 4.71
    },
    {
        "text": "earlier right inside vs code so I can",
        "start": 571.92,
        "duration": 4.11
    },
    {
        "text": "keep track of all of my key metrics and",
        "start": 574.17,
        "duration": 4.98
    },
    {
        "text": "such and that's when running doing that",
        "start": 576.03,
        "duration": 5.19
    },
    {
        "text": "run dot log stop that's right actually",
        "start": 579.15,
        "duration": 4.59
    },
    {
        "text": "gonna start saving stuff exactly yep yep",
        "start": 581.22,
        "duration": 5.16
    },
    {
        "text": "and we can tell exactly what is gonna",
        "start": 583.74,
        "duration": 6.39
    },
    {
        "text": "happen inside this run by edit run",
        "start": 586.38,
        "duration": 6.0
    },
    {
        "text": "configuration we can see in here it says",
        "start": 590.13,
        "duration": 6.15
    },
    {
        "text": "oh please use the Train PI file and then",
        "start": 592.38,
        "duration": 5.46
    },
    {
        "text": "we can also see there's a number of",
        "start": 596.28,
        "duration": 3.96
    },
    {
        "text": "other optional settings in here for",
        "start": 597.84,
        "duration": 4.32
    },
    {
        "text": "example we can look and see okay well",
        "start": 600.24,
        "duration": 4.35
    },
    {
        "text": "which Python interpreter path did I want",
        "start": 602.16,
        "duration": 3.33
    },
    {
        "text": "to use because I have a bunch of",
        "start": 604.59,
        "duration": 3.3
    },
    {
        "text": "differential Python environments and I",
        "start": 605.49,
        "duration": 4.68
    },
    {
        "text": "can also specify whether I want to you",
        "start": 607.89,
        "duration": 4.14
    },
    {
        "text": "know manage my own dependencies the user",
        "start": 610.17,
        "duration": 4.68
    },
    {
        "text": "manage dependencies equals true by",
        "start": 612.03,
        "duration": 4.56
    },
    {
        "text": "default it's actually gonna create it",
        "start": 614.85,
        "duration": 3.93
    },
    {
        "text": "with false meaning that Azure machine",
        "start": 616.59,
        "duration": 3.6
    },
    {
        "text": "learning will manage all of your",
        "start": 618.78,
        "duration": 4.05
    },
    {
        "text": "dependencies for you and so then in this",
        "start": 620.19,
        "duration": 5.22
    },
    {
        "text": "Conda dependencies file then this is",
        "start": 622.83,
        "duration": 4.89
    },
    {
        "text": "where it'll you specify what you want to",
        "start": 625.41,
        "duration": 4.08
    },
    {
        "text": "pip install what you want to kondeh",
        "start": 627.72,
        "duration": 4.38
    },
    {
        "text": "install and that enables a ml to create",
        "start": 629.49,
        "duration": 5.82
    },
    {
        "text": "a environment that is actually portable",
        "start": 632.1,
        "duration": 7.26
    },
    {
        "text": "so if you run this on a GPU VM in Azure",
        "start": 635.31,
        "duration": 6.27
    },
    {
        "text": "or you run it on your local machine all",
        "start": 639.36,
        "duration": 4.74
    },
    {
        "text": "the definitions of what different",
        "start": 641.58,
        "duration": 3.81
    },
    {
        "text": "libraries you should have in that",
        "start": 644.1,
        "duration": 3.42
    },
    {
        "text": "environment are in this file that's cool",
        "start": 645.39,
        "duration": 3.45
    },
    {
        "text": "and Azure machine learning will",
        "start": 647.52,
        "duration": 2.64
    },
    {
        "text": "automatically create that environment",
        "start": 648.84,
        "duration": 4.08
    },
    {
        "text": "for you based on that definition so it's",
        "start": 650.16,
        "duration": 5.1
    },
    {
        "text": "completely repeatable by everyone in",
        "start": 652.92,
        "duration": 4.41
    },
    {
        "text": "your team which is fantastic",
        "start": 655.26,
        "duration": 3.9
    },
    {
        "text": "so while is it still running just a",
        "start": 657.33,
        "duration": 4.56
    },
    {
        "text": "couple of other questions mm-hmm like",
        "start": 659.16,
        "duration": 4.62
    },
    {
        "text": "when it says it's running it locally is",
        "start": 661.89,
        "duration": 3.39
    },
    {
        "text": "it running it just like you would",
        "start": 663.78,
        "duration": 2.79
    },
    {
        "text": "normally run it or is it doing something",
        "start": 665.28,
        "duration": 4.02
    },
    {
        "text": "else it's doing it just like it would do",
        "start": 666.57,
        "duration": 5.61
    },
    {
        "text": "locally with the addition of having a",
        "start": 669.3,
        "duration": 5.88
    },
    {
        "text": "driver script that actually kicks it off",
        "start": 672.18,
        "duration": 6.06
    },
    {
        "text": "and does things like determines whether",
        "start": 675.18,
        "duration": 5.58
    },
    {
        "text": "it needs to prepare that environment it",
        "start": 678.24,
        "duration": 4.53
    },
    {
        "text": "then instantiates your run in the",
        "start": 680.76,
        "duration": 3.93
    },
    {
        "text": "environment you specify",
        "start": 682.77,
        "duration": 3.87
    },
    {
        "text": "then it automatically uploads all the",
        "start": 684.69,
        "duration": 5.85
    },
    {
        "text": "outputs so the log files as well as you",
        "start": 686.64,
        "duration": 6.27
    },
    {
        "text": "train model because you can see that in",
        "start": 690.54,
        "duration": 4.38
    },
    {
        "text": "my outputs folder I've got this Train",
        "start": 692.91,
        "duration": 4.8
    },
    {
        "text": "tensorflow model but in this experiment",
        "start": 694.92,
        "duration": 4.44
    },
    {
        "text": "you can see it's completed you can see",
        "start": 697.71,
        "duration": 3.72
    },
    {
        "text": "in this outputs I didn't write any code",
        "start": 699.36,
        "duration": 4.23
    },
    {
        "text": "to upload this model it automatically",
        "start": 701.43,
        "duration": 4.17
    },
    {
        "text": "got uploaded to Azure and it'll keep",
        "start": 703.59,
        "duration": 4.41
    },
    {
        "text": "track of all all the outputs so if you",
        "start": 705.6,
        "duration": 5.28
    },
    {
        "text": "output like an ROC curve or like you",
        "start": 708.0,
        "duration": 4.83
    },
    {
        "text": "know any kind of images that sort of",
        "start": 710.88,
        "duration": 4.35
    },
    {
        "text": "stuff will show up and be associated",
        "start": 712.83,
        "duration": 3.99
    },
    {
        "text": "with that experiment run automatically",
        "start": 715.23,
        "duration": 3.54
    },
    {
        "text": "and that that's that's really nice",
        "start": 716.82,
        "duration": 4.17
    },
    {
        "text": "because like now you actually have a",
        "start": 718.77,
        "duration": 4.14
    },
    {
        "text": "place where it's looked I'm gonna be",
        "start": 720.99,
        "duration": 3.3
    },
    {
        "text": "honest with you and I'm writing these",
        "start": 722.91,
        "duration": 3.84
    },
    {
        "text": "things it's pretty harrowing for me",
        "start": 724.29,
        "duration": 4.41
    },
    {
        "text": "because sometimes like basically these",
        "start": 726.75,
        "duration": 3.36
    },
    {
        "text": "things never work the first time and",
        "start": 728.7,
        "duration": 2.91
    },
    {
        "text": "then you're iterating for weeks",
        "start": 730.11,
        "duration": 4.59
    },
    {
        "text": "sometimes and I get lost of what I",
        "start": 731.61,
        "duration": 4.62
    },
    {
        "text": "actually tried and what I did it and",
        "start": 734.7,
        "duration": 2.91
    },
    {
        "text": "this actually helps me remember",
        "start": 736.23,
        "duration": 3.66
    },
    {
        "text": "everything that was try that's right",
        "start": 737.61,
        "duration": 3.06
    },
    {
        "text": "she's pretty amazing",
        "start": 739.89,
        "duration": 3.9
    },
    {
        "text": "absolutely so let's go ahead and and",
        "start": 740.67,
        "duration": 5.73
    },
    {
        "text": "test this model that I just trained so I",
        "start": 743.79,
        "duration": 4.95
    },
    {
        "text": "just have a test local script here and",
        "start": 746.4,
        "duration": 5.52
    },
    {
        "text": "we can go ahead and run this again and",
        "start": 748.74,
        "duration": 6.69
    },
    {
        "text": "so this is gonna simply load up show you",
        "start": 751.92,
        "duration": 8.52
    },
    {
        "text": "as some sample data here and then it'll",
        "start": 755.43,
        "duration": 8.07
    },
    {
        "text": "actually score it and we can see the the",
        "start": 760.44,
        "duration": 4.98
    },
    {
        "text": "labels and the predictions right right",
        "start": 763.5,
        "duration": 3.63
    },
    {
        "text": "here you see most of them are are",
        "start": 765.42,
        "duration": 4.41
    },
    {
        "text": "accurate but it's in this particular one",
        "start": 767.13,
        "duration": 6.18
    },
    {
        "text": "was a 96% or so accurate we can see like",
        "start": 769.83,
        "duration": 5.55
    },
    {
        "text": "in this one there's a five instead of a",
        "start": 773.31,
        "duration": 4.74
    },
    {
        "text": "six for example in the prediction so the",
        "start": 775.38,
        "duration": 4.26
    },
    {
        "text": "last thing I want to ask you if we go",
        "start": 778.05,
        "duration": 4.68
    },
    {
        "text": "back to the azure the azure tab that we",
        "start": 779.64,
        "duration": 4.62
    },
    {
        "text": "had before that shows all yeah as",
        "start": 782.73,
        "duration": 3.72
    },
    {
        "text": "machine learning service no not that one",
        "start": 784.26,
        "duration": 5.99
    },
    {
        "text": "the one in Visual Studio code sure say",
        "start": 786.45,
        "duration": 7.26
    },
    {
        "text": "what the docker run config what differs",
        "start": 790.25,
        "duration": 5.29
    },
    {
        "text": "between running the docker run config",
        "start": 793.71,
        "duration": 4.08
    },
    {
        "text": "course is the local config so that's",
        "start": 795.54,
        "duration": 4.76
    },
    {
        "text": "just specifying whether I want to use",
        "start": 797.79,
        "duration": 6.39
    },
    {
        "text": "docker on my local machine o or I or I",
        "start": 800.3,
        "duration": 5.8
    },
    {
        "text": "don't again there's just different",
        "start": 804.18,
        "duration": 4.26
    },
    {
        "text": "configuration settings so if I wanted to",
        "start": 806.1,
        "duration": 5.25
    },
    {
        "text": "prepare a docker image and then run my",
        "start": 808.44,
        "duration": 4.83
    },
    {
        "text": "experiment in that docker image on my",
        "start": 811.35,
        "duration": 4.86
    },
    {
        "text": "local machine absolutely could and",
        "start": 813.27,
        "duration": 5.1
    },
    {
        "text": "that's helpful yeah because if I'm",
        "start": 816.21,
        "duration": 4.26
    },
    {
        "text": "scale out to that GPU cluster for",
        "start": 818.37,
        "duration": 4.2
    },
    {
        "text": "example I want to make sure that all of",
        "start": 820.47,
        "duration": 4.559
    },
    {
        "text": "my dependencies for example are properly",
        "start": 822.57,
        "duration": 4.08
    },
    {
        "text": "installed and prepared in that docker",
        "start": 825.029,
        "duration": 4.111
    },
    {
        "text": "container so again test it out first",
        "start": 826.65,
        "duration": 4.41
    },
    {
        "text": "locally and then scale it out in the",
        "start": 829.14,
        "duration": 3.93
    },
    {
        "text": "cloud and it's also nice that it makes",
        "start": 831.06,
        "duration": 4.02
    },
    {
        "text": "it so it's a repeatable thing because if",
        "start": 833.07,
        "duration": 3.12
    },
    {
        "text": "it's in a container it's its own",
        "start": 835.08,
        "duration": 3.21
    },
    {
        "text": "execution environment that has all",
        "start": 836.19,
        "duration": 4.14
    },
    {
        "text": "definitions of what in there what's in",
        "start": 838.29,
        "duration": 3.78
    },
    {
        "text": "there with the Condit dependencies and",
        "start": 840.33,
        "duration": 3.93
    },
    {
        "text": "what's running if it runs in that docker",
        "start": 842.07,
        "duration": 4.65
    },
    {
        "text": "container it should run everywhere that",
        "start": 844.26,
        "duration": 4.35
    },
    {
        "text": "that's absolutely right so now not only",
        "start": 846.72,
        "duration": 4.02
    },
    {
        "text": "will Azure machine learning help you",
        "start": 848.61,
        "duration": 4.26
    },
    {
        "text": "create a docker container for testing",
        "start": 850.74,
        "duration": 4.32
    },
    {
        "text": "your models or training your models but",
        "start": 852.87,
        "duration": 4.35
    },
    {
        "text": "also for testing them and deploying them",
        "start": 855.06,
        "duration": 3.66
    },
    {
        "text": "to production as well awesome so let's",
        "start": 857.22,
        "duration": 3.27
    },
    {
        "text": "talk about that in the next episodes I",
        "start": 858.72,
        "duration": 3.72
    },
    {
        "text": "feel like we're already like it at 14",
        "start": 860.49,
        "duration": 3.66
    },
    {
        "text": "minutes and what I want to do is I want",
        "start": 862.44,
        "duration": 2.88
    },
    {
        "text": "to say this has been awesome because",
        "start": 864.15,
        "duration": 2.64
    },
    {
        "text": "I've learned a lot about how to do",
        "start": 865.32,
        "duration": 4.32
    },
    {
        "text": "actual experiments inside of Azure",
        "start": 866.79,
        "duration": 4.2
    },
    {
        "text": "machine learning service using the",
        "start": 869.64,
        "duration": 3.42
    },
    {
        "text": "awesome tools in the next episode let's",
        "start": 870.99,
        "duration": 4.38
    },
    {
        "text": "take a look at how we actually use the",
        "start": 873.06,
        "duration": 3.719
    },
    {
        "text": "output in a meaningful way what do you",
        "start": 875.37,
        "duration": 3.3
    },
    {
        "text": "think yeah it sounds great awesome well",
        "start": 876.779,
        "duration": 3.031
    },
    {
        "text": "thanks so much for watching you've",
        "start": 878.67,
        "duration": 2.93
    },
    {
        "text": "learned all about how to do experiments",
        "start": 879.81,
        "duration": 4.5
    },
    {
        "text": "using Azure machine learning service and",
        "start": 881.6,
        "duration": 5.08
    },
    {
        "text": "the visual studio code tools for AI",
        "start": 884.31,
        "duration": 3.87
    },
    {
        "text": "thanks so much for watching and we'll",
        "start": 886.68,
        "duration": 3.06
    },
    {
        "text": "see you next time take care",
        "start": 888.18,
        "duration": 1.73
    },
    {
        "text": "you",
        "start": 889.74,
        "duration": 9.25
    },
    {
        "text": "[Music]",
        "start": 889.91,
        "duration": 9.08
    }
]