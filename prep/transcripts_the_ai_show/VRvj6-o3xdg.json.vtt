[
    {
        "text": ">> You're not going to want to miss this episode of the AI Show.",
        "start": 0.0,
        "duration": 2.97
    },
    {
        "text": "We're look at amazing tooling to build",
        "start": 2.97,
        "duration": 1.77
    },
    {
        "text": "your own data science AI models",
        "start": 4.74,
        "duration": 3.195
    },
    {
        "text": "with Python. Make sure you tune in.",
        "start": 7.935,
        "duration": 2.505
    },
    {
        "text": "[MUSIC].",
        "start": 10.44,
        "duration": 8.54
    },
    {
        "text": ">> Hi there. My name is Seth Juarez.",
        "start": 18.98,
        "duration": 1.44
    },
    {
        "text": "Welcome to this episode of the AI Show.",
        "start": 20.42,
        "duration": 2.05
    },
    {
        "text": "We're talking about some awesome tooling that you can use as",
        "start": 22.47,
        "duration": 2.46
    },
    {
        "text": "a data scientist and a developer to do AI.",
        "start": 24.93,
        "duration": 2.55
    },
    {
        "text": "I want you to introduce yourself. Start with you John.",
        "start": 27.48,
        "duration": 1.62
    },
    {
        "text": ">> Sure. I'm John Lam.",
        "start": 29.1,
        "duration": 1.215
    },
    {
        "text": "I work on the Azure Notebooks team",
        "start": 30.315,
        "duration": 2.25
    },
    {
        "text": "and I'm building the experience.",
        "start": 32.565,
        "duration": 2.265
    },
    {
        "text": "I'm playing the data scientists as",
        "start": 34.83,
        "duration": 1.11
    },
    {
        "text": "well in the first part of this demo.",
        "start": 35.94,
        "duration": 2.475
    },
    {
        "text": ">> Awesome. Rong.",
        "start": 38.415,
        "duration": 0.78
    },
    {
        "text": ">> I'm Rong. I'm a PM on the Python team and",
        "start": 39.195,
        "duration": 4.025
    },
    {
        "text": "I work on tools in Visual Studio Code for data science jobs.",
        "start": 43.22,
        "duration": 4.08
    },
    {
        "text": ">> Fantastic. Oh, sorry, go ahead.",
        "start": 47.3,
        "duration": 1.38
    },
    {
        "text": ">> Oh, sorry. I was just going to say,",
        "start": 48.68,
        "duration": 1.35
    },
    {
        "text": "I'll be playing developer role in this episode.",
        "start": 50.03,
        "duration": 3.835
    },
    {
        "text": ">> Fantastic. If I interrupt too much,",
        "start": 53.865,
        "duration": 1.53
    },
    {
        "text": "just slap me because people watching want this to happen.",
        "start": 55.395,
        "duration": 3.065
    },
    {
        "text": "So, just be liberal.",
        "start": 58.46,
        "duration": 1.14
    },
    {
        "text": ">> Be entertaining.",
        "start": 59.6,
        "duration": 0.72
    },
    {
        "text": ">> That's right.",
        "start": 60.32,
        "duration": 0.63
    },
    {
        "text": ">> It sounds good.",
        "start": 60.95,
        "duration": 0.84
    },
    {
        "text": ">> Can I slap you?",
        "start": 61.79,
        "duration": 1.005
    },
    {
        "text": ">> Yes, please. You're supposed to slap me the whole time.",
        "start": 62.795,
        "duration": 1.995
    },
    {
        "text": "So, as a data scientist,",
        "start": 64.79,
        "duration": 2.15
    },
    {
        "text": "what do people actually do to build AI models?",
        "start": 66.94,
        "duration": 3.7
    },
    {
        "text": "Then, what are some things that we can",
        "start": 70.64,
        "duration": 1.41
    },
    {
        "text": "give them to help them with that process?",
        "start": 72.05,
        "duration": 1.965
    },
    {
        "text": ">> Absolutely. So, I think it all starts with a set of tools.",
        "start": 74.015,
        "duration": 2.475
    },
    {
        "text": "What we're going to do today,",
        "start": 76.49,
        "duration": 1.2
    },
    {
        "text": "is we're going to walk through training,",
        "start": 77.69,
        "duration": 3.81
    },
    {
        "text": "optimizing, and deploying this model",
        "start": 81.5,
        "duration": 2.82
    },
    {
        "text": "that allows us to detect different kinds of dogs and cats.",
        "start": 84.32,
        "duration": 2.92
    },
    {
        "text": "So, the idea really is, there's a picture.",
        "start": 87.24,
        "duration": 2.45
    },
    {
        "text": "What breed is this dog or cat?",
        "start": 89.69,
        "duration": 2.005
    },
    {
        "text": ">> Is it a hot dog or not a hot dog?",
        "start": 91.695,
        "duration": 2.445
    },
    {
        "text": ">> Exactly. Yes. So, this model",
        "start": 94.14,
        "duration": 3.56
    },
    {
        "text": "is going to be trained using TensorFlow.",
        "start": 97.7,
        "duration": 1.83
    },
    {
        "text": "It's using a technique called Transfer Learning,",
        "start": 99.53,
        "duration": 3.23
    },
    {
        "text": "where we're taking a model that's already",
        "start": 102.76,
        "duration": 1.87
    },
    {
        "text": "been pre-trained on a whole bunch of different images.",
        "start": 104.63,
        "duration": 2.25
    },
    {
        "text": "We're just going to retrain",
        "start": 106.88,
        "duration": 1.53
    },
    {
        "text": "the final layer of that model using a set of",
        "start": 108.41,
        "duration": 2.34
    },
    {
        "text": "37 categories of dogs and cats that we have selected.",
        "start": 110.75,
        "duration": 4.35
    },
    {
        "text": "It's a dataset called the Oxford on pet dataset.",
        "start": 115.1,
        "duration": 3.585
    },
    {
        "text": "We're going to go use a bunch of",
        "start": 118.685,
        "duration": 1.785
    },
    {
        "text": "Azure infrastructure and tooling to go go make that happen.",
        "start": 120.47,
        "duration": 2.75
    },
    {
        "text": ">> All right. Let's do it.",
        "start": 123.22,
        "duration": 0.65
    },
    {
        "text": ">> Cool. Let's go. So, what we have",
        "start": 123.87,
        "duration": 2.21
    },
    {
        "text": "is a GitHub repository which contains the files for our demo.",
        "start": 126.08,
        "duration": 3.33
    },
    {
        "text": "One of the really nice things that we have is",
        "start": 129.41,
        "duration": 2.895
    },
    {
        "text": "this badge on that you can click on",
        "start": 132.305,
        "duration": 2.415
    },
    {
        "text": "here which has Azure Notebooks and import written on it.",
        "start": 134.72,
        "duration": 2.88
    },
    {
        "text": "So, that's going to go take that thing",
        "start": 137.6,
        "duration": 1.635
    },
    {
        "text": "and import it into Azure Notebooks.",
        "start": 139.235,
        "duration": 2.115
    },
    {
        "text": "I've done that already here and",
        "start": 141.35,
        "duration": 1.77
    },
    {
        "text": "this brings us into the Azure Notebooks experience.",
        "start": 143.12,
        "duration": 1.92
    },
    {
        "text": "You can see it's exactly the same set of files that we have here.",
        "start": 145.04,
        "duration": 3.555
    },
    {
        "text": "What we want to do is we want to",
        "start": 148.595,
        "duration": 1.755
    },
    {
        "text": "start running one of",
        "start": 150.35,
        "duration": 2.26
    },
    {
        "text": "our Notebooks which will walk us through the training experience.",
        "start": 152.61,
        "duration": 2.42
    },
    {
        "text": ">> So, people at home can literally click on that button,",
        "start": 155.03,
        "duration": 2.17
    },
    {
        "text": "they will see this happen in their own Azure Notebooks account.",
        "start": 157.2,
        "duration": 2.555
    },
    {
        "text": "If they don't have one, you can create one is free.",
        "start": 159.755,
        "duration": 1.965
    },
    {
        "text": ">> Absolutely, and you can login with both a Microsoft account",
        "start": 161.72,
        "duration": 3.105
    },
    {
        "text": "or if you have a workplace account in",
        "start": 164.825,
        "duration": 1.435
    },
    {
        "text": "Azure Active Directory account you login using models as well.",
        "start": 166.26,
        "duration": 2.2
    },
    {
        "text": ">> I just interrupted you because I want people to start",
        "start": 168.46,
        "duration": 2.29
    },
    {
        "text": "following along because you can follow along and do this live.",
        "start": 170.75,
        "duration": 2.97
    },
    {
        "text": ">> Absolutely. Yeah. So, what I'm going to do now is,",
        "start": 173.72,
        "duration": 3.69
    },
    {
        "text": "again, since this is a deep learning model.",
        "start": 177.41,
        "duration": 2.28
    },
    {
        "text": "This really helps when you have",
        "start": 179.69,
        "duration": 2.385
    },
    {
        "text": "a GPU to help you accelerate the training process.",
        "start": 182.075,
        "duration": 3.135
    },
    {
        "text": "So, a new feature that we launched in",
        "start": 185.21,
        "duration": 2.16
    },
    {
        "text": "Azure Notebooks is, two things actually.",
        "start": 187.37,
        "duration": 2.415
    },
    {
        "text": "The first part of it is",
        "start": 189.785,
        "duration": 1.44
    },
    {
        "text": "we integrate with your Azure subscription now.",
        "start": 191.225,
        "duration": 2.235
    },
    {
        "text": "So, with the Azure subscription integration,",
        "start": 193.46,
        "duration": 2.43
    },
    {
        "text": "you can now run",
        "start": 195.89,
        "duration": 2.28
    },
    {
        "text": "your compute on arbitrary VM sizes inside of Azure.",
        "start": 198.17,
        "duration": 3.36
    },
    {
        "text": ">> Oh, cool.",
        "start": 201.53,
        "duration": 0.72
    },
    {
        "text": ">> So, what we have now is, I've already set up and started a VM.",
        "start": 202.25,
        "duration": 3.21
    },
    {
        "text": "You see here. There's this button here that says,",
        "start": 205.46,
        "duration": 1.59
    },
    {
        "text": "\"Run on GPU DSVM.\"",
        "start": 207.05,
        "duration": 2.01
    },
    {
        "text": "That starts up a Jupyter notebook",
        "start": 209.06,
        "duration": 2.28
    },
    {
        "text": "server running on top of one of the Azure,",
        "start": 211.34,
        "duration": 2.34
    },
    {
        "text": "happens to be in NC S6 VM size.",
        "start": 213.68,
        "duration": 2.31
    },
    {
        "text": "If you happen to know that already, which",
        "start": 215.99,
        "duration": 1.8
    },
    {
        "text": "contains the GPU that we're going to be using.",
        "start": 217.79,
        "duration": 2.66
    },
    {
        "text": ">> Is there something you have to do on the VM in order to make",
        "start": 220.45,
        "duration": 2.89
    },
    {
        "text": "this work or is it just like it finds it and it does it?",
        "start": 223.34,
        "duration": 3.03
    },
    {
        "text": ">> So, it's literally like a turnkey experience in the sense",
        "start": 226.37,
        "duration": 3.0
    },
    {
        "text": "that you start the VM right now in the portal.",
        "start": 229.37,
        "duration": 3.6
    },
    {
        "text": "So, we don't currently have the experience was started from",
        "start": 232.97,
        "duration": 2.43
    },
    {
        "text": "within the Azure Notebooks experience yet, but that's coming.",
        "start": 235.4,
        "duration": 2.94
    },
    {
        "text": "So, if you go to the Notebook, you start up the VM.",
        "start": 238.34,
        "duration": 1.86
    },
    {
        "text": "It's called a Data Science VM.",
        "start": 240.2,
        "duration": 1.35
    },
    {
        "text": "So, if you search for a Linux Data Science VM in",
        "start": 241.55,
        "duration": 2.64
    },
    {
        "text": "the portal and you fill out all the forums.",
        "start": 244.19,
        "duration": 3.06
    },
    {
        "text": "You start that thing running.",
        "start": 247.25,
        "duration": 1.575
    },
    {
        "text": "Then from Azure Notebooks what you'll do is,",
        "start": 248.825,
        "duration": 2.435
    },
    {
        "text": "you either look for the IP address for that VM",
        "start": 251.26,
        "duration": 2.965
    },
    {
        "text": "or its DNS name or you can",
        "start": 254.225,
        "duration": 3.465
    },
    {
        "text": "also use this built-in drop-down thing which will",
        "start": 257.69,
        "duration": 2.79
    },
    {
        "text": "enumerate all of the running VMs that are in your subscriptions.",
        "start": 260.48,
        "duration": 4.005
    },
    {
        "text": ">> Oh, wow.",
        "start": 264.485,
        "duration": 0.315
    },
    {
        "text": ">> You just pick that one out of the list.",
        "start": 264.8,
        "duration": 1.395
    },
    {
        "text": ">> So, you have to provision the VM or do anything?",
        "start": 266.195,
        "duration": 2.775
    },
    {
        "text": ">> You have to provision in the sense you've got to turn it",
        "start": 268.97,
        "duration": 1.5
    },
    {
        "text": "on. So, we don't have the ability to turn on.",
        "start": 270.47,
        "duration": 1.695
    },
    {
        "text": "But once it's there,",
        "start": 272.165,
        "duration": 1.335
    },
    {
        "text": "we will enumerate all the running VMs that you have in",
        "start": 273.5,
        "duration": 2.19
    },
    {
        "text": "your Azure subscriptions and",
        "start": 275.69,
        "duration": 1.23
    },
    {
        "text": "you just pick the one that you want to use.",
        "start": 276.92,
        "duration": 1.2
    },
    {
        "text": ">> I don't have to install something on the VM for this to work?",
        "start": 278.12,
        "duration": 2.64
    },
    {
        "text": ">> No, just because all this stuff",
        "start": 280.76,
        "duration": 1.74
    },
    {
        "text": "it's kind of batteries included inside the VM.",
        "start": 282.5,
        "duration": 1.86
    },
    {
        "text": ">> That's cool.",
        "start": 284.36,
        "duration": 0.475
    },
    {
        "text": ">> Yeah.",
        "start": 284.835,
        "duration": 0.265
    },
    {
        "text": ">> Love it.",
        "start": 285.1,
        "duration": 0.625
    },
    {
        "text": ">> So, now that we're in here,",
        "start": 285.725,
        "duration": 1.615
    },
    {
        "text": "we have this Notebook that's running.",
        "start": 287.34,
        "duration": 2.01
    },
    {
        "text": "The very first thing that we typically want to do as",
        "start": 289.35,
        "duration": 1.88
    },
    {
        "text": "a data scientist is just kind of",
        "start": 291.23,
        "duration": 1.14
    },
    {
        "text": "take a look at what the data looks like.",
        "start": 292.37,
        "duration": 1.38
    },
    {
        "text": "What I'm going to do is, I'm going to run this cell.",
        "start": 293.75,
        "duration": 1.935
    },
    {
        "text": "If you haven't seen a Jupyter Notebook before,",
        "start": 295.685,
        "duration": 2.775
    },
    {
        "text": "Jupyter Notebooks are like blogs except for",
        "start": 298.46,
        "duration": 3.24
    },
    {
        "text": "the fact that you can actually run the code inside of the cell.",
        "start": 301.7,
        "duration": 3.15
    },
    {
        "text": "So, I can run a couple of different ways.",
        "start": 304.85,
        "duration": 1.2
    },
    {
        "text": "I can click on this \"Run\" button up here or I",
        "start": 306.05,
        "duration": 3.0
    },
    {
        "text": "can hit Shift + Enter while I'm inside of the cell.",
        "start": 309.05,
        "duration": 3.25
    },
    {
        "text": "I'm just going to do that because it's a convenient shortcut.",
        "start": 312.3,
        "duration": 2.18
    },
    {
        "text": "You can see sample pictures",
        "start": 314.48,
        "duration": 2.64
    },
    {
        "text": "one from each category that I've shown below.",
        "start": 317.12,
        "duration": 2.18
    },
    {
        "text": "So, these are the 37 different categories",
        "start": 319.3,
        "duration": 2.02
    },
    {
        "text": "of dogs and cats that we'll be using.",
        "start": 321.32,
        "duration": 1.545
    },
    {
        "text": "I'm going to now run this cell to start the training process.",
        "start": 322.865,
        "duration": 2.925
    },
    {
        "text": "So remember, we talked about this Transfer Learning idea.",
        "start": 325.79,
        "duration": 3.165
    },
    {
        "text": "So, Transfer Learning is great because we can train",
        "start": 328.955,
        "duration": 2.955
    },
    {
        "text": "just the final layer and it gains",
        "start": 331.91,
        "duration": 1.89
    },
    {
        "text": "so much smaller set of data",
        "start": 333.8,
        "duration": 1.47
    },
    {
        "text": "because we're starting with a pre-trained model.",
        "start": 335.27,
        "duration": 2.025
    },
    {
        "text": "The model that we're starting with is a model called MobileNet.",
        "start": 337.295,
        "duration": 3.93
    },
    {
        "text": "MobileNet is particularly interesting because",
        "start": 341.225,
        "duration": 2.31
    },
    {
        "text": "it's optimized to run on small devices.",
        "start": 343.535,
        "duration": 2.625
    },
    {
        "text": "It can run on phones and it can also run on",
        "start": 346.16,
        "duration": 1.83
    },
    {
        "text": "this AI camera that we've been showing",
        "start": 347.99,
        "duration": 1.74
    },
    {
        "text": "recently at a bunch of different events.",
        "start": 349.73,
        "duration": 1.995
    },
    {
        "text": "So, when we look through",
        "start": 351.725,
        "duration": 2.025
    },
    {
        "text": "this thing and this dataset we scroll to the bottom here,",
        "start": 353.75,
        "duration": 3.12
    },
    {
        "text": "you can see that we have",
        "start": 356.87,
        "duration": 1.23
    },
    {
        "text": "this test accuracy of about 80 percent, 79.5 percent here.",
        "start": 358.1,
        "duration": 4.27
    },
    {
        "text": "The test accuracy is important because when we were training",
        "start": 362.37,
        "duration": 3.41
    },
    {
        "text": "the model there's a set",
        "start": 365.78,
        "duration": 2.82
    },
    {
        "text": "of data we're using in the training and there's",
        "start": 368.6,
        "duration": 1.285
    },
    {
        "text": "a set of data we're using to validate it.",
        "start": 369.885,
        "duration": 1.52
    },
    {
        "text": "Then there's a set of data we held back,",
        "start": 371.405,
        "duration": 2.035
    },
    {
        "text": "just to see how good is this model is seeing a bunch of",
        "start": 373.44,
        "duration": 2.35
    },
    {
        "text": "pictures that it's never",
        "start": 375.79,
        "duration": 1.35
    },
    {
        "text": "seen before or during the training validation.",
        "start": 377.14,
        "duration": 1.74
    },
    {
        "text": "So, that's a thing that we use to",
        "start": 378.88,
        "duration": 2.055
    },
    {
        "text": "evaluate the goodness of the model and",
        "start": 380.935,
        "duration": 2.115
    },
    {
        "text": "80 percent is a pretty impressive result because",
        "start": 383.05,
        "duration": 2.205
    },
    {
        "text": "when this dataset first came out back in 2012,",
        "start": 385.255,
        "duration": 3.03
    },
    {
        "text": "the best models in the world that were hand-tuned by",
        "start": 388.285,
        "duration": 2.445
    },
    {
        "text": "AI researchers could only hit 59 percent accuracy.",
        "start": 390.73,
        "duration": 2.37
    },
    {
        "text": "So, about 25 seconds,",
        "start": 393.1,
        "duration": 1.61
    },
    {
        "text": "80 percent accuracy running on Azure.",
        "start": 394.71,
        "duration": 1.92
    },
    {
        "text": ">> Is pretty amazing.",
        "start": 396.63,
        "duration": 1.17
    },
    {
        "text": "I mean, when I was in school I had",
        "start": 397.8,
        "duration": 1.44
    },
    {
        "text": "a run like this supercomputer with this kind of stuff",
        "start": 399.24,
        "duration": 2.74
    },
    {
        "text": "and they only let me do it between 3:00",
        "start": 401.98,
        "duration": 2.1
    },
    {
        "text": "and 4:00 AM because I was an undergrad grad.",
        "start": 404.08,
        "duration": 2.305
    },
    {
        "text": ">> Yeah.",
        "start": 406.385,
        "duration": 0.64
    },
    {
        "text": ">> It's pretty better. That's amazing.",
        "start": 407.025,
        "duration": 2.22
    },
    {
        "text": ">> Yeah, I know. It's awesome. Now that you've got this,",
        "start": 409.245,
        "duration": 3.5
    },
    {
        "text": "we can see if we can do better than 80 percent.",
        "start": 412.745,
        "duration": 2.405
    },
    {
        "text": "So, now what we're going to do is,",
        "start": 415.15,
        "duration": 2.04
    },
    {
        "text": "we did all of this training,",
        "start": 417.19,
        "duration": 1.23
    },
    {
        "text": "all this transfer learning thing that we did right now.",
        "start": 418.42,
        "duration": 1.815
    },
    {
        "text": "We did it all using that VM,",
        "start": 420.235,
        "duration": 3.56
    },
    {
        "text": "the Data Science VM running on",
        "start": 423.795,
        "duration": 1.645
    },
    {
        "text": "the GPU connected from the Notebook.",
        "start": 425.44,
        "duration": 2.475
    },
    {
        "text": "There's a service that GA just connected",
        "start": 427.915,
        "duration": 3.42
    },
    {
        "text": "last week called the Azure Machine Learning on service.",
        "start": 431.335,
        "duration": 3.105
    },
    {
        "text": "There is a feature of that surface called hyperdrive.",
        "start": 434.44,
        "duration": 3.285
    },
    {
        "text": "Now as a data scientist,",
        "start": 437.725,
        "duration": 1.275
    },
    {
        "text": "oftentimes what you do is you want to tunes some parameters.",
        "start": 439.0,
        "duration": 3.27
    },
    {
        "text": "So, if you're a developer you know that, \"Hey,",
        "start": 442.27,
        "duration": 2.335
    },
    {
        "text": "I can try different optimization settings",
        "start": 444.605,
        "duration": 1.655
    },
    {
        "text": "in my compiler,\" but that's an example of",
        "start": 446.26,
        "duration": 1.68
    },
    {
        "text": "a primer hyperparameter as data scientists like to call it.",
        "start": 447.94,
        "duration": 4.155
    },
    {
        "text": "So, we're going to start off by doing some hyperparameter tuning.",
        "start": 452.095,
        "duration": 3.795
    },
    {
        "text": "There's a particular parameter in training these models called the",
        "start": 455.89,
        "duration": 4.485
    },
    {
        "text": "learning rate that's kind of think about is",
        "start": 460.375,
        "duration": 2.355
    },
    {
        "text": "the size of the step that you're",
        "start": 462.73,
        "duration": 1.2
    },
    {
        "text": "taking while you're trying to find the solution.",
        "start": 463.93,
        "duration": 2.43
    },
    {
        "text": "We're just going to throw random values at this in",
        "start": 466.36,
        "duration": 2.73
    },
    {
        "text": "a random distribution between 10 to",
        "start": 469.09,
        "duration": 1.35
    },
    {
        "text": "minus 15 and 10 to minus three.",
        "start": 470.44,
        "duration": 1.66
    },
    {
        "text": "All right. So, I'm going to try different things.",
        "start": 472.1,
        "duration": 2.32
    },
    {
        "text": "So, this is a service.",
        "start": 474.42,
        "duration": 1.965
    },
    {
        "text": "It lives inside of this Azure Machine Learning service.",
        "start": 476.385,
        "duration": 3.595
    },
    {
        "text": "Azure Machine Learning service uses",
        "start": 479.98,
        "duration": 1.47
    },
    {
        "text": "a concept called a workspace to",
        "start": 481.45,
        "duration": 1.5
    },
    {
        "text": "organize a bunch of resources that",
        "start": 482.95,
        "duration": 1.59
    },
    {
        "text": "you have, your compute resources.",
        "start": 484.54,
        "duration": 1.65
    },
    {
        "text": "In this case, I have a cluster that I've already started up,",
        "start": 486.19,
        "duration": 2.475
    },
    {
        "text": "which has five nodes, five GPU nodes running right now.",
        "start": 488.665,
        "duration": 3.315
    },
    {
        "text": "It also has a concept of experiments",
        "start": 491.98,
        "duration": 2.58
    },
    {
        "text": "which shows the different runs that you've taken over time,",
        "start": 494.56,
        "duration": 2.789
    },
    {
        "text": "as well as a dataset that we're using has",
        "start": 497.349,
        "duration": 1.501
    },
    {
        "text": "already been provisioned inside of his workspace.",
        "start": 498.85,
        "duration": 2.44
    },
    {
        "text": "So, what I did in that first line of code that I just ran,",
        "start": 501.29,
        "duration": 2.33
    },
    {
        "text": "I was just get a reference",
        "start": 503.62,
        "duration": 1.71
    },
    {
        "text": "to an experiment that I've already setup.",
        "start": 505.33,
        "duration": 2.13
    },
    {
        "text": "This line, this chunk of code in here happens to",
        "start": 507.46,
        "duration": 3.78
    },
    {
        "text": "be the code that gets deployed to each node of the cluster.",
        "start": 511.24,
        "duration": 3.75
    },
    {
        "text": "If you look carefully at these two lines of code up here,",
        "start": 514.99,
        "duration": 3.3
    },
    {
        "text": "you'll see that there's two parameters we've",
        "start": 518.29,
        "duration": 1.83
    },
    {
        "text": "essentially passing on the command line.",
        "start": 520.12,
        "duration": 1.95
    },
    {
        "text": "So, the hyperdrive demon passes in two parameters.",
        "start": 522.07,
        "duration": 3.51
    },
    {
        "text": "One is, \"Hey, this is where the data is stored.\"",
        "start": 525.58,
        "duration": 2.36
    },
    {
        "text": "The second one is, what's that learning rate that I",
        "start": 527.94,
        "duration": 2.35
    },
    {
        "text": "want this node to run on? So, it's really cool.",
        "start": 530.29,
        "duration": 3.0
    },
    {
        "text": "Once we have that done, we can switch over to",
        "start": 533.29,
        "duration": 2.74
    },
    {
        "text": "this cell and what the cell does is a couple of things.",
        "start": 536.03,
        "duration": 3.095
    },
    {
        "text": "It does this learning rate things.",
        "start": 539.125,
        "duration": 2.185
    },
    {
        "text": "So, this log uniform distribution",
        "start": 541.31,
        "duration": 1.77
    },
    {
        "text": "is- yeah I just want random numbers",
        "start": 543.08,
        "duration": 1.78
    },
    {
        "text": "but random based on",
        "start": 544.86,
        "duration": 2.64
    },
    {
        "text": "logarithmic units not on non-logarithmic units.",
        "start": 547.5,
        "duration": 2.9
    },
    {
        "text": "And we're going to go deploy this thing out",
        "start": 550.4,
        "duration": 2.07
    },
    {
        "text": "and and start this run using the hyper drive demo.",
        "start": 552.47,
        "duration": 3.335
    },
    {
        "text": "Now, as this thing is running,",
        "start": 555.805,
        "duration": 1.885
    },
    {
        "text": "we'd like to see progress.",
        "start": 557.69,
        "duration": 1.56
    },
    {
        "text": "So we'll fire up",
        "start": 559.25,
        "duration": 1.715
    },
    {
        "text": "this next line of code which starts showing this on this widget.",
        "start": 560.965,
        "duration": 2.75
    },
    {
        "text": "This widget it's some HTML that's",
        "start": 563.715,
        "duration": 3.13
    },
    {
        "text": "running dynamically in there that shows me",
        "start": 566.845,
        "duration": 1.555
    },
    {
        "text": "the status of my cluster and what's going on.",
        "start": 568.4,
        "duration": 1.995
    },
    {
        "text": "This is going to take some time to complete.",
        "start": 570.395,
        "duration": 1.765
    },
    {
        "text": "So, I'm going to switch to looking at a completed run for",
        "start": 572.16,
        "duration": 3.3
    },
    {
        "text": "time and this completed run I did already,",
        "start": 575.46,
        "duration": 4.235
    },
    {
        "text": "a bit earlier and you'll see that it's populating the runs.",
        "start": 579.695,
        "duration": 4.2
    },
    {
        "text": "So, as it's trying each one,",
        "start": 583.895,
        "duration": 1.76
    },
    {
        "text": "the experiment that we ran",
        "start": 585.655,
        "duration": 2.295
    },
    {
        "text": "tried 20 different random values would run",
        "start": 588.11,
        "duration": 3.005
    },
    {
        "text": "up to four computes in parallel on the cluster and when it's done,",
        "start": 591.115,
        "duration": 6.165
    },
    {
        "text": "what's kind of cool here is it shows all of",
        "start": 597.28,
        "duration": 2.835
    },
    {
        "text": "the completed runs and it shows us graph of how",
        "start": 600.115,
        "duration": 2.975
    },
    {
        "text": "that validation error or",
        "start": 603.09,
        "duration": 2.245
    },
    {
        "text": "the validation accuracy was improving as the run went on.",
        "start": 605.335,
        "duration": 4.215
    },
    {
        "text": "Now, the interesting thing about what the final result was,",
        "start": 609.55,
        "duration": 3.935
    },
    {
        "text": "was that we got about a 90 percent test accuracy.",
        "start": 613.485,
        "duration": 4.635
    },
    {
        "text": "We traded maybe about 20 minutes to run on",
        "start": 618.12,
        "duration": 3.44
    },
    {
        "text": "this hyperdrive cluster to",
        "start": 621.56,
        "duration": 2.22
    },
    {
        "text": "get an additional 10 percent which is fantastic.",
        "start": 623.78,
        "duration": 2.465
    },
    {
        "text": ">> Yes, oh yes that's amazing.",
        "start": 626.245,
        "duration": 2.035
    },
    {
        "text": ">> Yeah.",
        "start": 628.28,
        "duration": 0.62
    },
    {
        "text": ">> The other thing is generally",
        "start": 628.9,
        "duration": 2.26
    },
    {
        "text": "what I would do as a data scientist would be like,",
        "start": 631.16,
        "duration": 2.04
    },
    {
        "text": "\"Well, let me try 10 to the minus five",
        "start": 633.2,
        "duration": 2.73
    },
    {
        "text": "here to see what happens\" and then I run it and six minutes later.",
        "start": 635.93,
        "duration": 3.345
    },
    {
        "text": "Let me try. So, this",
        "start": 639.275,
        "duration": 2.175
    },
    {
        "text": "is cool because it feels like it's a ginormous",
        "start": 641.45,
        "duration": 1.83
    },
    {
        "text": "for-loop going over random values",
        "start": 643.28,
        "duration": 2.2
    },
    {
        "text": "of these parameters and you don't have to do anything.",
        "start": 645.48,
        "duration": 1.9
    },
    {
        "text": ">> Yes.",
        "start": 647.38,
        "duration": 0.535
    },
    {
        "text": ">> Now is it going to run all of these jobs to",
        "start": 647.915,
        "duration": 2.065
    },
    {
        "text": "completion or is there a way to stop the ones that just stay?",
        "start": 649.98,
        "duration": 2.88
    },
    {
        "text": ">> Yeah, that's a fantastic question",
        "start": 652.86,
        "duration": 2.45
    },
    {
        "text": "because there's this- it's almost like I paid you to say that.",
        "start": 655.31,
        "duration": 2.88
    },
    {
        "text": ">> I know.",
        "start": 658.19,
        "duration": 0.825
    },
    {
        "text": ">> So, this one line of code that's sitting",
        "start": 659.015,
        "duration": 3.165
    },
    {
        "text": "inside of here which is called this early termination policy.",
        "start": 662.18,
        "duration": 3.305
    },
    {
        "text": "What the early termination policy says is if this run is",
        "start": 665.485,
        "duration": 4.365
    },
    {
        "text": "less than 15 percent",
        "start": 669.85,
        "duration": 2.12
    },
    {
        "text": "away from the best value that I've seen so far,",
        "start": 671.97,
        "duration": 4.235
    },
    {
        "text": "just go terminate this run early.",
        "start": 676.205,
        "duration": 2.51
    },
    {
        "text": "So after so many steps,",
        "start": 678.715,
        "duration": 1.78
    },
    {
        "text": "we're going to terminate this run and so",
        "start": 680.495,
        "duration": 2.055
    },
    {
        "text": "that allows me to reclaim that node that was",
        "start": 682.55,
        "duration": 2.24
    },
    {
        "text": "being used on this run that's probably not going to",
        "start": 684.79,
        "duration": 1.9
    },
    {
        "text": "convert and I can replace it with a different value.",
        "start": 686.69,
        "duration": 2.865
    },
    {
        "text": ">> That's awesome and I knew the answer to",
        "start": 689.555,
        "duration": 2.54
    },
    {
        "text": "this beforehand but it's cool because like originally,",
        "start": 692.095,
        "duration": 2.975
    },
    {
        "text": "I could just run a for-loop and think I'm",
        "start": 695.07,
        "duration": 1.26
    },
    {
        "text": "a really smart data scientists,",
        "start": 696.33,
        "duration": 1.325
    },
    {
        "text": "looping over random value,",
        "start": 697.655,
        "duration": 1.305
    },
    {
        "text": "log uniform values but now I can",
        "start": 698.96,
        "duration": 2.73
    },
    {
        "text": "actually run them and have",
        "start": 701.69,
        "duration": 1.2
    },
    {
        "text": "the jobs killed without having to do anything.",
        "start": 702.89,
        "duration": 1.785
    },
    {
        "text": ">> Exactly, yeah. So, now",
        "start": 704.675,
        "duration": 2.445
    },
    {
        "text": "they've got this experiment that's run to completion,",
        "start": 707.12,
        "duration": 2.58
    },
    {
        "text": "I can now register the best run inside of the model,",
        "start": 709.7,
        "duration": 5.05
    },
    {
        "text": "so there's this best run thing that I'm going to do",
        "start": 714.75,
        "duration": 3.835
    },
    {
        "text": "now which is going to go literally just",
        "start": 718.585,
        "duration": 2.125
    },
    {
        "text": "pull out the best one from that experiment,",
        "start": 720.71,
        "duration": 2.34
    },
    {
        "text": "register it inside of",
        "start": 723.05,
        "duration": 1.47
    },
    {
        "text": "the Azure Machine Learning Service",
        "start": 724.52,
        "duration": 1.37
    },
    {
        "text": "so that I can now give it a Wrong.",
        "start": 725.89,
        "duration": 2.16
    },
    {
        "text": "So Wrong is our developer here and she's going to",
        "start": 728.05,
        "duration": 2.2
    },
    {
        "text": "help us take this model that I finished training.",
        "start": 730.25,
        "duration": 2.01
    },
    {
        "text": "So remember I've trained and optimize my small amount,",
        "start": 732.26,
        "duration": 2.415
    },
    {
        "text": "90 percent on test accuracy.",
        "start": 734.675,
        "duration": 2.815
    },
    {
        "text": "Now she's going to deploy it into production.",
        "start": 737.49,
        "duration": 1.91
    },
    {
        "text": ">> So let's pause for a minute because maybe there are",
        "start": 739.4,
        "duration": 1.925
    },
    {
        "text": "people that are watching out there, they are new to AI.",
        "start": 741.325,
        "duration": 1.995
    },
    {
        "text": "You keep saying this notion of a model, what is a model?",
        "start": 743.32,
        "duration": 3.135
    },
    {
        "text": ">> So model you just think about it as a function.",
        "start": 746.455,
        "duration": 2.13
    },
    {
        "text": "It is a function that took some input and tries",
        "start": 748.585,
        "duration": 2.49
    },
    {
        "text": "to generate or make",
        "start": 751.075,
        "duration": 1.17
    },
    {
        "text": "a prediction about what the output is going to be.",
        "start": 752.245,
        "duration": 1.635
    },
    {
        "text": "So, what we'll see here",
        "start": 753.88,
        "duration": 1.905
    },
    {
        "text": "is the input obviously is going to be a picture,",
        "start": 755.785,
        "duration": 3.07
    },
    {
        "text": "it's going to be a picture of",
        "start": 758.855,
        "duration": 1.56
    },
    {
        "text": "some animal and the model is going to say,",
        "start": 760.415,
        "duration": 2.325
    },
    {
        "text": "oh this is- remember there's",
        "start": 762.74,
        "duration": 1.84
    },
    {
        "text": "these 37 categories that the model knows about.",
        "start": 764.58,
        "duration": 2.19
    },
    {
        "text": "So it knows what these 37 on",
        "start": 766.77,
        "duration": 1.5
    },
    {
        "text": "different breeds of dogs and cats and you say,",
        "start": 768.27,
        "duration": 2.275
    },
    {
        "text": "oh I think the likelihood of this thing",
        "start": 770.545,
        "duration": 2.005
    },
    {
        "text": "being this kind of dog is going to be this percent.",
        "start": 772.55,
        "duration": 3.275
    },
    {
        "text": ">> Got it.",
        "start": 775.825,
        "duration": 0.43
    },
    {
        "text": ">> So, it's going to give us a rank of the top five results.",
        "start": 776.255,
        "duration": 2.265
    },
    {
        "text": ">> Yeah. We'll see this thing action little bit.",
        "start": 778.52,
        "duration": 2.49
    },
    {
        "text": ">> Awesome. So now that the data scientists",
        "start": 781.01,
        "duration": 1.62
    },
    {
        "text": "is done and they've been overpaid,",
        "start": 782.63,
        "duration": 1.5
    },
    {
        "text": "let's get to the actual work.",
        "start": 784.13,
        "duration": 1.47
    },
    {
        "text": ">> Actual work is done by developers, right?",
        "start": 785.6,
        "duration": 2.95
    },
    {
        "text": ">> That's right. So I would say two things here,",
        "start": 788.55,
        "duration": 2.875
    },
    {
        "text": "first so John has trained",
        "start": 791.425,
        "duration": 2.19
    },
    {
        "text": "model in the notebook and we want to turn",
        "start": 793.615,
        "duration": 2.88
    },
    {
        "text": "this notebook into a Python module",
        "start": 796.495,
        "duration": 3.02
    },
    {
        "text": "so we can do more trainings in the future.",
        "start": 799.515,
        "duration": 2.525
    },
    {
        "text": "Let's say we get more data, we'll retrain,",
        "start": 802.04,
        "duration": 2.355
    },
    {
        "text": "we'll turn that into a piece of",
        "start": 804.395,
        "duration": 1.365
    },
    {
        "text": "software that can be source control.",
        "start": 805.76,
        "duration": 2.25
    },
    {
        "text": "So that would be my first job.",
        "start": 808.01,
        "duration": 1.7
    },
    {
        "text": "Second job is, the model that John has trained and optimized,",
        "start": 809.71,
        "duration": 4.265
    },
    {
        "text": "we're going to deploy that as a service in Azure and then",
        "start": 813.975,
        "duration": 3.905
    },
    {
        "text": "we'll see how we can use that model as a service in application.",
        "start": 817.88,
        "duration": 4.035
    },
    {
        "text": ">> And then become rich. So we make a mobile app",
        "start": 821.915,
        "duration": 1.915
    },
    {
        "text": "obviously that pings the API and then we're rich.",
        "start": 823.83,
        "duration": 2.04
    },
    {
        "text": ">> Yes.",
        "start": 825.87,
        "duration": 0.595
    },
    {
        "text": ">> Pretty excited about this. All in like 30 minutes.",
        "start": 826.465,
        "duration": 2.415
    },
    {
        "text": ">> Yes. All right, now, let's get started.",
        "start": 828.88,
        "duration": 2.645
    },
    {
        "text": ">> Let's do it.",
        "start": 831.525,
        "duration": 0.385
    },
    {
        "text": ">> So as a developer,",
        "start": 831.91,
        "duration": 1.425
    },
    {
        "text": "I'm going to use my favorite tool to do both jobs an,",
        "start": 833.335,
        "duration": 5.205
    },
    {
        "text": "d let's get started with getting the notebook that John had.",
        "start": 838.54,
        "duration": 4.23
    },
    {
        "text": "So, the easiest thing to get",
        "start": 842.77,
        "duration": 1.97
    },
    {
        "text": "that is to get clone because it's already on",
        "start": 844.74,
        "duration": 4.08
    },
    {
        "text": "GitHub and all I have to do is to run",
        "start": 848.82,
        "duration": 2.36
    },
    {
        "text": "this command VS code and give it the URL and download everything.",
        "start": 851.18,
        "duration": 4.55
    },
    {
        "text": "Now, I already have that downloaded",
        "start": 855.73,
        "duration": 2.8
    },
    {
        "text": "on my local machine right here.",
        "start": 858.53,
        "duration": 2.785
    },
    {
        "text": "So, the file we are",
        "start": 861.315,
        "duration": 1.445
    },
    {
        "text": "interested in here is this notebook file, exact same thing.",
        "start": 862.76,
        "duration": 2.19
    },
    {
        "text": ">> Here's the challenge that I have.",
        "start": 864.95,
        "duration": 1.415
    },
    {
        "text": "I have a challenge with notebook files primarily because I love",
        "start": 866.365,
        "duration": 2.92
    },
    {
        "text": "working with them but as a dev they're not useful.",
        "start": 869.285,
        "duration": 3.345
    },
    {
        "text": "I end up going over there and copying",
        "start": 872.63,
        "duration": 1.81
    },
    {
        "text": "the code and then I move it over and then I have to",
        "start": 874.44,
        "duration": 1.885
    },
    {
        "text": "refactor it because between us at",
        "start": 876.325,
        "duration": 2.695
    },
    {
        "text": "data scientists - So we have to fix it.",
        "start": 879.02,
        "duration": 4.98
    },
    {
        "text": ">> Lots of copying and pasting.",
        "start": 884.0,
        "duration": 1.02
    },
    {
        "text": ">> No offense.",
        "start": 885.02,
        "duration": 0.46
    },
    {
        "text": ">> Lots of copying and pasting",
        "start": 885.48,
        "duration": 1.05
    },
    {
        "text": ">> No offense. Zero ways for me to streamline this.",
        "start": 886.53,
        "duration": 2.42
    },
    {
        "text": ">> Right. So, yeah the first thing we're going to do",
        "start": 888.95,
        "duration": 2.87
    },
    {
        "text": "is let's take this notebook file and see what it looks like.",
        "start": 891.82,
        "duration": 3.745
    },
    {
        "text": "If you open this in- straight in VS code,",
        "start": 895.565,
        "duration": 2.46
    },
    {
        "text": "you get this as a JSON format.",
        "start": 898.025,
        "duration": 2.235
    },
    {
        "text": "But we're going to get a much richer experiencing",
        "start": 900.26,
        "duration": 2.59
    },
    {
        "text": "seeing this to the code using the Python extension.",
        "start": 902.85,
        "duration": 2.765
    },
    {
        "text": "Notice there's a pop-up message asking me if I want to import",
        "start": 905.615,
        "duration": 3.285
    },
    {
        "text": "this into VS Code as Python code and I do.",
        "start": 908.9,
        "duration": 3.8
    },
    {
        "text": "So, I click on import, and right there,",
        "start": 912.7,
        "duration": 2.485
    },
    {
        "text": "all the code is extracted from the notebook right here.",
        "start": 915.185,
        "duration": 4.485
    },
    {
        "text": ">> I feel like this happened really fast and people",
        "start": 919.67,
        "duration": 2.38
    },
    {
        "text": "just don't get the gravity of this and I've",
        "start": 922.05,
        "duration": 2.36
    },
    {
        "text": "seen this demo before and obviously I knew",
        "start": 924.41,
        "duration": 2.28
    },
    {
        "text": "a question to ask but I have spent",
        "start": 926.69,
        "duration": 2.57
    },
    {
        "text": "way too much of my life copying",
        "start": 929.26,
        "duration": 2.565
    },
    {
        "text": "stuff out of a notebook and then moving it over,",
        "start": 931.825,
        "duration": 2.8
    },
    {
        "text": "doing it in one click and doing it in a sensible way and",
        "start": 934.625,
        "duration": 2.75
    },
    {
        "text": "having this little thing that says run cell to me is amazing.",
        "start": 937.375,
        "duration": 2.98
    },
    {
        "text": ">> Yeah. That hopefully saves a lot of copy and paste work.",
        "start": 940.355,
        "duration": 4.4
    },
    {
        "text": "So, one thing you'll notice is we have",
        "start": 944.755,
        "duration": 2.425
    },
    {
        "text": "converted or the markdown cells as comments,",
        "start": 947.18,
        "duration": 3.27
    },
    {
        "text": "so you can keep those in your file and the code cells as code.",
        "start": 950.45,
        "duration": 4.32
    },
    {
        "text": "And what's more magic about this conversion",
        "start": 954.77,
        "duration": 2.74
    },
    {
        "text": "is we put these little marks in there so we keep",
        "start": 957.51,
        "duration": 3.76
    },
    {
        "text": "all your cell structure from the notebook into",
        "start": 961.27,
        "duration": 3.225
    },
    {
        "text": "your code and once you have those annotations your code,",
        "start": 964.495,
        "duration": 3.67
    },
    {
        "text": "you will see this Run Cell,",
        "start": 968.165,
        "duration": 1.575
    },
    {
        "text": "[inaudible] up which means we can run these cells",
        "start": 969.74,
        "duration": 4.655
    },
    {
        "text": "inside VS code in",
        "start": 974.395,
        "duration": 1.495
    },
    {
        "text": "an interactive way just like you're working with Jupyter.",
        "start": 975.89,
        "duration": 3.68
    },
    {
        "text": "So, I just clicked on \"Run Cell\" here here,",
        "start": 979.57,
        "duration": 4.01
    },
    {
        "text": "so what happened was this brings",
        "start": 983.58,
        "duration": 2.31
    },
    {
        "text": "up a Jupyter server on my machine and",
        "start": 985.89,
        "duration": 2.51
    },
    {
        "text": "then gets results back and we",
        "start": 988.4,
        "duration": 2.04
    },
    {
        "text": "present that in this Python interactive window.",
        "start": 990.44,
        "duration": 3.045
    },
    {
        "text": "So, this is a markdown cell,",
        "start": 993.485,
        "duration": 1.835
    },
    {
        "text": "if I move down here,",
        "start": 995.32,
        "duration": 1.5
    },
    {
        "text": "I can run a co cell and now again I can use",
        "start": 996.82,
        "duration": 2.72
    },
    {
        "text": "the same shortcut key",
        "start": 999.54,
        "duration": 2.255
    },
    {
        "text": "\"Shift+Enter\" that John used earlier to run a cell.",
        "start": 1001.795,
        "duration": 3.165
    },
    {
        "text": ">> Oops, \"Cmd+Enter\"",
        "start": 1004.96,
        "duration": 2.86
    },
    {
        "text": ">> Yes.",
        "start": 1007.87,
        "duration": 1.54
    },
    {
        "text": ">> Oops, not \"Cmd+Enter.\"",
        "start": 1009.41,
        "duration": 2.16
    },
    {
        "text": ">> I didn't realize that it didn't work,",
        "start": 1012.55,
        "duration": 2.755
    },
    {
        "text": "and must be something else.",
        "start": 1015.305,
        "duration": 2.1
    },
    {
        "text": ">> It's Max fault.",
        "start": 1017.405,
        "duration": 1.395
    },
    {
        "text": ">> Yeah.",
        "start": 1018.8,
        "duration": 0.735
    },
    {
        "text": ">> Yeah, we're going to blame it on that.",
        "start": 1019.535,
        "duration": 1.695
    },
    {
        "text": ">> Yeah.",
        "start": 1021.23,
        "duration": 0.435
    },
    {
        "text": ">> Look-.",
        "start": 1021.665,
        "duration": 0.36
    },
    {
        "text": ">> I [inaudible] like these these only seedy things",
        "start": 1022.025,
        "duration": 2.295
    },
    {
        "text": "with touch bar thing like that this copy.",
        "start": 1024.32,
        "duration": 1.56
    },
    {
        "text": ">> Honestly, I think that just being able to",
        "start": 1025.88,
        "duration": 1.95
    },
    {
        "text": "click on like having it there.",
        "start": 1027.83,
        "duration": 2.34
    },
    {
        "text": "I did a demo with this just recently and just",
        "start": 1030.17,
        "duration": 2.85
    },
    {
        "text": "being able to show like here's what happened and be like, \"Oh,",
        "start": 1033.02,
        "duration": 2.64
    },
    {
        "text": "let me type this up real quick and run it,\" and have it all in",
        "start": 1035.66,
        "duration": 1.92
    },
    {
        "text": "Visual Studio Code to me as a developer it kind of like,",
        "start": 1037.58,
        "duration": 2.55
    },
    {
        "text": "\"Oh, this is my environment. I like it.\"",
        "start": 1040.13,
        "duration": 1.74
    },
    {
        "text": ">> Yeah.",
        "start": 1041.87,
        "duration": 0.36
    },
    {
        "text": ">> All right. Let's just try,",
        "start": 1042.23,
        "duration": 1.41
    },
    {
        "text": "click which will run this code cell,",
        "start": 1043.64,
        "duration": 3.765
    },
    {
        "text": "and now we are looking at these pictures from",
        "start": 1047.405,
        "duration": 3.69
    },
    {
        "text": "each breed of dogs and",
        "start": 1051.095,
        "duration": 1.815
    },
    {
        "text": "cats that we have seen earlier in the notebook.",
        "start": 1052.91,
        "duration": 2.1
    },
    {
        "text": ">> Right.",
        "start": 1055.01,
        "duration": 0.24
    },
    {
        "text": ">> So, you get the similar experience in here.",
        "start": 1055.25,
        "duration": 2.97
    },
    {
        "text": "So, let's take a quick look at this interactive window.",
        "start": 1058.22,
        "duration": 3.66
    },
    {
        "text": "This is the newest feature edition",
        "start": 1061.88,
        "duration": 2.07
    },
    {
        "text": "in the Python extension for VS code.",
        "start": 1063.95,
        "duration": 2.295
    },
    {
        "text": "So in here, we can not only run,",
        "start": 1066.245,
        "duration": 2.55
    },
    {
        "text": "see the results, but also you could clear results.",
        "start": 1068.795,
        "duration": 4.365
    },
    {
        "text": "Say here, or you want you can navigate",
        "start": 1073.16,
        "duration": 2.73
    },
    {
        "text": "back to your source code, right there.",
        "start": 1075.89,
        "duration": 2.58
    },
    {
        "text": "So, it goes back there.",
        "start": 1078.47,
        "duration": 1.56
    },
    {
        "text": "You can restart kernel or instruct the kernel,",
        "start": 1080.03,
        "duration": 3.119
    },
    {
        "text": "and once you are done,",
        "start": 1083.149,
        "duration": 2.071
    },
    {
        "text": "you can even export the results back to be a notebook file.",
        "start": 1085.22,
        "duration": 3.6
    },
    {
        "text": ">> Oh, that's cool. So, you get start with code",
        "start": 1088.82,
        "duration": 1.62
    },
    {
        "text": "first and then go to note book if you want.",
        "start": 1090.44,
        "duration": 2.13
    },
    {
        "text": ">> So, give it to",
        "start": 1092.57,
        "duration": 1.32
    },
    {
        "text": "data scientists and to view the results and all that.",
        "start": 1093.89,
        "duration": 3.78
    },
    {
        "text": "Okay. So, let's close that window now.",
        "start": 1097.67,
        "duration": 4.485
    },
    {
        "text": "So now, I'm ready to start",
        "start": 1102.155,
        "duration": 2.025
    },
    {
        "text": "refactoring the code into a Python module.",
        "start": 1104.18,
        "duration": 2.13
    },
    {
        "text": "A couple of features that would be",
        "start": 1106.31,
        "duration": 1.92
    },
    {
        "text": "really handy in this task is let's say,",
        "start": 1108.23,
        "duration": 2.55
    },
    {
        "text": "I want to take this chunk of code and put that into a function.",
        "start": 1110.78,
        "duration": 5.895
    },
    {
        "text": "I can use extract method right there.",
        "start": 1116.675,
        "duration": 3.325
    },
    {
        "text": "Save changes and name it check_dataset,",
        "start": 1121.3,
        "duration": 6.235
    },
    {
        "text": "and just like that.",
        "start": 1127.535,
        "duration": 2.875
    },
    {
        "text": "Okay? Maybe not. Usually, this is pretty fast.",
        "start": 1132.07,
        "duration": 4.36
    },
    {
        "text": ">> Right.",
        "start": 1136.43,
        "duration": 0.39
    },
    {
        "text": ">> About second.",
        "start": 1136.82,
        "duration": 0.78
    },
    {
        "text": ">> As I'm looking at this like one of the cool things about this",
        "start": 1137.6,
        "duration": 2.61
    },
    {
        "text": "is like I said when I'm doing this code,",
        "start": 1140.21,
        "duration": 3.575
    },
    {
        "text": "it's nice to be able to take because look,",
        "start": 1143.785,
        "duration": 2.835
    },
    {
        "text": "notebook code is not something I would",
        "start": 1146.62,
        "duration": 1.65
    },
    {
        "text": "actually like it's not I wouldn't check it in,",
        "start": 1148.27,
        "duration": 2.38
    },
    {
        "text": "but I would check it in for other reasons to explore,",
        "start": 1150.65,
        "duration": 2.91
    },
    {
        "text": "to annotate, to understand, right?",
        "start": 1153.56,
        "duration": 1.98
    },
    {
        "text": "But this code I would actually use to",
        "start": 1155.54,
        "duration": 1.92
    },
    {
        "text": "actually check into source code,",
        "start": 1157.46,
        "duration": 2.505
    },
    {
        "text": "run interactive jobs somewhere else.",
        "start": 1159.965,
        "duration": 2.31
    },
    {
        "text": ">> Yeah. Kind of simple idea about why we want to do this.",
        "start": 1162.275,
        "duration": 2.805
    },
    {
        "text": "This refactoring here is to",
        "start": 1165.08,
        "duration": 1.35
    },
    {
        "text": "turn this thing into a software artifact.",
        "start": 1166.43,
        "duration": 1.89
    },
    {
        "text": ">> Right.",
        "start": 1168.32,
        "duration": 0.15
    },
    {
        "text": ">> Away from this notebook artifact you know software artifact.",
        "start": 1168.47,
        "duration": 2.4
    },
    {
        "text": "I can version control it.",
        "start": 1170.87,
        "duration": 1.245
    },
    {
        "text": "I can run it again simply by",
        "start": 1172.115,
        "duration": 1.44
    },
    {
        "text": "importing it as a module and just in Python script.",
        "start": 1173.555,
        "duration": 2.475
    },
    {
        "text": "So, this could happen if I",
        "start": 1176.03,
        "duration": 2.04
    },
    {
        "text": "wanted to train it on additional breeds of dogs.",
        "start": 1178.07,
        "duration": 2.19
    },
    {
        "text": "I find some more pictures of dogs and cats out",
        "start": 1180.26,
        "duration": 1.38
    },
    {
        "text": "there or just added to my dataset,",
        "start": 1181.64,
        "duration": 1.71
    },
    {
        "text": "and then we run the model [inaudible].",
        "start": 1183.35,
        "duration": 1.8
    },
    {
        "text": ">> Or you maybe you get someone who says,",
        "start": 1185.15,
        "duration": 1.86
    },
    {
        "text": "\"Hey is super important for the business that",
        "start": 1187.01,
        "duration": 2.28
    },
    {
        "text": "we start to understand cat breeds too.",
        "start": 1189.29,
        "duration": 2.46
    },
    {
        "text": "Then you can start to add",
        "start": 1191.75,
        "duration": 1.185
    },
    {
        "text": "more data and then do the training again.",
        "start": 1192.935,
        "duration": 1.935
    },
    {
        "text": "We know this works. We can try it again.",
        "start": 1194.87,
        "duration": 1.485
    },
    {
        "text": ">> Exactly.",
        "start": 1196.355,
        "duration": 0.615
    },
    {
        "text": ">> Yeah. In this process",
        "start": 1196.97,
        "duration": 1.995
    },
    {
        "text": "like I mentioned a couple of other features,",
        "start": 1198.965,
        "duration": 2.025
    },
    {
        "text": "let's just take a quick look and see if I",
        "start": 1200.99,
        "duration": 2.205
    },
    {
        "text": "have another piece of code I wanted to do something with,",
        "start": 1203.195,
        "duration": 3.285
    },
    {
        "text": "right click, and then I have renamed",
        "start": 1206.48,
        "duration": 2.37
    },
    {
        "text": "single, change our currencies.",
        "start": 1208.85,
        "duration": 2.745
    },
    {
        "text": "Like if you want to refactor code, no more format.",
        "start": 1211.595,
        "duration": 3.66
    },
    {
        "text": "That means you have to look for code across",
        "start": 1215.255,
        "duration": 2.895
    },
    {
        "text": "different cells which is really difficult to find and replace.",
        "start": 1218.15,
        "duration": 4.26
    },
    {
        "text": "But this you can do all once.",
        "start": 1222.41,
        "duration": 2.145
    },
    {
        "text": "I can sort my imports and",
        "start": 1224.555,
        "duration": 3.855
    },
    {
        "text": "I can even extract variables to make it cleaner.",
        "start": 1228.41,
        "duration": 4.095
    },
    {
        "text": "I can use the [inaudible] debugger right here in VS code, right here.",
        "start": 1232.505,
        "duration": 5.31
    },
    {
        "text": "So, all I have to do is click this button,",
        "start": 1237.815,
        "duration": 2.73
    },
    {
        "text": "arrow button or press F5 to start debugging.",
        "start": 1240.545,
        "duration": 2.49
    },
    {
        "text": "There's no configuration needed,",
        "start": 1243.035,
        "duration": 2.385
    },
    {
        "text": "if I only want to debug",
        "start": 1245.42,
        "duration": 1.755
    },
    {
        "text": "this one single file and you can hit breakpoints,",
        "start": 1247.175,
        "duration": 3.045
    },
    {
        "text": "look at variables and they call",
        "start": 1250.22,
        "duration": 2.22
    },
    {
        "text": "stack and everything you would expect with a debugger.",
        "start": 1252.44,
        "duration": 2.31
    },
    {
        "text": "So, all right there. So, just to putting chunks of time,",
        "start": 1254.75,
        "duration": 4.455
    },
    {
        "text": "let's switch over to finish the version",
        "start": 1259.205,
        "duration": 2.7
    },
    {
        "text": "that it kind of refactored it little bit.",
        "start": 1261.905,
        "duration": 2.265
    },
    {
        "text": "You can see I have imports sorted at the top,",
        "start": 1264.17,
        "duration": 3.84
    },
    {
        "text": "put code into functions.",
        "start": 1268.01,
        "duration": 2.4
    },
    {
        "text": ">> This feels more Cody to me.",
        "start": 1270.41,
        "duration": 1.65
    },
    {
        "text": ">> Right and then I can call",
        "start": 1272.06,
        "duration": 2.25
    },
    {
        "text": "these functions or even from a different module like John said,",
        "start": 1274.31,
        "duration": 3.945
    },
    {
        "text": "and then I can take this file,",
        "start": 1278.255,
        "duration": 2.25
    },
    {
        "text": "put this under source control and for collaboration,",
        "start": 1280.505,
        "duration": 5.025
    },
    {
        "text": "for version control and all that.",
        "start": 1285.53,
        "duration": 3.0
    },
    {
        "text": "Okay. So, now I've completed",
        "start": 1288.53,
        "duration": 2.82
    },
    {
        "text": "my first task which is turn code into a Python module.",
        "start": 1291.35,
        "duration": 3.645
    },
    {
        "text": "Now, let's work on the second one which",
        "start": 1294.995,
        "duration": 1.665
    },
    {
        "text": "is we're going to take model,",
        "start": 1296.66,
        "duration": 2.535
    },
    {
        "text": "the best model we have optimized and deploy that as",
        "start": 1299.195,
        "duration": 4.305
    },
    {
        "text": "a web service on Azure and look",
        "start": 1303.5,
        "duration": 2.31
    },
    {
        "text": "at how we can do that easily in VS code.",
        "start": 1305.81,
        "duration": 4.065
    },
    {
        "text": "So to do that, I'm going to need an extension",
        "start": 1309.875,
        "duration": 3.765
    },
    {
        "text": "called Azure Machine Learning extension,",
        "start": 1313.64,
        "duration": 3.599
    },
    {
        "text": "and I already have that installed.",
        "start": 1317.239,
        "duration": 1.531
    },
    {
        "text": "Once I have that, I can access",
        "start": 1318.77,
        "duration": 2.49
    },
    {
        "text": "everything in my Azure Machine Learning Service,",
        "start": 1321.26,
        "duration": 3.06
    },
    {
        "text": "and this is my workspace right here, my subscription,",
        "start": 1324.32,
        "duration": 4.605
    },
    {
        "text": "and what we're going to see is the model",
        "start": 1328.925,
        "duration": 4.005
    },
    {
        "text": "that John has registered earlier from the Azure Notebooks,",
        "start": 1332.93,
        "duration": 3.96
    },
    {
        "text": "and we can see the same information right here,",
        "start": 1336.89,
        "duration": 3.54
    },
    {
        "text": "and this is the model that was deployed and that was registered,",
        "start": 1340.43,
        "duration": 4.56
    },
    {
        "text": "and to deploy, you simple you just have to right click,",
        "start": 1344.99,
        "duration": 3.57
    },
    {
        "text": "and select this menu item.",
        "start": 1348.56,
        "duration": 2.28
    },
    {
        "text": "That says deploy service model,",
        "start": 1350.84,
        "duration": 2.445
    },
    {
        "text": "and that's all I need to do.",
        "start": 1353.285,
        "duration": 2.01
    },
    {
        "text": "Of course along the way,",
        "start": 1355.295,
        "duration": 2.445
    },
    {
        "text": "it's going to ask me for a file,",
        "start": 1357.74,
        "duration": 3.195
    },
    {
        "text": "a script file what we call a score file.",
        "start": 1360.935,
        "duration": 3.24
    },
    {
        "text": "Essentially, this is a file that's required",
        "start": 1364.175,
        "duration": 2.865
    },
    {
        "text": "by Azure Machine Learning Service to define,",
        "start": 1367.04,
        "duration": 2.64
    },
    {
        "text": "\"Hey, all the raw data coming into the web service.\"",
        "start": 1369.68,
        "duration": 3.03
    },
    {
        "text": "How am I going to process the data and",
        "start": 1372.71,
        "duration": 3.21
    },
    {
        "text": "how I am going to use the model to make predictions?",
        "start": 1375.92,
        "duration": 3.435
    },
    {
        "text": "This is defined in this run function.",
        "start": 1379.355,
        "duration": 2.34
    },
    {
        "text": ">> Could you just be clear because I mean,",
        "start": 1381.695,
        "duration": 1.875
    },
    {
        "text": "this is really cool.",
        "start": 1383.57,
        "duration": 1.395
    },
    {
        "text": "But what are we actually deployed?",
        "start": 1384.965,
        "duration": 1.425
    },
    {
        "text": "We deploy a web service or some kind of API service?",
        "start": 1386.39,
        "duration": 3.21
    },
    {
        "text": ">> This is a web service.",
        "start": 1389.6,
        "duration": 1.05
    },
    {
        "text": ">> Cool. So, the web service then you have to have",
        "start": 1390.65,
        "duration": 2.31
    },
    {
        "text": "this file that takes an input",
        "start": 1392.96,
        "duration": 1.56
    },
    {
        "text": "and then you have to load this model up.",
        "start": 1394.52,
        "duration": 1.605
    },
    {
        "text": ">> Right.",
        "start": 1396.125,
        "duration": 0.48
    },
    {
        "text": ">> Pass into things and then make sense of what the output.",
        "start": 1396.605,
        "duration": 2.475
    },
    {
        "text": ">> Right. Essentially, this is what",
        "start": 1399.08,
        "duration": 1.59
    },
    {
        "text": "this script file defines in this run function.",
        "start": 1400.67,
        "duration": 4.8
    },
    {
        "text": "It takes in my input which is my raw data in JSON format,",
        "start": 1405.47,
        "duration": 6.135
    },
    {
        "text": "convert that into a jpeg image because that's",
        "start": 1411.605,
        "duration": 2.655
    },
    {
        "text": "what our model takes in as input.",
        "start": 1414.26,
        "duration": 3.18
    },
    {
        "text": "So, I'm using TensorFlow here to do the conversion into image.",
        "start": 1417.44,
        "duration": 4.305
    },
    {
        "text": "But I'm not quite done yet.",
        "start": 1421.745,
        "duration": 2.115
    },
    {
        "text": "What I'm going to do here is add one line of code real quick.",
        "start": 1423.86,
        "duration": 4.305
    },
    {
        "text": "Say I want to resize all images coming.",
        "start": 1428.165,
        "duration": 2.85
    },
    {
        "text": "So, I know what size it's going to be.",
        "start": 1431.015,
        "duration": 2.445
    },
    {
        "text": "So, I'm going continue to use TensorFlow.",
        "start": 1433.46,
        "duration": 4.08
    },
    {
        "text": "You notice as soon as I type in TF,",
        "start": 1437.54,
        "duration": 3.66
    },
    {
        "text": "I get my regular IntelliSense,",
        "start": 1441.2,
        "duration": 2.76
    },
    {
        "text": "along with the document information right side.",
        "start": 1443.96,
        "duration": 2.55
    },
    {
        "text": ">> Sure.",
        "start": 1446.51,
        "duration": 1.14
    },
    {
        "text": ">> What's cooler is in here,",
        "start": 1447.65,
        "duration": 3.45
    },
    {
        "text": "if I type in dot,",
        "start": 1451.1,
        "duration": 1.845
    },
    {
        "text": "not only I get regular IntelliSense,",
        "start": 1452.945,
        "duration": 1.98
    },
    {
        "text": "but I also get,",
        "start": 1454.925,
        "duration": 1.155
    },
    {
        "text": "notice all the top five start results.",
        "start": 1456.08,
        "duration": 2.904
    },
    {
        "text": ">> Right.",
        "start": 1458.984,
        "duration": 0.381
    },
    {
        "text": ">> This is coming from a feature called IntelliCode,",
        "start": 1459.365,
        "duration": 3.0
    },
    {
        "text": "which is our AI-assisted IntelliSense. Essentially-",
        "start": 1462.365,
        "duration": 4.215
    },
    {
        "text": ">> We are using like AI?",
        "start": 1466.58,
        "duration": 1.485
    },
    {
        "text": ">> AI to build AI.",
        "start": 1468.065,
        "duration": 1.215
    },
    {
        "text": ">> Which is nice.",
        "start": 1469.28,
        "duration": 0.69
    },
    {
        "text": ">> So, we trained this engine with",
        "start": 1469.97,
        "duration": 2.85
    },
    {
        "text": "open-source projects that used TensorFlow and we know,",
        "start": 1472.82,
        "duration": 5.145
    },
    {
        "text": "in this context, these are the functions",
        "start": 1477.965,
        "duration": 3.345
    },
    {
        "text": "you're probably going to need and probably what you should use.",
        "start": 1481.31,
        "duration": 3.6
    },
    {
        "text": "So, right here, I'm going to use image,",
        "start": 1484.91,
        "duration": 1.995
    },
    {
        "text": "which is in the list.",
        "start": 1486.905,
        "duration": 1.74
    },
    {
        "text": "I'm going to tap, and dot again.",
        "start": 1488.645,
        "duration": 2.58
    },
    {
        "text": "You see we get a different list to store result,",
        "start": 1491.225,
        "duration": 2.955
    },
    {
        "text": "and just so happened I just need",
        "start": 1494.18,
        "duration": 2.4
    },
    {
        "text": "the first one because I should just",
        "start": 1496.58,
        "duration": 1.53
    },
    {
        "text": "do what IntelliSense telling me to do.",
        "start": 1498.11,
        "duration": 1.86
    },
    {
        "text": ">> Yeah, basically. I don't know why we even have jobs anymore.",
        "start": 1499.97,
        "duration": 2.31
    },
    {
        "text": ">> That's right. [inaudible] \"Start\" tab,",
        "start": 1502.28,
        "duration": 1.5
    },
    {
        "text": "dot tab, boom. You're done.",
        "start": 1503.78,
        "duration": 1.61
    },
    {
        "text": ">> Dot tab. That's all.",
        "start": 1505.39,
        "duration": 0.67
    },
    {
        "text": ">> I'm going to pass in the result from",
        "start": 1506.06,
        "duration": 2.43
    },
    {
        "text": "the previous step and just give it a size.",
        "start": 1508.49,
        "duration": 4.035
    },
    {
        "text": ">> This is because the model expects a specific size.",
        "start": 1512.525,
        "duration": 2.835
    },
    {
        "text": ">> Exactly.",
        "start": 1515.36,
        "duration": 0.885
    },
    {
        "text": ">> Then of course down here,",
        "start": 1516.245,
        "duration": 1.86
    },
    {
        "text": "we're going to start this TensorFlow session there, run.",
        "start": 1518.105,
        "duration": 3.465
    },
    {
        "text": "Then here is where we load this model.",
        "start": 1521.57,
        "duration": 3.54
    },
    {
        "text": "We look at the labels,",
        "start": 1525.11,
        "duration": 3.84
    },
    {
        "text": "the upper labels, and compare the species.",
        "start": 1528.95,
        "duration": 2.505
    },
    {
        "text": "Make predictions and return the top-k results.",
        "start": 1531.455,
        "duration": 3.06
    },
    {
        "text": ">> Right.",
        "start": 1534.515,
        "duration": 0.255
    },
    {
        "text": ">> Which we're going to see in our test app. All right.",
        "start": 1534.77,
        "duration": 2.43
    },
    {
        "text": "So, this is how we define how the service is going to work.",
        "start": 1537.2,
        "duration": 4.215
    },
    {
        "text": "Of course, coming back here,",
        "start": 1541.415,
        "duration": 1.65
    },
    {
        "text": "we're going to deploy the model,",
        "start": 1543.065,
        "duration": 2.04
    },
    {
        "text": "supply this file along",
        "start": 1545.105,
        "duration": 2.595
    },
    {
        "text": "with environment file that defines the dependencies we need.",
        "start": 1547.7,
        "duration": 3.525
    },
    {
        "text": "Like in this case,",
        "start": 1551.225,
        "duration": 1.245
    },
    {
        "text": "we're going to need TensorFlow.",
        "start": 1552.47,
        "duration": 1.5
    },
    {
        "text": "But that's all we need,",
        "start": 1553.97,
        "duration": 1.725
    },
    {
        "text": "and it only takes couple minutes to get that deployed.",
        "start": 1555.695,
        "duration": 4.92
    },
    {
        "text": "But again, for the sake of time,",
        "start": 1560.615,
        "duration": 2.325
    },
    {
        "text": "let's just look at one that's already deployed as a web service,",
        "start": 1562.94,
        "duration": 3.315
    },
    {
        "text": "and I can prove that to you by showing you the service properties.",
        "start": 1566.255,
        "duration": 4.335
    },
    {
        "text": ">> So, is this words it's putting in,",
        "start": 1570.59,
        "duration": 1.85
    },
    {
        "text": "is it putting in like in a VM?",
        "start": 1572.44,
        "duration": 1.74
    },
    {
        "text": "Is it some kind of something?",
        "start": 1574.18,
        "duration": 2.1
    },
    {
        "text": "Because I know it feels like you're building",
        "start": 1576.28,
        "duration": 1.41
    },
    {
        "text": "containers somehow because you're giving environments and stuff.",
        "start": 1577.69,
        "duration": 3.005
    },
    {
        "text": "Where are these containers going",
        "start": 1580.695,
        "duration": 1.565
    },
    {
        "text": "when you deploy them? Where can you put them?",
        "start": 1582.26,
        "duration": 1.77
    },
    {
        "text": ">> In this particular case,",
        "start": 1584.03,
        "duration": 1.44
    },
    {
        "text": "we're using Azure Container Service.",
        "start": 1585.47,
        "duration": 1.905
    },
    {
        "text": ">> Okay.",
        "start": 1587.375,
        "duration": 0.45
    },
    {
        "text": ">> Container Instances, which is",
        "start": 1587.825,
        "duration": 2.235
    },
    {
        "text": "single container that Azure spins up for you really, really quick.",
        "start": 1590.06,
        "duration": 3.655
    },
    {
        "text": "Especially great for testing purposes",
        "start": 1593.715,
        "duration": 3.07
    },
    {
        "text": "because it will spin up really fast in seconds,",
        "start": 1596.785,
        "duration": 3.704
    },
    {
        "text": "and they will be [inaudible] down once it's done.",
        "start": 1600.489,
        "duration": 3.071
    },
    {
        "text": "Of course, when you are more ready for production,",
        "start": 1603.56,
        "duration": 2.805
    },
    {
        "text": "you can use Kubernetes,",
        "start": 1606.365,
        "duration": 1.98
    },
    {
        "text": "which is going to spin up a cluster of",
        "start": 1608.345,
        "duration": 2.685
    },
    {
        "text": "container instances and the scales really, really well.",
        "start": 1611.03,
        "duration": 4.455
    },
    {
        "text": "But in this particular case,",
        "start": 1615.485,
        "duration": 1.635
    },
    {
        "text": "everything is run in a container that Azure spins up for me.",
        "start": 1617.12,
        "duration": 3.12
    },
    {
        "text": "I don't have to do anything.",
        "start": 1620.24,
        "duration": 1.14
    },
    {
        "text": "It happens automatically behind the scene.",
        "start": 1621.38,
        "duration": 2.145
    },
    {
        "text": ">> That's cool.",
        "start": 1623.525,
        "duration": 0.435
    },
    {
        "text": ">> That's all managed by the Azure Machine Learning Service.",
        "start": 1623.96,
        "duration": 2.46
    },
    {
        "text": "So, here, we have a web service.",
        "start": 1626.42,
        "duration": 2.475
    },
    {
        "text": "This is the URL we're going to use,",
        "start": 1628.895,
        "duration": 2.775
    },
    {
        "text": "and now let's go back to",
        "start": 1631.67,
        "duration": 2.025
    },
    {
        "text": "our code file and I have a test application here.",
        "start": 1633.695,
        "duration": 4.315
    },
    {
        "text": "So, we're going to test out if our model works.",
        "start": 1638.29,
        "duration": 3.61
    },
    {
        "text": "So, this is another Python file,",
        "start": 1641.9,
        "duration": 2.445
    },
    {
        "text": "but this service can be used by whatever language of your choice.",
        "start": 1644.345,
        "duration": 4.665
    },
    {
        "text": "Any kind of applications.",
        "start": 1649.01,
        "duration": 2.28
    },
    {
        "text": "So, what are we going to do here?",
        "start": 1651.29,
        "duration": 1.815
    },
    {
        "text": "This is a really simple application.",
        "start": 1653.105,
        "duration": 1.74
    },
    {
        "text": "We're going to take an image.",
        "start": 1654.845,
        "duration": 2.13
    },
    {
        "text": "In this case, it's a dog.",
        "start": 1656.975,
        "duration": 1.95
    },
    {
        "text": "An image that has a dog,",
        "start": 1658.925,
        "duration": 1.59
    },
    {
        "text": "and this is the service we're going to use.",
        "start": 1660.515,
        "duration": 1.845
    },
    {
        "text": "The same service URL we have seen.",
        "start": 1662.36,
        "duration": 2.565
    },
    {
        "text": "Essentially, it's going to do, when it comes in,",
        "start": 1664.925,
        "duration": 3.375
    },
    {
        "text": "we turn the image into JSON and send",
        "start": 1668.3,
        "duration": 3.06
    },
    {
        "text": "that information over as an HTTP request to the web service.",
        "start": 1671.36,
        "duration": 5.86
    },
    {
        "text": "This code. Then when the result comes back,",
        "start": 1677.26,
        "duration": 3.925
    },
    {
        "text": "we unpack the result and try to see what the predictions are.",
        "start": 1681.185,
        "duration": 6.985
    },
    {
        "text": "So, this piece of code,",
        "start": 1688.36,
        "duration": 2.185
    },
    {
        "text": "I can run this in a regular Python terminal.",
        "start": 1690.545,
        "duration": 3.345
    },
    {
        "text": "We can see what the numbers look like.",
        "start": 1693.89,
        "duration": 3.945
    },
    {
        "text": "But I'm going to do something even better.",
        "start": 1697.835,
        "duration": 2.925
    },
    {
        "text": "Remember we looked at the interactive window earlier?",
        "start": 1700.76,
        "duration": 2.835
    },
    {
        "text": ">> Yes.",
        "start": 1703.595,
        "duration": 0.855
    },
    {
        "text": ">> I'm going to just type in pound percent percent to",
        "start": 1704.45,
        "duration": 3.54
    },
    {
        "text": "turn this entire piece of code into one single cell.",
        "start": 1707.99,
        "duration": 3.765
    },
    {
        "text": "What's cool about this is now I can run",
        "start": 1711.755,
        "duration": 2.445
    },
    {
        "text": "the cell in this interactive window.",
        "start": 1714.2,
        "duration": 2.805
    },
    {
        "text": "So, I can view the results not only as text,",
        "start": 1717.005,
        "duration": 3.42
    },
    {
        "text": "but also as an image.",
        "start": 1720.425,
        "duration": 2.01
    },
    {
        "text": "Because I sent an image over to the web service,",
        "start": 1722.435,
        "duration": 2.865
    },
    {
        "text": "I want to see what the image looks like.",
        "start": 1725.3,
        "duration": 1.605
    },
    {
        "text": ">> That's cool.",
        "start": 1726.905,
        "duration": 0.405
    },
    {
        "text": ">> In here, I can see both.",
        "start": 1727.31,
        "duration": 1.53
    },
    {
        "text": "This is the image I sent.",
        "start": 1728.84,
        "duration": 1.71
    },
    {
        "text": "This is the prediction results that I got back.",
        "start": 1730.55,
        "duration": 2.985
    },
    {
        "text": "So, you see this is likely",
        "start": 1733.535,
        "duration": 2.505
    },
    {
        "text": "an English Cocker Spaniel with 98 percent probability.",
        "start": 1736.04,
        "duration": 5.635
    },
    {
        "text": "Very likely this is the breed.",
        "start": 1741.675,
        "duration": 2.86
    },
    {
        "text": "Some other guesses.",
        "start": 1744.535,
        "duration": 1.665
    },
    {
        "text": "The other top four guesses,",
        "start": 1746.2,
        "duration": 3.04
    },
    {
        "text": "but much, much small numbers.",
        "start": 1749.24,
        "duration": 2.28
    },
    {
        "text": ">> Yeah.",
        "start": 1751.52,
        "duration": 0.795
    },
    {
        "text": ">> Yeah. So, we kind of walk through how we",
        "start": 1752.315,
        "duration": 3.435
    },
    {
        "text": "turn a Notebook file into a Python module,",
        "start": 1755.75,
        "duration": 3.09
    },
    {
        "text": "how we deploy models,",
        "start": 1758.84,
        "duration": 1.35
    },
    {
        "text": "and how we can use the service to",
        "start": 1760.19,
        "duration": 1.68
    },
    {
        "text": "actually make predictions. This is real.",
        "start": 1761.87,
        "duration": 2.34
    },
    {
        "text": ">> This is pretty cool. This is a real thing. It's a real service.",
        "start": 1764.21,
        "duration": 2.55
    },
    {
        "text": "Now the thing is, just to summarize,",
        "start": 1766.76,
        "duration": 1.92
    },
    {
        "text": "because I feel like we went through stuff really fast.",
        "start": 1768.68,
        "duration": 1.89
    },
    {
        "text": "You actually train a model.",
        "start": 1770.57,
        "duration": 1.455
    },
    {
        "text": ">> Yeah.",
        "start": 1772.025,
        "duration": 0.405
    },
    {
        "text": ">> Optimize the hyperparameters.",
        "start": 1772.43,
        "duration": 1.74
    },
    {
        "text": "So, just get a better [inaudible] I think it was 75-80 percent accuracy.",
        "start": 1774.17,
        "duration": 3.3
    },
    {
        "text": "It went 95 percent accuracy.",
        "start": 1777.47,
        "duration": 1.725
    },
    {
        "text": ">> Ninety percent accuracy.",
        "start": 1779.195,
        "duration": 1.2
    },
    {
        "text": ">> Ninety percent accuracy.",
        "start": 1780.395,
        "duration": 1.455
    },
    {
        "text": "Then once you're done with all the experimentation,",
        "start": 1781.85,
        "duration": 2.01
    },
    {
        "text": "you're like, \"All right.",
        "start": 1783.86,
        "duration": 0.45
    },
    {
        "text": "Here, developer,\" and what you do is you take the Python.",
        "start": 1784.31,
        "duration": 2.443
    },
    {
        "text": ">> Import.",
        "start": 1786.753,
        "duration": 0.137
    },
    {
        "text": ">> You take the Python that you put in Notebook, import, refactor,",
        "start": 1786.89,
        "duration": 4.065
    },
    {
        "text": "get it ready to push out again so",
        "start": 1790.955,
        "duration": 2.235
    },
    {
        "text": "that if anyone wants to run the experiment again they can,",
        "start": 1793.19,
        "duration": 2.13
    },
    {
        "text": "and then you deploy that service",
        "start": 1795.32,
        "duration": 2.01
    },
    {
        "text": "using the model that you uploaded,",
        "start": 1797.33,
        "duration": 1.95
    },
    {
        "text": "and then we're off to the races after that.",
        "start": 1799.28,
        "duration": 1.35
    },
    {
        "text": ">> Yeah, exactly.",
        "start": 1800.63,
        "duration": 1.095
    },
    {
        "text": ">> That's pretty amazing. So just to finish up,",
        "start": 1801.725,
        "duration": 2.07
    },
    {
        "text": "where can people go to find out more about Azure notebooks?",
        "start": 1803.795,
        "duration": 3.015
    },
    {
        "text": ">> So, you go to notebooks.azure.com.",
        "start": 1806.81,
        "duration": 3.495
    },
    {
        "text": "It's a site, and all you need to do to",
        "start": 1810.305,
        "duration": 2.835
    },
    {
        "text": "sign is have a Microsoft account or a workplace account,",
        "start": 1813.14,
        "duration": 3.09
    },
    {
        "text": "like an Azure Active Directory account.",
        "start": 1816.23,
        "duration": 1.92
    },
    {
        "text": ">> That's awesome. Where do people go to",
        "start": 1818.15,
        "duration": 1.44
    },
    {
        "text": "find out about this cool extension?",
        "start": 1819.59,
        "duration": 1.815
    },
    {
        "text": "Is it all just one extension?",
        "start": 1821.405,
        "duration": 2.265
    },
    {
        "text": ">> It's actually two extensions.",
        "start": 1823.67,
        "duration": 1.419
    },
    {
        "text": ">> Okay.",
        "start": 1825.089,
        "duration": 0.501
    },
    {
        "text": ">> So, there's the Python extension that has",
        "start": 1825.59,
        "duration": 2.79
    },
    {
        "text": "the Python interactive experience for data science,",
        "start": 1828.38,
        "duration": 2.805
    },
    {
        "text": "and the other extension is Azure Machine Learning extension.",
        "start": 1831.185,
        "duration": 2.91
    },
    {
        "text": "That is for anything you want to",
        "start": 1834.095,
        "duration": 1.845
    },
    {
        "text": "use Azure Machine Learning Service for.",
        "start": 1835.94,
        "duration": 2.07
    },
    {
        "text": ">> Awesome, and you can just download",
        "start": 1838.01,
        "duration": 1.11
    },
    {
        "text": "those and play with them today for free?",
        "start": 1839.12,
        "duration": 1.395
    },
    {
        "text": ">> Yeah.",
        "start": 1840.515,
        "duration": 0.345
    },
    {
        "text": ">> Yeah.",
        "start": 1840.86,
        "duration": 0.315
    },
    {
        "text": ">> Fantastic. Well, thanks so much for spending",
        "start": 1841.175,
        "duration": 1.755
    },
    {
        "text": "some time with us and thanks so much for watching.",
        "start": 1842.93,
        "duration": 1.95
    },
    {
        "text": "We're learning all about the amazing tooling",
        "start": 1844.88,
        "duration": 1.95
    },
    {
        "text": "we have on Azure to do machine learning,",
        "start": 1846.83,
        "duration": 1.98
    },
    {
        "text": "not just Visual Studio Code, but Azure Notebooks.",
        "start": 1848.81,
        "duration": 1.98
    },
    {
        "text": "Thanks for watching. We'll see you next time. Take care.",
        "start": 1850.79,
        "duration": 2.74
    }
]