{"speaker": "", "title": "Batch Inference using Azure Machine Learning", "videoId": "o_EfzTjrdnY", "description": "In this episode we will cover a quick overview of new batch inference capability that allows Azure Machine Learning users to get inferences on large scale datasets in a secure, scalable, performant and cost-effective way by fully leveraging the power of cloud. \n\n00:20 \u2013 Context on Inference\n02:00 \u2013Handling High Volume Workloads\n03:05 \u2013ParallelRunStep Intro\n03:53 \u2013 Support for Structured and Unstructured data\n04:14 \u2013 Demo walkthrough\n06:17 \u2013 ParallelRunStep Config\n07:40 \u2013 Pre and Post Processing\n\nThe AI Show's Favorite links:\nDon't miss new episodes, subscribe to the AI Show: https://aka.ms/aishowsubscribe  \nCreate a Free account (Azure): https://aka.ms/aishow-seth-azurefree\nDeep Learning vs. Machine Learning: https://aka.ms/AIShow/DLvML\nGet Started with Machine Learning: https://aka.ms/AIShow/StartML\nFollow: https://twitter.com/sethjuarez\nFollow: https://twitter.com/ch9\nFollow: https://twitter.com/Azure\nFollow: https://twitter.com/msdev\n\n#azuremachinelearning #ai #microsoftai"}