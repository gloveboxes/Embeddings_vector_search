[
    {
        "text": "you're not gonna want to miss this",
        "start": 0.06,
        "duration": 3.51
    },
    {
        "text": "episode of the AI show where we talk all",
        "start": 1.199,
        "duration": 6.811
    },
    {
        "text": "about data preparation actually it's 80%",
        "start": 3.57,
        "duration": 6.359
    },
    {
        "text": "of the stuff they designed us do but",
        "start": 8.01,
        "duration": 4.049
    },
    {
        "text": "it's not very exciting but it is the",
        "start": 9.929,
        "duration": 6.471
    },
    {
        "text": "most important make sure you tune in",
        "start": 12.059,
        "duration": 4.341
    },
    {
        "text": "hello and welcome to this episode of the",
        "start": 21.09,
        "duration": 3.57
    },
    {
        "text": "AI show where we're gonna take a look at",
        "start": 22.859,
        "duration": 4.321
    },
    {
        "text": "some pretty interesting part well I",
        "start": 24.66,
        "duration": 4.08
    },
    {
        "text": "don't know if it's the interesting part",
        "start": 27.18,
        "duration": 3.75
    },
    {
        "text": "that's a part of data science everyone",
        "start": 28.74,
        "duration": 4.56
    },
    {
        "text": "has to do but nobody talks about why",
        "start": 30.93,
        "duration": 3.57
    },
    {
        "text": "don't you introduce yourself my friend",
        "start": 33.3,
        "duration": 3.87
    },
    {
        "text": "I'm you and garden I work on the AM L",
        "start": 34.5,
        "duration": 5.129
    },
    {
        "text": "platform team I specifically focus on",
        "start": 37.17,
        "duration": 6.12
    },
    {
        "text": "the most exciting part of AM L or always",
        "start": 39.629,
        "duration": 5.941
    },
    {
        "text": "also the most time-consuming as well",
        "start": 43.29,
        "duration": 3.93
    },
    {
        "text": "take a look at which is data preparation",
        "start": 45.57,
        "duration": 3.509
    },
    {
        "text": "I'm Jung garden and I'm here to",
        "start": 47.22,
        "duration": 3.75
    },
    {
        "text": "entertain and educate set for the next",
        "start": 49.079,
        "duration": 3.721
    },
    {
        "text": "little while I don't know like you say",
        "start": 50.97,
        "duration": 3.869
    },
    {
        "text": "the most interesting bit it's probably",
        "start": 52.8,
        "duration": 4.71
    },
    {
        "text": "the part that it's like it's like yeah",
        "start": 54.839,
        "duration": 4.261
    },
    {
        "text": "every Saturday I got to wash my clothes",
        "start": 57.51,
        "duration": 2.67
    },
    {
        "text": "you know otherwise I'll have dirty",
        "start": 59.1,
        "duration": 3.75
    },
    {
        "text": "clothes this feels like this part of",
        "start": 60.18,
        "duration": 4.14
    },
    {
        "text": "data science has been relegated to like",
        "start": 62.85,
        "duration": 3.809
    },
    {
        "text": "washing your clothes but tell us why it",
        "start": 64.32,
        "duration": 4.08
    },
    {
        "text": "should be exciting and maybe walk us",
        "start": 66.659,
        "duration": 3.811
    },
    {
        "text": "through what it actually means to do",
        "start": 68.4,
        "duration": 5.34
    },
    {
        "text": "data preparation okay so without",
        "start": 70.47,
        "duration": 5.88
    },
    {
        "text": "actually having the data in a reasonably",
        "start": 73.74,
        "duration": 4.65
    },
    {
        "text": "meaningful form you can't do any more",
        "start": 76.35,
        "duration": 4.17
    },
    {
        "text": "Ling on it so oh you're a nerdy PhD",
        "start": 78.39,
        "duration": 3.17
    },
    {
        "text": "stuff that you like to talk about",
        "start": 80.52,
        "duration": 3.48
    },
    {
        "text": "completely useless if what I'm handing",
        "start": 81.56,
        "duration": 4.269
    },
    {
        "text": "you is ditchwater and so the goal here",
        "start": 84.0,
        "duration": 3.899
    },
    {
        "text": "is to take something that is arbitrarily",
        "start": 85.829,
        "duration": 4.591
    },
    {
        "text": "ugly complex and not appropriate from",
        "start": 87.899,
        "duration": 4.381
    },
    {
        "text": "consumption which is the most important",
        "start": 90.42,
        "duration": 3.839
    },
    {
        "text": "kind of qualifier here it's you got to",
        "start": 92.28,
        "duration": 4.11
    },
    {
        "text": "make the data ready for consumption and",
        "start": 94.259,
        "duration": 3.661
    },
    {
        "text": "there's actually differences between bi",
        "start": 96.39,
        "duration": 3.63
    },
    {
        "text": "and AI in this sense I spent 20 years",
        "start": 97.92,
        "duration": 3.839
    },
    {
        "text": "working in the bi and data analytics",
        "start": 100.02,
        "duration": 3.599
    },
    {
        "text": "space and the tools you would use then",
        "start": 101.759,
        "duration": 4.081
    },
    {
        "text": "would be things like ETL tools extract",
        "start": 103.619,
        "duration": 3.661
    },
    {
        "text": "transform and load you suck some data up",
        "start": 105.84,
        "duration": 2.879
    },
    {
        "text": "you transform it in memory and then you",
        "start": 107.28,
        "duration": 3.509
    },
    {
        "text": "load into another schema in an",
        "start": 108.719,
        "duration": 3.871
    },
    {
        "text": "enterprise data warehouse a bi system or",
        "start": 110.789,
        "duration": 3.21
    },
    {
        "text": "something like that right now part bi is",
        "start": 112.59,
        "duration": 2.79
    },
    {
        "text": "kind of changed that it's a lot more ad",
        "start": 113.999,
        "duration": 3.271
    },
    {
        "text": "hoc can be a lot more dynamic but still",
        "start": 115.38,
        "duration": 3.15
    },
    {
        "text": "you're taking data from one known place",
        "start": 117.27,
        "duration": 3.57
    },
    {
        "text": "to another known place but the analysis",
        "start": 118.53,
        "duration": 3.359
    },
    {
        "text": "doesn't really have too many",
        "start": 120.84,
        "duration": 2.279
    },
    {
        "text": "requirements on the data other than it",
        "start": 121.889,
        "duration": 3.57
    },
    {
        "text": "not be ugly right we changed that a",
        "start": 123.119,
        "duration": 4.051
    },
    {
        "text": "little bit by doing alt with big data",
        "start": 125.459,
        "duration": 2.61
    },
    {
        "text": "because you can't do everything in",
        "start": 127.17,
        "duration": 2.85
    },
    {
        "text": "memory anymore so now you use spar can",
        "start": 128.069,
        "duration": 3.691
    },
    {
        "text": "do open stuff like that you read the",
        "start": 130.02,
        "duration": 3.06
    },
    {
        "text": "data you write it to the lake and then",
        "start": 131.76,
        "duration": 3.39
    },
    {
        "text": "you process it in place inside the lake",
        "start": 133.08,
        "duration": 3.989
    },
    {
        "text": "agile data preparation which is what",
        "start": 135.15,
        "duration": 3.15
    },
    {
        "text": "some of the analysts and customers call",
        "start": 137.069,
        "duration": 3.121
    },
    {
        "text": "it data wrangling you take your your",
        "start": 138.3,
        "duration": 3.36
    },
    {
        "text": "your choice in terms of what term you",
        "start": 140.19,
        "duration": 3.48
    },
    {
        "text": "want to use is really about a much more",
        "start": 141.66,
        "duration": 4.29
    },
    {
        "text": "interactive and iterative way of dealing",
        "start": 143.67,
        "duration": 4.289
    },
    {
        "text": "with data because as it is a scientist",
        "start": 145.95,
        "duration": 3.72
    },
    {
        "text": "you get given a data set you may know",
        "start": 147.959,
        "duration": 3.42
    },
    {
        "text": "nothing about and that may have a new",
        "start": 149.67,
        "duration": 4.89
    },
    {
        "text": "schema and your production artifact at",
        "start": 151.379,
        "duration": 3.481
    },
    {
        "text": "the",
        "start": 154.56,
        "duration": 1.83
    },
    {
        "text": "and is something you don't know about",
        "start": 154.86,
        "duration": 3.12
    },
    {
        "text": "yet if I turn around to you and say hey",
        "start": 156.39,
        "duration": 3.99
    },
    {
        "text": "predict my survival and Titanic would I",
        "start": 157.98,
        "duration": 4.17
    },
    {
        "text": "have survived Titanic sets right you're",
        "start": 160.38,
        "duration": 4.65
    },
    {
        "text": "the super highly qualified nerdy guy you",
        "start": 162.15,
        "duration": 5.13
    },
    {
        "text": "go to range of maybe 1520 algorithms",
        "start": 165.03,
        "duration": 3.72
    },
    {
        "text": "right each one of those has a different",
        "start": 167.28,
        "duration": 2.91
    },
    {
        "text": "dependency on the data requires",
        "start": 168.75,
        "duration": 2.85
    },
    {
        "text": "different characteristics on the data",
        "start": 170.19,
        "duration": 3.24
    },
    {
        "text": "and so you might end up actually",
        "start": 171.6,
        "duration": 3.72
    },
    {
        "text": "cleaning the data 15 to 20 different",
        "start": 173.43,
        "duration": 5.04
    },
    {
        "text": "times were slightly for the models all",
        "start": 175.32,
        "duration": 5.01
    },
    {
        "text": "right so there's a base languages get it",
        "start": 178.47,
        "duration": 4.08
    },
    {
        "text": "clean but then there's prepare the data",
        "start": 180.33,
        "duration": 5.37
    },
    {
        "text": "for consumption as well and so that's",
        "start": 182.55,
        "duration": 4.92
    },
    {
        "text": "why it's very unique in the AI space I",
        "start": 185.7,
        "duration": 3.3
    },
    {
        "text": "would argue over generalized data",
        "start": 187.47,
        "duration": 3.989
    },
    {
        "text": "integration and bi and ETL and ELT and",
        "start": 189.0,
        "duration": 3.33
    },
    {
        "text": "all kinds of stuff like that",
        "start": 191.459,
        "duration": 2.881
    },
    {
        "text": "and this is something that you have to",
        "start": 192.33,
        "duration": 3.81
    },
    {
        "text": "do like like one of the first things I",
        "start": 194.34,
        "duration": 4.29
    },
    {
        "text": "wrote was a line following robot and it",
        "start": 196.14,
        "duration": 4.47
    },
    {
        "text": "turned out that when I was training it I",
        "start": 198.63,
        "duration": 4.62
    },
    {
        "text": "never turned so I had a lot of zeroes in",
        "start": 200.61,
        "duration": 4.379
    },
    {
        "text": "my dataset so I had to like do some",
        "start": 203.25,
        "duration": 3.45
    },
    {
        "text": "interesting like well you got to take",
        "start": 204.989,
        "duration": 3.421
    },
    {
        "text": "data out you got a match so you got to",
        "start": 206.7,
        "duration": 3.21
    },
    {
        "text": "balance the labels you got to make sure",
        "start": 208.41,
        "duration": 3.69
    },
    {
        "text": "these columns were working it was it was",
        "start": 209.91,
        "duration": 4.5
    },
    {
        "text": "a lot of work and I found that like I",
        "start": 212.1,
        "duration": 3.75
    },
    {
        "text": "wish there was some tools that could",
        "start": 214.41,
        "duration": 3.36
    },
    {
        "text": "help me out with that so maybe can you",
        "start": 215.85,
        "duration": 4.29
    },
    {
        "text": "talk about like why do already talk",
        "start": 217.77,
        "duration": 3.45
    },
    {
        "text": "about why dating preparation is so",
        "start": 220.14,
        "duration": 2.849
    },
    {
        "text": "important when you talk about how what",
        "start": 221.22,
        "duration": 3.69
    },
    {
        "text": "is a good way to think about it yeah so",
        "start": 222.989,
        "duration": 3.991
    },
    {
        "text": "a good way to think about it is a series",
        "start": 224.91,
        "duration": 4.41
    },
    {
        "text": "of hypothesis and experiments which you",
        "start": 226.98,
        "duration": 4.08
    },
    {
        "text": "need to validate so your turn around and",
        "start": 229.32,
        "duration": 3.6
    },
    {
        "text": "say well I think that there shouldn't be",
        "start": 231.06,
        "duration": 3.33
    },
    {
        "text": "missing values in this column because my",
        "start": 232.92,
        "duration": 3.81
    },
    {
        "text": "model needs their values to be there but",
        "start": 234.39,
        "duration": 3.3
    },
    {
        "text": "now we have to come up with a set of",
        "start": 236.73,
        "duration": 2.22
    },
    {
        "text": "hypotheses about how you deal with",
        "start": 237.69,
        "duration": 2.91
    },
    {
        "text": "missing values should you delete the",
        "start": 238.95,
        "duration": 4.2
    },
    {
        "text": "rows if you delete 90% of the rows and",
        "start": 240.6,
        "duration": 3.6
    },
    {
        "text": "you have enough data for a meaningful",
        "start": 243.15,
        "duration": 3.6
    },
    {
        "text": "model right if you delete rows because",
        "start": 244.2,
        "duration": 5.25
    },
    {
        "text": "one column is missing a value what's the",
        "start": 246.75,
        "duration": 4.709
    },
    {
        "text": "side effect on the other columns in the",
        "start": 249.45,
        "duration": 3.69
    },
    {
        "text": "data set at that point in time because",
        "start": 251.459,
        "duration": 3.0
    },
    {
        "text": "those other columns might be really",
        "start": 253.14,
        "duration": 3.18
    },
    {
        "text": "important predictor columns for some",
        "start": 254.459,
        "duration": 3.96
    },
    {
        "text": "other algorithm using one of my favorite",
        "start": 256.32,
        "duration": 3.419
    },
    {
        "text": "quotes here as I was running a bunch of",
        "start": 258.419,
        "duration": 2.761
    },
    {
        "text": "focus groups before we built the current",
        "start": 259.739,
        "duration": 3.541
    },
    {
        "text": "AML product that you know we're a bunch",
        "start": 261.18,
        "duration": 3.57
    },
    {
        "text": "of Bhai people and we had a bunch of AI",
        "start": 263.28,
        "duration": 2.61
    },
    {
        "text": "people in the room and the question I",
        "start": 264.75,
        "duration": 1.68
    },
    {
        "text": "said was okay",
        "start": 265.89,
        "duration": 2.37
    },
    {
        "text": "you're dealing with IOT data and the",
        "start": 266.43,
        "duration": 3.27
    },
    {
        "text": "heart rate sensor is plotting along is",
        "start": 268.26,
        "duration": 3.3
    },
    {
        "text": "like 60 65 beats per minute and all of a",
        "start": 269.7,
        "duration": 3.99
    },
    {
        "text": "sudden you get 10 readings at 500 and",
        "start": 271.56,
        "duration": 4.47
    },
    {
        "text": "then it drops down to 60 65 again",
        "start": 273.69,
        "duration": 4.2
    },
    {
        "text": "clearly the person didn't die we're",
        "start": 276.03,
        "duration": 3.63
    },
    {
        "text": "happy about that but what do you do with",
        "start": 277.89,
        "duration": 2.339
    },
    {
        "text": "the data",
        "start": 279.66,
        "duration": 2.64
    },
    {
        "text": "so the BI guy immediately says well it's",
        "start": 280.229,
        "duration": 3.781
    },
    {
        "text": "clearly bad data so I'd filter it out as",
        "start": 282.3,
        "duration": 4.08
    },
    {
        "text": "part of the ETL process the AI guy turns",
        "start": 284.01,
        "duration": 4.26
    },
    {
        "text": "around goes now I would turn around and",
        "start": 286.38,
        "duration": 2.1
    },
    {
        "text": "I",
        "start": 288.27,
        "duration": 2.1
    },
    {
        "text": "either impute a new value because it's",
        "start": 288.48,
        "duration": 4.32
    },
    {
        "text": "clearly outside normal range or I would",
        "start": 290.37,
        "duration": 3.84
    },
    {
        "text": "build a model which was able to handle",
        "start": 292.8,
        "duration": 3.18
    },
    {
        "text": "outliers for that column because there",
        "start": 294.21,
        "duration": 3.75
    },
    {
        "text": "may be other attributes of that row of",
        "start": 295.98,
        "duration": 3.6
    },
    {
        "text": "data which are really critical to my",
        "start": 297.96,
        "duration": 4.26
    },
    {
        "text": "model right and so the techniques you",
        "start": 299.58,
        "duration": 6.09
    },
    {
        "text": "use are actually ml for ML so most",
        "start": 302.22,
        "duration": 5.13
    },
    {
        "text": "people doing data engineering for bi are",
        "start": 305.67,
        "duration": 3.06
    },
    {
        "text": "not going to use sophisticated",
        "start": 307.35,
        "duration": 2.82
    },
    {
        "text": "techniques to imputing data they might",
        "start": 308.73,
        "duration": 2.7
    },
    {
        "text": "compute the mean or the average and",
        "start": 310.17,
        "duration": 2.43
    },
    {
        "text": "stuff like that they're not gonna look",
        "start": 311.43,
        "duration": 2.49
    },
    {
        "text": "at distributions they're not going to",
        "start": 312.6,
        "duration": 3.75
    },
    {
        "text": "use features like scalars and things",
        "start": 313.92,
        "duration": 4.53
    },
    {
        "text": "like that to get the data into a really",
        "start": 316.35,
        "duration": 3.6
    },
    {
        "text": "really good shape and so that's kind of",
        "start": 318.45,
        "duration": 2.55
    },
    {
        "text": "one the fundamental differences that",
        "start": 319.95,
        "duration": 2.82
    },
    {
        "text": "exists awesome well let's dive in show",
        "start": 321.0,
        "duration": 3.33
    },
    {
        "text": "me how to do the thing okay so let's go",
        "start": 322.77,
        "duration": 3.6
    },
    {
        "text": "ahead I've got a very simple example",
        "start": 324.33,
        "duration": 4.17
    },
    {
        "text": "here that I won't make you do because",
        "start": 326.37,
        "duration": 5.97
    },
    {
        "text": "that would just humiliate you like for",
        "start": 328.5,
        "duration": 6.33
    },
    {
        "text": "years and this is a very simple example",
        "start": 332.34,
        "duration": 4.68
    },
    {
        "text": "that using a Titanic data very common",
        "start": 334.83,
        "duration": 3.69
    },
    {
        "text": "for tutorials there's thousands of",
        "start": 337.02,
        "duration": 2.82
    },
    {
        "text": "examples of ideas on the web is a great",
        "start": 338.52,
        "duration": 2.52
    },
    {
        "text": "kaggle competition and everything else",
        "start": 339.84,
        "duration": 2.46
    },
    {
        "text": "like that so we have this particular",
        "start": 341.04,
        "duration": 3.06
    },
    {
        "text": "version we call dirty Titanic and when",
        "start": 342.3,
        "duration": 3.03
    },
    {
        "text": "he's a library called pandas here in",
        "start": 344.1,
        "duration": 2.73
    },
    {
        "text": "Python and E that's done any sort of",
        "start": 345.33,
        "duration": 3.57
    },
    {
        "text": "data science at least Nosa pandas where",
        "start": 346.83,
        "duration": 3.72
    },
    {
        "text": "the user or none written by German",
        "start": 348.9,
        "duration": 3.9
    },
    {
        "text": "cosmic any it's been around for years so",
        "start": 350.55,
        "duration": 3.09
    },
    {
        "text": "we're gonna go ahead we're gonna read",
        "start": 352.8,
        "duration": 3.12
    },
    {
        "text": "that file so the first thing we get is",
        "start": 353.64,
        "duration": 4.41
    },
    {
        "text": "we get an error so I'm reading a CSV",
        "start": 355.92,
        "duration": 4.38
    },
    {
        "text": "file and the you know it says I'm",
        "start": 358.05,
        "duration": 4.32
    },
    {
        "text": "reading a CSV file the files got the CSV",
        "start": 360.3,
        "duration": 3.72
    },
    {
        "text": "on the end so why didn't it work right",
        "start": 362.37,
        "duration": 3.27
    },
    {
        "text": "so the first step we have to start doing",
        "start": 364.02,
        "duration": 2.85
    },
    {
        "text": "now is start trying to understand our",
        "start": 365.64,
        "duration": 4.17
    },
    {
        "text": "data so we go take a look at this and we",
        "start": 366.87,
        "duration": 4.77
    },
    {
        "text": "use a please favorite tool for debugging",
        "start": 369.81,
        "duration": 3.48
    },
    {
        "text": "files which is notepad plus plus source",
        "start": 371.64,
        "duration": 4.14
    },
    {
        "text": "so if we look at this file we go okay",
        "start": 373.29,
        "duration": 4.89
    },
    {
        "text": "that looks kind of interesting there's a",
        "start": 375.78,
        "duration": 4.65
    },
    {
        "text": "blank block at the top there's it's a",
        "start": 378.18,
        "duration": 4.53
    },
    {
        "text": "CSV but it's got pipe delimiters in the",
        "start": 380.43,
        "duration": 3.84
    },
    {
        "text": "middle of it and if you actually look",
        "start": 382.71,
        "duration": 3.36
    },
    {
        "text": "down the file far enough you'll see that",
        "start": 384.27,
        "duration": 3.6
    },
    {
        "text": "there's what we can call weird ragged",
        "start": 386.07,
        "duration": 3.84
    },
    {
        "text": "edges to the schema so there's not the",
        "start": 387.87,
        "duration": 3.39
    },
    {
        "text": "same number of columns in every single",
        "start": 389.91,
        "duration": 4.41
    },
    {
        "text": "position and it's remarkably common that",
        "start": 391.26,
        "duration": 4.97
    },
    {
        "text": "CSV is really the world's most",
        "start": 394.32,
        "duration": 4.05
    },
    {
        "text": "non-standard standard format when it",
        "start": 396.23,
        "duration": 3.49
    },
    {
        "text": "comes to data and this making me unhappy",
        "start": 398.37,
        "duration": 3.06
    },
    {
        "text": "because I'm looking at it I'm like oh",
        "start": 399.72,
        "duration": 4.59
    },
    {
        "text": "geez I gotta write something to fix this",
        "start": 401.43,
        "duration": 5.04
    },
    {
        "text": "stuff that's why you got to go do so",
        "start": 404.31,
        "duration": 4.17
    },
    {
        "text": "let's go back to spider and we'll cheat",
        "start": 406.47,
        "duration": 2.97
    },
    {
        "text": "a little bit because I've done this",
        "start": 408.48,
        "duration": 2.7
    },
    {
        "text": "particular example a couple of times and",
        "start": 409.44,
        "duration": 2.94
    },
    {
        "text": "we'll take a look at what we'd have to",
        "start": 411.18,
        "duration": 3.3
    },
    {
        "text": "do to fix it so the first thing you have",
        "start": 412.38,
        "duration": 3.99
    },
    {
        "text": "to do is change the separator then I",
        "start": 414.48,
        "duration": 3.3
    },
    {
        "text": "have to tell it to skip a certain number",
        "start": 416.37,
        "duration": 3.72
    },
    {
        "text": "of rows that might have worked but what",
        "start": 417.78,
        "duration": 4.08
    },
    {
        "text": "I know because I'm saving time on you",
        "start": 420.09,
        "duration": 3.599
    },
    {
        "text": "keep busy schedule here is that there's",
        "start": 421.86,
        "duration": 3.299
    },
    {
        "text": "actually also hidden at the bottom of",
        "start": 423.689,
        "duration": 3.151
    },
    {
        "text": "this file which we can read because it's",
        "start": 425.159,
        "duration": 3.51
    },
    {
        "text": "a reasonable-sized file it's only a few",
        "start": 426.84,
        "duration": 3.539
    },
    {
        "text": "hundred rows it's there's actually a",
        "start": 428.669,
        "duration": 3.921
    },
    {
        "text": "trailer at the end of this file as well",
        "start": 430.379,
        "duration": 5.1
    },
    {
        "text": "which will also screw up a read yeah and",
        "start": 432.59,
        "duration": 5.02
    },
    {
        "text": "so you've got to try the read in the",
        "start": 435.479,
        "duration": 3.391
    },
    {
        "text": "read event fail again and it's an",
        "start": 437.61,
        "duration": 2.459
    },
    {
        "text": "iterative process like I was saying",
        "start": 438.87,
        "duration": 2.43
    },
    {
        "text": "you're gonna try it you're gonna get a",
        "start": 440.069,
        "duration": 3.211
    },
    {
        "text": "little bit further every single time and",
        "start": 441.3,
        "duration": 3.299
    },
    {
        "text": "so in this particular case we know how",
        "start": 443.28,
        "duration": 2.609
    },
    {
        "text": "to fix that",
        "start": 444.599,
        "duration": 2.91
    },
    {
        "text": "there's luckily n pandas there's a skip",
        "start": 445.889,
        "duration": 4.02
    },
    {
        "text": "footer but there's a trick you have to",
        "start": 447.509,
        "duration": 4.141
    },
    {
        "text": "do here if you want to skip the footer",
        "start": 449.909,
        "duration": 4.41
    },
    {
        "text": "you can't use the C parser for the file",
        "start": 451.65,
        "duration": 4.62
    },
    {
        "text": "which is the super fast one because it",
        "start": 454.319,
        "duration": 3.6
    },
    {
        "text": "doesn't support skip footer and now you",
        "start": 456.27,
        "duration": 3.899
    },
    {
        "text": "have to go and switch to a Python one so",
        "start": 457.919,
        "duration": 4.231
    },
    {
        "text": "this is a very evolutionary process and",
        "start": 460.169,
        "duration": 3.09
    },
    {
        "text": "if you don't know this stuff if you",
        "start": 462.15,
        "duration": 3.509
    },
    {
        "text": "don't read dirty CSV every single day or",
        "start": 463.259,
        "duration": 3.87
    },
    {
        "text": "deal with some of these weirdest",
        "start": 465.659,
        "duration": 2.701
    },
    {
        "text": "centricity is that happen in the data",
        "start": 467.129,
        "duration": 2.79
    },
    {
        "text": "set you're going to hit it and then you",
        "start": 468.36,
        "duration": 3.239
    },
    {
        "text": "go to go to stack overflow and you're",
        "start": 469.919,
        "duration": 2.911
    },
    {
        "text": "gonna go find somebody else who's find",
        "start": 471.599,
        "duration": 2.25
    },
    {
        "text": "the same thing and you're slowly",
        "start": 472.83,
        "duration": 2.549
    },
    {
        "text": "building up knowledge about the data",
        "start": 473.849,
        "duration": 4.231
    },
    {
        "text": "okay so let's go ahead in just x2 that",
        "start": 475.379,
        "duration": 4.051
    },
    {
        "text": "line will super get a nice clean read of",
        "start": 478.08,
        "duration": 3.239
    },
    {
        "text": "the data turns out we do we go take a",
        "start": 479.43,
        "duration": 3.299
    },
    {
        "text": "look in the debugger we can see that we",
        "start": 481.319,
        "duration": 3.391
    },
    {
        "text": "now have a data frame and you can see",
        "start": 482.729,
        "duration": 3.601
    },
    {
        "text": "here there's a bunch of data in here and",
        "start": 484.71,
        "duration": 3.09
    },
    {
        "text": "there's names of people there's their",
        "start": 486.33,
        "duration": 3.449
    },
    {
        "text": "sacks and if you sort latest you can",
        "start": 487.8,
        "duration": 3.0
    },
    {
        "text": "start to see that you know there's",
        "start": 489.779,
        "duration": 2.7
    },
    {
        "text": "missing stuff and there's weird ages I",
        "start": 490.8,
        "duration": 3.06
    },
    {
        "text": "know you're a young man but I'm pretty",
        "start": 492.479,
        "duration": 2.881
    },
    {
        "text": "sure you're not point seven five years",
        "start": 493.86,
        "duration": 4.29
    },
    {
        "text": "old Seth I remember when our 0.75 is the",
        "start": 495.36,
        "duration": 4.799
    },
    {
        "text": "greatest time of my life and if you take",
        "start": 498.15,
        "duration": 3.509
    },
    {
        "text": "a look at this body column it's got its",
        "start": 500.159,
        "duration": 2.94
    },
    {
        "text": "full Nannes which is not a number in",
        "start": 501.659,
        "duration": 3.63
    },
    {
        "text": "Python so this is pretty much standard",
        "start": 503.099,
        "duration": 3.99
    },
    {
        "text": "for data sets that we see so it's kind",
        "start": 505.289,
        "duration": 4.44
    },
    {
        "text": "of ugly but now if I was to throw this",
        "start": 507.089,
        "duration": 4.561
    },
    {
        "text": "straight at SK learn or at some sort of",
        "start": 509.729,
        "duration": 4.321
    },
    {
        "text": "algorithm don't barf because there's",
        "start": 511.65,
        "duration": 3.809
    },
    {
        "text": "missing data the data is not of the",
        "start": 514.05,
        "duration": 2.94
    },
    {
        "text": "right type it's done to the right format",
        "start": 515.459,
        "duration": 3.21
    },
    {
        "text": "I'll save you the embarrassment of going",
        "start": 516.99,
        "duration": 3.33
    },
    {
        "text": "ahead and doing that and let's go and",
        "start": 518.669,
        "duration": 2.941
    },
    {
        "text": "take a look at how we could perhaps fix",
        "start": 520.32,
        "duration": 3.48
    },
    {
        "text": "this by creating a new derive data set",
        "start": 521.61,
        "duration": 4.8
    },
    {
        "text": "here so because we're in speeding along",
        "start": 523.8,
        "duration": 4.469
    },
    {
        "text": "I'm going to take the simplest route",
        "start": 526.41,
        "duration": 3.51
    },
    {
        "text": "possible through this ugly data I'm",
        "start": 528.269,
        "duration": 3.451
    },
    {
        "text": "gonna drop every single column that",
        "start": 529.92,
        "duration": 3.39
    },
    {
        "text": "causes me problems in my model whether",
        "start": 531.72,
        "duration": 3.0
    },
    {
        "text": "it's an interesting column or not I'm",
        "start": 533.31,
        "duration": 2.969
    },
    {
        "text": "just going to drop it and so we'll do",
        "start": 534.72,
        "duration": 2.85
    },
    {
        "text": "that by simply dropping those columns",
        "start": 536.279,
        "duration": 3.271
    },
    {
        "text": "and then I'm gonna drop all the rows",
        "start": 537.57,
        "duration": 4.11
    },
    {
        "text": "that are left that have any any value in",
        "start": 539.55,
        "duration": 4.74
    },
    {
        "text": "them at all oh this is painful - Wow",
        "start": 541.68,
        "duration": 4.469
    },
    {
        "text": "okay so the thing to look here is look",
        "start": 544.29,
        "duration": 3.27
    },
    {
        "text": "in the variable Explorer window top",
        "start": 546.149,
        "duration": 6.151
    },
    {
        "text": "right so we went from 11 columns to 6",
        "start": 547.56,
        "duration": 6.509
    },
    {
        "text": "columns with the drop and we've gone",
        "start": 552.3,
        "duration": 3.18
    },
    {
        "text": "from 1309",
        "start": 554.069,
        "duration": 4.471
    },
    {
        "text": "- a thousand rows so we've dropped 30%",
        "start": 555.48,
        "duration": 5.25
    },
    {
        "text": "issue of our data because there was one",
        "start": 558.54,
        "duration": 5.1
    },
    {
        "text": "missing value okay not perhaps the best",
        "start": 560.73,
        "duration": 5.1
    },
    {
        "text": "strategy but you pay me a little luck",
        "start": 563.64,
        "duration": 3.63
    },
    {
        "text": "and some better strategies in a second",
        "start": 565.83,
        "duration": 2.52
    },
    {
        "text": "there's gotta be a way to do this a",
        "start": 567.27,
        "duration": 2.22
    },
    {
        "text": "little bit better and so if we go ahead",
        "start": 568.35,
        "duration": 3.03
    },
    {
        "text": "and we'll just write that out let me",
        "start": 569.49,
        "duration": 3.63
    },
    {
        "text": "switch to my modelling file here so here",
        "start": 571.38,
        "duration": 4.53
    },
    {
        "text": "we got a very simple set of models I'm",
        "start": 573.12,
        "duration": 4.58
    },
    {
        "text": "someone going to reread the data again",
        "start": 575.91,
        "duration": 3.81
    },
    {
        "text": "I'm going to say I want to predict",
        "start": 577.7,
        "duration": 4.45
    },
    {
        "text": "whether somebody survived or not I went",
        "start": 579.72,
        "duration": 3.96
    },
    {
        "text": "to split the data test and train which",
        "start": 582.15,
        "duration": 2.76
    },
    {
        "text": "is a standard technique and then I'm",
        "start": 583.68,
        "duration": 2.31
    },
    {
        "text": "simply going to run a logistic",
        "start": 584.91,
        "duration": 3.21
    },
    {
        "text": "regression a random forest in a decision",
        "start": 585.99,
        "duration": 4.02
    },
    {
        "text": "tree I'm going to print out the results",
        "start": 588.12,
        "duration": 3.18
    },
    {
        "text": "from the three of those guys it's gone",
        "start": 590.01,
        "duration": 2.76
    },
    {
        "text": "ahead and run them and you can see we're",
        "start": 591.3,
        "duration": 3.24
    },
    {
        "text": "in the 0.6 6.67",
        "start": 592.77,
        "duration": 4.56
    },
    {
        "text": "range which it's not slightly better",
        "start": 594.54,
        "duration": 4.77
    },
    {
        "text": "than tossing a coin but it doesn't",
        "start": 597.33,
        "duration": 5.04
    },
    {
        "text": "justify your PhD or your vast salary to",
        "start": 599.31,
        "duration": 5.7
    },
    {
        "text": "get a 60-ish number and here's the sad",
        "start": 602.37,
        "duration": 5.25
    },
    {
        "text": "bit like you basically gone through like",
        "start": 605.01,
        "duration": 4.35
    },
    {
        "text": "this is everything a data scientist",
        "start": 607.62,
        "duration": 4.02
    },
    {
        "text": "would try first yep like you would",
        "start": 609.36,
        "duration": 4.74
    },
    {
        "text": "basically be like okay let's just do the",
        "start": 611.64,
        "duration": 4.14
    },
    {
        "text": "dumbest thing first so that I don't have",
        "start": 614.1,
        "duration": 3.72
    },
    {
        "text": "to pull my hair out later and you would",
        "start": 615.78,
        "duration": 3.57
    },
    {
        "text": "literally run our logistic regression",
        "start": 617.82,
        "duration": 4.26
    },
    {
        "text": "logistic regression classifier a random",
        "start": 619.35,
        "duration": 4.14
    },
    {
        "text": "forest and what was the decision tree",
        "start": 622.08,
        "duration": 3.18
    },
    {
        "text": "yeah because those are the ones that",
        "start": 623.49,
        "duration": 3.3
    },
    {
        "text": "usually get the fastest bang for your",
        "start": 625.26,
        "duration": 3.93
    },
    {
        "text": "buck and then you would find out that",
        "start": 626.79,
        "duration": 5.4
    },
    {
        "text": "you get 66 percent yeah and then this is",
        "start": 629.19,
        "duration": 4.77
    },
    {
        "text": "where the ugly work happens and it's",
        "start": 632.19,
        "duration": 3.29
    },
    {
        "text": "generally not trying a different model",
        "start": 633.96,
        "duration": 4.56
    },
    {
        "text": "it's fixing the data correct and that's",
        "start": 635.48,
        "duration": 4.81
    },
    {
        "text": "what we'll do now and again this is a",
        "start": 638.52,
        "duration": 4.14
    },
    {
        "text": "difference in data prep for AI versus",
        "start": 640.29,
        "duration": 4.2
    },
    {
        "text": "other consumption patterns because if",
        "start": 642.66,
        "duration": 3.27
    },
    {
        "text": "you're predicting the sales so it goes",
        "start": 644.49,
        "duration": 2.79
    },
    {
        "text": "or you're measuring sales figures for",
        "start": 645.93,
        "duration": 3.3
    },
    {
        "text": "your organization you're going to turn",
        "start": 647.28,
        "duration": 3.48
    },
    {
        "text": "around and say the data is either right",
        "start": 649.23,
        "duration": 2.64
    },
    {
        "text": "or not because I'm gonna have some sort",
        "start": 650.76,
        "duration": 2.46
    },
    {
        "text": "of verification process in my data",
        "start": 651.87,
        "duration": 3.18
    },
    {
        "text": "where's that extract some LTP system and",
        "start": 653.22,
        "duration": 2.94
    },
    {
        "text": "everything else like that",
        "start": 655.05,
        "duration": 2.49
    },
    {
        "text": "you're either right or wrong right right",
        "start": 656.16,
        "duration": 5.85
    },
    {
        "text": "here is 66% right or wrong is it right",
        "start": 657.54,
        "duration": 7.2
    },
    {
        "text": "enough is it too wrong it's this weird",
        "start": 662.01,
        "duration": 5.4
    },
    {
        "text": "gray area and can we make it better and",
        "start": 664.74,
        "duration": 5.22
    },
    {
        "text": "how much of messing with the data is",
        "start": 667.41,
        "duration": 5.31
    },
    {
        "text": "still a valid thing to go do right if I",
        "start": 669.96,
        "duration": 4.2
    },
    {
        "text": "start creating synthetic data time",
        "start": 672.72,
        "duration": 2.64
    },
    {
        "text": "series is a great example where you",
        "start": 674.16,
        "duration": 3.45
    },
    {
        "text": "create synthetic representations of data",
        "start": 675.36,
        "duration": 4.29
    },
    {
        "text": "over sliding windows because you can't",
        "start": 677.61,
        "duration": 3.57
    },
    {
        "text": "throw that much data at the algorithms",
        "start": 679.65,
        "duration": 3.93
    },
    {
        "text": "it's not the actual data from the system",
        "start": 681.18,
        "duration": 3.54
    },
    {
        "text": "that I'm running my model one I'm",
        "start": 683.58,
        "duration": 2.58
    },
    {
        "text": "running on synthetic there I created",
        "start": 684.72,
        "duration": 3.42
    },
    {
        "text": "from the raw data so in this very",
        "start": 686.16,
        "duration": 3.15
    },
    {
        "text": "interesting space okay so as",
        "start": 688.14,
        "duration": 2.19
    },
    {
        "text": "go back and let's take a different",
        "start": 689.31,
        "duration": 3.84
    },
    {
        "text": "approach much more of I kind of Seth I",
        "start": 690.33,
        "duration": 5.46
    },
    {
        "text": "max a highly qualified PhD sort of",
        "start": 693.15,
        "duration": 4.08
    },
    {
        "text": "approach and we'll go ahead and we'll",
        "start": 695.79,
        "duration": 3.84
    },
    {
        "text": "read read the data and we'll draw up",
        "start": 697.23,
        "duration": 4.14
    },
    {
        "text": "less columns than we did before so it's",
        "start": 699.63,
        "duration": 3.77
    },
    {
        "text": "going to reread that file again oh",
        "start": 701.37,
        "duration": 4.5
    },
    {
        "text": "excuse me go to import a new set of",
        "start": 703.4,
        "duration": 5.86
    },
    {
        "text": "libraries here and let's go ahead and we",
        "start": 705.87,
        "duration": 6.63
    },
    {
        "text": "will drop some columns because I know",
        "start": 709.26,
        "duration": 4.53
    },
    {
        "text": "having played with the data which I",
        "start": 712.5,
        "duration": 3.33
    },
    {
        "text": "saved you the me doing it the home",
        "start": 713.79,
        "duration": 3.239
    },
    {
        "text": "destination column is not particularly",
        "start": 715.83,
        "duration": 2.31
    },
    {
        "text": "good your ticket number is not",
        "start": 717.029,
        "duration": 2.851
    },
    {
        "text": "interesting names not interesting which",
        "start": 718.14,
        "duration": 3.06
    },
    {
        "text": "bought you were in when you survived",
        "start": 719.88,
        "duration": 2.79
    },
    {
        "text": "isn't actually indicated whether you're",
        "start": 721.2,
        "duration": 2.88
    },
    {
        "text": "going to survive or not whether you",
        "start": 722.67,
        "duration": 3.12
    },
    {
        "text": "found your body or not not such a good",
        "start": 724.08,
        "duration": 3.66
    },
    {
        "text": "indicator and also which cabin you're in",
        "start": 725.79,
        "duration": 3.15
    },
    {
        "text": "okay so when we go ahead and drop those",
        "start": 727.74,
        "duration": 2.849
    },
    {
        "text": "columns because they're not good from a",
        "start": 728.94,
        "duration": 2.82
    },
    {
        "text": "modal perspectives are also kind of",
        "start": 730.589,
        "duration": 4.011
    },
    {
        "text": "dirty I want to step through a series of",
        "start": 731.76,
        "duration": 5.34
    },
    {
        "text": "you can call them data preparation steps",
        "start": 734.6,
        "duration": 4.0
    },
    {
        "text": "you can call them feature ization steps",
        "start": 737.1,
        "duration": 3.33
    },
    {
        "text": "we blend all that together because it",
        "start": 738.6,
        "duration": 3.21
    },
    {
        "text": "doesn't really matter so the first thing",
        "start": 740.43,
        "duration": 2.25
    },
    {
        "text": "we're going to do is we're going to map",
        "start": 741.81,
        "duration": 3.15
    },
    {
        "text": "the sex column because if we go back in",
        "start": 742.68,
        "duration": 3.45
    },
    {
        "text": "here and take a look at this code that",
        "start": 744.96,
        "duration": 3.629
    },
    {
        "text": "does this a lot of classifiers don't",
        "start": 746.13,
        "duration": 4.14
    },
    {
        "text": "like categorical variables they want",
        "start": 748.589,
        "duration": 3.811
    },
    {
        "text": "zeros and ones they want numbers and if",
        "start": 750.27,
        "duration": 4.319
    },
    {
        "text": "you have male female or MF know there's",
        "start": 752.4,
        "duration": 3.42
    },
    {
        "text": "a whole range of algorithms you simply",
        "start": 754.589,
        "duration": 3.481
    },
    {
        "text": "can't use basically it's all comes down",
        "start": 755.82,
        "duration": 4.5
    },
    {
        "text": "to converting your square of data into",
        "start": 758.07,
        "duration": 5.76
    },
    {
        "text": "numbers it all comes down to you have to",
        "start": 760.32,
        "duration": 5.73
    },
    {
        "text": "know how you're consuming your data to",
        "start": 763.83,
        "duration": 3.509
    },
    {
        "text": "prepare it I talked to everyone about",
        "start": 766.05,
        "duration": 3.12
    },
    {
        "text": "multiple different branches so we have a",
        "start": 767.339,
        "duration": 4.081
    },
    {
        "text": "bunch of missing data in the age column",
        "start": 769.17,
        "duration": 3.45
    },
    {
        "text": "and the age column feels like it might",
        "start": 771.42,
        "duration": 2.88
    },
    {
        "text": "be an interesting one from the data set",
        "start": 772.62,
        "duration": 3.24
    },
    {
        "text": "perspective so in this case I want to",
        "start": 774.3,
        "duration": 3.96
    },
    {
        "text": "compute median even with an example like",
        "start": 775.86,
        "duration": 3.72
    },
    {
        "text": "something as simple as computing median",
        "start": 778.26,
        "duration": 3.36
    },
    {
        "text": "you have a choice if in computing median",
        "start": 779.58,
        "duration": 4.259
    },
    {
        "text": "over the entire data set are you in a",
        "start": 781.62,
        "duration": 4.77
    },
    {
        "text": "force some sort of distribution uniform",
        "start": 783.839,
        "duration": 4.771
    },
    {
        "text": "distribution you are or should you group",
        "start": 786.39,
        "duration": 3.63
    },
    {
        "text": "by first class second class third class",
        "start": 788.61,
        "duration": 2.88
    },
    {
        "text": "should you group by whether they're",
        "start": 790.02,
        "duration": 2.819
    },
    {
        "text": "parents or not whether they're children",
        "start": 791.49,
        "duration": 2.28
    },
    {
        "text": "right",
        "start": 792.839,
        "duration": 3.601
    },
    {
        "text": "what their title is and so again come up",
        "start": 793.77,
        "duration": 5.01
    },
    {
        "text": "with a hypothesis try the hypothesis",
        "start": 796.44,
        "duration": 4.08
    },
    {
        "text": "evaluate successfully and compare",
        "start": 798.78,
        "duration": 3.45
    },
    {
        "text": "multiple different options of your",
        "start": 800.52,
        "duration": 3.0
    },
    {
        "text": "hypothesis to work out which one gives",
        "start": 802.23,
        "duration": 2.46
    },
    {
        "text": "you the best answer this is the same",
        "start": 803.52,
        "duration": 2.43
    },
    {
        "text": "kind of issue you have when you're",
        "start": 804.69,
        "duration": 4.07
    },
    {
        "text": "trying to convert like like continuous",
        "start": 805.95,
        "duration": 5.97
    },
    {
        "text": "numbers into bins like how big should",
        "start": 808.76,
        "duration": 5.26
    },
    {
        "text": "your bins be are you assuming anything",
        "start": 811.92,
        "duration": 3.75
    },
    {
        "text": "about your distribution like if it's a",
        "start": 814.02,
        "duration": 4.02
    },
    {
        "text": "if it's a if it's a not a uniform but",
        "start": 815.67,
        "duration": 3.93
    },
    {
        "text": "like a Gaussian distribution and your",
        "start": 818.04,
        "duration": 4.02
    },
    {
        "text": "bin covers like two standard deviations",
        "start": 819.6,
        "duration": 3.13
    },
    {
        "text": "to the mean you just",
        "start": 822.06,
        "duration": 2.469
    },
    {
        "text": "you got two rebuilds and nothing's gonna",
        "start": 822.73,
        "duration": 3.599
    },
    {
        "text": "do I mean it's not very predictive and",
        "start": 824.529,
        "duration": 3.541
    },
    {
        "text": "so there's a lot of like trying stuff",
        "start": 826.329,
        "duration": 3.661
    },
    {
        "text": "out yeah it's why histograms are both",
        "start": 828.07,
        "duration": 4.139
    },
    {
        "text": "the most loved and most hated technique",
        "start": 829.99,
        "duration": 3.93
    },
    {
        "text": "in data science for doing exploratory",
        "start": 832.209,
        "duration": 4.261
    },
    {
        "text": "data analysis because you can sit down",
        "start": 833.92,
        "duration": 4.65
    },
    {
        "text": "with a histogram and simply by changing",
        "start": 836.47,
        "duration": 3.929
    },
    {
        "text": "the start position and the width of the",
        "start": 838.57,
        "duration": 3.99
    },
    {
        "text": "bins you can end up with completely",
        "start": 840.399,
        "duration": 3.81
    },
    {
        "text": "different views on the day and that's",
        "start": 842.56,
        "duration": 3.209
    },
    {
        "text": "why even using histograms is an",
        "start": 844.209,
        "duration": 2.851
    },
    {
        "text": "iterative process and you should try",
        "start": 845.769,
        "duration": 2.37
    },
    {
        "text": "multiple different approaches to a",
        "start": 847.06,
        "duration": 2.91
    },
    {
        "text": "histogram display to make sure you get",
        "start": 848.139,
        "duration": 3.0
    },
    {
        "text": "the right answer coming back out the",
        "start": 849.97,
        "duration": 3.869
    },
    {
        "text": "other side okay so I'm gonna drop Enys",
        "start": 851.139,
        "duration": 4.2
    },
    {
        "text": "because I've imputed the missing values",
        "start": 853.839,
        "duration": 3.421
    },
    {
        "text": "now for the column I think I care about",
        "start": 855.339,
        "duration": 3.541
    },
    {
        "text": "so if there are any s in any of the",
        "start": 857.26,
        "duration": 3.87
    },
    {
        "text": "columns then it's okay now because I've",
        "start": 858.88,
        "duration": 3.509
    },
    {
        "text": "got the thing I think is most important",
        "start": 861.13,
        "duration": 2.85
    },
    {
        "text": "I've imputed that I'm gonna use a",
        "start": 862.389,
        "duration": 3.481
    },
    {
        "text": "standard scaler here to scale the Feres",
        "start": 863.98,
        "duration": 3.69
    },
    {
        "text": "into a consistent range which somehow",
        "start": 865.87,
        "duration": 3.57
    },
    {
        "text": "rhythms work better with a narrower",
        "start": 867.67,
        "duration": 4.44
    },
    {
        "text": "range in terms of how they work and then",
        "start": 869.44,
        "duration": 3.81
    },
    {
        "text": "I'm going to do is called handle the",
        "start": 872.11,
        "duration": 2.55
    },
    {
        "text": "embark comb and I'll show you that in a",
        "start": 873.25,
        "duration": 3.18
    },
    {
        "text": "second and then we're gonna drop the",
        "start": 874.66,
        "duration": 2.82
    },
    {
        "text": "embark combs they don't want the",
        "start": 876.43,
        "duration": 2.849
    },
    {
        "text": "original so let's go back through here",
        "start": 877.48,
        "duration": 2.789
    },
    {
        "text": "and we'll take a look at what we're",
        "start": 879.279,
        "duration": 2.341
    },
    {
        "text": "doing with these last couple yeah this",
        "start": 880.269,
        "duration": 2.791
    },
    {
        "text": "is a lot of code I mean like you're",
        "start": 881.62,
        "duration": 3.089
    },
    {
        "text": "you're obviously going through this",
        "start": 883.06,
        "duration": 3.839
    },
    {
        "text": "super fast but there was a lot of code",
        "start": 884.709,
        "duration": 4.201
    },
    {
        "text": "that you wrote and had to scare up and",
        "start": 886.899,
        "duration": 4.261
    },
    {
        "text": "write and figure out if it even if",
        "start": 888.91,
        "duration": 3.539
    },
    {
        "text": "you're you really want to nerd out on",
        "start": 891.16,
        "duration": 3.03
    },
    {
        "text": "this stuff there's a cattle competition",
        "start": 892.449,
        "duration": 3.961
    },
    {
        "text": "I think from 2015 on the Titanic data",
        "start": 894.19,
        "duration": 4.11
    },
    {
        "text": "set and when it starts the first few",
        "start": 896.41,
        "duration": 3.51
    },
    {
        "text": "scores like a point seven nine out of",
        "start": 898.3,
        "duration": 2.61
    },
    {
        "text": "the box because that's what scikit-learn",
        "start": 899.92,
        "duration": 2.46
    },
    {
        "text": "will do if you do a little bit of work",
        "start": 900.91,
        "duration": 3.09
    },
    {
        "text": "on the data and then you can see the",
        "start": 902.38,
        "duration": 3.12
    },
    {
        "text": "scores progressing over time and finally",
        "start": 904.0,
        "duration": 3.389
    },
    {
        "text": "somebody nails and gets a one if you",
        "start": 905.5,
        "duration": 3.42
    },
    {
        "text": "look at how much work each of the",
        "start": 907.389,
        "duration": 3.241
    },
    {
        "text": "different people had to do to drive the",
        "start": 908.92,
        "duration": 3.599
    },
    {
        "text": "scales off it's some of its and the",
        "start": 910.63,
        "duration": 3.329
    },
    {
        "text": "algorithms like parameters and tuning",
        "start": 912.519,
        "duration": 2.25
    },
    {
        "text": "the algorithms and using different",
        "start": 913.959,
        "duration": 3.451
    },
    {
        "text": "algorithms but a lot of it is in what",
        "start": 914.769,
        "duration": 4.05
    },
    {
        "text": "features risers am i using and how am i",
        "start": 917.41,
        "duration": 3.299
    },
    {
        "text": "messing with the data okay so here's",
        "start": 918.819,
        "duration": 3.33
    },
    {
        "text": "what we're doing for handle embarked and",
        "start": 920.709,
        "duration": 3.031
    },
    {
        "text": "the trick we're doing with handle them",
        "start": 922.149,
        "duration": 3.571
    },
    {
        "text": "to handle embarked is we're creating a",
        "start": 923.74,
        "duration": 3.87
    },
    {
        "text": "dummy variable so embarked in the",
        "start": 925.72,
        "duration": 3.299
    },
    {
        "text": "Titanic data sets it's which side you",
        "start": 927.61,
        "duration": 3.12
    },
    {
        "text": "start on and so it's a letter which",
        "start": 929.019,
        "duration": 3.18
    },
    {
        "text": "indicates whether you boarded at",
        "start": 930.73,
        "duration": 3.78
    },
    {
        "text": "Southampton or wherever again it's a",
        "start": 932.199,
        "duration": 3.75
    },
    {
        "text": "categorical variable the algorithms",
        "start": 934.51,
        "duration": 2.55
    },
    {
        "text": "can't do anything with it so in this",
        "start": 935.949,
        "duration": 3.091
    },
    {
        "text": "case instead of doing a map what we",
        "start": 937.06,
        "duration": 3.24
    },
    {
        "text": "actually do is create dummy variables",
        "start": 939.04,
        "duration": 3.029
    },
    {
        "text": "which is where we Kate a column for each",
        "start": 940.3,
        "duration": 3.81
    },
    {
        "text": "one of the variable values then we do 0",
        "start": 942.069,
        "duration": 5.25
    },
    {
        "text": "0 1 0 1 0 to indicate what that was a",
        "start": 944.11,
        "duration": 4.44
    },
    {
        "text": "lot of classification algorithms work",
        "start": 947.319,
        "duration": 3.361
    },
    {
        "text": "much better with that structure of data",
        "start": 948.55,
        "duration": 3.539
    },
    {
        "text": "than they will do with a kind of map",
        "start": 950.68,
        "duration": 2.64
    },
    {
        "text": "style",
        "start": 952.089,
        "duration": 3.241
    },
    {
        "text": "one hot encoding there's three or four",
        "start": 953.32,
        "duration": 3.36
    },
    {
        "text": "different ways of encoding I just did",
        "start": 955.33,
        "duration": 3.3
    },
    {
        "text": "dummy for this one you can do on one",
        "start": 956.68,
        "duration": 3.66
    },
    {
        "text": "hand coding as two as well and so that's",
        "start": 958.63,
        "duration": 3.99
    },
    {
        "text": "what that trick is doing there and then",
        "start": 960.34,
        "duration": 3.51
    },
    {
        "text": "that's really what we're doing there's",
        "start": 962.62,
        "duration": 3.48
    },
    {
        "text": "the example I said for scaling the fares",
        "start": 963.85,
        "duration": 3.84
    },
    {
        "text": "so it's just using a standard scaler",
        "start": 966.1,
        "duration": 3.36
    },
    {
        "text": "that's built into the preprocessor and",
        "start": 967.69,
        "duration": 3.87
    },
    {
        "text": "we do a very simple median here on the",
        "start": 969.46,
        "duration": 3.81
    },
    {
        "text": "aged as I was mentioning earlier but we",
        "start": 971.56,
        "duration": 3.0
    },
    {
        "text": "could group by we could use",
        "start": 973.27,
        "duration": 2.79
    },
    {
        "text": "distributions to compute rather than",
        "start": 974.56,
        "duration": 3.39
    },
    {
        "text": "simple median you have many options and",
        "start": 976.06,
        "duration": 3.54
    },
    {
        "text": "many hypotheses to go ahead and try here",
        "start": 977.95,
        "duration": 3.27
    },
    {
        "text": "so if we go ahead back here we'll go",
        "start": 979.6,
        "duration": 3.0
    },
    {
        "text": "ahead and finish up so we'll just go",
        "start": 981.22,
        "duration": 2.52
    },
    {
        "text": "ahead and write this file out and we're",
        "start": 982.6,
        "duration": 2.7
    },
    {
        "text": "just gonna write this same file back out",
        "start": 983.74,
        "duration": 3.6
    },
    {
        "text": "and we'll go back to our modeling code",
        "start": 985.3,
        "duration": 3.84
    },
    {
        "text": "and we'll go ahead and was read our",
        "start": 987.34,
        "duration": 3.81
    },
    {
        "text": "modeling code now remember we were in",
        "start": 989.14,
        "duration": 4.32
    },
    {
        "text": "the high 60s was the score that we were",
        "start": 991.15,
        "duration": 4.47
    },
    {
        "text": "able to get by using that quick and",
        "start": 993.46,
        "duration": 5.34
    },
    {
        "text": "dirty approach we go ahead and run that",
        "start": 995.62,
        "duration": 5.67
    },
    {
        "text": "we're now up in the high 17 point",
        "start": 998.8,
        "duration": 4.32
    },
    {
        "text": "there's nothing to laugh at correct and",
        "start": 1001.29,
        "duration": 4.65
    },
    {
        "text": "that was relatively simple processing of",
        "start": 1003.12,
        "duration": 4.59
    },
    {
        "text": "the data here there's a lot more you can",
        "start": 1005.94,
        "duration": 2.97
    },
    {
        "text": "do and if you go to Kaggle you'll see",
        "start": 1007.71,
        "duration": 2.48
    },
    {
        "text": "all the other examples that people",
        "start": 1008.91,
        "duration": 3.63
    },
    {
        "text": "abused you basically say it's relatively",
        "start": 1010.19,
        "duration": 4.75
    },
    {
        "text": "simple processing it is but the amount",
        "start": 1012.54,
        "duration": 4.17
    },
    {
        "text": "of time that it takes to arrive at those",
        "start": 1014.94,
        "duration": 4.05
    },
    {
        "text": "things it's not gonna be said you're",
        "start": 1016.71,
        "duration": 4.05
    },
    {
        "text": "spending a couple of days I'm just doing",
        "start": 1018.99,
        "duration": 4.02
    },
    {
        "text": "stuff like this correct yeah and that's",
        "start": 1020.76,
        "duration": 4.35
    },
    {
        "text": "frustrating for sometimes for people and",
        "start": 1023.01,
        "duration": 3.63
    },
    {
        "text": "for organizations which is you know we",
        "start": 1025.11,
        "duration": 4.44
    },
    {
        "text": "say you know we have empirical evidence",
        "start": 1026.64,
        "duration": 4.71
    },
    {
        "text": "at Microsoft from surveys we've done",
        "start": 1029.55,
        "duration": 2.85
    },
    {
        "text": "interviews we've done with customers",
        "start": 1031.35,
        "duration": 2.339
    },
    {
        "text": "anything between eighteen one hundred",
        "start": 1032.4,
        "duration": 2.429
    },
    {
        "text": "and fifty percent to the time when of",
        "start": 1033.689,
        "duration": 3.0
    },
    {
        "text": "advanced analytics project is spent on",
        "start": 1034.829,
        "duration": 3.75
    },
    {
        "text": "data preparation so you've got all your",
        "start": 1036.689,
        "duration": 3.9
    },
    {
        "text": "you know PhD guys who you want to be",
        "start": 1038.579,
        "duration": 4.231
    },
    {
        "text": "letting loose on morals and really",
        "start": 1040.589,
        "duration": 3.481
    },
    {
        "text": "thinking about hard things how they",
        "start": 1042.81,
        "duration": 3.36
    },
    {
        "text": "represent the data visualization they're",
        "start": 1044.07,
        "duration": 3.36
    },
    {
        "text": "sitting working at what parameters to",
        "start": 1046.17,
        "duration": 2.76
    },
    {
        "text": "send to a CSV reader what features",
        "start": 1047.43,
        "duration": 4.08
    },
    {
        "text": "reviews and you know most of the",
        "start": 1048.93,
        "duration": 3.87
    },
    {
        "text": "analysts will agree with that number so",
        "start": 1051.51,
        "duration": 2.85
    },
    {
        "text": "that 80% number here's an",
        "start": 1052.8,
        "duration": 3.24
    },
    {
        "text": "industry-recognized number and it's all",
        "start": 1054.36,
        "duration": 4.53
    },
    {
        "text": "stuff like this and it's generally stuff",
        "start": 1056.04,
        "duration": 5.39
    },
    {
        "text": "that people don't talk about because I",
        "start": 1058.89,
        "duration": 4.53
    },
    {
        "text": "mean it's not exciting",
        "start": 1061.43,
        "duration": 4.66
    },
    {
        "text": "no well and the step that's missing here",
        "start": 1063.42,
        "duration": 4.17
    },
    {
        "text": "what we did great I got everything",
        "start": 1066.09,
        "duration": 3.03
    },
    {
        "text": "working here inside spider on my laptop",
        "start": 1067.59,
        "duration": 3.93
    },
    {
        "text": "this is a small data set let's say it",
        "start": 1069.12,
        "duration": 4.68
    },
    {
        "text": "was a billion rows now you go to go get",
        "start": 1071.52,
        "duration": 4.83
    },
    {
        "text": "this working scale ablai reliably what",
        "start": 1073.8,
        "duration": 3.93
    },
    {
        "text": "happens is the data gets updated once an",
        "start": 1076.35,
        "duration": 3.42
    },
    {
        "text": "hour because it's IOT data what happens",
        "start": 1077.73,
        "duration": 4.38
    },
    {
        "text": "when you add a new region of product",
        "start": 1079.77,
        "duration": 3.54
    },
    {
        "text": "sales because you're taking product data",
        "start": 1082.11,
        "duration": 3.48
    },
    {
        "text": "a new class of device or something like",
        "start": 1083.31,
        "duration": 3.03
    },
    {
        "text": "that",
        "start": 1085.59,
        "duration": 2.91
    },
    {
        "text": "think about how exponential complexity",
        "start": 1086.34,
        "duration": 4.469
    },
    {
        "text": "is in terms of the classic big v's of",
        "start": 1088.5,
        "duration": 4.44
    },
    {
        "text": "big data but also this stuff you've got",
        "start": 1090.809,
        "duration": 3.781
    },
    {
        "text": "to get it to scale you got to make it",
        "start": 1092.94,
        "duration": 4.89
    },
    {
        "text": "secure right repeatable otherwise the",
        "start": 1094.59,
        "duration": 5.43
    },
    {
        "text": "project fails awesome so how would you",
        "start": 1097.83,
        "duration": 3.959
    },
    {
        "text": "summarize the whole data prep stuff I",
        "start": 1100.02,
        "duration": 5.039
    },
    {
        "text": "think it's still the coolest part but",
        "start": 1101.789,
        "duration": 4.5
    },
    {
        "text": "it's also quite frankly the most",
        "start": 1105.059,
        "duration": 2.671
    },
    {
        "text": "important part because if you don't get",
        "start": 1106.289,
        "duration": 3.451
    },
    {
        "text": "the data right then it doesn't matter",
        "start": 1107.73,
        "duration": 3.6
    },
    {
        "text": "how smart your algorithms are how smart",
        "start": 1109.74,
        "duration": 3.63
    },
    {
        "text": "you are at doing algorithms then you're",
        "start": 1111.33,
        "duration": 3.839
    },
    {
        "text": "starting from a pretty bad position so",
        "start": 1113.37,
        "duration": 3.57
    },
    {
        "text": "you got to get the data right and you've",
        "start": 1115.169,
        "duration": 3.451
    },
    {
        "text": "got to think about data differently for",
        "start": 1116.94,
        "duration": 3.3
    },
    {
        "text": "AI then you think of how you think about",
        "start": 1118.62,
        "duration": 4.439
    },
    {
        "text": "data in the case of something like bi or",
        "start": 1120.24,
        "duration": 4.319
    },
    {
        "text": "general data engineering and just to",
        "start": 1123.059,
        "duration": 3.24
    },
    {
        "text": "finish up any tips for people that are",
        "start": 1124.559,
        "duration": 3.441
    },
    {
        "text": "struggling with this right now",
        "start": 1126.299,
        "duration": 5.941
    },
    {
        "text": "yeah work hard all right well thanks so",
        "start": 1128.0,
        "duration": 5.32
    },
    {
        "text": "much for spending some time with us",
        "start": 1132.24,
        "duration": 2.37
    },
    {
        "text": "we've been learning all about data",
        "start": 1133.32,
        "duration": 3.719
    },
    {
        "text": "preparation what it looks like I'm",
        "start": 1134.61,
        "duration": 3.98
    },
    {
        "text": "pretty excited about it",
        "start": 1137.039,
        "duration": 4.711
    },
    {
        "text": "sometimes but I think that I do get",
        "start": 1138.59,
        "duration": 4.63
    },
    {
        "text": "really excited about it when actually",
        "start": 1141.75,
        "duration": 4.049
    },
    {
        "text": "you can see jumps and in accuracy and",
        "start": 1143.22,
        "duration": 3.959
    },
    {
        "text": "precision and that kind of stuff it's",
        "start": 1145.799,
        "duration": 2.581
    },
    {
        "text": "pretty cool thanks for watch for",
        "start": 1147.179,
        "duration": 2.431
    },
    {
        "text": "watching we'll see you next time take",
        "start": 1148.38,
        "duration": 1.66
    },
    {
        "text": "care",
        "start": 1149.61,
        "duration": 9.53
    },
    {
        "text": "[Music]",
        "start": 1150.04,
        "duration": 9.1
    }
]