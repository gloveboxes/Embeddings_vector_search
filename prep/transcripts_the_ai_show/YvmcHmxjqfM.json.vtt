[
    {
        "text": ">> Hey everyone you're not going to want to miss",
        "start": 0.0,
        "duration": 1.8
    },
    {
        "text": "this episode of The AI Show where we are going to",
        "start": 1.8,
        "duration": 2.37
    },
    {
        "text": "be talking about combining",
        "start": 4.17,
        "duration": 1.05
    },
    {
        "text": "the power of vector search with function",
        "start": 5.22,
        "duration": 1.98
    },
    {
        "text": "calling an Azure OpenAI Service, let's jump it.",
        "start": 7.2,
        "duration": 4.06
    },
    {
        "text": "[MUSIC] Today we are joined by Derek. Welcome Derek.",
        "start": 17.72,
        "duration": 3.37
    },
    {
        "text": "Thank you so much for hanging out with us today.",
        "start": 21.09,
        "duration": 1.93
    },
    {
        "text": "Why don't you tell us a little bit about yourself and what you do?",
        "start": 23.02,
        "duration": 2.9
    },
    {
        "text": ">> Thanks for having me on the show Cassie.",
        "start": 25.92,
        "duration": 1.995
    },
    {
        "text": "My name is Derek Legenzof,",
        "start": 27.915,
        "duration": 1.675
    },
    {
        "text": "I'm one of the Product Managers on the Azure OpenAI Service.",
        "start": 29.59,
        "duration": 3.635
    },
    {
        "text": ">> Awesome. Today you're going to be going",
        "start": 33.225,
        "duration": 1.725
    },
    {
        "text": "over some really cool things",
        "start": 34.95,
        "duration": 1.875
    },
    {
        "text": "with function calling from the Azure OpenAI service.",
        "start": 36.825,
        "duration": 3.545
    },
    {
        "text": "For people that aren't familiar with what that is,",
        "start": 40.37,
        "duration": 2.13
    },
    {
        "text": "can you tell us a little bit about it?",
        "start": 42.5,
        "duration": 1.99
    },
    {
        "text": ">> Sure to. What function calling really does is it enables you",
        "start": 44.49,
        "duration": 3.56
    },
    {
        "text": "to use these new versions of GPT-3.5 Turbo and GPT-4,",
        "start": 48.05,
        "duration": 3.75
    },
    {
        "text": "and be able to create structured outputs.",
        "start": 51.8,
        "duration": 2.325
    },
    {
        "text": "What that really enables you to do is be able to get you connect",
        "start": 54.125,
        "duration": 3.465
    },
    {
        "text": "these models with other tools or systems you have.",
        "start": 57.59,
        "duration": 3.585
    },
    {
        "text": "For example, you might want to",
        "start": 61.175,
        "duration": 2.025
    },
    {
        "text": "connect to your search index that will be showing you later",
        "start": 63.2,
        "duration": 2.535
    },
    {
        "text": "in this video are to be able to retrieve",
        "start": 65.735,
        "duration": 2.205
    },
    {
        "text": "data and augment your prompts us you can",
        "start": 67.94,
        "duration": 2.16
    },
    {
        "text": "leverage that in the prompt field to get those answers or you can",
        "start": 70.1,
        "duration": 3.03
    },
    {
        "text": "also use it to you add your additional capabilities of the models.",
        "start": 73.13,
        "duration": 3.48
    },
    {
        "text": "For example, these language models",
        "start": 76.61,
        "duration": 1.47
    },
    {
        "text": "really aren't that great at math,",
        "start": 78.08,
        "duration": 1.59
    },
    {
        "text": "but now you can create a function that maybe is",
        "start": 79.67,
        "duration": 2.43
    },
    {
        "text": "a calculator or does",
        "start": 82.1,
        "duration": 1.17
    },
    {
        "text": "calculations that are important for your use case.",
        "start": 83.27,
        "duration": 2.4
    },
    {
        "text": "Really can help augment the capabilities of",
        "start": 85.67,
        "duration": 2.16
    },
    {
        "text": "these models for scenarios",
        "start": 87.83,
        "duration": 2.85
    },
    {
        "text": "that might have been difficult but just these models on their own.",
        "start": 90.68,
        "duration": 2.945
    },
    {
        "text": ">> Awesome. We're going to learn how to do",
        "start": 93.625,
        "duration": 2.345
    },
    {
        "text": "that then you're going to show us how we're able",
        "start": 95.97,
        "duration": 1.82
    },
    {
        "text": "to augment the model to",
        "start": 97.79,
        "duration": 2.265
    },
    {
        "text": "better serve different scenarios that we need and make it better.",
        "start": 100.055,
        "duration": 3.105
    },
    {
        "text": "I think that may be out of the box that's not great at.",
        "start": 103.16,
        "duration": 2.285
    },
    {
        "text": ">> Exactly. This is where building",
        "start": 105.445,
        "duration": 2.705
    },
    {
        "text": "off of the AI show that William did last week,",
        "start": 108.15,
        "duration": 2.46
    },
    {
        "text": "where you can create an index using vector search.",
        "start": 110.61,
        "duration": 2.19
    },
    {
        "text": "Now what I'm going to show you how to do it's",
        "start": 112.8,
        "duration": 1.79
    },
    {
        "text": "actually used function calling to be able to query of",
        "start": 114.59,
        "duration": 2.33
    },
    {
        "text": "that index and we'll actually throughout",
        "start": 116.92,
        "duration": 2.36
    },
    {
        "text": "this video be building a little chat-bot to help you",
        "start": 119.28,
        "duration": 2.36
    },
    {
        "text": "search for recipes and and find",
        "start": 121.64,
        "duration": 1.71
    },
    {
        "text": "a good recipe to make and we'd actually even leverage",
        "start": 123.35,
        "duration": 2.28
    },
    {
        "text": "the capability of the model to help maybe",
        "start": 125.63,
        "duration": 1.77
    },
    {
        "text": "tailor that recipe or come up with replacement ideas.",
        "start": 127.4,
        "duration": 2.955
    },
    {
        "text": "Hopefully we'll be able to show a nice little end to end",
        "start": 130.355,
        "duration": 2.985
    },
    {
        "text": "snare of how you can use function calling",
        "start": 133.34,
        "duration": 1.44
    },
    {
        "text": "for a real-world scenario.",
        "start": 134.78,
        "duration": 1.755
    },
    {
        "text": ">> That's awesome. Let's take a look at how we can do that.",
        "start": 136.535,
        "duration": 3.2
    },
    {
        "text": ">> Sure. I have a Jupyter Notebook here",
        "start": 139.735,
        "duration": 3.095
    },
    {
        "text": "set up and up here I'm just importing",
        "start": 142.83,
        "duration": 2.39
    },
    {
        "text": "some libraries and defining my credentials for",
        "start": 145.22,
        "duration": 2.7
    },
    {
        "text": "both my Azure Cognitive Search Index",
        "start": 147.92,
        "duration": 2.13
    },
    {
        "text": "as well as my Azure OpenAI Service.",
        "start": 150.05,
        "duration": 3.55
    },
    {
        "text": "Next what we want to do is actually define the messages we want to",
        "start": 154.82,
        "duration": 3.54
    },
    {
        "text": "send to the model as well as the functions.",
        "start": 158.36,
        "duration": 3.85
    },
    {
        "text": "If we look at this function there's",
        "start": 162.37,
        "duration": 2.155
    },
    {
        "text": "a few key things we're going to provide.",
        "start": 164.525,
        "duration": 1.86
    },
    {
        "text": "We're going to give this function a name.",
        "start": 166.385,
        "duration": 2.56
    },
    {
        "text": "This case we want to be able to query",
        "start": 168.945,
        "duration": 1.415
    },
    {
        "text": "recipes from our Azure Cognitive Search index.",
        "start": 170.36,
        "duration": 3.525
    },
    {
        "text": "We've named the function there.",
        "start": 173.885,
        "duration": 2.37
    },
    {
        "text": "We're just going to give the model a few details",
        "start": 176.255,
        "duration": 2.175
    },
    {
        "text": "about what this function is designed to do.",
        "start": 178.43,
        "duration": 1.8
    },
    {
        "text": "We're pretty simply just saying it's going to retrieve",
        "start": 180.23,
        "duration": 1.98
    },
    {
        "text": "recipes from an Azure Cognitive Search index.",
        "start": 182.21,
        "duration": 2.775
    },
    {
        "text": "This description will actually be added to",
        "start": 184.985,
        "duration": 2.685
    },
    {
        "text": "the prompt behind the scenes.",
        "start": 187.67,
        "duration": 2.35
    },
    {
        "text": "It's almost like a new style of",
        "start": 190.02,
        "duration": 1.79
    },
    {
        "text": "prompt engineer where within",
        "start": 191.81,
        "duration": 1.17
    },
    {
        "text": "this function we're giving details and",
        "start": 192.98,
        "duration": 1.83
    },
    {
        "text": "in teaching the model how to use our function",
        "start": 194.81,
        "duration": 2.04
    },
    {
        "text": "because these new versions of GPT-3.5 Turbo and",
        "start": 196.85,
        "duration": 2.82
    },
    {
        "text": "GPT-4 the 0613 versions to be precise had been fine tuned to",
        "start": 199.67,
        "duration": 4.92
    },
    {
        "text": "learn how to use these functions and then you're within the call",
        "start": 204.59,
        "duration": 2.61
    },
    {
        "text": "we're actually going to teach it to use our particular function.",
        "start": 207.2,
        "duration": 2.82
    },
    {
        "text": "We're also going to give it the parameters.",
        "start": 210.02,
        "duration": 2.025
    },
    {
        "text": "In this case, I've defined",
        "start": 212.045,
        "duration": 1.845
    },
    {
        "text": "a pretty simple function that just has your one property,",
        "start": 213.89,
        "duration": 4.49
    },
    {
        "text": "it's a query that's a string and we're going to",
        "start": 218.38,
        "duration": 2.65
    },
    {
        "text": "describe that executes the query string to search for recipes.",
        "start": 221.03,
        "duration": 3.615
    },
    {
        "text": "That also define my user message.",
        "start": 224.645,
        "duration": 2.985
    },
    {
        "text": "In this case it's just a simple prompt saying,",
        "start": 227.63,
        "duration": 2.165
    },
    {
        "text": "you help me find a good lasagna recipe.",
        "start": 229.795,
        "duration": 2.405
    },
    {
        "text": "Now what I can do, is I can send",
        "start": 232.2,
        "duration": 3.0
    },
    {
        "text": "both those messages in the functions of the model and the model is",
        "start": 235.2,
        "duration": 4.1
    },
    {
        "text": "actually going to determine if we should make",
        "start": 239.3,
        "duration": 2.25
    },
    {
        "text": "a call to this function or not and if it",
        "start": 241.55,
        "duration": 2.37
    },
    {
        "text": "does determine we should make that",
        "start": 243.92,
        "duration": 1.05
    },
    {
        "text": "call then it's going to actually",
        "start": 244.97,
        "duration": 1.17
    },
    {
        "text": "give us the JSON that it thinks we should use.",
        "start": 246.14,
        "duration": 2.855
    },
    {
        "text": "Here we can see it's actually proposing that we call this query",
        "start": 248.995,
        "duration": 3.835
    },
    {
        "text": "recipes function with the query term lasagna.",
        "start": 252.83,
        "duration": 4.325
    },
    {
        "text": "Actually from there the idea being that you would go",
        "start": 257.155,
        "duration": 3.025
    },
    {
        "text": "and what you do is you take",
        "start": 260.18,
        "duration": 2.64
    },
    {
        "text": "the string converts JSON go in and actually call",
        "start": 262.82,
        "duration": 2.76
    },
    {
        "text": "that function get the results and",
        "start": 265.58,
        "duration": 1.47
    },
    {
        "text": "then send another request to the model.",
        "start": 267.05,
        "duration": 2.195
    },
    {
        "text": ">> The query string has been returned",
        "start": 269.245,
        "duration": 2.065
    },
    {
        "text": "is the query string that's going to be",
        "start": 271.31,
        "duration": 1.29
    },
    {
        "text": "sent to our Azure Cognitive Search, right?",
        "start": 272.6,
        "duration": 3.45
    },
    {
        "text": ">> That's exactly right. In this case",
        "start": 276.05,
        "duration": 2.1
    },
    {
        "text": "now that Azure Cognitive Search has vector search,",
        "start": 278.15,
        "duration": 2.45
    },
    {
        "text": "what we can actually do is you convert",
        "start": 280.6,
        "duration": 2.38
    },
    {
        "text": "this query term embedding and send that embedding as the queries.",
        "start": 282.98,
        "duration": 2.64
    },
    {
        "text": "You can get even more accurate results.",
        "start": 285.62,
        "duration": 3.29
    },
    {
        "text": ">> So it's now helping us figure out what we want to ask",
        "start": 288.91,
        "duration": 3.16
    },
    {
        "text": "our search index to get what we want returned.",
        "start": 292.07,
        "duration": 4.36
    },
    {
        "text": ">> That's exactly right. I've logged into a function calling,",
        "start": 296.57,
        "duration": 4.2
    },
    {
        "text": "like you can define a variety of functions.",
        "start": 300.77,
        "duration": 2.04
    },
    {
        "text": "Here we have just defined that",
        "start": 302.81,
        "duration": 1.38
    },
    {
        "text": "one but we can have a bunch of functions.",
        "start": 304.19,
        "duration": 1.77
    },
    {
        "text": "What the model is really able to do is determine",
        "start": 305.96,
        "duration": 2.03
    },
    {
        "text": "your based off the context of this conversation,",
        "start": 307.99,
        "duration": 2.67
    },
    {
        "text": "if we should call a function and then then how we should call it.",
        "start": 310.66,
        "duration": 3.88
    },
    {
        "text": "You'll be able to do a lot with these capabilities. Go ahead.",
        "start": 314.54,
        "duration": 5.26
    },
    {
        "text": ">> As the developer, do I still decide when it's called though?",
        "start": 319.8,
        "duration": 3.9
    },
    {
        "text": "It's suggesting that I call it,",
        "start": 323.7,
        "duration": 1.56
    },
    {
        "text": "but I still control that the call is made, correct?",
        "start": 325.26,
        "duration": 2.64
    },
    {
        "text": ">> Exactly right. With function calling we're not",
        "start": 327.9,
        "duration": 2.9
    },
    {
        "text": "giving the model actual access to these systems.",
        "start": 330.8,
        "duration": 2.805
    },
    {
        "text": "All the model is ever going to do is generate this query.",
        "start": 333.605,
        "duration": 4.48
    },
    {
        "text": "Then from there you as the developer can take take this.",
        "start": 338.085,
        "duration": 3.725
    },
    {
        "text": "You determine if you actually want to make that call,",
        "start": 341.81,
        "duration": 1.79
    },
    {
        "text": "you validate this response and actually go ahead and make",
        "start": 343.6,
        "duration": 2.17
    },
    {
        "text": "that call and the models behalf and everything.",
        "start": 345.77,
        "duration": 3.11
    },
    {
        "text": ">> Very cool.",
        "start": 348.88,
        "duration": 2.12
    },
    {
        "text": ">> This is a fairly simple example here.",
        "start": 351.0,
        "duration": 3.075
    },
    {
        "text": "Let's imagine for a second that you were building a chat-bot",
        "start": 354.075,
        "duration": 3.065
    },
    {
        "text": "to help you find",
        "start": 357.14,
        "duration": 2.41
    },
    {
        "text": "recipes and help you make something good for dinner.",
        "start": 359.55,
        "duration": 4.15
    },
    {
        "text": "We could also try your another example of,",
        "start": 364.13,
        "duration": 3.925
    },
    {
        "text": "you maybe were looking for",
        "start": 368.055,
        "duration": 1.77
    },
    {
        "text": "your Mexican recipe that has a beans and rice at it.",
        "start": 369.825,
        "duration": 3.405
    },
    {
        "text": "We can try that and we can see now you are",
        "start": 373.23,
        "duration": 2.375
    },
    {
        "text": "able to convert that to a query as well.",
        "start": 375.605,
        "duration": 2.705
    },
    {
        "text": "But as another example if I'm using this",
        "start": 378.31,
        "duration": 2.51
    },
    {
        "text": "this chat bot I might just say something fairly simple like,",
        "start": 380.82,
        "duration": 4.58
    },
    {
        "text": "what should I cook for dinner?",
        "start": 385.4,
        "duration": 2.525
    },
    {
        "text": "In this case, the model",
        "start": 387.925,
        "duration": 3.305
    },
    {
        "text": "does a pretty good job based of the contract giving it,",
        "start": 391.23,
        "duration": 2.42
    },
    {
        "text": "you're trying to query for dinner.",
        "start": 393.65,
        "duration": 1.71
    },
    {
        "text": "But if I have your search index of a recipes,",
        "start": 395.36,
        "duration": 3.635
    },
    {
        "text": "this might not be a particularly useful query.",
        "start": 398.995,
        "duration": 4.66
    },
    {
        "text": "What I can actually do, is do a little bit of",
        "start": 403.655,
        "duration": 1.785
    },
    {
        "text": "additional prompt engineering and actually add",
        "start": 405.44,
        "duration": 1.71
    },
    {
        "text": "a system message to give the model",
        "start": 407.15,
        "duration": 2.01
    },
    {
        "text": "a little bit more context about what I'm trying to really do here.",
        "start": 409.16,
        "duration": 4.425
    },
    {
        "text": "Let me just paste in the system message I prepared ahead of time.",
        "start": 413.585,
        "duration": 5.38
    },
    {
        "text": "Since now I'm just telling the model,",
        "start": 418.965,
        "duration": 2.155
    },
    {
        "text": "hey you're an assistant it's a large language model",
        "start": 421.12,
        "duration": 2.185
    },
    {
        "text": "designed to help users find and create",
        "start": 423.305,
        "duration": 1.545
    },
    {
        "text": "recipes you have access to",
        "start": 424.85,
        "duration": 1.71
    },
    {
        "text": "an Azure Cognitive Search index with hundreds of recipes.",
        "start": 426.56,
        "duration": 2.945
    },
    {
        "text": "Then the other thing is like in the case of this dinner,",
        "start": 429.505,
        "duration": 2.66
    },
    {
        "text": "do I really want it to be interactive?",
        "start": 432.165,
        "duration": 1.455
    },
    {
        "text": "Well, I say, hey help me cook something different dinner.",
        "start": 433.62,
        "duration": 2.88
    },
    {
        "text": "I want to carry on that conversation and help",
        "start": 436.5,
        "duration": 2.59
    },
    {
        "text": "me come up with ideas",
        "start": 439.09,
        "duration": 1.42
    },
    {
        "text": "before it actually goes and issues that query.",
        "start": 440.51,
        "duration": 2.03
    },
    {
        "text": "Now I'm telling you hey you're",
        "start": 442.54,
        "duration": 1.3
    },
    {
        "text": "designed to be an interactive assistant",
        "start": 443.84,
        "duration": 1.71
    },
    {
        "text": "you can ask users clarifying",
        "start": 445.55,
        "duration": 1.5
    },
    {
        "text": "questions help to find the right recipe.",
        "start": 447.05,
        "duration": 1.86
    },
    {
        "text": "Now after I add all of this in,",
        "start": 448.91,
        "duration": 2.085
    },
    {
        "text": "you want to go ahead and send this request,",
        "start": 450.995,
        "duration": 2.795
    },
    {
        "text": "now it's going to determine hey you I'm not ready to",
        "start": 453.79,
        "duration": 2.68
    },
    {
        "text": "call this this function yet I need to get",
        "start": 456.47,
        "duration": 2.55
    },
    {
        "text": "more details from the user and",
        "start": 459.02,
        "duration": 1.68
    },
    {
        "text": "now it responds yes sure I can help you with",
        "start": 460.7,
        "duration": 1.71
    },
    {
        "text": "that you could you please let me know if any",
        "start": 462.41,
        "duration": 1.62
    },
    {
        "text": "specific preferences or dietary restrictions.",
        "start": 464.03,
        "duration": 2.43
    },
    {
        "text": "This is a fairly simple system message,",
        "start": 466.46,
        "duration": 2.13
    },
    {
        "text": "you could always add more details to try to give",
        "start": 468.59,
        "duration": 1.65
    },
    {
        "text": "a little bit more personality and stuff like that.",
        "start": 470.24,
        "duration": 2.365
    },
    {
        "text": "You can see you're pretty much with just a few sentences",
        "start": 472.605,
        "duration": 2.385
    },
    {
        "text": "we're able to completely change the behavior of the model",
        "start": 474.99,
        "duration": 2.53
    },
    {
        "text": ">> I'm thinking to myself and I think you've just",
        "start": 477.52,
        "duration": 2.245
    },
    {
        "text": "automated half the conversations married couples have,",
        "start": 479.765,
        "duration": 3.225
    },
    {
        "text": "what should we have for dinner?",
        "start": 482.99,
        "duration": 1.665
    },
    {
        "text": "So we can just let the OpenAI model help us figure that out and",
        "start": 484.655,
        "duration": 3.765
    },
    {
        "text": "suggest something and now we've saved",
        "start": 488.42,
        "duration": 1.62
    },
    {
        "text": "ourselves a lot of time",
        "start": 490.04,
        "duration": 1.14
    },
    {
        "text": "on trying to figure what we shall have for dinner.",
        "start": 491.18,
        "duration": 1.8
    },
    {
        "text": ">> You have totally. I'd honestly",
        "start": 492.98,
        "duration": 2.34
    },
    {
        "text": "love to use something like this by myself.",
        "start": 495.32,
        "duration": 2.595
    },
    {
        "text": "One thing I find when I'm trying to cook",
        "start": 497.915,
        "duration": 2.595
    },
    {
        "text": "is maybe I have broccoli and tofu or somethings like,",
        "start": 500.51,
        "duration": 5.25
    },
    {
        "text": "I need to find a recipe that has those things.",
        "start": 505.76,
        "duration": 3.005
    },
    {
        "text": "This function we've defined currently as is fairly simple,",
        "start": 508.765,
        "duration": 4.655
    },
    {
        "text": "we're just passing into query.",
        "start": 513.61,
        "duration": 2.11
    },
    {
        "text": "It actually within Azure OpenAI Service",
        "start": 515.72,
        "duration": 2.25
    },
    {
        "text": "we now support Azure OpenAI on your data,",
        "start": 517.97,
        "duration": 2.205
    },
    {
        "text": "which actually makes it really easy to do this retrieval augment",
        "start": 520.175,
        "duration": 2.51
    },
    {
        "text": "generation pretty much like out of the box.",
        "start": 522.685,
        "duration": 3.475
    },
    {
        "text": "What I wanted to show is actually how we can make",
        "start": 526.16,
        "duration": 1.94
    },
    {
        "text": "this function a little bit more sophisticated,",
        "start": 528.1,
        "duration": 1.8
    },
    {
        "text": "actually tailored even more to our use case.",
        "start": 529.9,
        "duration": 3.12
    },
    {
        "text": "I had to find a slightly more complex function",
        "start": 533.02,
        "duration": 4.185
    },
    {
        "text": "that does a little bit more that we",
        "start": 537.205,
        "duration": 2.145
    },
    {
        "text": "might want to do in this use case available.",
        "start": 539.35,
        "duration": 1.97
    },
    {
        "text": "We still have that query string but",
        "start": 541.32,
        "duration": 2.2
    },
    {
        "text": "now I have an ingredients filter where if",
        "start": 543.52,
        "duration": 2.46
    },
    {
        "text": "I list your ingredients like beans and",
        "start": 545.98,
        "duration": 2.84
    },
    {
        "text": "rice in my recipe I want",
        "start": 548.82,
        "duration": 1.63
    },
    {
        "text": "to actually be able to explicitly add a filter.",
        "start": 550.45,
        "duration": 1.725
    },
    {
        "text": "In addition to this, this vector",
        "start": 552.175,
        "duration": 1.485
    },
    {
        "text": "query that we're going to be sending we can",
        "start": 553.66,
        "duration": 1.71
    },
    {
        "text": "also add explicit filters in",
        "start": 555.37,
        "duration": 1.38
    },
    {
        "text": "Azure Cognitive Search to trim down the results.",
        "start": 556.75,
        "duration": 2.27
    },
    {
        "text": "One thing that's interesting here is the Azure search",
        "start": 559.02,
        "duration": 2.83
    },
    {
        "text": "has specific syntax for being able to filter.",
        "start": 561.85,
        "duration": 3.375
    },
    {
        "text": "Actually within this, we need to teach the model how to",
        "start": 565.225,
        "duration": 2.815
    },
    {
        "text": "create appropriate filters for [inaudible] I need to teach it,",
        "start": 568.04,
        "duration": 3.35
    },
    {
        "text": "what are the names of my fields what does that syntax look like?",
        "start": 571.39,
        "duration": 3.615
    },
    {
        "text": "In this case in the ingredients filter,",
        "start": 575.005,
        "duration": 3.415
    },
    {
        "text": "I say this is an OData filter",
        "start": 578.42,
        "duration": 2.82
    },
    {
        "text": "to apply to the the ingredients field.",
        "start": 581.24,
        "duration": 2.415
    },
    {
        "text": "Your only actual ingredient names should be used",
        "start": 583.655,
        "duration": 3.435
    },
    {
        "text": "in this and then we give an example of",
        "start": 587.09,
        "duration": 1.59
    },
    {
        "text": "what this filter should look like.",
        "start": 588.68,
        "duration": 2.495
    },
    {
        "text": "I also have another field like,",
        "start": 591.175,
        "duration": 2.24
    },
    {
        "text": "for me you, long work day,",
        "start": 593.415,
        "duration": 1.505
    },
    {
        "text": "I usually just want something that I",
        "start": 594.92,
        "duration": 1.62
    },
    {
        "text": "can cook in 25 minutes or less.",
        "start": 596.54,
        "duration": 2.01
    },
    {
        "text": "I also added a time filter so that we can",
        "start": 598.55,
        "duration": 3.6
    },
    {
        "text": "filter down based off of the time the recipe would take.",
        "start": 602.15,
        "duration": 3.93
    },
    {
        "text": "It actually dig in any further,",
        "start": 606.08,
        "duration": 1.8
    },
    {
        "text": "that should probably just show what example recipe",
        "start": 607.88,
        "duration": 2.31
    },
    {
        "text": "looks like in a search index you can get a feel for it.",
        "start": 610.19,
        "duration": 3.045
    },
    {
        "text": "We'll have a category recipe name,",
        "start": 613.235,
        "duration": 2.895
    },
    {
        "text": "the full recipe itself,",
        "start": 616.13,
        "duration": 1.47
    },
    {
        "text": "the description that we have,",
        "start": 617.6,
        "duration": 1.35
    },
    {
        "text": "that list of ingredients, and that total time.",
        "start": 618.95,
        "duration": 2.595
    },
    {
        "text": "We're essentially using these two fields",
        "start": 621.545,
        "duration": 2.055
    },
    {
        "text": "now to be able to filter down a little bit further",
        "start": 623.6,
        "duration": 3.185
    },
    {
        "text": ">> Those are the static search things that are going to be",
        "start": 626.785,
        "duration": 2.595
    },
    {
        "text": "sent in along with the vector.",
        "start": 629.38,
        "duration": 2.39
    },
    {
        "text": ">> That's exactly right. Actually in just a second I can show you",
        "start": 631.77,
        "duration": 2.83
    },
    {
        "text": "what the model will will generate for these filters now.",
        "start": 634.6,
        "duration": 3.96
    },
    {
        "text": "I can try that same query I tried before of,",
        "start": 638.56,
        "duration": 4.305
    },
    {
        "text": "you'll find an easy Mexican recipe with with beans and rice.",
        "start": 642.865,
        "duration": 3.27
    },
    {
        "text": "It should hopefully be able to create those filters force.",
        "start": 646.135,
        "duration": 3.255
    },
    {
        "text": "Now we see if the query is Mexican,",
        "start": 649.39,
        "duration": 2.22
    },
    {
        "text": "so we're going to be able to search for all Mexican type food.",
        "start": 651.61,
        "duration": 2.68
    },
    {
        "text": "We have that ingredients filter,",
        "start": 654.29,
        "duration": 2.125
    },
    {
        "text": "so it's going to filter down to",
        "start": 656.415,
        "duration": 2.785
    },
    {
        "text": "only recipes that I get explicitly mentioned beans and rice.",
        "start": 659.2,
        "duration": 3.385
    },
    {
        "text": "We've also added a time filter words,",
        "start": 662.585,
        "duration": 2.93
    },
    {
        "text": "it's going to look for recipes that",
        "start": 665.515,
        "duration": 2.295
    },
    {
        "text": "your total time is less than 30 minutes.",
        "start": 667.81,
        "duration": 2.92
    },
    {
        "text": "With that I did bake in a little bit",
        "start": 670.73,
        "duration": 2.48
    },
    {
        "text": "of a business logic into this here too.",
        "start": 673.21,
        "duration": 2.99
    },
    {
        "text": "I explicitly told the model,",
        "start": 676.2,
        "duration": 1.72
    },
    {
        "text": "if someone's asking for easier quick,",
        "start": 677.92,
        "duration": 1.78
    },
    {
        "text": "let's filter down the recipes that take less than 30 minutes.",
        "start": 679.7,
        "duration": 3.44
    },
    {
        "text": "We can really add a lot of logic into",
        "start": 683.14,
        "duration": 1.63
    },
    {
        "text": "this function call to make the model perform how you want it to.",
        "start": 684.77,
        "duration": 3.215
    },
    {
        "text": ">> Very cool so we're really describing what we",
        "start": 687.985,
        "duration": 3.535
    },
    {
        "text": "want in the JSON calls so that it can make an accurate request?",
        "start": 691.52,
        "duration": 3.93
    },
    {
        "text": ">> Exactly. So you get",
        "start": 695.45,
        "duration": 1.83
    },
    {
        "text": "the full flexibility to define however you want.",
        "start": 697.28,
        "duration": 2.28
    },
    {
        "text": "You can do pump engineering within this function call,",
        "start": 699.56,
        "duration": 3.34
    },
    {
        "text": "within your system message and all that stuff.",
        "start": 702.9,
        "duration": 2.06
    },
    {
        "text": "You can really tailor that behavior so you can find",
        "start": 704.96,
        "duration": 2.73
    },
    {
        "text": "the most relevant results for the user and",
        "start": 707.69,
        "duration": 1.41
    },
    {
        "text": "give them that experience they're looking for",
        "start": 709.1,
        "duration": 2.405
    },
    {
        "text": ">> From a way that you would implement this in an application",
        "start": 711.505,
        "duration": 5.615
    },
    {
        "text": ">> You're setting all this up right",
        "start": 717.45,
        "duration": 2.98
    },
    {
        "text": "now and we're testing and we're iterating through it.",
        "start": 720.43,
        "duration": 2.73
    },
    {
        "text": "If I was going to be putting this in an application feature,",
        "start": 723.16,
        "duration": 3.69
    },
    {
        "text": "would I be sending in this system message and function",
        "start": 726.85,
        "duration": 3.72
    },
    {
        "text": "every time I start a session with the model?",
        "start": 730.57,
        "duration": 4.3
    },
    {
        "text": ">> Great question.",
        "start": 735.14,
        "duration": 2.53
    },
    {
        "text": "Normally when you're using these models with Azure OpenAI,",
        "start": 737.67,
        "duration": 3.15
    },
    {
        "text": "you're going to include the system message",
        "start": 740.82,
        "duration": 1.86
    },
    {
        "text": "in every request and then you'll",
        "start": 742.68,
        "duration": 1.47
    },
    {
        "text": "also keep your running list of the user and assistant messages.",
        "start": 744.15,
        "duration": 4.115
    },
    {
        "text": "Like in this case I've just shown you that first message,",
        "start": 748.265,
        "duration": 2.765
    },
    {
        "text": "we're always just setting that one user message",
        "start": 751.03,
        "duration": 2.37
    },
    {
        "text": "but interestingly what I'll show you towards the end,",
        "start": 753.4,
        "duration": 2.55
    },
    {
        "text": "is we can continue on",
        "start": 755.95,
        "duration": 2.58
    },
    {
        "text": "the conversation and add the previous messages into this array.",
        "start": 758.53,
        "duration": 5.115
    },
    {
        "text": "What I've showed you so far is really just showing you how",
        "start": 763.645,
        "duration": 3.855
    },
    {
        "text": "you get the function call for the model.",
        "start": 767.5,
        "duration": 6.24
    },
    {
        "text": "But I think what I'd love to show you next",
        "start": 773.74,
        "duration": 1.8
    },
    {
        "text": "is how we can actually go and string all of",
        "start": 775.54,
        "duration": 2.79
    },
    {
        "text": "this logic together and",
        "start": 778.33,
        "duration": 1.02
    },
    {
        "text": "actually then be able to retrieve the recipes",
        "start": 779.35,
        "duration": 2.1
    },
    {
        "text": "from the search index and then you'll get those results.",
        "start": 781.45,
        "duration": 4.18
    },
    {
        "text": "I've defined this function called generate embeddings.",
        "start": 785.81,
        "duration": 3.67
    },
    {
        "text": "This is a fairly simple function you are just going to pass in",
        "start": 789.48,
        "duration": 2.19
    },
    {
        "text": "a string and then we'll get",
        "start": 791.67,
        "duration": 1.38
    },
    {
        "text": "the embedding back. We're going to use that.",
        "start": 793.05,
        "duration": 2.52
    },
    {
        "text": "Every time we send a query to the search index,",
        "start": 795.57,
        "duration": 1.845
    },
    {
        "text": "we'll first use Azure OpenAI I service to get that embedding.",
        "start": 797.415,
        "duration": 2.415
    },
    {
        "text": "They were able to do that vector search in Azure Cognitive Search.",
        "start": 799.83,
        "duration": 3.4
    },
    {
        "text": "Then I've also defined",
        "start": 803.23,
        "duration": 1.965
    },
    {
        "text": "your fairly simple function for recalling Azure Cognitive Search.",
        "start": 805.195,
        "duration": 3.405
    },
    {
        "text": "I'll pass in that query then it'll pass in my filter.",
        "start": 808.6,
        "duration": 3.18
    },
    {
        "text": "I have a little bit of logic here just to",
        "start": 811.78,
        "duration": 1.62
    },
    {
        "text": "join the filters together properly.",
        "start": 813.4,
        "duration": 2.385
    },
    {
        "text": "Then now I'm using all the bells",
        "start": 815.785,
        "duration": 2.145
    },
    {
        "text": "and whistles and Azure Cognitive Search.",
        "start": 817.93,
        "duration": 2.145
    },
    {
        "text": "I'm using vector search here.",
        "start": 820.075,
        "duration": 2.01
    },
    {
        "text": "Like you were mentioning early, I'm also using",
        "start": 822.085,
        "duration": 1.515
    },
    {
        "text": "hybrid search because you're sending in that,",
        "start": 823.6,
        "duration": 3.0
    },
    {
        "text": "the rostering, like in this case the string was Mexican.",
        "start": 826.6,
        "duration": 3.48
    },
    {
        "text": "And that way you get your keyword results and these magic results.",
        "start": 830.08,
        "duration": 4.875
    },
    {
        "text": "I think the one example I love to give there is,",
        "start": 834.955,
        "duration": 2.25
    },
    {
        "text": "if you search like ice cream,",
        "start": 837.205,
        "duration": 1.815
    },
    {
        "text": "Vector Search is really good because it's going",
        "start": 839.02,
        "duration": 1.59
    },
    {
        "text": "to to get you results on like ice cream,",
        "start": 840.61,
        "duration": 1.77
    },
    {
        "text": "frozen yogurt, gelato.",
        "start": 842.38,
        "duration": 1.665
    },
    {
        "text": "But if you only got results on frozen yogurt and gelato,",
        "start": 844.045,
        "duration": 3.315
    },
    {
        "text": "you'd probably be a little bit upset.",
        "start": 847.36,
        "duration": 1.35
    },
    {
        "text": "You want to see some ice cream results because I",
        "start": 848.71,
        "duration": 1.47
    },
    {
        "text": "think Hybrid is really good because it takes",
        "start": 850.18,
        "duration": 1.89
    },
    {
        "text": "advantage of those keywords as well.",
        "start": 852.07,
        "duration": 3.735
    },
    {
        "text": "We're also leveraging semantic search,",
        "start": 855.805,
        "duration": 2.205
    },
    {
        "text": "Janelle, we haven't talked about in this video.",
        "start": 858.01,
        "duration": 1.665
    },
    {
        "text": "We're leveraging all the bells and",
        "start": 859.675,
        "duration": 1.455
    },
    {
        "text": "whistles of Azure Cognitive Search here.",
        "start": 861.13,
        "duration": 3.31
    },
    {
        "text": "Azure Cognitive Search is going to return a bunch of JSON.",
        "start": 868.8,
        "duration": 3.355
    },
    {
        "text": "What I really want to do is I want to take the text",
        "start": 872.155,
        "duration": 2.49
    },
    {
        "text": "Azure Cognitive Search and put it into",
        "start": 874.645,
        "duration": 1.455
    },
    {
        "text": "format where the models can understand it well.",
        "start": 876.1,
        "duration": 2.22
    },
    {
        "text": "I'm looping through the results",
        "start": 878.32,
        "duration": 2.0
    },
    {
        "text": "here and then I'm going to print out the recipe ID,",
        "start": 880.32,
        "duration": 2.7
    },
    {
        "text": "the recipe name, and the description of that recipe,",
        "start": 883.02,
        "duration": 3.255
    },
    {
        "text": "and that's what we're going to get back to the model.",
        "start": 886.275,
        "duration": 1.905
    },
    {
        "text": "You can use that to inform it's response to the user.",
        "start": 888.18,
        "duration": 3.26
    },
    {
        "text": ">> We're at so far is that you have told",
        "start": 891.44,
        "duration": 4.37
    },
    {
        "text": "the OpenAI model what you want it to assist with.",
        "start": 895.81,
        "duration": 5.445
    },
    {
        "text": "It's giving us JSON result with",
        "start": 901.255,
        "duration": 2.415
    },
    {
        "text": "suggestions based on a prompt that we sent in.",
        "start": 903.67,
        "duration": 2.76
    },
    {
        "text": "Then from there,",
        "start": 906.43,
        "duration": 1.455
    },
    {
        "text": "we're passing that out and now we're going to",
        "start": 907.885,
        "duration": 1.815
    },
    {
        "text": "query Cognitive Search to get",
        "start": 909.7,
        "duration": 2.01
    },
    {
        "text": "back from our index recipes that would fit that. Correct?",
        "start": 911.71,
        "duration": 4.845
    },
    {
        "text": ">> That's exactly right.",
        "start": 916.555,
        "duration": 1.35
    },
    {
        "text": ">> Then are you going to take that and feed that back into",
        "start": 917.905,
        "duration": 2.265
    },
    {
        "text": "the OpenAI model or is that just going to",
        "start": 920.17,
        "duration": 1.92
    },
    {
        "text": "be displayed to the user or what's next?",
        "start": 922.09,
        "duration": 2.28
    },
    {
        "text": ">> That's exactly right. Actually, right below this",
        "start": 924.37,
        "duration": 2.22
    },
    {
        "text": "I have the logic all stitched together.",
        "start": 926.59,
        "duration": 3.01
    },
    {
        "text": "I've defined the function in the prompts.",
        "start": 930.24,
        "duration": 3.64
    },
    {
        "text": "I need to actually define the function we want to",
        "start": 933.88,
        "duration": 1.8
    },
    {
        "text": "call when that gets so that we define",
        "start": 935.68,
        "duration": 2.16
    },
    {
        "text": "that function we call Azure Cognitive Search",
        "start": 937.84,
        "duration": 2.07
    },
    {
        "text": "is now what you do is you need to stitch all this logic together.",
        "start": 939.91,
        "duration": 3.105
    },
    {
        "text": "I wrote this run conversation function.",
        "start": 943.015,
        "duration": 3.285
    },
    {
        "text": "We'll start and we'll send that call,",
        "start": 946.3,
        "duration": 2.37
    },
    {
        "text": "that initial call of the model like we were doing up above.",
        "start": 948.67,
        "duration": 2.385
    },
    {
        "text": "Then at this point, we're going to check if the model tells",
        "start": 951.055,
        "duration": 2.445
    },
    {
        "text": "us to call a function or not.",
        "start": 953.5,
        "duration": 2.685
    },
    {
        "text": "Then if it does tell us we need to call a function,",
        "start": 956.185,
        "duration": 3.99
    },
    {
        "text": "then we're going to get the function name,",
        "start": 960.175,
        "duration": 3.51
    },
    {
        "text": "make sure that's a function that we actually are able to call.",
        "start": 963.685,
        "duration": 3.045
    },
    {
        "text": "Then we'll go ahead and actually",
        "start": 966.73,
        "duration": 2.22
    },
    {
        "text": "call that function and pass in the arguments.",
        "start": 968.95,
        "duration": 3.42
    },
    {
        "text": "Just for demo purpose, when we run this,",
        "start": 972.37,
        "duration": 1.95
    },
    {
        "text": "I'll print out the function call.",
        "start": 974.32,
        "duration": 1.92
    },
    {
        "text": "But then once we get the results",
        "start": 976.24,
        "duration": 1.5
    },
    {
        "text": "from the function call and everything,",
        "start": 977.74,
        "duration": 1.665
    },
    {
        "text": "what we'll do is we're going to",
        "start": 979.405,
        "duration": 1.365
    },
    {
        "text": "append that back into this array of",
        "start": 980.77,
        "duration": 1.89
    },
    {
        "text": "messages that we have and then make another request to the model.",
        "start": 982.66,
        "duration": 3.96
    },
    {
        "text": "Then that's how we're going to get",
        "start": 986.62,
        "duration": 1.77
    },
    {
        "text": "this final response from the model.",
        "start": 988.39,
        "duration": 2.265
    },
    {
        "text": "Now that we've defined the function",
        "start": 990.655,
        "duration": 1.725
    },
    {
        "text": "to call Azure Cognitive Search and",
        "start": 992.38,
        "duration": 1.44
    },
    {
        "text": "this run conversation function to go through that process,",
        "start": 993.82,
        "duration": 3.12
    },
    {
        "text": "what we could do is you have defined",
        "start": 996.94,
        "duration": 1.23
    },
    {
        "text": "the system message again and now we have a new query,",
        "start": 998.17,
        "duration": 2.355
    },
    {
        "text": "I want to make a pasta dish that takes",
        "start": 1000.525,
        "duration": 1.575
    },
    {
        "text": "less than 60 minutes to make.",
        "start": 1002.1,
        "duration": 2.215
    },
    {
        "text": "Let's go ahead and run this.",
        "start": 1004.315,
        "duration": 1.915
    },
    {
        "text": "We can see the end-to-end flow here.",
        "start": 1006.23,
        "duration": 3.09
    },
    {
        "text": "We can see, if we've got the function call like we",
        "start": 1009.32,
        "duration": 2.34
    },
    {
        "text": "hope it's querying,",
        "start": 1011.66,
        "duration": 1.83
    },
    {
        "text": "it wants to query for pasta and filter",
        "start": 1013.49,
        "duration": 1.53
    },
    {
        "text": "down the recipes that take less than 60 minutes,",
        "start": 1015.02,
        "duration": 1.89
    },
    {
        "text": "that looks perfect to me.",
        "start": 1016.91,
        "duration": 2.005
    },
    {
        "text": "Then we can see the results that we",
        "start": 1018.915,
        "duration": 1.575
    },
    {
        "text": "got from Azure Cognitive Search.",
        "start": 1020.49,
        "duration": 2.07
    },
    {
        "text": "We had pesto pasta and some other recipes.",
        "start": 1022.56,
        "duration": 3.93
    },
    {
        "text": "Now at this point what we needed to do is",
        "start": 1026.49,
        "duration": 2.16
    },
    {
        "text": "then take this function",
        "start": 1028.65,
        "duration": 1.92
    },
    {
        "text": "called take the operand function call and use that",
        "start": 1030.57,
        "duration": 2.16
    },
    {
        "text": "to send another request to the model.You",
        "start": 1032.73,
        "duration": 1.62
    },
    {
        "text": "can see now we're about to send",
        "start": 1034.35,
        "duration": 1.65
    },
    {
        "text": "another request and you can",
        "start": 1036.0,
        "duration": 1.55
    },
    {
        "text": "see all the details that we now have in the prompt.",
        "start": 1037.55,
        "duration": 2.415
    },
    {
        "text": "Then when we send this we're going to get",
        "start": 1039.965,
        "duration": 1.335
    },
    {
        "text": "this final response from the model,",
        "start": 1041.3,
        "duration": 1.56
    },
    {
        "text": "we're just going to take this data we give it",
        "start": 1042.86,
        "duration": 2.13
    },
    {
        "text": "and really give to us a nice natural language way.",
        "start": 1044.99,
        "duration": 3.105
    },
    {
        "text": "Here are a few pasta dishes that",
        "start": 1048.095,
        "duration": 1.515
    },
    {
        "text": "takes less than 60 minutes to make.",
        "start": 1049.61,
        "duration": 1.445
    },
    {
        "text": "Gives us those options and everything.",
        "start": 1051.055,
        "duration": 2.66
    },
    {
        "text": "Now that we have the basics working here,",
        "start": 1053.715,
        "duration": 2.115
    },
    {
        "text": "we can actually take it a little bit further.",
        "start": 1055.83,
        "duration": 1.395
    },
    {
        "text": "One thing you might notice is,",
        "start": 1057.225,
        "duration": 1.425
    },
    {
        "text": "it's not actually telling us how to cook these recipes yet,",
        "start": 1058.65,
        "duration": 3.525
    },
    {
        "text": "and if you add UI I'm sure you could just make",
        "start": 1062.175,
        "duration": 2.085
    },
    {
        "text": "these hyperlinks to handle that in the application layer.",
        "start": 1064.26,
        "duration": 3.3
    },
    {
        "text": "But I figured like we might as well show how we",
        "start": 1067.56,
        "duration": 1.83
    },
    {
        "text": "can let the model be able to do this as well.",
        "start": 1069.39,
        "duration": 3.0
    },
    {
        "text": "We had this one additional query recipes function",
        "start": 1072.39,
        "duration": 3.39
    },
    {
        "text": "and actually one thing to call out,",
        "start": 1075.78,
        "duration": 1.755
    },
    {
        "text": "in my testing but I found out",
        "start": 1077.535,
        "duration": 2.055
    },
    {
        "text": "the ingredients filter was actually a little bit too rigid.",
        "start": 1079.59,
        "duration": 2.58
    },
    {
        "text": "Like if we filter down to beans and rice,",
        "start": 1082.17,
        "duration": 2.685
    },
    {
        "text": "a lot of times it might say brown rice or",
        "start": 1084.855,
        "duration": 3.885
    },
    {
        "text": "white rice and then",
        "start": 1088.74,
        "duration": 1.32
    },
    {
        "text": "my filters are a little bit too explicit for that.",
        "start": 1090.06,
        "duration": 2.34
    },
    {
        "text": "That's actually where vector search is",
        "start": 1092.4,
        "duration": 1.68
    },
    {
        "text": "super useful where it's going to be able to",
        "start": 1094.08,
        "duration": 1.71
    },
    {
        "text": "do that semantic similarity and be able to find some.",
        "start": 1095.79,
        "duration": 4.38
    },
    {
        "text": "I've actually taken out that ingredients filter for",
        "start": 1100.17,
        "duration": 2.31
    },
    {
        "text": "now and we're just going to",
        "start": 1102.48,
        "duration": 1.11
    },
    {
        "text": "leverage this time filter because that one did,",
        "start": 1103.59,
        "duration": 1.59
    },
    {
        "text": "it worked really worked for my scenario.",
        "start": 1105.18,
        "duration": 2.31
    },
    {
        "text": "Then I've defined a couple more functions as well.",
        "start": 1107.49,
        "duration": 2.685
    },
    {
        "text": "One is a fairly simple function to go ahead and get the recipe.",
        "start": 1110.175,
        "duration": 4.89
    },
    {
        "text": "Is essentially we're going to take the recipe ID which",
        "start": 1115.065,
        "duration": 2.91
    },
    {
        "text": "you gave to the model in the previous function call,",
        "start": 1117.975,
        "duration": 3.255
    },
    {
        "text": "and the model can use that to go and look up",
        "start": 1121.23,
        "duration": 2.01
    },
    {
        "text": "for a recipe There's another one,",
        "start": 1123.24,
        "duration": 1.89
    },
    {
        "text": "I don't know about you but I don't get to spend",
        "start": 1125.13,
        "duration": 2.01
    },
    {
        "text": "quite enough time cooking so I'm not really good at",
        "start": 1127.14,
        "duration": 2.475
    },
    {
        "text": "recipe measurement conversions so",
        "start": 1129.615,
        "duration": 2.565
    },
    {
        "text": "I thought it'd be nice just to have a function",
        "start": 1132.18,
        "duration": 2.19
    },
    {
        "text": "to give some new capabilities to",
        "start": 1134.37,
        "duration": 2.28
    },
    {
        "text": "the model where it's going to be able to convert",
        "start": 1136.65,
        "duration": 1.32
    },
    {
        "text": "these different measurements and everything.",
        "start": 1137.97,
        "duration": 1.605
    },
    {
        "text": "If you need, you don't have any clean teaspoons around,",
        "start": 1139.575,
        "duration": 2.685
    },
    {
        "text": "you figure out what the appropriate number of",
        "start": 1142.26,
        "duration": 1.38
    },
    {
        "text": "tablespoons is, stuff like that.",
        "start": 1143.64,
        "duration": 2.55
    },
    {
        "text": "This is another fairly simple function",
        "start": 1146.19,
        "duration": 2.445
    },
    {
        "text": "where we're going to pass in",
        "start": 1148.635,
        "duration": 1.365
    },
    {
        "text": "the amount and the original unit",
        "start": 1150.0,
        "duration": 2.175
    },
    {
        "text": "and the unit we want to convert it to.",
        "start": 1152.175,
        "duration": 3.105
    },
    {
        "text": "Same thing, you have to find these functions in code as well.",
        "start": 1155.28,
        "duration": 3.21
    },
    {
        "text": "Actually co-pilot chat helped",
        "start": 1158.49,
        "duration": 1.83
    },
    {
        "text": "me create this one which was super nice,",
        "start": 1160.32,
        "duration": 2.625
    },
    {
        "text": "and then we have this this get recipe function.",
        "start": 1162.945,
        "duration": 3.36
    },
    {
        "text": "We pass an ID we can see that we're able",
        "start": 1166.305,
        "duration": 2.835
    },
    {
        "text": "to get that full recipe back.",
        "start": 1169.14,
        "duration": 3.96
    },
    {
        "text": "Now we can try this one more time.",
        "start": 1173.1,
        "duration": 2.445
    },
    {
        "text": "You test out these new functions.",
        "start": 1175.545,
        "duration": 1.53
    },
    {
        "text": "If I say you get details of recipe 124,",
        "start": 1177.075,
        "duration": 2.7
    },
    {
        "text": "obviously user wouldn't quite do that",
        "start": 1179.775,
        "duration": 1.575
    },
    {
        "text": "but just to show functions working.",
        "start": 1181.35,
        "duration": 1.38
    },
    {
        "text": "We can see it's able to do that.",
        "start": 1182.73,
        "duration": 2.865
    },
    {
        "text": "Or if I were to ask it to",
        "start": 1185.595,
        "duration": 3.495
    },
    {
        "text": "convert how many cups is two tablespoons of butter,",
        "start": 1189.09,
        "duration": 5.37
    },
    {
        "text": "here we can see that it's able to generate",
        "start": 1194.46,
        "duration": 1.8
    },
    {
        "text": "that correct function call for us as well.",
        "start": 1196.26,
        "duration": 3.585
    },
    {
        "text": "At this point we've gone through",
        "start": 1199.845,
        "duration": 2.565
    },
    {
        "text": "the whole development process of getting this all wired up.",
        "start": 1202.41,
        "duration": 3.675
    },
    {
        "text": "Do you want to see the thing running end-to-end,",
        "start": 1206.085,
        "duration": 2.445
    },
    {
        "text": "see if we can help you find dinner recipe for us?",
        "start": 1208.53,
        "duration": 3.36
    },
    {
        "text": ">> Yes, absolutely.",
        "start": 1211.89,
        "duration": 1.545
    },
    {
        "text": ">> Great. I've stitched all this logic.",
        "start": 1213.435,
        "duration": 2.52
    },
    {
        "text": "I've copied and paste all this logic over into",
        "start": 1215.955,
        "duration": 2.265
    },
    {
        "text": "this run recipe chat function.",
        "start": 1218.22,
        "duration": 2.76
    },
    {
        "text": "Just go ahead and run that.",
        "start": 1220.98,
        "duration": 2.73
    },
    {
        "text": "Now we'll be able to give it",
        "start": 1223.71,
        "duration": 1.395
    },
    {
        "text": "a few messages and have that true conversation.",
        "start": 1225.105,
        "duration": 3.435
    },
    {
        "text": "Let's start with something simple.",
        "start": 1228.54,
        "duration": 1.62
    },
    {
        "text": "You'll help me find something good for dinner.",
        "start": 1230.16,
        "duration": 4.425
    },
    {
        "text": "At this point where we can add that it should be prompting",
        "start": 1234.585,
        "duration": 2.085
    },
    {
        "text": "us to come up with some ideas.",
        "start": 1236.67,
        "duration": 2.1
    },
    {
        "text": "Now it's asking do you have any cuisine or ingredients in mind?",
        "start": 1238.77,
        "duration": 4.51
    },
    {
        "text": "How about some Thai food that I can cook in less than an hour.",
        "start": 1244.07,
        "duration": 7.94
    },
    {
        "text": "You can see that you've gone ahead and printed out,",
        "start": 1252.74,
        "duration": 3.115
    },
    {
        "text": "so it's searching for Thai and total time is less than 60 minutes.",
        "start": 1255.855,
        "duration": 4.68
    },
    {
        "text": "Then we can see the recipes that they came up with.",
        "start": 1260.535,
        "duration": 2.625
    },
    {
        "text": "So it's proposing your Thai peanut noodles,",
        "start": 1263.16,
        "duration": 2.19
    },
    {
        "text": "Thai cashew tofu stir fry and so on.",
        "start": 1265.35,
        "duration": 3.645
    },
    {
        "text": "Then we can see the response from the model.",
        "start": 1268.995,
        "duration": 3.015
    },
    {
        "text": "Maybe read through this,",
        "start": 1272.01,
        "duration": 1.26
    },
    {
        "text": "the Thai peanut noodles sounds pretty good.",
        "start": 1273.27,
        "duration": 3.09
    },
    {
        "text": "Now we can say show me the recipe for",
        "start": 1276.36,
        "duration": 3.885
    },
    {
        "text": "Thai peanut noodles and",
        "start": 1280.245,
        "duration": 4.215
    },
    {
        "text": "we can see now it prints out that full recipe for us.",
        "start": 1284.46,
        "duration": 3.15
    },
    {
        "text": "We get the name, description,",
        "start": 1287.61,
        "duration": 1.89
    },
    {
        "text": "details like the prep time and everything and",
        "start": 1289.5,
        "duration": 2.04
    },
    {
        "text": "the ingredients and then those instruction.",
        "start": 1291.54,
        "duration": 2.46
    },
    {
        "text": "You see it's printing twice,",
        "start": 1294.0,
        "duration": 1.065
    },
    {
        "text": "just one is the function output,",
        "start": 1295.065,
        "duration": 1.755
    },
    {
        "text": "the other one is the actual response to the model.",
        "start": 1296.82,
        "duration": 3.645
    },
    {
        "text": "But let's say now it was asking for rice noodles.",
        "start": 1300.465,
        "duration": 3.135
    },
    {
        "text": "I don't have any rice noodles on hand.",
        "start": 1303.6,
        "duration": 1.725
    },
    {
        "text": "One nice thing is in addition to using",
        "start": 1305.325,
        "duration": 1.695
    },
    {
        "text": "these functions would be able to query",
        "start": 1307.02,
        "duration": 1.14
    },
    {
        "text": "Azure Cognitive Search data,",
        "start": 1308.16,
        "duration": 1.35
    },
    {
        "text": "we can still leverage all the knowledge from the model to help us.",
        "start": 1309.51,
        "duration": 2.865
    },
    {
        "text": "You have this really useful system.",
        "start": 1312.375,
        "duration": 1.74
    },
    {
        "text": "Maybe I say,",
        "start": 1314.115,
        "duration": 1.905
    },
    {
        "text": "are there any good alternatives to rice noodles.",
        "start": 1316.02,
        "duration": 6.81
    },
    {
        "text": "Now it shouldn't be calling your function or anything,",
        "start": 1322.83,
        "duration": 2.82
    },
    {
        "text": "it's just going to actually leverage the knowledge of",
        "start": 1325.65,
        "duration": 1.86
    },
    {
        "text": "the model itself and give",
        "start": 1327.51,
        "duration": 2.28
    },
    {
        "text": "us some ideas of what we could do.",
        "start": 1329.79,
        "duration": 4.26
    },
    {
        "text": "Soba noodles or udon noodles or zucchini noodles,",
        "start": 1334.05,
        "duration": 2.505
    },
    {
        "text": "so we were able to combine both.",
        "start": 1336.555,
        "duration": 1.605
    },
    {
        "text": "What's in our search index we've had a group",
        "start": 1338.16,
        "duration": 1.8
    },
    {
        "text": "there but also you combine the power of the model.",
        "start": 1339.96,
        "duration": 2.55
    },
    {
        "text": "But really, you create",
        "start": 1342.51,
        "duration": 1.23
    },
    {
        "text": "a nice interactive chatbot",
        "start": 1343.74,
        "duration": 1.89
    },
    {
        "text": "to help us find exactly what we're looking for.",
        "start": 1345.63,
        "duration": 2.355
    },
    {
        "text": ">> We went over a really cool example of how you",
        "start": 1347.985,
        "duration": 2.925
    },
    {
        "text": "can leverage Azure OpenAI Service and",
        "start": 1350.91,
        "duration": 2.58
    },
    {
        "text": "Azure Cognitive Search to create",
        "start": 1353.49,
        "duration": 2.055
    },
    {
        "text": "a recipe assistant with",
        "start": 1355.545,
        "duration": 1.755
    },
    {
        "text": "really not that much code, super cool to do.",
        "start": 1357.3,
        "duration": 2.28
    },
    {
        "text": "Where can people go recreate this and learn more?",
        "start": 1359.58,
        "duration": 3.12
    },
    {
        "text": ">> So first I recommend you can go check out",
        "start": 1362.7,
        "duration": 2.16
    },
    {
        "text": "that blog and documentation on Vector Search and",
        "start": 1364.86,
        "duration": 2.19
    },
    {
        "text": "Azure Cognitive Search to learn",
        "start": 1367.05,
        "duration": 1.74
    },
    {
        "text": "more about how to get up and running with that.",
        "start": 1368.79,
        "duration": 2.76
    },
    {
        "text": "In addition to that, you can check out the documentation on",
        "start": 1371.55,
        "duration": 2.565
    },
    {
        "text": "function calling in Azure OpenAI and within",
        "start": 1374.115,
        "duration": 2.565
    },
    {
        "text": "that documentation will link out some sample code that will",
        "start": 1376.68,
        "duration": 2.13
    },
    {
        "text": "show you a similar end-to-end patterns of how you can",
        "start": 1378.81,
        "duration": 2.64
    },
    {
        "text": "define some functions and get things running end-to-end to be able",
        "start": 1381.45,
        "duration": 2.91
    },
    {
        "text": "to really build out that experience you're looking for.",
        "start": 1384.36,
        "duration": 3.0
    },
    {
        "text": ">> That's great. So this is all stuff they can go do right now?",
        "start": 1387.36,
        "duration": 3.24
    },
    {
        "text": ">> Exactly. All of this is publicly available;",
        "start": 1390.6,
        "duration": 2.37
    },
    {
        "text": "both Vector Search and Azure Cognitive Search and",
        "start": 1392.97,
        "duration": 2.4
    },
    {
        "text": "function calling in Azure OpenAI are in public previously.",
        "start": 1395.37,
        "duration": 3.075
    },
    {
        "text": "You can go ahead and start playing and",
        "start": 1398.445,
        "duration": 1.875
    },
    {
        "text": "we're super excited to see what our customers build.",
        "start": 1400.32,
        "duration": 2.31
    },
    {
        "text": ">> That's great. Thank you so much for hanging out with",
        "start": 1402.63,
        "duration": 2.22
    },
    {
        "text": "us today and showing us these unique features.",
        "start": 1404.85,
        "duration": 2.37
    },
    {
        "text": ">> Thanks for having me on the show.",
        "start": 1407.22,
        "duration": 2.35
    }
]