[
    {
        "text": ">> You're not going want to miss this episode",
        "start": 0.0,
        "duration": 1.62
    },
    {
        "text": "of The AI Show where Alon Bochman",
        "start": 1.62,
        "duration": 1.83
    },
    {
        "text": "talks all about PyTorch Enterprise on Microsoft Azure.",
        "start": 3.45,
        "duration": 4.215
    },
    {
        "text": "Make sure you tune in.",
        "start": 7.665,
        "duration": 1.305
    },
    {
        "text": "[MUSIC]",
        "start": 8.97,
        "duration": 7.5
    },
    {
        "text": ">> Hello. Welcome to this episode of the AI Show,",
        "start": 16.47,
        "duration": 2.07
    },
    {
        "text": "where we're talking about PyTorch Enterprise on Microsoft Azure.",
        "start": 18.54,
        "duration": 5.4
    },
    {
        "text": "We're excited to have here Alon Bochman.",
        "start": 23.94,
        "duration": 1.56
    },
    {
        "text": "Tell us a little bit about yourself, Alon.",
        "start": 25.5,
        "duration": 1.81
    },
    {
        "text": ">> Hi Seth. It's great to be here.",
        "start": 27.31,
        "duration": 2.63
    },
    {
        "text": "My name is Alon Bochman.",
        "start": 29.94,
        "duration": 1.62
    },
    {
        "text": "I am new at Microsoft,",
        "start": 31.56,
        "duration": 1.589
    },
    {
        "text": "as of January this year.",
        "start": 33.149,
        "duration": 2.816
    },
    {
        "text": "I spent my career in software and financial services,",
        "start": 35.965,
        "duration": 5.74
    },
    {
        "text": "used to be a hedge fund manager as well.",
        "start": 41.705,
        "duration": 3.94
    },
    {
        "text": "One of my earliest partners in",
        "start": 45.645,
        "duration": 2.195
    },
    {
        "text": "business came from Microsoft Consulting,",
        "start": 47.84,
        "duration": 1.71
    },
    {
        "text": "and so really thrilled to be",
        "start": 49.55,
        "duration": 1.95
    },
    {
        "text": "here at the company and here on your show.",
        "start": 51.5,
        "duration": 2.39
    },
    {
        "text": ">> Fantastic. Let's start first with PyTorch.",
        "start": 53.89,
        "duration": 3.579
    },
    {
        "text": "For those that don't know what PyTorch is,",
        "start": 57.469,
        "duration": 2.071
    },
    {
        "text": "can you give us a little bit of a recap,",
        "start": 59.54,
        "duration": 2.31
    },
    {
        "text": "elevator pitch so to speak?",
        "start": 61.85,
        "duration": 1.325
    },
    {
        "text": ">> Sure. PyTorch is a deep learning framework.",
        "start": 63.175,
        "duration": 3.35
    },
    {
        "text": "You've probably heard about deep learning,",
        "start": 66.525,
        "duration": 3.18
    },
    {
        "text": "as have your viewers.",
        "start": 69.705,
        "duration": 3.45
    },
    {
        "text": "Deep learning is a really exciting technology where you",
        "start": 73.155,
        "duration": 4.435
    },
    {
        "text": "can create some magic moments for users.",
        "start": 77.59,
        "duration": 4.38
    },
    {
        "text": "Learning from images, texts,",
        "start": 81.97,
        "duration": 2.58
    },
    {
        "text": "and audio, all sorts of data.",
        "start": 84.55,
        "duration": 2.0
    },
    {
        "text": "It's really a foundational technology for artificial intelligence.",
        "start": 86.55,
        "duration": 4.014
    },
    {
        "text": "A lot of people use them interchangeably.",
        "start": 90.564,
        "duration": 3.16
    },
    {
        "text": ">> Microsoft is doing a lot with PyTorch for a while,",
        "start": 93.724,
        "duration": 4.536
    },
    {
        "text": "can you describe some of those efforts currently?",
        "start": 98.26,
        "duration": 2.2
    },
    {
        "text": ">> Absolutely. It's been a really exciting space to be in, Seth.",
        "start": 100.46,
        "duration": 5.975
    },
    {
        "text": "We've been working with PyTorch and we've we've",
        "start": 106.435,
        "duration": 4.665
    },
    {
        "text": "delivered a couple of tools to help the PyTorch community.",
        "start": 111.1,
        "duration": 6.505
    },
    {
        "text": "One of them is delivering PyTorch on Windows.",
        "start": 117.605,
        "duration": 3.475
    },
    {
        "text": "Used to be just on Linux,",
        "start": 121.08,
        "duration": 1.41
    },
    {
        "text": "now it's available on Windows.",
        "start": 122.49,
        "duration": 1.595
    },
    {
        "text": "One of them is called PyTorch Profiler,",
        "start": 124.085,
        "duration": 2.955
    },
    {
        "text": "which we're super-excited about,",
        "start": 127.04,
        "duration": 1.5
    },
    {
        "text": "that just got released a couple of months ago.",
        "start": 128.54,
        "duration": 2.7
    },
    {
        "text": "It lets you step through code and figure out some inefficiencies",
        "start": 131.24,
        "duration": 4.47
    },
    {
        "text": "and squeeze out some extra performance from your hardware.",
        "start": 135.71,
        "duration": 5.59
    },
    {
        "text": "Lastly, we have a special program to announce.",
        "start": 142.0,
        "duration": 5.56
    },
    {
        "text": ">> That's cool. For those who don't know,",
        "start": 147.56,
        "duration": 2.685
    },
    {
        "text": "in my group we've also written some of the documentation",
        "start": 150.245,
        "duration": 2.88
    },
    {
        "text": "that you'll find on PyTorch.org for something called,",
        "start": 153.125,
        "duration": 3.065
    },
    {
        "text": "Learn the Basics, and we're coming out with something called",
        "start": 156.19,
        "duration": 2.8
    },
    {
        "text": "PyTorch Fundamentals Learning Path",
        "start": 158.99,
        "duration": 1.875
    },
    {
        "text": "on Microsoft Learn, which is pretty cool.",
        "start": 160.865,
        "duration": 2.445
    },
    {
        "text": "Now let's dive into the actual topic,",
        "start": 163.31,
        "duration": 2.64
    },
    {
        "text": "which is PyTorch Enterprise on Microsoft Azure.",
        "start": 165.95,
        "duration": 3.63
    },
    {
        "text": "Did we create a secret fork of PyTorch?",
        "start": 169.58,
        "duration": 3.72
    },
    {
        "text": "Is this what this is? Tell us what this is?",
        "start": 173.3,
        "duration": 1.755
    },
    {
        "text": ">> No secret fork, Seth.",
        "start": 175.055,
        "duration": 2.25
    },
    {
        "text": "PyTorch Enterprise is PyTorch.",
        "start": 177.305,
        "duration": 3.27
    },
    {
        "text": "It's the open source version of PyTorch.",
        "start": 180.575,
        "duration": 2.445
    },
    {
        "text": "But what we've done is,",
        "start": 183.02,
        "duration": 1.35
    },
    {
        "text": "we've structured a program around it",
        "start": 184.37,
        "duration": 2.01
    },
    {
        "text": "to support enterprise users and",
        "start": 186.38,
        "duration": 3.285
    },
    {
        "text": "make it even easier to go into",
        "start": 189.665,
        "duration": 2.655
    },
    {
        "text": "production at scale with PyTorch workloads.",
        "start": 192.32,
        "duration": 4.0
    },
    {
        "text": "It's been a brainchild of Microsoft and PyTorch.",
        "start": 196.63,
        "duration": 4.81
    },
    {
        "text": "We've been working on it together for",
        "start": 201.44,
        "duration": 2.4
    },
    {
        "text": "quite some time and we're super",
        "start": 203.84,
        "duration": 1.77
    },
    {
        "text": "excited to unveil it here at Build.",
        "start": 205.61,
        "duration": 2.63
    },
    {
        "text": ">> The collaboration that we have between PyTorch and Microsoft,",
        "start": 208.24,
        "duration": 3.82
    },
    {
        "text": "can you tell us what it entails?",
        "start": 212.06,
        "duration": 2.1
    },
    {
        "text": "What are we getting with this new PyTorch Enterprise on Azure?",
        "start": 214.16,
        "duration": 4.76
    },
    {
        "text": ">> It's essentially three things.",
        "start": 218.92,
        "duration": 2.405
    },
    {
        "text": "It is support, it is testing, and it's integration.",
        "start": 221.325,
        "duration": 5.22
    },
    {
        "text": "On the support side,",
        "start": 226.545,
        "duration": 2.06
    },
    {
        "text": "what we're offering with this program is",
        "start": 228.605,
        "duration": 4.214
    },
    {
        "text": "essentially that Microsoft will",
        "start": 232.819,
        "duration": 2.941
    },
    {
        "text": "support core open-source PyTorch code,",
        "start": 235.76,
        "duration": 3.69
    },
    {
        "text": "as well as a couple of libraries that depend on it.",
        "start": 239.45,
        "duration": 4.19
    },
    {
        "text": "That support is going to be available to",
        "start": 243.64,
        "duration": 3.145
    },
    {
        "text": "all Microsoft enterprise customers",
        "start": 246.785,
        "duration": 2.355
    },
    {
        "text": "that have the Enterprise Support Agreement.",
        "start": 249.14,
        "duration": 2.175
    },
    {
        "text": "The important part of that, Seth,",
        "start": 251.315,
        "duration": 1.545
    },
    {
        "text": "is that those customers are going to be able",
        "start": 252.86,
        "duration": 2.25
    },
    {
        "text": "to get prioritized hotfixes.",
        "start": 255.11,
        "duration": 2.73
    },
    {
        "text": "For example, if you're running",
        "start": 257.84,
        "duration": 2.175
    },
    {
        "text": "a workload with PyTorch, it's at scale.",
        "start": 260.015,
        "duration": 3.3
    },
    {
        "text": "There's a lot of resources involved.",
        "start": 263.315,
        "duration": 1.785
    },
    {
        "text": "You may not want to",
        "start": 265.1,
        "duration": 1.79
    },
    {
        "text": "upgrade to the latest version of PyTorch every night,",
        "start": 266.89,
        "duration": 3.475
    },
    {
        "text": "that's going to be quite a bit of investment.",
        "start": 270.365,
        "duration": 3.48
    },
    {
        "text": "What you may want to do is,",
        "start": 273.845,
        "duration": 1.785
    },
    {
        "text": "you may want to just stick with one stable version.",
        "start": 275.63,
        "duration": 3.0
    },
    {
        "text": "But that's stable version might have a bug,",
        "start": 278.63,
        "duration": 2.88
    },
    {
        "text": "might have a problem that you discover or somebody else discovers.",
        "start": 281.51,
        "duration": 2.67
    },
    {
        "text": "Maybe it's a security issue,",
        "start": 284.18,
        "duration": 2.055
    },
    {
        "text": "maybe it's a memory leak. What have you.",
        "start": 286.235,
        "duration": 2.34
    },
    {
        "text": "What you really want, is to just patch that single problem",
        "start": 288.575,
        "duration": 3.225
    },
    {
        "text": "without overhauling the entire installation.",
        "start": 291.8,
        "duration": 3.94
    },
    {
        "text": "That is what this program offers.",
        "start": 295.74,
        "duration": 3.035
    },
    {
        "text": "We will actually work with you.",
        "start": 298.775,
        "duration": 1.575
    },
    {
        "text": "We will reproduce the problem, will troubleshoot with you.",
        "start": 300.35,
        "duration": 3.495
    },
    {
        "text": "We will actually create the fix and will submit it to PyTorch.",
        "start": 303.845,
        "duration": 5.095
    },
    {
        "text": "At that point, they will integrate it",
        "start": 308.94,
        "duration": 2.18
    },
    {
        "text": "into a special long-term support version,",
        "start": 311.12,
        "duration": 2.345
    },
    {
        "text": "so that you can keep running as you were.",
        "start": 313.465,
        "duration": 3.595
    },
    {
        "text": "You can get the hotfix.",
        "start": 317.06,
        "duration": 1.53
    },
    {
        "text": "You don't have to swap out the tires on the car.",
        "start": 318.59,
        "duration": 3.78
    },
    {
        "text": ">> That's awesome. Because I mean, with open-source stuff,",
        "start": 322.37,
        "duration": 3.09
    },
    {
        "text": "sometimes you run into things and you may be at the mercy",
        "start": 325.46,
        "duration": 3.24
    },
    {
        "text": "of maintainers which have jobs and lives and other things.",
        "start": 328.7,
        "duration": 3.9
    },
    {
        "text": "You mentioned testing, what does that mean?",
        "start": 332.6,
        "duration": 3.22
    },
    {
        "text": ">> Open source is great,",
        "start": 335.84,
        "duration": 2.04
    },
    {
        "text": "because you get the latest and",
        "start": 337.88,
        "duration": 1.98
    },
    {
        "text": "greatest innovation for free at your fingertips,",
        "start": 339.86,
        "duration": 3.16
    },
    {
        "text": "so the price is right.",
        "start": 343.02,
        "duration": 1.325
    },
    {
        "text": "But as we all know,",
        "start": 344.345,
        "duration": 2.9
    },
    {
        "text": "open source doesn't work 100 percent all the time,",
        "start": 347.245,
        "duration": 3.455
    },
    {
        "text": "so the price of all that innovation",
        "start": 350.7,
        "duration": 2.51
    },
    {
        "text": "is sometimes unexpected things happen.",
        "start": 353.21,
        "duration": 3.24
    },
    {
        "text": "Enterprise software is usually a little bit different from that.",
        "start": 356.45,
        "duration": 3.06
    },
    {
        "text": "If you pay for enterprise software,",
        "start": 359.51,
        "duration": 1.875
    },
    {
        "text": "there's usually a team that's dedicated",
        "start": 361.385,
        "duration": 1.845
    },
    {
        "text": "to going through a set of tests,",
        "start": 363.23,
        "duration": 3.595
    },
    {
        "text": "a rigorous battery of tests,",
        "start": 366.825,
        "duration": 1.625
    },
    {
        "text": "and that gives you some peace of mind as you install the software,",
        "start": 368.45,
        "duration": 3.69
    },
    {
        "text": "especially when you go to production.",
        "start": 372.14,
        "duration": 1.95
    },
    {
        "text": "What PyTorch Enterprise does is,",
        "start": 374.09,
        "duration": 2.13
    },
    {
        "text": "we're trying to get the best of both those worlds.",
        "start": 376.22,
        "duration": 3.69
    },
    {
        "text": "You will get the open source software.",
        "start": 379.91,
        "duration": 2.64
    },
    {
        "text": "It's the same open source software that everybody else has,",
        "start": 382.55,
        "duration": 3.105
    },
    {
        "text": "but you also get a battery of tests from Microsoft.",
        "start": 385.655,
        "duration": 3.255
    },
    {
        "text": "There's two kinds of testing that we're doing.",
        "start": 388.91,
        "duration": 2.235
    },
    {
        "text": "One is continuous integration testing,",
        "start": 391.145,
        "duration": 3.525
    },
    {
        "text": "which is a battery of tests that we will",
        "start": 394.67,
        "duration": 1.86
    },
    {
        "text": "run every time that there's a pull request from GitHub,",
        "start": 396.53,
        "duration": 3.255
    },
    {
        "text": "it goes into PyTorch.org.",
        "start": 399.785,
        "duration": 2.025
    },
    {
        "text": "That means anytime anybody writes a contribution to PyTorch,",
        "start": 401.81,
        "duration": 4.59
    },
    {
        "text": "that contribution is going to run through",
        "start": 406.4,
        "duration": 2.07
    },
    {
        "text": "our series of tests to make sure that it's completely compatible.",
        "start": 408.47,
        "duration": 4.11
    },
    {
        "text": "The second is a set of nightly tests.",
        "start": 412.58,
        "duration": 3.66
    },
    {
        "text": "Actually going to put each release of PyTorch through",
        "start": 416.24,
        "duration": 5.64
    },
    {
        "text": "its paces with realistic workloads from Microsoft.",
        "start": 421.88,
        "duration": 5.605
    },
    {
        "text": "This is not going to be a simple unit test that I get",
        "start": 427.485,
        "duration": 4.085
    },
    {
        "text": "an okay or that I get a failed code on this little piece of code.",
        "start": 431.57,
        "duration": 4.815
    },
    {
        "text": "It's actually a workflow.",
        "start": 436.385,
        "duration": 1.855
    },
    {
        "text": "It might be from Bing,",
        "start": 438.24,
        "duration": 1.525
    },
    {
        "text": "it might be from Office.",
        "start": 439.765,
        "duration": 2.935
    },
    {
        "text": "It's going to be at scale and it's going to run frequently.",
        "start": 442.7,
        "duration": 3.3
    },
    {
        "text": "The point of all that testing, Seth,",
        "start": 446.0,
        "duration": 2.22
    },
    {
        "text": "is that every release of PyTorch,",
        "start": 448.22,
        "duration": 3.8
    },
    {
        "text": "is going to come with its health check car.",
        "start": 452.02,
        "duration": 3.305
    },
    {
        "text": "Think of it like a vaccination card.",
        "start": 455.325,
        "duration": 2.595
    },
    {
        "text": "You will know before you upgrade,",
        "start": 457.92,
        "duration": 1.82
    },
    {
        "text": "you will know whether the version that you're",
        "start": 459.74,
        "duration": 2.28
    },
    {
        "text": "upgrading to is performing as well as your version.",
        "start": 462.02,
        "duration": 2.98
    },
    {
        "text": "Because you will see the test for yours and",
        "start": 465.0,
        "duration": 1.64
    },
    {
        "text": "you'll see the test for the new one.",
        "start": 466.64,
        "duration": 1.83
    },
    {
        "text": "You will have that much more peace of",
        "start": 468.47,
        "duration": 2.25
    },
    {
        "text": "mind or confidence to make that upgrade or not.",
        "start": 470.72,
        "duration": 3.455
    },
    {
        "text": ">> That's really cool.",
        "start": 474.175,
        "duration": 1.415
    },
    {
        "text": "The safety in that knowing that",
        "start": 475.59,
        "duration": 1.82
    },
    {
        "text": "the next version won't break your previous version's code.",
        "start": 477.41,
        "duration": 2.805
    },
    {
        "text": "If it does, that you'll know, is amazing.",
        "start": 480.215,
        "duration": 2.58
    },
    {
        "text": "The last thing you mentioned was",
        "start": 482.795,
        "duration": 1.215
    },
    {
        "text": "Azure integration. What does that look like?",
        "start": 484.01,
        "duration": 2.51
    },
    {
        "text": ">> Well, basically, that's the easiest piece.",
        "start": 486.52,
        "duration": 2.65
    },
    {
        "text": "What it means is that,",
        "start": 489.17,
        "duration": 1.26
    },
    {
        "text": "we've worked with teams throughout Azure to make sure",
        "start": 490.43,
        "duration": 3.03
    },
    {
        "text": "that anywhere that you go in Azure,",
        "start": 493.46,
        "duration": 3.515
    },
    {
        "text": "you'll get the right version of the software and",
        "start": 496.975,
        "duration": 3.625
    },
    {
        "text": "the right thread stack to be able to use PyTorch Enterprise.",
        "start": 500.6,
        "duration": 5.425
    },
    {
        "text": "Basically, we've done all the leg work so that you don't have to.",
        "start": 506.025,
        "duration": 5.915
    },
    {
        "text": "It just makes for a nice and easy experience for customers.",
        "start": 511.94,
        "duration": 3.875
    },
    {
        "text": ">> This is really cool.",
        "start": 515.815,
        "duration": 1.565
    },
    {
        "text": "For those that are watching that want to get involved,",
        "start": 517.38,
        "duration": 3.3
    },
    {
        "text": "how does someone sign up,",
        "start": 520.68,
        "duration": 1.73
    },
    {
        "text": "so to speak, for PyTorch Enterprise on Microsoft Azure?",
        "start": 522.41,
        "duration": 3.385
    },
    {
        "text": ">> That's the best part, Seth.",
        "start": 525.795,
        "duration": 2.03
    },
    {
        "text": "There's actually no extra charge for this Service,",
        "start": 527.825,
        "duration": 3.75
    },
    {
        "text": "which is I think, it's pretty amazing.",
        "start": 531.575,
        "duration": 2.715
    },
    {
        "text": "It's a lot of value and a large investment.",
        "start": 534.29,
        "duration": 2.04
    },
    {
        "text": "It's completely free to",
        "start": 536.33,
        "duration": 2.04
    },
    {
        "text": "existing customers of both a Premier Support and Unified Support.",
        "start": 538.37,
        "duration": 5.945
    },
    {
        "text": "If you're already on those contracts,",
        "start": 544.315,
        "duration": 2.17
    },
    {
        "text": "you literally don't have to pay anything else.",
        "start": 546.485,
        "duration": 2.325
    },
    {
        "text": "You don't have to sign another form.",
        "start": 548.81,
        "duration": 1.98
    },
    {
        "text": "You just can open a ticket and it'll get routed to",
        "start": 550.79,
        "duration": 2.895
    },
    {
        "text": "our a set of PyTorch experts right in Azure,",
        "start": 553.685,
        "duration": 3.615
    },
    {
        "text": "we'll start working with you.",
        "start": 557.3,
        "duration": 1.305
    },
    {
        "text": "If you're not yet on those support contracts,",
        "start": 558.605,
        "duration": 2.925
    },
    {
        "text": "we hope that you will consider them,",
        "start": 561.53,
        "duration": 1.62
    },
    {
        "text": "but there's no other requirement.",
        "start": 563.15,
        "duration": 2.195
    },
    {
        "text": ">> Awesome. Anything else you want to add to this?",
        "start": 565.345,
        "duration": 2.38
    },
    {
        "text": "By the way, I'll put a link up for those that want to learn more.",
        "start": 567.725,
        "duration": 2.325
    },
    {
        "text": "Anything else you want to add, my friend?",
        "start": 570.05,
        "duration": 1.745
    },
    {
        "text": ">> Yeah. There's just one thing.",
        "start": 571.795,
        "duration": 2.225
    },
    {
        "text": "As we've been developing this program,",
        "start": 574.02,
        "duration": 2.345
    },
    {
        "text": "we've had a chance to preview it with",
        "start": 576.365,
        "duration": 1.815
    },
    {
        "text": "a couple of our partners and a couple of our customers.",
        "start": 578.18,
        "duration": 2.985
    },
    {
        "text": "The result has been just amazing.",
        "start": 581.165,
        "duration": 3.66
    },
    {
        "text": "People are so excited that they're going to get the support.",
        "start": 584.825,
        "duration": 5.225
    },
    {
        "text": "This is not support that you can buy",
        "start": 590.05,
        "duration": 1.9
    },
    {
        "text": "for love or money anywhere else.",
        "start": 591.95,
        "duration": 2.57
    },
    {
        "text": "It's only available on Azure.",
        "start": 594.52,
        "duration": 2.235
    },
    {
        "text": "We've heard really positive reactions from NVIDIA,",
        "start": 596.755,
        "duration": 6.035
    },
    {
        "text": "from Nuance, and from Crayon.",
        "start": 602.79,
        "duration": 3.555
    },
    {
        "text": "Crayon is an IT consulting shop.",
        "start": 606.345,
        "duration": 2.415
    },
    {
        "text": "NVIDIA is really excited that",
        "start": 608.76,
        "duration": 2.15
    },
    {
        "text": "people are spending a lot of money on their hardware.",
        "start": 610.91,
        "duration": 3.095
    },
    {
        "text": "If there's the slightest problem",
        "start": 614.005,
        "duration": 2.77
    },
    {
        "text": "that's reducing the efficiency of the workload,",
        "start": 616.775,
        "duration": 2.685
    },
    {
        "text": "then customers get upset.",
        "start": 619.46,
        "duration": 2.985
    },
    {
        "text": "The fact that Microsoft is going to stand behind",
        "start": 622.445,
        "duration": 2.45
    },
    {
        "text": "this really foundational layer of the code,",
        "start": 624.895,
        "duration": 3.395
    },
    {
        "text": "means that people will be",
        "start": 628.29,
        "duration": 1.67
    },
    {
        "text": "able to get the most out of the hardware.",
        "start": 629.96,
        "duration": 1.46
    },
    {
        "text": "NVIDIA is pretty happy about that.",
        "start": 631.42,
        "duration": 1.63
    },
    {
        "text": "Nuance has an application in",
        "start": 633.05,
        "duration": 3.51
    },
    {
        "text": "health tech which relies on very real time transcription.",
        "start": 636.56,
        "duration": 5.905
    },
    {
        "text": "It's very, very important that the model execute fast.",
        "start": 642.465,
        "duration": 2.81
    },
    {
        "text": "Again, it's an astounding scale.",
        "start": 645.275,
        "duration": 3.495
    },
    {
        "text": "The fact that we will be there",
        "start": 648.77,
        "duration": 2.71
    },
    {
        "text": "to help them through any issues that might come up,",
        "start": 651.48,
        "duration": 2.75
    },
    {
        "text": "is the real risk reduction for them.",
        "start": 654.23,
        "duration": 3.07
    },
    {
        "text": "It's just great to hear that feedback from customers.",
        "start": 657.73,
        "duration": 5.415
    },
    {
        "text": ">> Well, Alon, this has been amazing.",
        "start": 663.145,
        "duration": 2.365
    },
    {
        "text": "Thank you so much for spending some time with us,",
        "start": 665.51,
        "duration": 1.725
    },
    {
        "text": "and thank you so much for watching and learning all",
        "start": 667.235,
        "duration": 2.115
    },
    {
        "text": "about PyTorch Enterprise on Microsoft Azure.",
        "start": 669.35,
        "duration": 3.39
    },
    {
        "text": "Thank you so much for watching.",
        "start": 672.74,
        "duration": 1.29
    },
    {
        "text": "Hopefully, we'll see you next time. Take care.",
        "start": 674.03,
        "duration": 1.6
    },
    {
        "text": "[MUSIC]",
        "start": 675.63,
        "duration": 11.02
    }
]