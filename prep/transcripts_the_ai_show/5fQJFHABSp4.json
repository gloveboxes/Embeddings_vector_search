{"speaker": "Andreas Vr\u00e5lstad", "title": "Tagging Audio using Deep Learning", "videoId": "5fQJFHABSp4", "description": "Andreas Vr\u00e5lstad chats with Seth Juarez about how we can use deep learning for audio. We'll explain how we can use sounds, convert them into images and build a classifier model to tag songs  according to mood.\n\nJump To:\n[00:00] Introduction\n[01:05] Introducing the case\n[01:16] Demo\n[02:42] Working with the Peltarion Platform\n[17:05] Building a spectrogram\n[22:57] Calling the deployed model\n\nLearn More:  \nDo this yourself - step-by-step tutorial https://aka.ms/AIShow/TaggingAudioDidYouKnow\nHow this case has been done in real life. Case story with the music marketplace, Epidemic Sound https://aka.ms/AIShow/EpidemicSoundCaseStudy\n\nCreate a Free account (Azure) https://aka.ms/aishow-seth-azurefree \nDeep Learning vs. Machine Learning https://aka.ms/AIShow/DLvML \nGet Started with Machine Learning https://aka.ms/AIShow/StartML \nFollow Seth https://twitter.com/sethjuarez \n\nDon't miss new episodes, subscribe to the AI Show https://aka.ms/aishowsubscribe"}