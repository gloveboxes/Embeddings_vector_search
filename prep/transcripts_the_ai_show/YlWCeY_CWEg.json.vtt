[
    {
        "text": ">> You're not going to want to miss this episode",
        "start": 0.0,
        "duration": 1.41
    },
    {
        "text": "of the AI Show where we do",
        "start": 1.41,
        "duration": 1.08
    },
    {
        "text": "a whirlwind tour of what's new in Azure Machine Learning.",
        "start": 2.49,
        "duration": 2.73
    },
    {
        "text": "Don't miss it, tune-in. We'll see you there.",
        "start": 5.22,
        "duration": 2.01
    },
    {
        "text": "[MUSIC].",
        "start": 7.23,
        "duration": 4.53
    },
    {
        "text": ">> Hello. Welcome to this episode of the AI show.",
        "start": 11.76,
        "duration": 1.8
    },
    {
        "text": "We're going learn all about what's",
        "start": 13.56,
        "duration": 1.62
    },
    {
        "text": "new in Azure Machine Learning with Chris,",
        "start": 15.18,
        "duration": 1.92
    },
    {
        "text": "my good friend. How are you doing, bud?",
        "start": 17.1,
        "duration": 1.515
    },
    {
        "text": ">> Excellent. How are you?",
        "start": 18.615,
        "duration": 1.08
    },
    {
        "text": ">> Good. Tell us who you are,",
        "start": 19.695,
        "duration": 0.795
    },
    {
        "text": "what you do for those who don't know.",
        "start": 20.49,
        "duration": 0.99
    },
    {
        "text": ">> I'm Chris Lauren. I'm a PM",
        "start": 21.48,
        "duration": 1.47
    },
    {
        "text": "on the Azure Machine Learning Server.",
        "start": 22.95,
        "duration": 1.365
    },
    {
        "text": ">> Fantastic. So my understanding",
        "start": 24.315,
        "duration": 2.19
    },
    {
        "text": "is that Azure Machine Learning is",
        "start": 26.505,
        "duration": 1.665
    },
    {
        "text": "supposed to be the one-stop shop for data scientists from data,",
        "start": 28.17,
        "duration": 4.62
    },
    {
        "text": "all the way to deployed models, is that true?",
        "start": 32.79,
        "duration": 3.75
    },
    {
        "text": ">> Absolutely, almost.",
        "start": 36.54,
        "duration": 2.31
    },
    {
        "text": ">> Okay.",
        "start": 38.85,
        "duration": 0.39
    },
    {
        "text": ">> So in any machine learning experiment,",
        "start": 39.24,
        "duration": 2.805
    },
    {
        "text": "about 80-90 percent of the work is absolutely finding,",
        "start": 42.045,
        "duration": 3.155
    },
    {
        "text": "discovering, and working with data.",
        "start": 45.2,
        "duration": 1.545
    },
    {
        "text": ">> Correct.",
        "start": 46.745,
        "duration": 0.225
    },
    {
        "text": ">> You've got to find it, prep it,",
        "start": 46.97,
        "duration": 1.82
    },
    {
        "text": "then you can train and deploy your Machine Learning Model.",
        "start": 48.79,
        "duration": 2.65
    },
    {
        "text": "So in Azure, we integrate a bunch of different products",
        "start": 51.44,
        "duration": 3.3
    },
    {
        "text": "together to make this work as seamlessly as",
        "start": 54.74,
        "duration": 2.1
    },
    {
        "text": "possible across data engineers,",
        "start": 56.84,
        "duration": 2.19
    },
    {
        "text": "data scientists, and engineers that are going to",
        "start": 59.03,
        "duration": 2.58
    },
    {
        "text": "deploy web services or there applications.",
        "start": 61.61,
        "duration": 2.715
    },
    {
        "text": ">> Awesome.",
        "start": 64.325,
        "duration": 0.315
    },
    {
        "text": ">> So I'll show you how Azure Machine Learning",
        "start": 64.64,
        "duration": 2.03
    },
    {
        "text": "enables this end to end lifecycle.",
        "start": 66.67,
        "duration": 2.11
    },
    {
        "text": ">> Fantastic, and show us a little bit about what's new, right?",
        "start": 68.78,
        "duration": 2.085
    },
    {
        "text": ">> Oh, for sure.",
        "start": 70.865,
        "duration": 0.69
    },
    {
        "text": ">> All right, let's get started.",
        "start": 71.555,
        "duration": 0.735
    },
    {
        "text": ">> Sweet. So this is Azure Data Factory,",
        "start": 72.29,
        "duration": 2.31
    },
    {
        "text": "and one of the things that",
        "start": 74.6,
        "duration": 1.23
    },
    {
        "text": "Azure Data Factory enables is connecting",
        "start": 75.83,
        "duration": 1.62
    },
    {
        "text": "a bunch of different data sources like whether it's in S3 buckets,",
        "start": 77.45,
        "duration": 3.37
    },
    {
        "text": "or on-prem data sources and such.",
        "start": 80.82,
        "duration": 1.98
    },
    {
        "text": "So we've fetched are data from a bunch of different locations.",
        "start": 82.8,
        "duration": 3.16
    },
    {
        "text": "On-prem, maybe prep the data in Azure Databricks,",
        "start": 85.96,
        "duration": 3.045
    },
    {
        "text": "and then we'll save it in Azure data storage,",
        "start": 89.005,
        "duration": 2.53
    },
    {
        "text": "and then we'll fundamentally train and",
        "start": 91.535,
        "duration": 2.265
    },
    {
        "text": "deploy a machine learning model using Azure Machine Learning,",
        "start": 93.8,
        "duration": 2.45
    },
    {
        "text": "which is what we're primarily here to talk about.",
        "start": 96.25,
        "duration": 1.99
    },
    {
        "text": "So I'm going to show you how to train and deploy",
        "start": 98.24,
        "duration": 2.31
    },
    {
        "text": "your Machine Learning Model once you've prepared your data.",
        "start": 100.55,
        "duration": 2.545
    },
    {
        "text": ">> Let's pause right there. So that was Azure Data Factory?",
        "start": 103.095,
        "duration": 3.255
    },
    {
        "text": ">> Azure Data Factory.",
        "start": 106.35,
        "duration": 0.9
    },
    {
        "text": ">> I See.",
        "start": 107.25,
        "duration": 0.3
    },
    {
        "text": ">> Integrated with Azure Machine Learning.",
        "start": 107.55,
        "duration": 1.875
    },
    {
        "text": ">> That's where you're like almost,",
        "start": 109.425,
        "duration": 1.325
    },
    {
        "text": "because we have other things that we can",
        "start": 110.75,
        "duration": 1.53
    },
    {
        "text": "pipe it into Azure Machine Learning, this is one of them.",
        "start": 112.28,
        "duration": 2.0
    },
    {
        "text": ">> That's right.",
        "start": 114.28,
        "duration": 0.62
    },
    {
        "text": ">> Fantastic.",
        "start": 114.9,
        "duration": 0.35
    },
    {
        "text": ">> Yeah. So for example,",
        "start": 115.25,
        "duration": 2.92
    },
    {
        "text": "I'm going to show you how to train models to",
        "start": 118.17,
        "duration": 2.06
    },
    {
        "text": "calculate whether a flight is likely to be delayed.",
        "start": 120.23,
        "duration": 2.745
    },
    {
        "text": ">> Okay.",
        "start": 122.975,
        "duration": 0.6
    },
    {
        "text": ">> So there are some types of datasets that you may not",
        "start": 123.575,
        "duration": 2.475
    },
    {
        "text": "have on-prem or readily available,",
        "start": 126.05,
        "duration": 2.315
    },
    {
        "text": "and so we've released Azure open",
        "start": 128.365,
        "duration": 1.615
    },
    {
        "text": "datasets to enable discovering that sort of stuff as well.",
        "start": 129.98,
        "duration": 2.925
    },
    {
        "text": "So we can search for weather data,",
        "start": 132.905,
        "duration": 2.895
    },
    {
        "text": "we can look at the NOAA data,",
        "start": 135.8,
        "duration": 1.68
    },
    {
        "text": "for example, and then we can identify",
        "start": 137.48,
        "duration": 2.07
    },
    {
        "text": "what kind of columns or features are available in that data.",
        "start": 139.55,
        "duration": 2.565
    },
    {
        "text": ">> I see.",
        "start": 142.115,
        "duration": 0.39
    },
    {
        "text": ">> Then we can even see how to get access to this data.",
        "start": 142.505,
        "duration": 3.09
    },
    {
        "text": "It generates a code using the Azure ML Open Datasets.",
        "start": 145.595,
        "duration": 3.195
    },
    {
        "text": "So you can use this Python package anywhere on",
        "start": 148.79,
        "duration": 2.31
    },
    {
        "text": "your local machine or in the Cloud to be able to get access",
        "start": 151.1,
        "duration": 2.82
    },
    {
        "text": "to data so that you can enrich",
        "start": 153.92,
        "duration": 1.23
    },
    {
        "text": "the datasets you do have with datasets",
        "start": 155.15,
        "duration": 1.8
    },
    {
        "text": "you don't have to get better more predictive data.",
        "start": 156.95,
        "duration": 3.145
    },
    {
        "text": ">> I see. So when I started dataset at first, I was like, \"Well,",
        "start": 160.095,
        "duration": 5.055
    },
    {
        "text": "this is very useful to train novel",
        "start": 165.15,
        "duration": 1.67
    },
    {
        "text": "models,\" but you're saying that we use this data",
        "start": 166.82,
        "duration": 2.13
    },
    {
        "text": "to augment the data we",
        "start": 168.95,
        "duration": 1.74
    },
    {
        "text": "already have to make it even better models with what we got.",
        "start": 170.69,
        "duration": 2.31
    },
    {
        "text": ">> Yes.",
        "start": 173.0,
        "duration": 0.45
    },
    {
        "text": ">> I love it.",
        "start": 173.45,
        "duration": 0.585
    },
    {
        "text": ">> That's right. Absolutely. So now,",
        "start": 174.035,
        "duration": 2.82
    },
    {
        "text": "one of the things that our customers",
        "start": 176.855,
        "duration": 2.445
    },
    {
        "text": "have told us a lot is they really like",
        "start": 179.3,
        "duration": 2.22
    },
    {
        "text": "the shift in Azure Machine Learning to provide",
        "start": 181.52,
        "duration": 2.34
    },
    {
        "text": "the Python SDK and the Jupyter Notebook experience,",
        "start": 183.86,
        "duration": 3.125
    },
    {
        "text": "but a lot of people in their companies really like",
        "start": 186.985,
        "duration": 3.505
    },
    {
        "text": "the drag-and-drop UI experience that we",
        "start": 190.49,
        "duration": 2.25
    },
    {
        "text": "had in Azure ML studio as well.",
        "start": 192.74,
        "duration": 2.67
    },
    {
        "text": "So now one of the things I'm proud to",
        "start": 195.41,
        "duration": 2.19
    },
    {
        "text": "tell you this morning is that we've integrated",
        "start": 197.6,
        "duration": 2.219
    },
    {
        "text": "that visual interface with",
        "start": 199.819,
        "duration": 2.191
    },
    {
        "text": "the new Azure Machine Learning service so that",
        "start": 202.01,
        "duration": 2.595
    },
    {
        "text": "no matter the level of experience you have with data science,",
        "start": 204.605,
        "duration": 2.675
    },
    {
        "text": "you can train and deploy",
        "start": 207.28,
        "duration": 1.315
    },
    {
        "text": "great models using Azure Machine Learning.",
        "start": 208.595,
        "duration": 2.24
    },
    {
        "text": ">> Now, when you brought this in,",
        "start": 210.835,
        "duration": 1.485
    },
    {
        "text": "are you integrating it with all the other stuff",
        "start": 212.32,
        "duration": 2.08
    },
    {
        "text": "that was already in Azure Machine Learning?",
        "start": 214.4,
        "duration": 1.65
    },
    {
        "text": "So like stuff you shared?",
        "start": 216.05,
        "duration": 1.05
    },
    {
        "text": ">> Absolutely.",
        "start": 217.1,
        "duration": 1.08
    },
    {
        "text": "So you can use the same set of compute resources,",
        "start": 218.18,
        "duration": 2.07
    },
    {
        "text": "you can discover the same set of",
        "start": 220.25,
        "duration": 1.485
    },
    {
        "text": "datasets that are all available within",
        "start": 221.735,
        "duration": 2.595
    },
    {
        "text": "one cohesive Azure Machine Learning workspace",
        "start": 224.33,
        "duration": 2.969
    },
    {
        "text": "that you can provide Role-Based Access Security for,",
        "start": 227.299,
        "duration": 2.941
    },
    {
        "text": "so you can control who has access to what,",
        "start": 230.24,
        "duration": 2.03
    },
    {
        "text": "and enable your data scientists and engineers",
        "start": 232.27,
        "duration": 2.14
    },
    {
        "text": "to work together in one cohesive experience.",
        "start": 234.41,
        "duration": 2.205
    },
    {
        "text": ">> Fantastic. So the drag-and-drop experience is",
        "start": 236.615,
        "duration": 1.815
    },
    {
        "text": "coming integrated into Azure Machine Learning.",
        "start": 238.43,
        "duration": 2.075
    },
    {
        "text": ">> That's absolutely right.",
        "start": 240.505,
        "duration": 1.085
    },
    {
        "text": ">> Love it.",
        "start": 241.59,
        "duration": 0.525
    },
    {
        "text": ">> Now, that Azure Machine Learning workspace",
        "start": 242.115,
        "duration": 3.59
    },
    {
        "text": "enables bringing together your compute,",
        "start": 245.705,
        "duration": 2.46
    },
    {
        "text": "your data, and your model's all-in-one UI.",
        "start": 248.165,
        "duration": 2.745
    },
    {
        "text": "So you can see I've got some Notebook virtual machines here.",
        "start": 250.91,
        "duration": 3.315
    },
    {
        "text": "This enables running those Jupyter Notebooks which are",
        "start": 254.225,
        "duration": 2.355
    },
    {
        "text": "the bread and butter for most data scientists these days.",
        "start": 256.58,
        "duration": 2.82
    },
    {
        "text": "We also have auto scalable GPU or CPU clusters in the Cloud.",
        "start": 259.4,
        "duration": 5.955
    },
    {
        "text": "So when you're not using them,",
        "start": 265.355,
        "duration": 1.515
    },
    {
        "text": "they'll automatically shrink to zero machines.",
        "start": 266.87,
        "duration": 2.16
    },
    {
        "text": "You're not paying for compute that you're not using.",
        "start": 269.03,
        "duration": 2.25
    },
    {
        "text": "But notice that it's all available right here.",
        "start": 271.28,
        "duration": 2.28
    },
    {
        "text": "So we can provision and manage all of our assets,",
        "start": 273.56,
        "duration": 3.21
    },
    {
        "text": "whether it's compute, data etc,",
        "start": 276.77,
        "duration": 2.025
    },
    {
        "text": "all in one place.",
        "start": 278.795,
        "duration": 1.44
    },
    {
        "text": "So we can look in our data stores, for example here,",
        "start": 280.235,
        "duration": 2.55
    },
    {
        "text": "and we can see the list of data that's available",
        "start": 282.785,
        "duration": 2.88
    },
    {
        "text": "across Azure Blob or SQL etc in here as well.",
        "start": 285.665,
        "duration": 3.405
    },
    {
        "text": "But once you've trained your models,",
        "start": 289.07,
        "duration": 2.95
    },
    {
        "text": "you can store those models in",
        "start": 292.02,
        "duration": 1.25
    },
    {
        "text": "the Azure Machine Learning Model registry,",
        "start": 293.27,
        "duration": 2.075
    },
    {
        "text": "and we can see that these models are versioned,",
        "start": 295.345,
        "duration": 2.709
    },
    {
        "text": "and we have full lineage to see which experiment",
        "start": 298.054,
        "duration": 3.361
    },
    {
        "text": "was used to train those models as well quickly and easily.",
        "start": 301.415,
        "duration": 3.9
    },
    {
        "text": ">> The thing I like about that is",
        "start": 305.315,
        "duration": 1.38
    },
    {
        "text": "sometimes when a model is deployed,",
        "start": 306.695,
        "duration": 2.325
    },
    {
        "text": "I don't know where it came from.",
        "start": 309.02,
        "duration": 1.815
    },
    {
        "text": "Is there a way to trace back to",
        "start": 310.835,
        "duration": 1.845
    },
    {
        "text": "an experiment to the actual data that was used as well?",
        "start": 312.68,
        "duration": 2.66
    },
    {
        "text": ">> Yeah, absolutely.",
        "start": 315.34,
        "duration": 1.29
    },
    {
        "text": "So when you drill into each one of these experiments,",
        "start": 316.63,
        "duration": 2.515
    },
    {
        "text": "then you can see a whole bunch of details about the metrics,",
        "start": 319.145,
        "duration": 4.185
    },
    {
        "text": "and child runs, and the links back to the individual,",
        "start": 323.33,
        "duration": 3.02
    },
    {
        "text": "the input dataset as well.",
        "start": 326.35,
        "duration": 2.02
    },
    {
        "text": ">> That's cool.",
        "start": 328.37,
        "duration": 0.825
    },
    {
        "text": ">> Let me show you how to train a machine learning model",
        "start": 329.195,
        "duration": 3.42
    },
    {
        "text": "using one of the other really neat capabilities",
        "start": 332.615,
        "duration": 2.475
    },
    {
        "text": "called the Automated Machine Learning.",
        "start": 335.09,
        "duration": 1.62
    },
    {
        "text": ">> Cool.",
        "start": 336.71,
        "duration": 0.465
    },
    {
        "text": ">> So as a data scientists,",
        "start": 337.175,
        "duration": 1.725
    },
    {
        "text": "sometimes you just want to determine quickly",
        "start": 338.9,
        "duration": 2.28
    },
    {
        "text": "whether dataset has any predictive power at all.",
        "start": 341.18,
        "duration": 2.33
    },
    {
        "text": ">> Right.",
        "start": 343.51,
        "duration": 0.29
    },
    {
        "text": ">> So you can use the Python SDK in",
        "start": 343.8,
        "duration": 2.3
    },
    {
        "text": "this Jupyter Notebook to connect to the workspace,",
        "start": 346.1,
        "duration": 2.95
    },
    {
        "text": "so that's what we were just looking at.",
        "start": 349.05,
        "duration": 1.77
    },
    {
        "text": "Create an experiment and experiment is just like a project.",
        "start": 350.82,
        "duration": 2.75
    },
    {
        "text": "It'll keep track of all your attempts to train a great model.",
        "start": 353.57,
        "duration": 3.52
    },
    {
        "text": "Then we can explore the data,",
        "start": 357.09,
        "duration": 1.965
    },
    {
        "text": "get a quick profile to understand",
        "start": 359.055,
        "duration": 2.525
    },
    {
        "text": "the distribution of the different values in your dataset,",
        "start": 361.58,
        "duration": 3.224
    },
    {
        "text": "and then using open source libraries,",
        "start": 364.804,
        "duration": 3.616
    },
    {
        "text": "we can certainly understand",
        "start": 368.42,
        "duration": 1.724
    },
    {
        "text": "the distribution of values plotted visually as well.",
        "start": 370.144,
        "duration": 3.576
    },
    {
        "text": ">> So this stuff is already available but",
        "start": 373.72,
        "duration": 1.87
    },
    {
        "text": "the main difference is that I could be running this",
        "start": 375.59,
        "duration": 2.79
    },
    {
        "text": "on my surface goal because it's connected to",
        "start": 378.38,
        "duration": 1.98
    },
    {
        "text": "a Cloud VM doing the Notebook?",
        "start": 380.36,
        "duration": 2.71
    },
    {
        "text": ">> Absolutely.",
        "start": 383.07,
        "duration": 0.54
    },
    {
        "text": ">> That's cool.",
        "start": 383.61,
        "duration": 0.48
    },
    {
        "text": ">> Or the Linux Machine Learning desk.",
        "start": 384.09,
        "duration": 1.575
    },
    {
        "text": ">> Oh, that's right. There's a machine desk too.",
        "start": 385.665,
        "duration": 1.665
    },
    {
        "text": ">> Yeah, do that. So the Automated Machine Learning",
        "start": 387.33,
        "duration": 3.32
    },
    {
        "text": "enables taking all those different features",
        "start": 390.65,
        "duration": 2.31
    },
    {
        "text": "that are available in that dataset",
        "start": 392.96,
        "duration": 1.71
    },
    {
        "text": "and then identifying different combinations",
        "start": 394.67,
        "duration": 2.07
    },
    {
        "text": "of algorithms and hyper parameter values",
        "start": 396.74,
        "duration": 2.16
    },
    {
        "text": "for those algorithms to identify on how to train our best model.",
        "start": 398.9,
        "duration": 4.375
    },
    {
        "text": ">> Got it.",
        "start": 403.275,
        "duration": 0.225
    },
    {
        "text": ">> Including data pre-processing or augmentation.",
        "start": 403.5,
        "duration": 2.67
    },
    {
        "text": "Because sometimes,",
        "start": 406.17,
        "duration": 1.365
    },
    {
        "text": "extracting individual values are",
        "start": 407.535,
        "duration": 1.775
    },
    {
        "text": "transforming that input data to create",
        "start": 409.31,
        "duration": 2.1
    },
    {
        "text": "new columns in your dataset",
        "start": 411.41,
        "duration": 2.115
    },
    {
        "text": "can help increase the predictive power of your data as well.",
        "start": 413.525,
        "duration": 3.055
    },
    {
        "text": "So all that happens automatically just by",
        "start": 416.58,
        "duration": 2.57
    },
    {
        "text": "providing a simple script to get your input data,",
        "start": 419.15,
        "duration": 3.815
    },
    {
        "text": "and then deciding where you want to",
        "start": 422.965,
        "duration": 2.455
    },
    {
        "text": "run this Automated Machine Learning job.",
        "start": 425.42,
        "duration": 2.85
    },
    {
        "text": "So in this case,",
        "start": 428.27,
        "duration": 1.65
    },
    {
        "text": "we're going to automatically create",
        "start": 429.92,
        "duration": 2.28
    },
    {
        "text": "a CPU cluster because we're using tabular data,",
        "start": 432.2,
        "duration": 2.89
    },
    {
        "text": "we don't necessarily need GPUs for us so we can control our costs,",
        "start": 435.09,
        "duration": 3.455
    },
    {
        "text": "and then we can submit this",
        "start": 438.545,
        "duration": 3.06
    },
    {
        "text": "using an Automated Machine Learning config file here.",
        "start": 441.605,
        "duration": 3.43
    },
    {
        "text": "Now, what this does is this enables easily repeating",
        "start": 445.035,
        "duration": 4.7
    },
    {
        "text": "this experiment over and over in",
        "start": 449.735,
        "duration": 2.265
    },
    {
        "text": "a Docker container with the same set of the Python libraries,",
        "start": 452.0,
        "duration": 3.99
    },
    {
        "text": "the right versions so you can make sure that",
        "start": 455.99,
        "duration": 2.04
    },
    {
        "text": "your code always runs properly, right?",
        "start": 458.03,
        "duration": 2.35
    },
    {
        "text": ">> So Automated Machine Learning basically is like a for loop",
        "start": 460.38,
        "duration": 3.02
    },
    {
        "text": "that's smarter that runs over",
        "start": 463.4,
        "duration": 1.38
    },
    {
        "text": "a bunch of for example scikit-learn models.",
        "start": 464.78,
        "duration": 2.21
    },
    {
        "text": ">> Yeah, but not just scikit-learn models,",
        "start": 466.99,
        "duration": 2.36
    },
    {
        "text": "even model ensembles including all of the pre-processing.",
        "start": 469.35,
        "duration": 3.65
    },
    {
        "text": ">> That's cool.",
        "start": 473.0,
        "duration": 0.435
    },
    {
        "text": ">> So pretty much any way you could achieve your goal,",
        "start": 473.435,
        "duration": 3.24
    },
    {
        "text": "it'll iterate over all of",
        "start": 476.675,
        "duration": 1.935
    },
    {
        "text": "those possibilities to create the best model possible.",
        "start": 478.61,
        "duration": 2.76
    },
    {
        "text": ">> Got it.",
        "start": 481.37,
        "duration": 0.57
    },
    {
        "text": ">> You can see here,",
        "start": 481.94,
        "duration": 1.395
    },
    {
        "text": "we specify the goal by telling it I'm",
        "start": 483.335,
        "duration": 2.295
    },
    {
        "text": "doing a classification tasks in this case,",
        "start": 485.63,
        "duration": 2.415
    },
    {
        "text": "is the flight going to be late or not?",
        "start": 488.045,
        "duration": 2.39
    },
    {
        "text": "Then we can set some parameters like",
        "start": 490.435,
        "duration": 3.115
    },
    {
        "text": "how many times am I willing to",
        "start": 493.55,
        "duration": 1.59
    },
    {
        "text": "try this just so I can control the costs.",
        "start": 495.14,
        "duration": 2.175
    },
    {
        "text": "One of the new things that we've added here",
        "start": 497.315,
        "duration": 2.025
    },
    {
        "text": "is the experiment exit score.",
        "start": 499.34,
        "duration": 1.92
    },
    {
        "text": "Basically saying this high-quality bar,",
        "start": 501.26,
        "duration": 1.905
    },
    {
        "text": "I want to be like 80 percent confident in this case.",
        "start": 503.165,
        "duration": 2.325
    },
    {
        "text": ">> That's cool.",
        "start": 505.49,
        "duration": 0.385
    },
    {
        "text": ">> As soon as I get there, just stop.",
        "start": 505.875,
        "duration": 1.73
    },
    {
        "text": "So they may not go all the way to those 50 runs for example.",
        "start": 507.605,
        "duration": 3.935
    },
    {
        "text": ">> That's cool.",
        "start": 511.54,
        "duration": 1.025
    },
    {
        "text": ">> We've added the model explain stability as well,",
        "start": 512.565,
        "duration": 2.915
    },
    {
        "text": "which is super important in certain industries to understand",
        "start": 515.48,
        "duration": 2.43
    },
    {
        "text": "why a model predicted the way that it does.",
        "start": 517.91,
        "duration": 2.7
    },
    {
        "text": "So I'll show you how that works in just a second here.",
        "start": 520.61,
        "duration": 2.62
    },
    {
        "text": "So we'll go ahead and run this experiment on",
        "start": 523.23,
        "duration": 2.03
    },
    {
        "text": "that compute that I mentioned above.",
        "start": 525.26,
        "duration": 2.505
    },
    {
        "text": "Then we'll see right in line here,",
        "start": 527.765,
        "duration": 2.445
    },
    {
        "text": "how well the different combinations",
        "start": 530.21,
        "duration": 2.19
    },
    {
        "text": "of preprocessing steps and things work.",
        "start": 532.4,
        "duration": 3.66
    },
    {
        "text": "As we mouse over in the widget,",
        "start": 536.06,
        "duration": 1.65
    },
    {
        "text": "we can see the different hyper parameter values and such.",
        "start": 537.71,
        "duration": 3.39
    },
    {
        "text": ">> I think those things on its own and we didn't do anything.",
        "start": 541.1,
        "duration": 2.76
    },
    {
        "text": ">> Absolute.",
        "start": 543.86,
        "duration": 0.39
    },
    {
        "text": ">> Here's some data, let's see if any of you done.",
        "start": 544.25,
        "duration": 1.8
    },
    {
        "text": "Because usually what I do when I do a machine learning model,",
        "start": 546.05,
        "duration": 2.49
    },
    {
        "text": "I start with a dumbest models first",
        "start": 548.54,
        "duration": 1.38
    },
    {
        "text": "like decision tree or Naive Bayes,",
        "start": 549.92,
        "duration": 2.01
    },
    {
        "text": "logistic regression usually in that order,",
        "start": 551.93,
        "duration": 2.38
    },
    {
        "text": "and then if it works great, if it",
        "start": 554.31,
        "duration": 1.11
    },
    {
        "text": "doesn't, then I have to do something else.",
        "start": 555.42,
        "duration": 1.42
    },
    {
        "text": "But it's a lot of work for me to set",
        "start": 556.84,
        "duration": 1.66
    },
    {
        "text": "that up myself, this does it all on its own.",
        "start": 558.5,
        "duration": 1.56
    },
    {
        "text": ">> That's right. Yeah, absolutely.",
        "start": 560.06,
        "duration": 2.19
    },
    {
        "text": "Then we can see right here in",
        "start": 562.25,
        "duration": 1.56
    },
    {
        "text": "the widget how well the different attempts are working,",
        "start": 563.81,
        "duration": 3.54
    },
    {
        "text": "so you don't have to go anywhere to",
        "start": 567.35,
        "duration": 1.725
    },
    {
        "text": "monitor how well the experiment worked.",
        "start": 569.075,
        "duration": 3.475
    },
    {
        "text": ">> This feels like a lot of",
        "start": 574.13,
        "duration": 2.38
    },
    {
        "text": "typing stuff and is there a way I can do this a lot easier?",
        "start": 576.51,
        "duration": 2.6
    },
    {
        "text": ">> Yeah, absolutely.",
        "start": 579.11,
        "duration": 1.56
    },
    {
        "text": "So in the UI,",
        "start": 580.67,
        "duration": 2.315
    },
    {
        "text": "now we can simply create an experiment and we can give it a name,",
        "start": 582.985,
        "duration": 4.9
    },
    {
        "text": "and then we can select the compute target we want to run on.",
        "start": 587.885,
        "duration": 2.745
    },
    {
        "text": ">> See Chris, you should elaborate this.",
        "start": 590.63,
        "duration": 2.175
    },
    {
        "text": ">> Well, but then it doesn't have the same [inaudible].",
        "start": 592.805,
        "duration": 3.625
    },
    {
        "text": ">> That's true. So we'll select our data.",
        "start": 596.43,
        "duration": 2.72
    },
    {
        "text": "Now we can preview this data.",
        "start": 599.15,
        "duration": 2.385
    },
    {
        "text": "We're going to see all the different columns",
        "start": 601.535,
        "duration": 1.905
    },
    {
        "text": "that are available in this tabular dataset.",
        "start": 603.44,
        "duration": 2.0
    },
    {
        "text": "We can even click profile to get a quick understanding of",
        "start": 605.44,
        "duration": 2.98
    },
    {
        "text": "the distribution of the different columns that are in the dataset.",
        "start": 608.42,
        "duration": 3.39
    },
    {
        "text": ">> That's cool.",
        "start": 611.81,
        "duration": 0.795
    },
    {
        "text": ">> Then again, specify that this is a classification task.",
        "start": 612.605,
        "duration": 3.435
    },
    {
        "text": "Notice we've also added forecasting now which is pretty cool.",
        "start": 616.04,
        "duration": 3.18
    },
    {
        "text": ">> That's cool.",
        "start": 619.22,
        "duration": 1.7
    },
    {
        "text": ">> Then we specify the column that we want to target,",
        "start": 620.92,
        "duration": 4.345
    },
    {
        "text": "and then we simply hit \"Start\" if we wanted to run it,",
        "start": 625.265,
        "duration": 3.54
    },
    {
        "text": "but we can even have additional controls like",
        "start": 628.805,
        "duration": 3.165
    },
    {
        "text": "specify if I wanted to choose",
        "start": 631.97,
        "duration": 1.83
    },
    {
        "text": "a different metric for my target here.",
        "start": 633.8,
        "duration": 2.78
    },
    {
        "text": "If I wanted to block some of the algorithms.",
        "start": 636.58,
        "duration": 2.054
    },
    {
        "text": ">> I see.",
        "start": 638.634,
        "duration": 0.106
    },
    {
        "text": ">> So don't even bother wasting any compute resources on those.",
        "start": 638.74,
        "duration": 3.19
    },
    {
        "text": ">> If you don't like the researcher that",
        "start": 641.93,
        "duration": 1.35
    },
    {
        "text": "invented that particular model, don't use it.",
        "start": 643.28,
        "duration": 2.27
    },
    {
        "text": ">> Absolutely.",
        "start": 645.55,
        "duration": 0.89
    },
    {
        "text": ">> You don't have to?",
        "start": 646.44,
        "duration": 0.765
    },
    {
        "text": ">> Absolutely. So that's",
        "start": 647.205,
        "duration": 2.35
    },
    {
        "text": "how we get started quickly in the Auto ML UI.",
        "start": 649.555,
        "duration": 3.235
    },
    {
        "text": ">> That's cool.",
        "start": 652.79,
        "duration": 0.665
    },
    {
        "text": ">> However, there are certain types of things",
        "start": 653.455,
        "duration": 2.695
    },
    {
        "text": "like vision object detection type of scenarios,",
        "start": 656.15,
        "duration": 3.69
    },
    {
        "text": "or audio signals, etc,",
        "start": 659.84,
        "duration": 1.95
    },
    {
        "text": "deep learning scenarios that just don't work well here yet.",
        "start": 661.79,
        "duration": 4.475
    },
    {
        "text": "We'll work on enabling those someday, but for now,",
        "start": 666.265,
        "duration": 3.585
    },
    {
        "text": "most classic business problems work with tabular data,",
        "start": 669.85,
        "duration": 3.775
    },
    {
        "text": "this is an awesome solution.",
        "start": 673.625,
        "duration": 1.35
    },
    {
        "text": ">> I'm a vision person.",
        "start": 674.975,
        "duration": 1.335
    },
    {
        "text": "So now you're getting to my area",
        "start": 676.31,
        "duration": 1.38
    },
    {
        "text": "because everything looks super nice,",
        "start": 677.69,
        "duration": 1.86
    },
    {
        "text": "but I don't know how to automatically say",
        "start": 679.55,
        "duration": 2.31
    },
    {
        "text": "how many internal neurons you need for your deep learning network,",
        "start": 681.86,
        "duration": 2.89
    },
    {
        "text": "and so is there a way we can do that here?",
        "start": 684.75,
        "duration": 1.99
    },
    {
        "text": ">> Yeah, absolutely.",
        "start": 686.74,
        "duration": 1.73
    },
    {
        "text": "So using the open source",
        "start": 688.47,
        "duration": 2.67
    },
    {
        "text": "deep-learning libraries like TensorFlow or PyTorch,",
        "start": 691.14,
        "duration": 2.96
    },
    {
        "text": "we can run experiments using our Jupyter Notebooks.",
        "start": 694.1,
        "duration": 3.66
    },
    {
        "text": "Again, powered by the Notebook VMs",
        "start": 697.76,
        "duration": 2.25
    },
    {
        "text": "that are contained within that workspace,",
        "start": 700.01,
        "duration": 1.815
    },
    {
        "text": "make it really easy to bring all this together.",
        "start": 701.825,
        "duration": 2.54
    },
    {
        "text": "So again, we'll connect to our experiment.",
        "start": 704.365,
        "duration": 3.32
    },
    {
        "text": "We'll load up some training data.",
        "start": 707.685,
        "duration": 2.78
    },
    {
        "text": "I can even enumerate the different types of",
        "start": 710.465,
        "duration": 2.175
    },
    {
        "text": "GPU virtual machines that I want to",
        "start": 712.64,
        "duration": 2.49
    },
    {
        "text": "include in a cluster because I can never",
        "start": 715.13,
        "duration": 2.34
    },
    {
        "text": "remember the names of these type of virtual machines.",
        "start": 717.47,
        "duration": 3.23
    },
    {
        "text": "So then we can create again,",
        "start": 720.7,
        "duration": 2.24
    },
    {
        "text": "an auto scalable cluster using the latest in video GPU VMs,",
        "start": 722.94,
        "duration": 3.95
    },
    {
        "text": "these are V100s which are pretty awesome,",
        "start": 726.89,
        "duration": 2.515
    },
    {
        "text": "but they are a little bit pricier than CPU machines.",
        "start": 729.405,
        "duration": 2.615
    },
    {
        "text": "So again, with a minimum nodes of zero,",
        "start": 732.02,
        "duration": 2.25
    },
    {
        "text": "this is going to shrink down,",
        "start": 734.27,
        "duration": 1.365
    },
    {
        "text": "so I'm not paying for it when I'm not using it.",
        "start": 735.635,
        "duration": 1.835
    },
    {
        "text": ">> I loved the option of having the ability to do it in code,",
        "start": 737.47,
        "duration": 2.335
    },
    {
        "text": "and also in the new UI as well.",
        "start": 739.805,
        "duration": 2.285
    },
    {
        "text": ">> Yeah, absolutely.",
        "start": 742.09,
        "duration": 1.54
    },
    {
        "text": "So then just like before,",
        "start": 743.63,
        "duration": 1.35
    },
    {
        "text": "I'll go ahead and call experiment.submit to run this in the Cloud.",
        "start": 744.98,
        "duration": 4.15
    },
    {
        "text": "They'll automatically provision.",
        "start": 749.13,
        "duration": 1.44
    },
    {
        "text": ">> Scroll up there because I'm looking at this estimator here,",
        "start": 750.57,
        "duration": 3.98
    },
    {
        "text": "it's literally called TensorFlow,",
        "start": 754.55,
        "duration": 1.62
    },
    {
        "text": "so there's first-class support for things like",
        "start": 756.17,
        "duration": 2.04
    },
    {
        "text": "TensorFlow and PyTorch in the SDK.",
        "start": 758.21,
        "duration": 2.175
    },
    {
        "text": ">> That's absolutely right.",
        "start": 760.385,
        "duration": 0.9
    },
    {
        "text": ">> That's cool.",
        "start": 761.285,
        "duration": 0.615
    },
    {
        "text": ">> Yeah. Then we can simply specify there train.py script,",
        "start": 761.9,
        "duration": 5.735
    },
    {
        "text": "which can be any arbitrary TensorFlow or PyTorch script.",
        "start": 767.635,
        "duration": 5.965
    },
    {
        "text": "So you don't have to add any special magic",
        "start": 773.6,
        "duration": 2.52
    },
    {
        "text": "in there to be able to use Azure Machine Learning.",
        "start": 776.12,
        "duration": 2.4
    },
    {
        "text": ">> So if you already have something that's working,",
        "start": 778.52,
        "duration": 1.755
    },
    {
        "text": "just put it up there and we got it.",
        "start": 780.275,
        "duration": 1.515
    },
    {
        "text": ">> That's exactly right.",
        "start": 781.79,
        "duration": 1.95
    },
    {
        "text": "However, if you want to make some small changes like include",
        "start": 783.74,
        "duration": 3.03
    },
    {
        "text": "the run.log mechanism in our SDK,",
        "start": 786.77,
        "duration": 3.495
    },
    {
        "text": "then that will take lost metrics or",
        "start": 790.265,
        "duration": 2.715
    },
    {
        "text": "any other metrics and it will store them in the Cloud with",
        "start": 792.98,
        "duration": 3.24
    },
    {
        "text": "that run so then when you have that lineage back",
        "start": 796.22,
        "duration": 2.94
    },
    {
        "text": "from the model looking at what experiment was run,",
        "start": 799.16,
        "duration": 3.015
    },
    {
        "text": "then all the key metrics get stored as well.",
        "start": 802.175,
        "duration": 2.735
    },
    {
        "text": ">> That's awesome.",
        "start": 804.91,
        "duration": 0.83
    },
    {
        "text": ">> Along with all of your log files.",
        "start": 805.74,
        "duration": 1.14
    },
    {
        "text": ">> That way when you hire your brand new data scientist,",
        "start": 806.88,
        "duration": 2.115
    },
    {
        "text": "Sally, who is a rockstar data scientist,",
        "start": 808.995,
        "duration": 2.359
    },
    {
        "text": "she can come in and look at what",
        "start": 811.354,
        "duration": 1.921
    },
    {
        "text": "the organization has done",
        "start": 813.275,
        "duration": 1.785
    },
    {
        "text": "historically and be able to move forward.",
        "start": 815.06,
        "duration": 1.8
    },
    {
        "text": "Generally, a data scientist comes in and they're like, \"All right,",
        "start": 816.86,
        "duration": 2.055
    },
    {
        "text": "I got to start from scratch,\" but",
        "start": 818.915,
        "duration": 1.395
    },
    {
        "text": "here they have all the history of everything ever run.",
        "start": 820.31,
        "duration": 1.605
    },
    {
        "text": ">> Yeah.",
        "start": 821.915,
        "duration": 0.285
    },
    {
        "text": ">> That's cool.",
        "start": 822.2,
        "duration": 0.435
    },
    {
        "text": ">> Yeah, absolutely.",
        "start": 822.635,
        "duration": 1.29
    },
    {
        "text": ">> But here's the thing, I like TensorFlow,",
        "start": 823.925,
        "duration": 3.55
    },
    {
        "text": "and we didn't rehearse this at all,",
        "start": 827.475,
        "duration": 1.875
    },
    {
        "text": "but I like to use TensorBoard,",
        "start": 829.35,
        "duration": 2.19
    },
    {
        "text": "do you have something for that?",
        "start": 831.54,
        "duration": 1.965
    },
    {
        "text": ">> I do.",
        "start": 833.505,
        "duration": 0.9
    },
    {
        "text": ">> What?",
        "start": 834.405,
        "duration": 0.765
    },
    {
        "text": ">> Absolutely. So you can see it from using Azure ML TensorBoard,",
        "start": 835.17,
        "duration": 4.19
    },
    {
        "text": "we can export all of those key metrics to TensorBoard format or",
        "start": 839.36,
        "duration": 4.005
    },
    {
        "text": "use the existing TensorBoard logs if you're",
        "start": 843.365,
        "duration": 1.995
    },
    {
        "text": "logging into TensorBoard in your experiment,",
        "start": 845.36,
        "duration": 2.465
    },
    {
        "text": "and then that'll start a TensorBoard session.",
        "start": 847.825,
        "duration": 3.605
    },
    {
        "text": ">> So that the regular TensorBoard",
        "start": 851.43,
        "duration": 2.18
    },
    {
        "text": "that I know and love is all here?",
        "start": 853.61,
        "duration": 2.055
    },
    {
        "text": ">> Yeah, absolutely.",
        "start": 855.665,
        "duration": 2.235
    },
    {
        "text": "Now, sometimes to get the best quality model,",
        "start": 857.9,
        "duration": 5.255
    },
    {
        "text": "we need to iterate over",
        "start": 863.155,
        "duration": 1.255
    },
    {
        "text": "multiple hyperparameters and try and figure out the best values.",
        "start": 864.41,
        "duration": 3.63
    },
    {
        "text": "So we have an automated",
        "start": 868.04,
        "duration": 1.83
    },
    {
        "text": "hyperparameters sweep built-in here as well.",
        "start": 869.87,
        "duration": 2.75
    },
    {
        "text": "So we can see we run multiple attempts to find",
        "start": 872.62,
        "duration": 3.4
    },
    {
        "text": "the best values to get",
        "start": 876.02,
        "duration": 1.26
    },
    {
        "text": "the highest quality model before deploying that to production.",
        "start": 877.28,
        "duration": 2.91
    },
    {
        "text": ">> That's cool. Like different learning rates,",
        "start": 880.19,
        "duration": 1.62
    },
    {
        "text": "different batch sizes, stuff like that.",
        "start": 881.81,
        "duration": 1.41
    },
    {
        "text": ">> Yeah, that's right.",
        "start": 883.22,
        "duration": 1.665
    },
    {
        "text": "Now to facilitate deploying these models to production,",
        "start": 884.885,
        "duration": 4.695
    },
    {
        "text": "we've automated this process with",
        "start": 889.58,
        "duration": 3.015
    },
    {
        "text": "Azure Machine Learning and Azure DevOps to",
        "start": 892.595,
        "duration": 3.405
    },
    {
        "text": "facilitate bringing together the best of what data scientists",
        "start": 896.0,
        "duration": 3.42
    },
    {
        "text": "do with the best of what engineers",
        "start": 899.42,
        "duration": 1.74
    },
    {
        "text": "do and enable them to collaborate easily.",
        "start": 901.16,
        "duration": 2.44
    },
    {
        "text": ">> That's cool because generally, most models die.",
        "start": 903.6,
        "duration": 2.865
    },
    {
        "text": "The model is great, but then nothing happens,",
        "start": 906.465,
        "duration": 2.365
    },
    {
        "text": "I wanted to see what we're doing to go the last mile and this is",
        "start": 908.83,
        "duration": 2.65
    },
    {
        "text": "what you're talking about Azure DevOps",
        "start": 911.48,
        "duration": 1.32
    },
    {
        "text": "and Azure Machine Learning together.",
        "start": 912.8,
        "duration": 1.395
    },
    {
        "text": ">> That's right.",
        "start": 914.195,
        "duration": 0.765
    },
    {
        "text": ">> How does it look?",
        "start": 914.96,
        "duration": 0.585
    },
    {
        "text": ">> So we can see here I've got",
        "start": 915.545,
        "duration": 1.785
    },
    {
        "text": "a build which is simply going to run",
        "start": 917.33,
        "duration": 3.09
    },
    {
        "text": "an Azure Machine Learning pipeline",
        "start": 920.42,
        "duration": 2.43
    },
    {
        "text": "to train the machine learning model,",
        "start": 922.85,
        "duration": 3.03
    },
    {
        "text": "and then register that model",
        "start": 925.88,
        "duration": 1.71
    },
    {
        "text": "in the model registry that we saw before,",
        "start": 927.59,
        "duration": 1.73
    },
    {
        "text": "different models in the different versions.",
        "start": 929.32,
        "duration": 2.11
    },
    {
        "text": "So to create that pipeline,",
        "start": 931.43,
        "duration": 1.99
    },
    {
        "text": "then we'll go through the process of",
        "start": 933.42,
        "duration": 3.57
    },
    {
        "text": "creating a process whereby",
        "start": 936.99,
        "duration": 2.52
    },
    {
        "text": "we have the scoring script and the animals script.",
        "start": 939.51,
        "duration": 2.75
    },
    {
        "text": "This will facilitate creating",
        "start": 942.26,
        "duration": 1.71
    },
    {
        "text": "a Docker container to make the deployment super repeatable.",
        "start": 943.97,
        "duration": 3.34
    },
    {
        "text": ">> I see. So for the inference part of the thing,",
        "start": 947.31,
        "duration": 2.52
    },
    {
        "text": "we can have our own scoring mechanism.",
        "start": 949.83,
        "duration": 2.6
    },
    {
        "text": "We just have to adhere to whatever protocol we have.",
        "start": 952.43,
        "duration": 2.4
    },
    {
        "text": ">> Yeah, that's absolutely right.",
        "start": 954.83,
        "duration": 1.695
    },
    {
        "text": ">> If I remember right, it's just literally",
        "start": 956.525,
        "duration": 1.185
    },
    {
        "text": "an init method and a run method.",
        "start": 957.71,
        "duration": 1.57
    },
    {
        "text": "You just have to have those two and you're good.",
        "start": 959.28,
        "duration": 1.57
    },
    {
        "text": ">> Yeah.",
        "start": 960.85,
        "duration": 0.305
    },
    {
        "text": ">> Cool.",
        "start": 961.155,
        "duration": 0.375
    },
    {
        "text": ">> Yeah, absolutely.",
        "start": 961.53,
        "duration": 1.395
    },
    {
        "text": "So then we can facilitate deploying",
        "start": 962.925,
        "duration": 3.514
    },
    {
        "text": "those using a release pipeline.",
        "start": 966.439,
        "duration": 3.826
    },
    {
        "text": "So we can trigger the release to say an Azure Container instance,",
        "start": 970.265,
        "duration": 3.735
    },
    {
        "text": "run some integration test cases,",
        "start": 974.0,
        "duration": 2.34
    },
    {
        "text": "and then if they pass,",
        "start": 976.34,
        "duration": 1.835
    },
    {
        "text": "then we can facilitate deploying that to",
        "start": 978.175,
        "duration": 2.695
    },
    {
        "text": "the Azure Kubernetes service which is fully",
        "start": 980.87,
        "duration": 2.34
    },
    {
        "text": "integrated with Azure Machine Learning as well.",
        "start": 983.21,
        "duration": 2.37
    },
    {
        "text": ">> That's cool. So this is all nice and good.",
        "start": 985.58,
        "duration": 2.325
    },
    {
        "text": "Can you show us how we can use the model natively?",
        "start": 987.905,
        "duration": 3.8
    },
    {
        "text": ">> Yeah, absolutely.",
        "start": 991.705,
        "duration": 1.46
    },
    {
        "text": "So oftentimes,",
        "start": 993.165,
        "duration": 1.86
    },
    {
        "text": "people simply want to enrich",
        "start": 995.025,
        "duration": 1.505
    },
    {
        "text": "their data with the predictive power of the model,",
        "start": 996.53,
        "duration": 2.835
    },
    {
        "text": "and there's no better place to do that than in Power BI.",
        "start": 999.365,
        "duration": 3.015
    },
    {
        "text": ">> Of course because the pictures are beautiful.",
        "start": 1002.38,
        "duration": 2.03
    },
    {
        "text": ">> They absolutely are.",
        "start": 1004.41,
        "duration": 1.39
    },
    {
        "text": "So in this case,",
        "start": 1005.8,
        "duration": 1.11
    },
    {
        "text": "I have a dashboard that shows how to use",
        "start": 1006.91,
        "duration": 2.73
    },
    {
        "text": "that machine learning model in Power BI,",
        "start": 1009.64,
        "duration": 3.125
    },
    {
        "text": "and we can see the predictions of",
        "start": 1012.765,
        "duration": 2.36
    },
    {
        "text": "flight delays by different airports or by carriers,",
        "start": 1015.125,
        "duration": 3.405
    },
    {
        "text": "and we even used a new key influencer widget",
        "start": 1018.53,
        "duration": 2.96
    },
    {
        "text": "here to see what characteristics of",
        "start": 1021.49,
        "duration": 2.76
    },
    {
        "text": "that data has the strongest predictive power to",
        "start": 1024.25,
        "duration": 3.12
    },
    {
        "text": "determine whether the flight is going to be delayed or not.",
        "start": 1027.37,
        "duration": 3.27
    },
    {
        "text": ">> How do you hook this all up though,",
        "start": 1030.64,
        "duration": 1.35
    },
    {
        "text": "it seems to magical to me?",
        "start": 1031.99,
        "duration": 1.235
    },
    {
        "text": ">> Yeah. So with a Power BI data flows,",
        "start": 1033.225,
        "duration": 2.4
    },
    {
        "text": "we can incorporate these new AI insights which have",
        "start": 1035.625,
        "duration": 3.34
    },
    {
        "text": "either the Azure Cognitive Services",
        "start": 1038.965,
        "duration": 2.085
    },
    {
        "text": "or Azure Machine Learning models,",
        "start": 1041.05,
        "duration": 1.59
    },
    {
        "text": "built right into the data flow,",
        "start": 1042.64,
        "duration": 1.43
    },
    {
        "text": "so it enriches all the rows in",
        "start": 1044.07,
        "duration": 1.72
    },
    {
        "text": "your dataset with the results of that model.",
        "start": 1045.79,
        "duration": 3.0
    },
    {
        "text": ">> That's awesome.",
        "start": 1048.79,
        "duration": 0.48
    },
    {
        "text": ">> So here I can discover all the different deployed models that I",
        "start": 1049.27,
        "duration": 3.39
    },
    {
        "text": "have in Azure Container Instance or an Azure Kubernetes Service,",
        "start": 1052.66,
        "duration": 3.92
    },
    {
        "text": "map the fields of my dataset,",
        "start": 1056.58,
        "duration": 2.094
    },
    {
        "text": "and then I can see the results right here in Power BI.",
        "start": 1058.674,
        "duration": 4.226
    },
    {
        "text": ">> That goes directly into the visualizations.",
        "start": 1062.9,
        "duration": 2.51
    },
    {
        "text": ">> That's right.",
        "start": 1065.41,
        "duration": 0.66
    },
    {
        "text": ">> All right. Well, that was kind of a whirlwind tour.",
        "start": 1066.07,
        "duration": 3.06
    },
    {
        "text": "Anything else you'd like to add?",
        "start": 1069.13,
        "duration": 2.17
    },
    {
        "text": ">> Fundamentally, Azure Machine Learning is",
        "start": 1071.53,
        "duration": 3.915
    },
    {
        "text": "the best place for",
        "start": 1075.445,
        "duration": 1.485
    },
    {
        "text": "enterprises to bring together all of their data,",
        "start": 1076.93,
        "duration": 2.4
    },
    {
        "text": "their compute to empower their data scientists",
        "start": 1079.33,
        "duration": 2.25
    },
    {
        "text": "to collaborate on training great models,",
        "start": 1081.58,
        "duration": 2.86
    },
    {
        "text": "and then deploying those with",
        "start": 1084.44,
        "duration": 1.64
    },
    {
        "text": "the best practices for what we call MLOps",
        "start": 1086.08,
        "duration": 3.525
    },
    {
        "text": "to ensure that those models can actually get out to",
        "start": 1089.605,
        "duration": 2.535
    },
    {
        "text": "production and have high value for your business.",
        "start": 1092.14,
        "duration": 3.06
    },
    {
        "text": ">> Fantastic. Now if you felt like we went really fast,",
        "start": 1095.2,
        "duration": 2.505
    },
    {
        "text": "take a break because that's all that's",
        "start": 1097.705,
        "duration": 1.965
    },
    {
        "text": "new in Azure Machine Learning from data,",
        "start": 1099.67,
        "duration": 1.8
    },
    {
        "text": "all the way to deployed models.",
        "start": 1101.47,
        "duration": 1.41
    },
    {
        "text": "Thank you so much for watching.",
        "start": 1102.88,
        "duration": 1.17
    },
    {
        "text": "Thank you for being here.",
        "start": 1104.05,
        "duration": 1.035
    },
    {
        "text": "We'll see you next time. Take care.",
        "start": 1105.085,
        "duration": 1.275
    },
    {
        "text": ">> Thank you.",
        "start": 1106.36,
        "duration": 1.51
    }
]