[
    {
        "text": ">> You're not going to want to miss this episode of The AI Show,",
        "start": 0.0,
        "duration": 2.58
    },
    {
        "text": "where Sethu talks all about a brand new feature in",
        "start": 2.58,
        "duration": 2.97
    },
    {
        "text": "Azure Machine Learning called",
        "start": 5.55,
        "duration": 1.23
    },
    {
        "text": "Managed Endpoints. Make sure you tune in.",
        "start": 6.78,
        "duration": 2.04
    },
    {
        "text": "[MUSIC]",
        "start": 8.82,
        "duration": 7.65
    },
    {
        "text": ">> Hello and welcome to this episode of The AI Show.",
        "start": 16.47,
        "duration": 2.1
    },
    {
        "text": "We're talking all about Managed Endpoints.",
        "start": 18.57,
        "duration": 2.1
    },
    {
        "text": "I've got a special guest. Sethu, why don't you introduce yourself,",
        "start": 20.67,
        "duration": 2.28
    },
    {
        "text": "tell us who you are and what you do my friend.",
        "start": 22.95,
        "duration": 1.71
    },
    {
        "text": ">> Hey, Seth. My name is Sethu Raman,",
        "start": 24.66,
        "duration": 2.94
    },
    {
        "text": "I'm a Product Manager in Azure ML,",
        "start": 27.6,
        "duration": 2.61
    },
    {
        "text": "focusing primarily in the [inaudible] side of things.",
        "start": 30.21,
        "duration": 3.37
    },
    {
        "text": ">> Fantastic.",
        "start": 33.58,
        "duration": 2.155
    },
    {
        "text": "Let's start fast with,",
        "start": 35.735,
        "duration": 1.77
    },
    {
        "text": "look, Software deployments in general are hard.",
        "start": 37.505,
        "duration": 5.72
    },
    {
        "text": "It's got to be even harder with Machine Learning and",
        "start": 43.225,
        "duration": 3.625
    },
    {
        "text": "with machine-learning based software,",
        "start": 46.85,
        "duration": 2.265
    },
    {
        "text": "what are you-all doing to help?",
        "start": 49.115,
        "duration": 2.125
    },
    {
        "text": ">> We've been hearing from a lot of",
        "start": 51.79,
        "duration": 2.11
    },
    {
        "text": "our customers who have been working with us,",
        "start": 53.9,
        "duration": 2.01
    },
    {
        "text": "and we'll be releasing this new capability",
        "start": 55.91,
        "duration": 3.33
    },
    {
        "text": "called Managed Online Endpoints",
        "start": 59.24,
        "duration": 2.025
    },
    {
        "text": "as a part of public review in Build,",
        "start": 61.265,
        "duration": 2.01
    },
    {
        "text": "which gives users the ability to bring their model and",
        "start": 63.275,
        "duration": 4.005
    },
    {
        "text": "deploy it across powerful GPU and CPU compute in Azure.",
        "start": 67.28,
        "duration": 4.68
    },
    {
        "text": "Primarily, I want to call out three things, Seth.",
        "start": 71.96,
        "duration": 2.745
    },
    {
        "text": ">> Okay.",
        "start": 74.705,
        "duration": 0.415
    },
    {
        "text": ">> First one is the managed infrastructure.",
        "start": 75.12,
        "duration": 2.6
    },
    {
        "text": "Users need not worry about creating a cluster,",
        "start": 77.72,
        "duration": 2.97
    },
    {
        "text": "upgrading it, and so on.",
        "start": 80.69,
        "duration": 2.38
    },
    {
        "text": "The system takes care of",
        "start": 83.07,
        "duration": 1.55
    },
    {
        "text": "the underlying patching of the software host,",
        "start": 84.62,
        "duration": 4.395
    },
    {
        "text": "upgrading the host images,",
        "start": 89.015,
        "duration": 1.47
    },
    {
        "text": "decoding them failure, all of this is handled for you.",
        "start": 90.485,
        "duration": 3.45
    },
    {
        "text": "The second thing is we spent a lot of time thinking about",
        "start": 93.935,
        "duration": 3.27
    },
    {
        "text": "the ops support for Machine Learning.",
        "start": 97.205,
        "duration": 3.555
    },
    {
        "text": "Here, we give users the ability to do",
        "start": 100.76,
        "duration": 2.76
    },
    {
        "text": "safe roll out of their models",
        "start": 103.52,
        "duration": 1.59
    },
    {
        "text": "using [inaudible] support for blue-green.",
        "start": 105.11,
        "duration": 2.405
    },
    {
        "text": "Deployment we give a built-in support",
        "start": 107.515,
        "duration": 4.045
    },
    {
        "text": "for Azure Monitor integration to give SLA monitoring,",
        "start": 111.56,
        "duration": 3.855
    },
    {
        "text": "and then we also integrate with",
        "start": 115.415,
        "duration": 1.86
    },
    {
        "text": "log analytics and app insights and more.",
        "start": 117.275,
        "duration": 3.26
    },
    {
        "text": "The third thing is debuggability.",
        "start": 120.535,
        "duration": 2.69
    },
    {
        "text": "One primary thing I want to call out here is",
        "start": 123.225,
        "duration": 2.335
    },
    {
        "text": "the local endpoint support that users would be able",
        "start": 125.56,
        "duration": 3.55
    },
    {
        "text": "to deploy and test and debug",
        "start": 129.11,
        "duration": 3.105
    },
    {
        "text": "iteratively the endpoint logic in their local docker container.",
        "start": 132.215,
        "duration": 5.055
    },
    {
        "text": "I want to talk about a new concept we are introducing here,",
        "start": 137.27,
        "duration": 4.02
    },
    {
        "text": "which is the endpoint and the deployments.",
        "start": 141.29,
        "duration": 3.275
    },
    {
        "text": "Here, they picks clients that",
        "start": 144.565,
        "duration": 2.21
    },
    {
        "text": "score want to do the invocation hit an endpoint,",
        "start": 146.775,
        "duration": 4.12
    },
    {
        "text": "and the endpoint has the SSL termination.",
        "start": 150.895,
        "duration": 4.895
    },
    {
        "text": "It has got the op, and it has got a traffic split logic there.",
        "start": 155.79,
        "duration": 4.475
    },
    {
        "text": "Users have an endpoints,",
        "start": 160.265,
        "duration": 2.055
    },
    {
        "text": "the developers deploy an endpoint",
        "start": 162.32,
        "duration": 1.89
    },
    {
        "text": "and then multiple deployments underneath this.",
        "start": 164.21,
        "duration": 3.035
    },
    {
        "text": "Deployment, you can have more than one.",
        "start": 167.245,
        "duration": 2.125
    },
    {
        "text": "In this example, you can see I've got a blue and a green.",
        "start": 169.37,
        "duration": 2.46
    },
    {
        "text": "Blue is running at different version of the model that's",
        "start": 171.83,
        "duration": 2.49
    },
    {
        "text": "running CPU machines and green is running on GPU machines,",
        "start": 174.32,
        "duration": 2.91
    },
    {
        "text": "you'll be able to do safe roll out using",
        "start": 177.23,
        "duration": 3.0
    },
    {
        "text": "the endpoint and the deployments and the managed endpoints.",
        "start": 180.23,
        "duration": 3.665
    },
    {
        "text": ">> This is really cool",
        "start": 183.895,
        "duration": 1.625
    },
    {
        "text": "because rolling out software safely is hard,",
        "start": 185.52,
        "duration": 4.98
    },
    {
        "text": "and being able to do with Machine Learning is even better.",
        "start": 190.5,
        "duration": 2.105
    },
    {
        "text": "Can you show us how it works?",
        "start": 192.605,
        "duration": 1.65
    },
    {
        "text": ">> Absolutely, Seth. Here, you can see I have two folders.",
        "start": 194.255,
        "duration": 6.07
    },
    {
        "text": "First of all, I'll tell you what I'm trying to do here.",
        "start": 200.325,
        "duration": 2.3
    },
    {
        "text": "I'm going to deploy a Machine Learning model",
        "start": 202.625,
        "duration": 4.755
    },
    {
        "text": "in GPU servers in Azure,",
        "start": 207.38,
        "duration": 1.515
    },
    {
        "text": "so that's what we're trying to do here.",
        "start": 208.895,
        "duration": 2.04
    },
    {
        "text": "You can see two folders here.",
        "start": 210.935,
        "duration": 2.07
    },
    {
        "text": "One is the GPT-2 model,",
        "start": 213.005,
        "duration": 1.455
    },
    {
        "text": "so in this case I'm using a GPT-2.",
        "start": 214.46,
        "duration": 1.875
    },
    {
        "text": "Machine Learning model is a popular model",
        "start": 216.335,
        "duration": 1.755
    },
    {
        "text": "for natural language generation.",
        "start": 218.09,
        "duration": 1.455
    },
    {
        "text": "I just flaunt it from hugging page.",
        "start": 219.545,
        "duration": 1.59
    },
    {
        "text": "It's a open source repo.",
        "start": 221.135,
        "duration": 1.565
    },
    {
        "text": "Then I've got an Azure directory",
        "start": 222.7,
        "duration": 2.92
    },
    {
        "text": "in which I have three files that you need for the deployment.",
        "start": 225.62,
        "duration": 3.16
    },
    {
        "text": "One is the score.py,",
        "start": 228.78,
        "duration": 1.355
    },
    {
        "text": "which has the logic for loading and storing the file.",
        "start": 230.135,
        "duration": 3.12
    },
    {
        "text": "Then you have your python dependencies in the command YAML,",
        "start": 233.255,
        "duration": 2.955
    },
    {
        "text": "and then finally you have the endpoint YAML here.",
        "start": 236.21,
        "duration": 2.585
    },
    {
        "text": "The endpoint YAML, just is a configuration for wiring up",
        "start": 238.795,
        "duration": 3.73
    },
    {
        "text": "all your inputs that are needed to deploy create the model,",
        "start": 242.525,
        "duration": 4.065
    },
    {
        "text": "so you have the endpoint later detail,",
        "start": 246.59,
        "duration": 2.19
    },
    {
        "text": "which is the name and ought and traffic",
        "start": 248.78,
        "duration": 1.95
    },
    {
        "text": "details and the deployment,",
        "start": 250.73,
        "duration": 2.229
    },
    {
        "text": "you can here only one deployment in blue,",
        "start": 252.959,
        "duration": 2.616
    },
    {
        "text": "you have model specific details, code details.",
        "start": 255.575,
        "duration": 2.805
    },
    {
        "text": "You're giving all these wiring of",
        "start": 258.38,
        "duration": 1.11
    },
    {
        "text": "these details for deployment, and finally,",
        "start": 259.49,
        "duration": 1.8
    },
    {
        "text": "you have GPU machine instance type.",
        "start": 261.29,
        "duration": 3.03
    },
    {
        "text": "It's clear you want to use for GPU.",
        "start": 264.32,
        "duration": 2.06
    },
    {
        "text": "Once you set this up, the only prerequisite to",
        "start": 266.38,
        "duration": 3.64
    },
    {
        "text": "create this endpoint is you need to have",
        "start": 270.02,
        "duration": 2.22
    },
    {
        "text": "Azure in My Workspace no other prerequisite.",
        "start": 272.24,
        "duration": 2.57
    },
    {
        "text": "I'm running this single command which is azml Endpoint",
        "start": 274.81,
        "duration": 4.04
    },
    {
        "text": "Create from my CMI and just passing this YAML file.",
        "start": 278.85,
        "duration": 4.155
    },
    {
        "text": "Once you do that, you will get endpoint,",
        "start": 283.005,
        "duration": 2.915
    },
    {
        "text": "which is going to be deployed in Azure in",
        "start": 285.92,
        "duration": 2.025
    },
    {
        "text": "the GPU nodes and you get a rest endpoint for scoring.",
        "start": 287.945,
        "duration": 3.66
    },
    {
        "text": "In order to save time,",
        "start": 291.605,
        "duration": 2.415
    },
    {
        "text": "I'm going to run these commands and I'm going to",
        "start": 294.02,
        "duration": 2.67
    },
    {
        "text": "show you how the experience works in hindsight.",
        "start": 296.69,
        "duration": 2.49
    },
    {
        "text": ">> Got it.",
        "start": 299.18,
        "duration": 1.45
    },
    {
        "text": ">> I've run this command here.",
        "start": 300.68,
        "duration": 2.37
    },
    {
        "text": "It takes a few minutes and you can see that,",
        "start": 303.05,
        "duration": 2.37
    },
    {
        "text": "hey, the whole thing is done,",
        "start": 305.42,
        "duration": 1.245
    },
    {
        "text": "the model is registered,",
        "start": 306.665,
        "duration": 1.2
    },
    {
        "text": "I've got an endpoint created,",
        "start": 307.865,
        "duration": 1.94
    },
    {
        "text": "now let's pull the endpoint details.",
        "start": 309.805,
        "duration": 2.225
    },
    {
        "text": "In order to score it, we need two details.",
        "start": 312.03,
        "duration": 1.725
    },
    {
        "text": "We need these coding URI and the auth details,",
        "start": 313.755,
        "duration": 2.815
    },
    {
        "text": "so I'm using a shell command here to pull the coding URI here.",
        "start": 316.57,
        "duration": 5.005
    },
    {
        "text": "Here, I can see this coding URI good,",
        "start": 321.575,
        "duration": 3.55
    },
    {
        "text": "and I have a command for pulling the auth, again,",
        "start": 325.125,
        "duration": 2.765
    },
    {
        "text": "credentials, and I have actually filled in the details",
        "start": 327.89,
        "duration": 2.79
    },
    {
        "text": "here is a rest client similarly to a postman but bit into VS code,",
        "start": 330.68,
        "duration": 3.03
    },
    {
        "text": "but you can use a rest client of your choice.",
        "start": 333.71,
        "duration": 2.16
    },
    {
        "text": "Here I have put the details of",
        "start": 335.87,
        "duration": 1.65
    },
    {
        "text": "the URI and the token information here.",
        "start": 337.52,
        "duration": 3.315
    },
    {
        "text": "This is the input [inaudible] and",
        "start": 340.835,
        "duration": 2.415
    },
    {
        "text": "I expect the Machine Learning model to auto",
        "start": 343.25,
        "duration": 1.5
    },
    {
        "text": "complete so is making an invocation right",
        "start": 344.75,
        "duration": 1.83
    },
    {
        "text": "now and executing in the GPU nodes,",
        "start": 346.58,
        "duration": 2.505
    },
    {
        "text": "and there is our response here.",
        "start": 349.085,
        "duration": 2.335
    },
    {
        "text": "It generated some interesting text here.",
        "start": 351.74,
        "duration": 3.27
    },
    {
        "text": ">> That's cool.",
        "start": 355.01,
        "duration": 0.63
    },
    {
        "text": ">> This shows you how you are able to deploy",
        "start": 355.64,
        "duration": 2.82
    },
    {
        "text": "a model into GPU and get an endpoint within a few steps,",
        "start": 358.46,
        "duration": 4.78
    },
    {
        "text": "so this is all well and good.",
        "start": 363.24,
        "duration": 1.995
    },
    {
        "text": "I also wanted to show you how users can debug this.",
        "start": 365.235,
        "duration": 5.85
    },
    {
        "text": "People who have tried to deploy models into",
        "start": 371.085,
        "duration": 2.645
    },
    {
        "text": "Cloud know how difficult it is to debug their models,",
        "start": 373.73,
        "duration": 2.85
    },
    {
        "text": "because whenever you want to make a change,",
        "start": 376.58,
        "duration": 1.56
    },
    {
        "text": "you want to wait for a few minutes,",
        "start": 378.14,
        "duration": 1.23
    },
    {
        "text": "it goes to the Cloud and deploy it.",
        "start": 379.37,
        "duration": 1.8
    },
    {
        "text": "Here what we have is a concept of local deployments.",
        "start": 381.17,
        "duration": 4.055
    },
    {
        "text": "In this, you are able to create any command that we run,",
        "start": 385.225,
        "duration": 4.6
    },
    {
        "text": "you are able to run that, and all you can do",
        "start": 389.825,
        "duration": 2.505
    },
    {
        "text": "is just do a dash dash local in the end.",
        "start": 392.33,
        "duration": 2.985
    },
    {
        "text": "In this case, we're doing a azml endpoint create,",
        "start": 395.315,
        "duration": 3.36
    },
    {
        "text": "and you have to do a dash dash local.",
        "start": 398.675,
        "duration": 3.28
    },
    {
        "text": "I think when I zoomed in,",
        "start": 401.955,
        "duration": 1.845
    },
    {
        "text": "some of the CLA got clipped here.",
        "start": 403.8,
        "duration": 2.34
    },
    {
        "text": ">> Yeah.",
        "start": 406.14,
        "duration": 0.275
    },
    {
        "text": ">> But I'll show you how it looks.",
        "start": 406.415,
        "duration": 2.505
    },
    {
        "text": "The same command that we did,",
        "start": 408.92,
        "duration": 1.575
    },
    {
        "text": "you just do a flag here dash dash local and you'll",
        "start": 410.495,
        "duration": 3.945
    },
    {
        "text": "be able to execute all of",
        "start": 414.44,
        "duration": 1.59
    },
    {
        "text": "these commands like az ml endpoint invoke,",
        "start": 416.03,
        "duration": 2.505
    },
    {
        "text": "and gate logs, all of them,",
        "start": 418.535,
        "duration": 2.4
    },
    {
        "text": "you'd be able to do, like debug locally in docker container.",
        "start": 420.935,
        "duration": 4.29
    },
    {
        "text": ">> This is so easy.",
        "start": 425.225,
        "duration": 1.425
    },
    {
        "text": ">> Yeah.",
        "start": 426.65,
        "duration": 0.42
    },
    {
        "text": ">> This isn't so hard to do.",
        "start": 427.07,
        "duration": 1.795
    },
    {
        "text": ">> Exactly. I want to show you",
        "start": 428.865,
        "duration": 1.37
    },
    {
        "text": "because the information got clipped.",
        "start": 430.235,
        "duration": 1.44
    },
    {
        "text": "I will show you how it is done. Here's what we do.",
        "start": 431.675,
        "duration": 2.945
    },
    {
        "text": "When you do this, you create",
        "start": 434.62,
        "duration": 2.15
    },
    {
        "text": "the same YAML that you used for production,",
        "start": 436.77,
        "duration": 1.86
    },
    {
        "text": "but you just do dash dash local,",
        "start": 438.63,
        "duration": 1.35
    },
    {
        "text": "so it's going to deploy in a local docker image.",
        "start": 439.98,
        "duration": 1.98
    },
    {
        "text": ">> That's really cool.",
        "start": 441.96,
        "duration": 1.755
    },
    {
        "text": ">> There's first part of the demo,",
        "start": 443.715,
        "duration": 1.575
    },
    {
        "text": "now let's go to the part that you asked with a safe roll out,",
        "start": 445.29,
        "duration": 4.65
    },
    {
        "text": "how can users do the safe roll out?",
        "start": 449.94,
        "duration": 1.74
    },
    {
        "text": ">> Let's hit Control plus just a couple of",
        "start": 451.68,
        "duration": 1.79
    },
    {
        "text": "times to make sure we can see the text.",
        "start": 453.47,
        "duration": 2.195
    },
    {
        "text": ">> Yes.",
        "start": 455.665,
        "duration": 1.355
    },
    {
        "text": ">> There you go.",
        "start": 457.02,
        "duration": 2.14
    },
    {
        "text": ">> Here in this part of the demo,",
        "start": 461.57,
        "duration": 3.54
    },
    {
        "text": "I'm going to show you the safe roll out capability.",
        "start": 465.11,
        "duration": 2.625
    },
    {
        "text": "You have a linear endpoint",
        "start": 467.735,
        "duration": 2.58
    },
    {
        "text": "and a deployment which is deployed in production.",
        "start": 470.315,
        "duration": 2.475
    },
    {
        "text": "Let's say one diploma named blue,",
        "start": 472.79,
        "duration": 2.82
    },
    {
        "text": "which is up and running.",
        "start": 475.61,
        "duration": 1.2
    },
    {
        "text": "Now, I want to roll out a new model.",
        "start": 476.81,
        "duration": 3.03
    },
    {
        "text": "New what's not the model, a more efficient version.",
        "start": 479.84,
        "duration": 2.525
    },
    {
        "text": "What I'm going to do is I'm going to",
        "start": 482.365,
        "duration": 1.885
    },
    {
        "text": "update the same input, same YAML,",
        "start": 484.25,
        "duration": 2.13
    },
    {
        "text": "and I'm going to add a new deployment called green here,",
        "start": 486.38,
        "duration": 3.645
    },
    {
        "text": "and here, if you look at my scoring code,",
        "start": 490.025,
        "duration": 3.375
    },
    {
        "text": "I am purposefully putting scoring with error.",
        "start": 493.4,
        "duration": 3.33
    },
    {
        "text": "I'm introducing a parsing error so that I can show you how",
        "start": 496.73,
        "duration": 2.34
    },
    {
        "text": "users would be able to catch this unlike roll out a new version.",
        "start": 499.07,
        "duration": 3.005
    },
    {
        "text": ">> Right.",
        "start": 502.075,
        "duration": 0.635
    },
    {
        "text": ">> When I want to roll this into production,",
        "start": 502.71,
        "duration": 1.52
    },
    {
        "text": "all I need to do is do a azml endpoint",
        "start": 504.23,
        "duration": 3.015
    },
    {
        "text": "Update and just pass the name of the YAML.",
        "start": 507.245,
        "duration": 3.525
    },
    {
        "text": "You can update it in the same YAML,",
        "start": 510.77,
        "duration": 1.83
    },
    {
        "text": "but for the sake of the demo,",
        "start": 512.6,
        "duration": 1.23
    },
    {
        "text": "I created another one here.",
        "start": 513.83,
        "duration": 1.595
    },
    {
        "text": "Once I do that, let's go to",
        "start": 515.425,
        "duration": 3.625
    },
    {
        "text": "the metrics Azure Monitor integration and see what happens.",
        "start": 519.05,
        "duration": 3.725
    },
    {
        "text": "Before that, we had zero percentage traffic to green,",
        "start": 522.775,
        "duration": 3.865
    },
    {
        "text": "so let's try and divert some percentage of traffic to green.",
        "start": 526.64,
        "duration": 3.64
    },
    {
        "text": "I'm saying it's 10 percent traffic to green to start with,",
        "start": 530.28,
        "duration": 2.995
    },
    {
        "text": "and I'm clicking \"Update\".",
        "start": 533.275,
        "duration": 1.64
    },
    {
        "text": "Once I update, now",
        "start": 534.915,
        "duration": 2.135
    },
    {
        "text": "green is going to take 10 percent light traffic.",
        "start": 537.05,
        "duration": 1.83
    },
    {
        "text": "Initially it took zero percent,",
        "start": 538.88,
        "duration": 1.26
    },
    {
        "text": "now it's taking 10 percent and let go and",
        "start": 540.14,
        "duration": 2.19
    },
    {
        "text": "see the metrics whether our roll out was successful.",
        "start": 542.33,
        "duration": 2.915
    },
    {
        "text": "Here you can see in the metrics page.",
        "start": 545.245,
        "duration": 1.945
    },
    {
        "text": "The first chart shows you that the traffic split",
        "start": 547.19,
        "duration": 2.25
    },
    {
        "text": "between blue and green is good, we have 10 percent,",
        "start": 549.44,
        "duration": 2.795
    },
    {
        "text": "90 percent like 115 requests per minute",
        "start": 552.235,
        "duration": 2.115
    },
    {
        "text": "in blue and 10 request per minute in green, looks good,",
        "start": 554.35,
        "duration": 2.41
    },
    {
        "text": "but if you look at the status code split that we have here,",
        "start": 556.76,
        "duration": 2.625
    },
    {
        "text": "we're preparing on green and",
        "start": 559.385,
        "duration": 1.83
    },
    {
        "text": "we're displaying the HTTP status code.",
        "start": 561.215,
        "duration": 3.27
    },
    {
        "text": "You can see in the bottom chart",
        "start": 564.485,
        "duration": 1.605
    },
    {
        "text": "all the input that came to green are error,",
        "start": 566.09,
        "duration": 2.31
    },
    {
        "text": "the HTTP status for x x.",
        "start": 568.4,
        "duration": 2.265
    },
    {
        "text": "That means something has gone wrong in our deployment,",
        "start": 570.665,
        "duration": 2.4
    },
    {
        "text": "so what we do is we pull our log analytics",
        "start": 573.065,
        "duration": 3.539
    },
    {
        "text": "and we can pin it to green and filter on a specific time,",
        "start": 576.604,
        "duration": 4.231
    },
    {
        "text": "and actually, I can see that there is an error here.",
        "start": 580.835,
        "duration": 2.445
    },
    {
        "text": "I can see in my score.py there are some exception thrown.",
        "start": 583.28,
        "duration": 2.46
    },
    {
        "text": "Looks like a parsing error, so I found my issue.",
        "start": 585.74,
        "duration": 4.045
    },
    {
        "text": "I am going back and I'm updating the same YAML,",
        "start": 589.785,
        "duration": 2.71
    },
    {
        "text": "but this time I'm going to use a scoring fix.",
        "start": 592.495,
        "duration": 2.555
    },
    {
        "text": "I fix that scoring file",
        "start": 595.05,
        "duration": 1.52
    },
    {
        "text": "grabbing the same score.py that's updated by the day,",
        "start": 596.57,
        "duration": 2.525
    },
    {
        "text": "and I found, an Update command again.",
        "start": 599.095,
        "duration": 3.145
    },
    {
        "text": "Here you will see the power of",
        "start": 602.24,
        "duration": 2.5
    },
    {
        "text": "how we declaratively able to update the YAML,",
        "start": 604.74,
        "duration": 3.54
    },
    {
        "text": "so this is like an aligned with",
        "start": 608.28,
        "duration": 2.09
    },
    {
        "text": "the principles of [inaudible] about",
        "start": 610.37,
        "duration": 1.01
    },
    {
        "text": "where all the changes go through,",
        "start": 611.38,
        "duration": 1.27
    },
    {
        "text": "get in a declarative way and everything is audited.",
        "start": 612.65,
        "duration": 3.035
    },
    {
        "text": "Now we've fared the update and let's",
        "start": 615.685,
        "duration": 2.015
    },
    {
        "text": "see if our roll out was successful this time.",
        "start": 617.7,
        "duration": 1.785
    },
    {
        "text": "This time you hadn't notice it's an in-place Update,",
        "start": 619.485,
        "duration": 2.645
    },
    {
        "text": "the first time we did a blue-green,",
        "start": 622.13,
        "duration": 1.26
    },
    {
        "text": "now it's an in-place Update",
        "start": 623.39,
        "duration": 1.8
    },
    {
        "text": "and it's a rolling update that happens in the back-end.",
        "start": 625.19,
        "duration": 2.94
    },
    {
        "text": "We go here, hey,",
        "start": 628.13,
        "duration": 1.62
    },
    {
        "text": "it looks like all the red has gone down,",
        "start": 629.75,
        "duration": 4.08
    },
    {
        "text": "so basically all the HTTP status code 400 as going down",
        "start": 633.83,
        "duration": 3.18
    },
    {
        "text": "after we passed the fakes and all the HTTP 200 is rising up.",
        "start": 637.01,
        "duration": 3.505
    },
    {
        "text": "This basically means that our fix worked,",
        "start": 640.515,
        "duration": 2.895
    },
    {
        "text": "so all success is after the fix is done,",
        "start": 643.41,
        "duration": 2.58
    },
    {
        "text": "so this is great news.",
        "start": 645.99,
        "duration": 1.77
    },
    {
        "text": "We can go here back and Update.",
        "start": 647.76,
        "duration": 2.49
    },
    {
        "text": "We can give more traffic here,",
        "start": 650.25,
        "duration": 1.14
    },
    {
        "text": "50 percent traffic, and we can see what happens,",
        "start": 651.39,
        "duration": 2.69
    },
    {
        "text": "whether we get the CLA,",
        "start": 654.08,
        "duration": 1.59
    },
    {
        "text": "you'll be able to do that using the CLA escrow.",
        "start": 655.67,
        "duration": 3.135
    },
    {
        "text": "We are now going to see in the screen",
        "start": 658.805,
        "duration": 2.705
    },
    {
        "text": "how the 50 percent traffic looks like.",
        "start": 661.51,
        "duration": 2.215
    },
    {
        "text": "You will see that blue is coming down and green is popping up.",
        "start": 663.725,
        "duration": 5.505
    },
    {
        "text": ">> As that's coming up,",
        "start": 669.23,
        "duration": 1.32
    },
    {
        "text": "I just want people to understand because we're going fast.",
        "start": 670.55,
        "duration": 3.51
    },
    {
        "text": "Basically, you're able with the new managed points,",
        "start": 674.06,
        "duration": 4.155
    },
    {
        "text": "you're able to create deployment slots with different models.",
        "start": 678.215,
        "duration": 3.975
    },
    {
        "text": "He showed one that broke everything,",
        "start": 682.19,
        "duration": 3.525
    },
    {
        "text": "but it didn't break us because",
        "start": 685.715,
        "duration": 3.12
    },
    {
        "text": "only 10 percent of the traffic went",
        "start": 688.835,
        "duration": 1.965
    },
    {
        "text": "there and he was able to simply Update it, which is really cool.",
        "start": 690.8,
        "duration": 2.7
    },
    {
        "text": "Show us what you got right here, my friend.",
        "start": 693.5,
        "duration": 1.41
    },
    {
        "text": ">> Yeah, absolutely, Seth. Here you can see",
        "start": 694.91,
        "duration": 2.23
    },
    {
        "text": "that now after green is taking 50 percent,",
        "start": 697.14,
        "duration": 2.29
    },
    {
        "text": "you can see the traffic blue and green are like near 50-50,",
        "start": 699.43,
        "duration": 3.43
    },
    {
        "text": "so this looks good,",
        "start": 702.86,
        "duration": 1.2
    },
    {
        "text": "our traffic update worked.",
        "start": 704.06,
        "duration": 1.36
    },
    {
        "text": "We can see the latency that blue is taking 95 milliseconds and",
        "start": 705.42,
        "duration": 3.45
    },
    {
        "text": "the new efficient model just taking",
        "start": 708.87,
        "duration": 1.52
    },
    {
        "text": "23 milliseconds are p90 latency.",
        "start": 710.39,
        "duration": 2.43
    },
    {
        "text": "Our roll out is successful,",
        "start": 712.82,
        "duration": 1.455
    },
    {
        "text": "our model is efficient as we expect, so great.",
        "start": 714.275,
        "duration": 2.83
    },
    {
        "text": "Then we can of course, roll out",
        "start": 717.105,
        "duration": 1.485
    },
    {
        "text": "the 100 percent traffic and we are ready to delete blue.",
        "start": 718.59,
        "duration": 4.265
    },
    {
        "text": "This shows the journey on how user starts from playing",
        "start": 722.855,
        "duration": 5.125
    },
    {
        "text": "locally with the docker to make sure",
        "start": 727.98,
        "duration": 2.18
    },
    {
        "text": "all the core and the dependency is split.",
        "start": 730.16,
        "duration": 3.01
    },
    {
        "text": "Then move to the Cloud,",
        "start": 733.17,
        "duration": 1.605
    },
    {
        "text": "in the first version monitor SLAs,",
        "start": 734.775,
        "duration": 2.61
    },
    {
        "text": "and then going with the other second version with",
        "start": 737.385,
        "duration": 1.905
    },
    {
        "text": "a safe roll out and able",
        "start": 739.29,
        "duration": 1.86
    },
    {
        "text": "to debug any issues",
        "start": 741.15,
        "duration": 3.215
    },
    {
        "text": "and move forward and phase out the old version.",
        "start": 744.365,
        "duration": 3.29
    },
    {
        "text": ">> That was cool.",
        "start": 747.655,
        "duration": 1.415
    },
    {
        "text": "I know we went by really fast,",
        "start": 749.07,
        "duration": 1.34
    },
    {
        "text": "but that journey is super important because before",
        "start": 750.41,
        "duration": 2.88
    },
    {
        "text": "people would deploy a Flask app and everything would break.",
        "start": 753.29,
        "duration": 3.15
    },
    {
        "text": "Here, you can manage it safely with",
        "start": 756.44,
        "duration": 1.95
    },
    {
        "text": "a deployment with 10 percent and then it breaks,",
        "start": 758.39,
        "duration": 2.85
    },
    {
        "text": "you switch it out and then you move stuff up.",
        "start": 761.24,
        "duration": 1.845
    },
    {
        "text": "This is really cool, my friend.",
        "start": 763.085,
        "duration": 1.125
    },
    {
        "text": "Where can people go to find out more?",
        "start": 764.21,
        "duration": 1.685
    },
    {
        "text": ">> There is a link that's right there displayed.",
        "start": 765.895,
        "duration": 2.825
    },
    {
        "text": "People can go there and here users would be able to run",
        "start": 768.72,
        "duration": 4.05
    },
    {
        "text": "a hands-on exercise from starting to end.",
        "start": 772.77,
        "duration": 4.76
    },
    {
        "text": "Users would be able to experience this themselves.",
        "start": 777.53,
        "duration": 3.33
    },
    {
        "text": ">> Awesome Sethu. This has been amazing.",
        "start": 780.86,
        "duration": 2.94
    },
    {
        "text": "You've been learning all about Managed Endpoints.",
        "start": 783.8,
        "duration": 2.37
    },
    {
        "text": "Here on The AI Show thank you so much for",
        "start": 786.17,
        "duration": 1.62
    },
    {
        "text": "watching and hopefully we'll see you next time. Take care.",
        "start": 787.79,
        "duration": 2.1
    },
    {
        "text": "[MUSIC].",
        "start": 789.89,
        "duration": 10.61
    }
]