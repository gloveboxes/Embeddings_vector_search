[
    {
        "text": ">> You're not going to want to miss this episode of",
        "start": 0.0,
        "duration": 1.74
    },
    {
        "text": "the AI show where Jeremy Howard takes",
        "start": 1.74,
        "duration": 2.25
    },
    {
        "text": "us through how to be a deep learning practitioner.",
        "start": 3.99,
        "duration": 4.035
    },
    {
        "text": "You don't even need a PhD.",
        "start": 8.025,
        "duration": 1.77
    },
    {
        "text": "He's going to give us all the details.",
        "start": 9.795,
        "duration": 1.455
    },
    {
        "text": "Make sure you tune in.",
        "start": 11.25,
        "duration": 1.2
    },
    {
        "text": "[MUSIC].",
        "start": 12.45,
        "duration": 8.52
    },
    {
        "text": ">> Hello and welcome to this special edition of",
        "start": 20.97,
        "duration": 1.86
    },
    {
        "text": "the AI show where we've got a special guest, Jeremy Howard.",
        "start": 22.83,
        "duration": 2.79
    },
    {
        "text": "We'll talk about how to actually build",
        "start": 25.62,
        "duration": 1.98
    },
    {
        "text": "AI applications without really needing a PhD,",
        "start": 27.6,
        "duration": 3.9
    },
    {
        "text": "something I don't have.",
        "start": 31.5,
        "duration": 1.165
    },
    {
        "text": "Jeremy, why don't you tell us who you are and",
        "start": 32.665,
        "duration": 1.745
    },
    {
        "text": "what you do and how you got involved with AI?",
        "start": 34.41,
        "duration": 2.295
    },
    {
        "text": ">> Sure. I'm the co-founder of Fast.ai.",
        "start": 36.705,
        "duration": 3.975
    },
    {
        "text": "Fast.ai is a research,",
        "start": 40.68,
        "duration": 2.835
    },
    {
        "text": "teaching, and development lab based in San Francisco.",
        "start": 43.515,
        "duration": 4.15
    },
    {
        "text": "Our specialty is deep learning and",
        "start": 47.665,
        "duration": 2.245
    },
    {
        "text": "specifically about making deep learning more accessible.",
        "start": 49.91,
        "duration": 2.705
    },
    {
        "text": "We've been doing that for a few years now.",
        "start": 52.615,
        "duration": 1.855
    },
    {
        "text": "We have what might be",
        "start": 54.47,
        "duration": 1.68
    },
    {
        "text": "the most popular course in the world for deep learning.",
        "start": 56.15,
        "duration": 2.535
    },
    {
        "text": "We have one of",
        "start": 58.685,
        "duration": 1.395
    },
    {
        "text": "the world's most popular software libraries for deep learning and",
        "start": 60.08,
        "duration": 3.16
    },
    {
        "text": "our research have developed some of",
        "start": 63.24,
        "duration": 1.79
    },
    {
        "text": "the world's most important new algorithms for deep learning.",
        "start": 65.03,
        "duration": 3.18
    },
    {
        "text": "We also have a fantastic community of tens of thousands of people",
        "start": 68.21,
        "duration": 3.9
    },
    {
        "text": "who help each other out and help me",
        "start": 72.11,
        "duration": 1.89
    },
    {
        "text": "out on our deep learning journey.",
        "start": 74.0,
        "duration": 2.22
    },
    {
        "text": "It's been a real pleasure and it's been",
        "start": 76.22,
        "duration": 1.65
    },
    {
        "text": "exciting to see the impact it's had so far.",
        "start": 77.87,
        "duration": 2.48
    },
    {
        "text": ">> How did you get involved",
        "start": 80.35,
        "duration": 1.94
    },
    {
        "text": "with AI and specifically, deep learning?",
        "start": 82.29,
        "duration": 2.07
    },
    {
        "text": "Look, I went to school when SVMs were all the rage and to me,",
        "start": 84.36,
        "duration": 3.68
    },
    {
        "text": "they were beautiful because mathematically,",
        "start": 88.04,
        "duration": 1.98
    },
    {
        "text": "they were convex functions and it did really cool stuff.",
        "start": 90.02,
        "duration": 3.42
    },
    {
        "text": "How did you shift over to the world of deep learning?",
        "start": 93.44,
        "duration": 4.17
    },
    {
        "text": ">> I was the opposite.",
        "start": 97.61,
        "duration": 2.07
    },
    {
        "text": "I guess, well, I was 10 years ahead of that maybe.",
        "start": 99.68,
        "duration": 4.375
    },
    {
        "text": "I was starting my working life when neural nets",
        "start": 104.055,
        "duration": 4.005
    },
    {
        "text": "were last huge and I was using them in banking,",
        "start": 108.06,
        "duration": 4.1
    },
    {
        "text": "I was using them in marketing.",
        "start": 112.16,
        "duration": 1.365
    },
    {
        "text": "I thought they were fantastic.",
        "start": 113.525,
        "duration": 1.62
    },
    {
        "text": "But we had to spend literally millions of dollars to get",
        "start": 115.145,
        "duration": 3.465
    },
    {
        "text": "custom silicon to do anything at a working scale.",
        "start": 118.61,
        "duration": 4.68
    },
    {
        "text": "Then, SVMs came and",
        "start": 123.29,
        "duration": 4.105
    },
    {
        "text": "killed neural networks for the reason you mentioned,",
        "start": 127.395,
        "duration": 3.195
    },
    {
        "text": "all the people with",
        "start": 130.59,
        "duration": 2.53
    },
    {
        "text": "bigger brains and many folks like you",
        "start": 133.12,
        "duration": 2.02
    },
    {
        "text": "that understood all the math but well,",
        "start": 135.14,
        "duration": 1.71
    },
    {
        "text": "these are mathematically very attractive.",
        "start": 136.85,
        "duration": 1.8
    },
    {
        "text": "I'm going to focus on this.",
        "start": 138.65,
        "duration": 1.89
    },
    {
        "text": "Whereas to have boring software engineer like me,",
        "start": 140.54,
        "duration": 2.97
    },
    {
        "text": "I was like, Yeah, they don't work very well,",
        "start": 143.51,
        "duration": 2.01
    },
    {
        "text": "but don't predict my mind in",
        "start": 145.52,
        "duration": 1.825
    },
    {
        "text": "the outcomes very well",
        "start": 147.345,
        "duration": 2.165
    },
    {
        "text": "or they don't predict the financials very well.",
        "start": 149.51,
        "duration": 2.25
    },
    {
        "text": "I put everything aside for a while.",
        "start": 151.76,
        "duration": 3.39
    },
    {
        "text": "Then, in early 2000s,",
        "start": 155.15,
        "duration": 2.4
    },
    {
        "text": "the random forests came along and that was,",
        "start": 157.55,
        "duration": 3.045
    },
    {
        "text": "this is back in my territory. A simple thing.",
        "start": 160.595,
        "duration": 2.715
    },
    {
        "text": "I can code it up in two hours, it works great.",
        "start": 163.31,
        "duration": 3.57
    },
    {
        "text": "I was a President and Chief",
        "start": 167.24,
        "duration": 2.95
    },
    {
        "text": "Scientist of a company called Kaggle which",
        "start": 170.19,
        "duration": 2.15
    },
    {
        "text": "is the world's largest data science community",
        "start": 172.34,
        "duration": 2.535
    },
    {
        "text": "and a competition platform.",
        "start": 174.875,
        "duration": 2.265
    },
    {
        "text": "I had this unique position",
        "start": 177.14,
        "duration": 2.52
    },
    {
        "text": "there where I saw all the competitions coming in.",
        "start": 179.66,
        "duration": 2.43
    },
    {
        "text": "I saw opening solutions and I",
        "start": 182.09,
        "duration": 2.37
    },
    {
        "text": "saw deep learning suddenly started taking over and I was like,",
        "start": 184.46,
        "duration": 3.57
    },
    {
        "text": "hurray, neural nets that back and they're working.",
        "start": 188.03,
        "duration": 3.89
    },
    {
        "text": "I quit Kaggle and decided to really",
        "start": 191.92,
        "duration": 3.16
    },
    {
        "text": "focus on what I've been waiting decades for,",
        "start": 195.08,
        "duration": 3.165
    },
    {
        "text": "which is to bring neural networks back.",
        "start": 198.245,
        "duration": 2.355
    },
    {
        "text": ">> Now, the interesting thing about",
        "start": 200.6,
        "duration": 2.205
    },
    {
        "text": "neural networks is whenever we talk about deep learning,",
        "start": 202.805,
        "duration": 3.255
    },
    {
        "text": "there is this baggage of I know in America we say math,",
        "start": 206.06,
        "duration": 4.59
    },
    {
        "text": "but everywhere else they say maths because if feels",
        "start": 210.65,
        "duration": 2.25
    },
    {
        "text": "like deep learning has a lot of extra maths.",
        "start": 212.9,
        "duration": 2.663
    },
    {
        "text": ">> Yeah.",
        "start": 215.563,
        "duration": 0.367
    },
    {
        "text": ">> Is that a warranted thing",
        "start": 215.93,
        "duration": 1.77
    },
    {
        "text": "to assume that there's a lot of math baggage in there?",
        "start": 217.7,
        "duration": 2.735
    },
    {
        "text": ">> Yes. It turns out that it's not.",
        "start": 220.435,
        "duration": 2.12
    },
    {
        "text": "I don't have a PhD myself.",
        "start": 222.555,
        "duration": 2.295
    },
    {
        "text": "This has been a real boom for me in teaching because",
        "start": 224.85,
        "duration": 2.54
    },
    {
        "text": "I have to make things understandable for me,",
        "start": 227.39,
        "duration": 2.725
    },
    {
        "text": "and that's a really hard task.",
        "start": 230.115,
        "duration": 2.655
    },
    {
        "text": "It turns out that the actual math we need for deep learning.",
        "start": 232.77,
        "duration": 4.215
    },
    {
        "text": "Basically, you need to be able to add.",
        "start": 236.985,
        "duration": 3.235
    },
    {
        "text": "You need to be able to replace negative numbers with zeros.",
        "start": 240.22,
        "duration": 3.93
    },
    {
        "text": "You need be able to multiply.",
        "start": 244.15,
        "duration": 2.33
    },
    {
        "text": "Then, in theory, you need to be able to",
        "start": 246.48,
        "duration": 2.66
    },
    {
        "text": "take the derivatives of those things.",
        "start": 249.14,
        "duration": 2.91
    },
    {
        "text": "Fairly simple derivatives, although in practice,",
        "start": 252.05,
        "duration": 2.73
    },
    {
        "text": "actually, the libraries will do it for us.",
        "start": 254.78,
        "duration": 2.115
    },
    {
        "text": "If you can add, replace negatives with zeros,",
        "start": 256.895,
        "duration": 4.015
    },
    {
        "text": "and multiply, then you basically have",
        "start": 260.91,
        "duration": 2.04
    },
    {
        "text": "the math you need to do deep learning.",
        "start": 262.95,
        "duration": 2.845
    },
    {
        "text": ">> You've spent a lot of time.",
        "start": 265.795,
        "duration": 2.125
    },
    {
        "text": "It feels like trying to get people to understand",
        "start": 267.92,
        "duration": 2.64
    },
    {
        "text": "these primitives but in a unique way.",
        "start": 270.56,
        "duration": 3.09
    },
    {
        "text": "Tell us about the goal of",
        "start": 273.65,
        "duration": 1.5
    },
    {
        "text": "Fast.ai and what are some things available to people right now,",
        "start": 275.15,
        "duration": 3.6
    },
    {
        "text": "if they can go look at?",
        "start": 278.75,
        "duration": 1.89
    },
    {
        "text": ">> Yeah. Let me explain how we think about this.",
        "start": 280.64,
        "duration": 5.59
    },
    {
        "text": "The way we think about this is heavily influenced",
        "start": 286.23,
        "duration": 3.59
    },
    {
        "text": "by expert educators like Paul Lockhart.",
        "start": 289.82,
        "duration": 4.75
    },
    {
        "text": "The real top educators say that the way you need to teach",
        "start": 294.73,
        "duration": 4.87
    },
    {
        "text": "somebody something is to give them",
        "start": 299.6,
        "duration": 1.32
    },
    {
        "text": "context and get them in the game.",
        "start": 300.92,
        "duration": 2.64
    },
    {
        "text": "In other words, you need to say this",
        "start": 303.56,
        "duration": 1.59
    },
    {
        "text": "is why you're learning this and",
        "start": 305.15,
        "duration": 1.66
    },
    {
        "text": "let's go ahead and use this thing you're",
        "start": 306.81,
        "duration": 1.61
    },
    {
        "text": "learning right away to do something you care about.",
        "start": 308.42,
        "duration": 1.95
    },
    {
        "text": "The vast majority of deep learning and",
        "start": 310.37,
        "duration": 3.27
    },
    {
        "text": "technical subjects in more numeric subjects",
        "start": 313.64,
        "duration": 2.88
    },
    {
        "text": "have not taught like this.",
        "start": 316.52,
        "duration": 1.2
    },
    {
        "text": "It's like, let's do a year of linear algebra.",
        "start": 317.72,
        "duration": 2.47
    },
    {
        "text": "Now, we'll do a year of calculus, and then,",
        "start": 320.19,
        "duration": 2.7
    },
    {
        "text": "we might finally then start to learn",
        "start": 322.89,
        "duration": 1.46
    },
    {
        "text": "about a theory of neural networks.",
        "start": 324.35,
        "duration": 1.665
    },
    {
        "text": "Then in your graduate degree,",
        "start": 326.015,
        "duration": 1.785
    },
    {
        "text": "we might let you write some code.",
        "start": 327.8,
        "duration": 1.965
    },
    {
        "text": "Our approach is the opposite and it is much more like",
        "start": 329.765,
        "duration": 2.865
    },
    {
        "text": "the way Microsoft would",
        "start": 332.63,
        "duration": 3.04
    },
    {
        "text": "teach like here's how to getting going with Visual Studio.",
        "start": 335.67,
        "duration": 3.29
    },
    {
        "text": "It's like start Visual Studio, type this,",
        "start": 338.96,
        "duration": 2.91
    },
    {
        "text": "press \"Run\", and look,",
        "start": 341.87,
        "duration": 1.77
    },
    {
        "text": "the thing pops up and you've created an application.",
        "start": 343.64,
        "duration": 2.1
    },
    {
        "text": "Now how to deploy it, click over here and press \"Publish\".",
        "start": 345.74,
        "duration": 2.5
    },
    {
        "text": "Now, people could use replication.",
        "start": 348.24,
        "duration": 1.52
    },
    {
        "text": "With our approach with that book and with that course,",
        "start": 349.76,
        "duration": 3.45
    },
    {
        "text": "within the first half hour,",
        "start": 353.21,
        "duration": 1.65
    },
    {
        "text": "you have created a pretty close to state of",
        "start": 354.86,
        "duration": 3.15
    },
    {
        "text": "the art vision classifier yourself.",
        "start": 358.01,
        "duration": 3.485
    },
    {
        "text": "By Lesson 2, you've written",
        "start": 361.495,
        "duration": 2.54
    },
    {
        "text": "a new vision classifier that no one has ever created before,",
        "start": 364.035,
        "duration": 3.635
    },
    {
        "text": "especially using your own dataset",
        "start": 367.67,
        "duration": 2.235
    },
    {
        "text": "that you actually get with the Bing API.",
        "start": 369.905,
        "duration": 2.145
    },
    {
        "text": "You deploy it for anybody to use as a web application.",
        "start": 372.05,
        "duration": 5.054
    },
    {
        "text": "Then, we have the context,",
        "start": 377.104,
        "duration": 3.331
    },
    {
        "text": "we have the motivation,",
        "start": 380.435,
        "duration": 1.485
    },
    {
        "text": "you're building stuff that matters.",
        "start": 381.92,
        "duration": 1.395
    },
    {
        "text": "Then, we say, here's a problem.",
        "start": 383.315,
        "duration": 3.195
    },
    {
        "text": "It doesn't understand this category",
        "start": 386.51,
        "duration": 2.07
    },
    {
        "text": "very well or it doesn't handle false negatives very well.",
        "start": 388.58,
        "duration": 2.325
    },
    {
        "text": "How do we solve that?",
        "start": 390.905,
        "duration": 1.385
    },
    {
        "text": "Then we'll say, \"Well, to understand why there's that problem,",
        "start": 392.29,
        "duration": 2.77
    },
    {
        "text": "we need to understand this little bit of math.\"",
        "start": 395.06,
        "duration": 2.24
    },
    {
        "text": "I want to say, here's",
        "start": 397.3,
        "duration": 1.42
    },
    {
        "text": "this little bit of math to explain everything you",
        "start": 398.72,
        "duration": 1.41
    },
    {
        "text": "need to know and so here's how we convert that to code,",
        "start": 400.13,
        "duration": 2.7
    },
    {
        "text": "and then, here's how you can see that code lives in the library.",
        "start": 402.83,
        "duration": 3.06
    },
    {
        "text": "Then, here's how we can use that to solve a problem.",
        "start": 405.89,
        "duration": 2.495
    },
    {
        "text": "Every time we learn a piece of math or a new piece of code,",
        "start": 408.385,
        "duration": 3.775
    },
    {
        "text": "it's within the context of solving a problem.",
        "start": 412.16,
        "duration": 2.43
    },
    {
        "text": "By the end of the book and by the end of the course,",
        "start": 414.59,
        "duration": 3.285
    },
    {
        "text": "you know a very wide spectrum",
        "start": 417.875,
        "duration": 4.119
    },
    {
        "text": "of deep research topics in deep learning.",
        "start": 421.994,
        "duration": 2.851
    },
    {
        "text": "A lot of Fast.ai alumni have ended up presenting papers at",
        "start": 424.845,
        "duration": 4.085
    },
    {
        "text": "the world's top deep learning conferences",
        "start": 428.93,
        "duration": 2.969
    },
    {
        "text": "like Europe's and so forth.",
        "start": 431.899,
        "duration": 1.951
    },
    {
        "text": "It really goes deep,",
        "start": 433.85,
        "duration": 1.815
    },
    {
        "text": "but the whole time it's motivated by practice.",
        "start": 435.665,
        "duration": 5.044
    },
    {
        "text": ">> I have the book right here.",
        "start": 441.11,
        "duration": 2.085
    },
    {
        "text": "I went through it just a couple of days ago.",
        "start": 443.195,
        "duration": 2.025
    },
    {
        "text": "The reality of the matter is literally in Chapter 1.",
        "start": 445.22,
        "duration": 4.085
    },
    {
        "text": "You are building and I'm going to try to open the page,",
        "start": 449.305,
        "duration": 2.815
    },
    {
        "text": "it literally says, \"Your deep learning journey\".",
        "start": 452.12,
        "duration": 2.79
    },
    {
        "text": "There's my camera. You can see literally it says,",
        "start": 454.91,
        "duration": 3.99
    },
    {
        "text": "\"Your first model\", and you're starting to",
        "start": 458.9,
        "duration": 1.65
    },
    {
        "text": "classify pictures that look like this.",
        "start": 460.55,
        "duration": 2.135
    },
    {
        "text": ">> Right.",
        "start": 462.685,
        "duration": 0.875
    },
    {
        "text": ">> This is not how I was taught,",
        "start": 463.56,
        "duration": 3.045
    },
    {
        "text": "but it feels like providing contexts of front is super helpful.",
        "start": 466.605,
        "duration": 4.985
    },
    {
        "text": "Are you finding success with the people that",
        "start": 471.59,
        "duration": 2.19
    },
    {
        "text": "are taking your course on that [inaudible] ?",
        "start": 473.78,
        "duration": 2.405
    },
    {
        "text": ">> Yeah. Very much. It's a real problem that the people that",
        "start": 476.185,
        "duration": 4.945
    },
    {
        "text": "teach technical topics like deep learning are",
        "start": 481.13,
        "duration": 4.12
    },
    {
        "text": "the people who have had successful academic careers.",
        "start": 485.25,
        "duration": 4.07
    },
    {
        "text": "These are the people who found the traditional approach",
        "start": 489.32,
        "duration": 2.91
    },
    {
        "text": "to teaching technical subjects quite adequate.",
        "start": 492.23,
        "duration": 3.095
    },
    {
        "text": "The bottom up start with the math and",
        "start": 495.325,
        "duration": 3.565
    },
    {
        "text": "then spend years and years before you",
        "start": 498.89,
        "duration": 1.56
    },
    {
        "text": "start actually using it in practice.",
        "start": 500.45,
        "duration": 2.28
    },
    {
        "text": "That means that teachers are different to the rest of us.",
        "start": 502.73,
        "duration": 5.46
    },
    {
        "text": "We tried to build something for the rest of us,",
        "start": 508.19,
        "duration": 3.37
    },
    {
        "text": "to people like me.",
        "start": 511.56,
        "duration": 1.19
    },
    {
        "text": "I didn't have that technical background.",
        "start": 512.75,
        "duration": 2.79
    },
    {
        "text": "I was tracked into business when I was 18.",
        "start": 515.54,
        "duration": 3.585
    },
    {
        "text": "It's been amazing to see how well it's worked.",
        "start": 519.125,
        "duration": 4.425
    },
    {
        "text": "For example, in a lot of",
        "start": 523.55,
        "duration": 2.775
    },
    {
        "text": "business and scientific domains, it's taking over.",
        "start": 526.325,
        "duration": 2.895
    },
    {
        "text": "For example, in protein analysis,",
        "start": 529.22,
        "duration": 2.61
    },
    {
        "text": "so many scientific papers are now being written",
        "start": 531.83,
        "duration": 3.29
    },
    {
        "text": "by Fast.ai alumni using the Fast.ai library.",
        "start": 535.12,
        "duration": 4.465
    },
    {
        "text": "We see in business,",
        "start": 539.585,
        "duration": 2.875
    },
    {
        "text": "so many CTOs and so forth from insurance companies, from banks,",
        "start": 542.46,
        "duration": 5.07
    },
    {
        "text": "from telecommunication companies are contacting me and saying,",
        "start": 547.53,
        "duration": 2.835
    },
    {
        "text": "\"Thank God for your course and for your library.",
        "start": 550.365,
        "duration": 5.325
    },
    {
        "text": "Everybody who joins our organization",
        "start": 555.69,
        "duration": 2.295
    },
    {
        "text": "has to do the course before I stop,",
        "start": 557.985,
        "duration": 1.89
    },
    {
        "text": "we find that everybody hits the ground running\".",
        "start": 559.875,
        "duration": 2.55
    },
    {
        "text": "Even places that you might think are pretty full",
        "start": 562.425,
        "duration": 2.325
    },
    {
        "text": "of PhDs anyway, like Tesla.",
        "start": 564.75,
        "duration": 2.49
    },
    {
        "text": "Andre Karpathy who runs the AI group at",
        "start": 567.24,
        "duration": 2.4
    },
    {
        "text": "Tesla told me last time I saw him, \"Hey.",
        "start": 569.64,
        "duration": 2.25
    },
    {
        "text": "Everybody who joins this company in my team,",
        "start": 571.89,
        "duration": 3.45
    },
    {
        "text": "I tell them, 'make sure you've done the Fast.ai course.'\"",
        "start": 575.34,
        "duration": 3.48
    },
    {
        "text": "I know at OpenAI,",
        "start": 578.82,
        "duration": 2.31
    },
    {
        "text": "which is a very popular research lab,",
        "start": 581.13,
        "duration": 1.74
    },
    {
        "text": "a lot of the residents in",
        "start": 582.87,
        "duration": 1.35
    },
    {
        "text": "particular are told to do the Fast.ai course first.",
        "start": 584.22,
        "duration": 3.54
    },
    {
        "text": "It's really working great, I couldn't be happier.",
        "start": 587.76,
        "duration": 4.065
    },
    {
        "text": ">> This is cool because it's an interesting distinction",
        "start": 591.825,
        "duration": 2.595
    },
    {
        "text": "between what a scientist might do to push the envelope",
        "start": 594.42,
        "duration": 2.94
    },
    {
        "text": "forward and what an engineer might do to",
        "start": 597.36,
        "duration": 2.04
    },
    {
        "text": "actually make something work and you're seeing that success.",
        "start": 599.4,
        "duration": 3.675
    },
    {
        "text": "We talked about Fast.ai,",
        "start": 603.075,
        "duration": 1.665
    },
    {
        "text": "we talked about course,",
        "start": 604.74,
        "duration": 1.845
    },
    {
        "text": "where can people find the course?",
        "start": 606.585,
        "duration": 2.1
    },
    {
        "text": ">> They can go to course.fast.ai.",
        "start": 608.685,
        "duration": 2.28
    },
    {
        "text": "The whole thing's free, there's no ads.",
        "start": 610.965,
        "duration": 2.235
    },
    {
        "text": "In fact, everything Fast.ai does is",
        "start": 613.2,
        "duration": 2.34
    },
    {
        "text": "free because it is a self-funded lab.",
        "start": 615.54,
        "duration": 3.03
    },
    {
        "text": "We have no business model,",
        "start": 618.57,
        "duration": 2.7
    },
    {
        "text": "it's just entirely an altruistic exercise.",
        "start": 621.27,
        "duration": 2.13
    },
    {
        "text": "It's all out there for you to take, enjoy,",
        "start": 623.4,
        "duration": 2.475
    },
    {
        "text": "and all we ask is that you give back by telling others",
        "start": 625.875,
        "duration": 3.255
    },
    {
        "text": "about us and helping out",
        "start": 629.13,
        "duration": 1.47
    },
    {
        "text": "answer questions in the community and so forth.",
        "start": 630.6,
        "duration": 2.625
    },
    {
        "text": ">> I want to make a decision with",
        "start": 633.225,
        "duration": 1.635
    },
    {
        "text": "Fast.ai as an organization that puts these things together,",
        "start": 634.86,
        "duration": 3.105
    },
    {
        "text": "the course where people can go and take,",
        "start": 637.965,
        "duration": 2.01
    },
    {
        "text": "but then you mentioned something about a library.",
        "start": 639.975,
        "duration": 2.175
    },
    {
        "text": "Tell us a little bit about the library for Fast.ai.",
        "start": 642.15,
        "duration": 3.42
    },
    {
        "text": ">> Our goal is to not need any code.",
        "start": 645.57,
        "duration": 5.97
    },
    {
        "text": "That's the ultimate and accessibility.",
        "start": 651.54,
        "duration": 2.25
    },
    {
        "text": "Our first step was to say,",
        "start": 653.79,
        "duration": 2.235
    },
    {
        "text": "\"Very few people in the world are expert mathematicians.",
        "start": 656.025,
        "duration": 4.485
    },
    {
        "text": "Relatively speaking, far more people are expert coders.",
        "start": 660.51,
        "duration": 3.225
    },
    {
        "text": "So let's first of all,",
        "start": 663.735,
        "duration": 1.305
    },
    {
        "text": "build something that expert coders can do.\"",
        "start": 665.04,
        "duration": 2.715
    },
    {
        "text": "The current Fast.ai offerings are",
        "start": 667.755,
        "duration": 2.355
    },
    {
        "text": "designed for people who have very comfortable coding.",
        "start": 670.11,
        "duration": 3.195
    },
    {
        "text": "Then our next step is to say,",
        "start": 673.305,
        "duration": 2.25
    },
    {
        "text": "\"Now there are far more people that don't know how to",
        "start": 675.555,
        "duration": 2.475
    },
    {
        "text": "code and are expert mathematicians, how do we get to them?\"",
        "start": 678.03,
        "duration": 3.975
    },
    {
        "text": "The eventual goal therefore is to get rid of code entirely.",
        "start": 682.005,
        "duration": 4.395
    },
    {
        "text": "Our intermediate step there is to",
        "start": 686.4,
        "duration": 3.15
    },
    {
        "text": "make the code easier and easier and easier to use.",
        "start": 689.55,
        "duration": 2.85
    },
    {
        "text": "Now, we build on top of a library called PyTorch,",
        "start": 692.4,
        "duration": 3.27
    },
    {
        "text": "which is by far",
        "start": 695.67,
        "duration": 1.665
    },
    {
        "text": "the world's most popular library amongst researchers,",
        "start": 697.335,
        "duration": 3.315
    },
    {
        "text": "and it's by far the world's fastest",
        "start": 700.65,
        "duration": 1.83
    },
    {
        "text": "growing library for deep learning.",
        "start": 702.48,
        "duration": 1.725
    },
    {
        "text": "I think for that reason, because whatever",
        "start": 704.205,
        "duration": 1.725
    },
    {
        "text": "the researchers are using is what everybody",
        "start": 705.93,
        "duration": 1.8
    },
    {
        "text": "else eventually ends up using because",
        "start": 707.73,
        "duration": 1.59
    },
    {
        "text": "the researchers build the stuff the rest of us use.",
        "start": 709.32,
        "duration": 2.895
    },
    {
        "text": "Now, PyTorch as you know, Seth,",
        "start": 712.215,
        "duration": 4.05
    },
    {
        "text": "it's brilliant and flexible,",
        "start": 716.265,
        "duration": 2.61
    },
    {
        "text": "but it requires a whole lot of boilerplate",
        "start": 718.875,
        "duration": 2.115
    },
    {
        "text": "and code is may hate boilerplate.",
        "start": 720.99,
        "duration": 3.03
    },
    {
        "text": "Boilerplate is particularly problematic for",
        "start": 724.02,
        "duration": 2.22
    },
    {
        "text": "stuff like deep learning because every line of code",
        "start": 726.24,
        "duration": 2.4
    },
    {
        "text": "that you don't really have to write is",
        "start": 728.64,
        "duration": 2.16
    },
    {
        "text": "a line of code you can get subtly wrong,",
        "start": 730.8,
        "duration": 2.355
    },
    {
        "text": "and unfortunately in deep learning,",
        "start": 733.155,
        "duration": 2.055
    },
    {
        "text": "you don't get an error message,",
        "start": 735.21,
        "duration": 1.83
    },
    {
        "text": "you'll just get an accuracy that's 2.3",
        "start": 737.04,
        "duration": 2.28
    },
    {
        "text": "percent worse and you don't even know that it happened.",
        "start": 739.32,
        "duration": 2.52
    },
    {
        "text": "We got to get rid of all the boilerplate.",
        "start": 741.84,
        "duration": 1.92
    },
    {
        "text": "Fast.ai is a library that sits on top of PyTorch,",
        "start": 743.76,
        "duration": 5.849
    },
    {
        "text": "and you write only the code",
        "start": 749.609,
        "duration": 4.216
    },
    {
        "text": "that the computer can't figure out for itself.",
        "start": 753.825,
        "duration": 2.13
    },
    {
        "text": "You just tell it what you want.",
        "start": 755.955,
        "duration": 3.285
    },
    {
        "text": "It's literally four lines of code to",
        "start": 759.24,
        "duration": 2.55
    },
    {
        "text": "create a state of the art vision classifier,",
        "start": 761.79,
        "duration": 2.445
    },
    {
        "text": "a state of the art neural network for text analysis,",
        "start": 764.235,
        "duration": 4.215
    },
    {
        "text": "a state of the art collaborative filtering system,",
        "start": 768.45,
        "duration": 2.534
    },
    {
        "text": "a state of the art tabular analysis system,",
        "start": 770.984,
        "duration": 2.641
    },
    {
        "text": "and in each case the four lines of code are nearly the same.",
        "start": 773.625,
        "duration": 3.42
    },
    {
        "text": "Because the whole thing is built",
        "start": 777.045,
        "duration": 1.755
    },
    {
        "text": "on time tested software engineering principles",
        "start": 778.8,
        "duration": 5.01
    },
    {
        "text": "of consistent APIs and the decoupled design and",
        "start": 783.81,
        "duration": 3.48
    },
    {
        "text": "the very clear API boundaries.",
        "start": 787.29,
        "duration": 3.915
    },
    {
        "text": "For a coder, it's something you can dive into pretty quickly,",
        "start": 791.205,
        "duration": 5.01
    },
    {
        "text": "and then you can start to peel under the layers and",
        "start": 796.215,
        "duration": 2.655
    },
    {
        "text": "customizings at deeper and deeper levels as you're ready to do so.",
        "start": 798.87,
        "duration": 4.485
    },
    {
        "text": ">> That's the thing I like most about it",
        "start": 803.355,
        "duration": 2.535
    },
    {
        "text": "because most people don't know this,",
        "start": 805.89,
        "duration": 2.37
    },
    {
        "text": "but I was a dev for 10 years and",
        "start": 808.26,
        "duration": 1.86
    },
    {
        "text": "then I went to grad school to do this stuff.",
        "start": 810.12,
        "duration": 2.13
    },
    {
        "text": "I started making these analogies in my head that a model",
        "start": 812.25,
        "duration": 3.24
    },
    {
        "text": "is just a leisurely written function with data,",
        "start": 815.49,
        "duration": 2.985
    },
    {
        "text": "and so you should see",
        "start": 818.475,
        "duration": 1.47
    },
    {
        "text": "similar steps when you're building any model,",
        "start": 819.945,
        "duration": 3.195
    },
    {
        "text": "and I felt like I was running too many for loops.",
        "start": 823.14,
        "duration": 2.08
    },
    {
        "text": "By the way, PyTorch is an excellent library",
        "start": 825.22,
        "duration": 2.23
    },
    {
        "text": "written by really good programmers.",
        "start": 827.45,
        "duration": 1.815
    },
    {
        "text": "But I was running a lot of for loops,",
        "start": 829.265,
        "duration": 1.65
    },
    {
        "text": "I was doing a lot of data stuff that felt like it was the same,",
        "start": 830.915,
        "duration": 3.885
    },
    {
        "text": "and you abstract those concepts in the things like",
        "start": 834.8,
        "duration": 2.04
    },
    {
        "text": "data blocks, optimization, etc.",
        "start": 836.84,
        "duration": 3.805
    },
    {
        "text": ">> This is also great for researchers.",
        "start": 840.645,
        "duration": 2.52
    },
    {
        "text": "It turns out that a lot of what ends up in",
        "start": 843.165,
        "duration": 2.235
    },
    {
        "text": "research papers is basically refactoring.",
        "start": 845.4,
        "duration": 3.375
    },
    {
        "text": "We actually ended up writing a peer reviewed paper about the",
        "start": 848.775,
        "duration": 4.455
    },
    {
        "text": "Fast.ai library that really",
        "start": 853.23,
        "duration": 1.83
    },
    {
        "text": "is just describing the refactorings that we did.",
        "start": 855.06,
        "duration": 2.055
    },
    {
        "text": "You mentioned, for example, the optimizer.",
        "start": 857.115,
        "duration": 2.054
    },
    {
        "text": "We've built this, what is I believe the first and it's peer",
        "start": 859.169,
        "duration": 3.301
    },
    {
        "text": "reviewed so I think it's fair to say this,",
        "start": 862.47,
        "duration": 1.5
    },
    {
        "text": "the first generic optimizer.",
        "start": 863.97,
        "duration": 2.31
    },
    {
        "text": "The optimizer is the thing that sits underneath",
        "start": 866.28,
        "duration": 3.195
    },
    {
        "text": "the neural network training and actually makes",
        "start": 869.475,
        "duration": 2.505
    },
    {
        "text": "the weights get better and better at",
        "start": 871.98,
        "duration": 1.32
    },
    {
        "text": "doing whatever you want it to do.",
        "start": 873.3,
        "duration": 2.355
    },
    {
        "text": "We looked across dozens of state of",
        "start": 875.655,
        "duration": 3.195
    },
    {
        "text": "the art research optimizers and we found there was basically",
        "start": 878.85,
        "duration": 2.73
    },
    {
        "text": "two building blocks that they",
        "start": 881.58,
        "duration": 1.71
    },
    {
        "text": "all sat on top off and we can rewrite",
        "start": 883.29,
        "duration": 2.04
    },
    {
        "text": "the equations in their papers using these two building blocks.",
        "start": 885.33,
        "duration": 4.815
    },
    {
        "text": "Then we rewrote the whole lot in code.",
        "start": 890.145,
        "duration": 4.17
    },
    {
        "text": "We created those two building blocks in",
        "start": 894.315,
        "duration": 2.115
    },
    {
        "text": "a generic optimizer base class,",
        "start": 896.43,
        "duration": 3.765
    },
    {
        "text": "and then we superclass,",
        "start": 900.195,
        "duration": 1.71
    },
    {
        "text": "then we subclass that.",
        "start": 901.905,
        "duration": 2.19
    },
    {
        "text": "We'll sometimes use composition,",
        "start": 904.095,
        "duration": 1.515
    },
    {
        "text": "sometimes subclassing to create all these data with",
        "start": 905.61,
        "duration": 3.0
    },
    {
        "text": "the optimizers often with",
        "start": 908.61,
        "duration": 1.29
    },
    {
        "text": "one line of code or sometimes with two lines of code.",
        "start": 909.9,
        "duration": 3.495
    },
    {
        "text": "It great for researchers because then they can say, \"Okay,",
        "start": 913.395,
        "duration": 3.075
    },
    {
        "text": "I wonder what would happen if we took",
        "start": 916.47,
        "duration": 1.92
    },
    {
        "text": "the Adam optimizer and replaced",
        "start": 918.39,
        "duration": 2.73
    },
    {
        "text": "the de-biasing approach with this differently de-biasing approach.",
        "start": 921.12,
        "duration": 2.565
    },
    {
        "text": "You can literally just plug in with different de-biasing approach.",
        "start": 923.685,
        "duration": 3.315
    },
    {
        "text": "Whereas if you look at how",
        "start": 927.0,
        "duration": 1.665
    },
    {
        "text": "research code was written before Fast.ai,",
        "start": 928.665,
        "duration": 2.91
    },
    {
        "text": "people would write their own 200 line optimizer from scratch.",
        "start": 931.575,
        "duration": 3.51
    },
    {
        "text": "Often they would have mistakes or it wasn't state of the art",
        "start": 935.085,
        "duration": 3.555
    },
    {
        "text": "because they've missed some important thing like",
        "start": 938.64,
        "duration": 1.875
    },
    {
        "text": "weight decay, decoupling or whatever.",
        "start": 940.515,
        "duration": 2.775
    },
    {
        "text": "They spend months as researchers",
        "start": 943.29,
        "duration": 2.88
    },
    {
        "text": "writing code rather than implementing their research.",
        "start": 946.17,
        "duration": 3.12
    },
    {
        "text": ">> Even in my fast game of the book and looking over the library,",
        "start": 949.29,
        "duration": 4.725
    },
    {
        "text": "I was super impressed because like I've gotten",
        "start": 954.015,
        "duration": 2.61
    },
    {
        "text": "research code that's been thrown at me from my MSR for example,",
        "start": 956.625,
        "duration": 4.005
    },
    {
        "text": "and they said, \"Hey, implement this so",
        "start": 960.63,
        "duration": 1.78
    },
    {
        "text": "the customer can see how cool this model is.\"",
        "start": 962.41,
        "duration": 2.06
    },
    {
        "text": "It was actually really hard to see because in research code,",
        "start": 964.47,
        "duration": 5.04
    },
    {
        "text": "maybe you have seen this as well,",
        "start": 969.51,
        "duration": 1.89
    },
    {
        "text": "you can see where the data scientists even changed their mind when",
        "start": 971.4,
        "duration": 3.75
    },
    {
        "text": "they were writing code and you're like this should get taken out,",
        "start": 975.15,
        "duration": 4.065
    },
    {
        "text": "and when you abstract certain concepts away,",
        "start": 979.215,
        "duration": 1.965
    },
    {
        "text": "it just makes everything more powerful I think.",
        "start": 981.18,
        "duration": 2.16
    },
    {
        "text": ">> Exactly. Abstractions are so important.",
        "start": 983.34,
        "duration": 2.445
    },
    {
        "text": "The Fast.ai library has",
        "start": 985.785,
        "duration": 1.545
    },
    {
        "text": "four API layers and they're just different levels of abstraction.",
        "start": 987.33,
        "duration": 3.585
    },
    {
        "text": "At the top layer, we have",
        "start": 990.915,
        "duration": 2.025
    },
    {
        "text": "these high-level API concepts",
        "start": 992.94,
        "duration": 1.77
    },
    {
        "text": "like the data blocks API you mentioned.",
        "start": 994.71,
        "duration": 2.04
    },
    {
        "text": "The data blocks API came from me after",
        "start": 996.75,
        "duration": 3.674
    },
    {
        "text": "working for more than 25 years with data and machine learning,",
        "start": 1000.424,
        "duration": 5.206
    },
    {
        "text": "and realizing there's this handful of things that covers",
        "start": 1005.63,
        "duration": 3.48
    },
    {
        "text": "the entire spectrum of everything I've ever",
        "start": 1009.11,
        "duration": 1.68
    },
    {
        "text": "done with data processing.",
        "start": 1010.79,
        "duration": 2.19
    },
    {
        "text": "For example, you have to separate out your data",
        "start": 1012.98,
        "duration": 2.97
    },
    {
        "text": "set into a validation set and a training set.",
        "start": 1015.95,
        "duration": 2.985
    },
    {
        "text": "You have to label it.",
        "start": 1018.935,
        "duration": 2.22
    },
    {
        "text": "Sometimes you have to filter it.",
        "start": 1021.155,
        "duration": 1.98
    },
    {
        "text": "Sometimes you have to pre-process it.",
        "start": 1023.135,
        "duration": 3.195
    },
    {
        "text": "Sometimes you have to do an on",
        "start": 1026.33,
        "duration": 1.2
    },
    {
        "text": "the fly transform of an individual item.",
        "start": 1027.53,
        "duration": 2.22
    },
    {
        "text": "Sometimes you have to do an on",
        "start": 1029.75,
        "duration": 1.11
    },
    {
        "text": "the fly transform of a batch on the GPU, so forth.",
        "start": 1030.86,
        "duration": 3.165
    },
    {
        "text": "I just listed down what these things were and",
        "start": 1034.025,
        "duration": 2.925
    },
    {
        "text": "we saw how we can create",
        "start": 1036.95,
        "duration": 2.94
    },
    {
        "text": "this really simple little class called data block where",
        "start": 1039.89,
        "duration": 2.985
    },
    {
        "text": "you as a user can say how to do each of those things.",
        "start": 1042.875,
        "duration": 3.585
    },
    {
        "text": "We've actually been really lucky to",
        "start": 1046.46,
        "duration": 3.12
    },
    {
        "text": "benefit from some brilliant help with that.",
        "start": 1049.58,
        "duration": 3.195
    },
    {
        "text": "When I first wrote it,",
        "start": 1052.775,
        "duration": 1.275
    },
    {
        "text": "I used to Fluent API.",
        "start": 1054.05,
        "duration": 1.83
    },
    {
        "text": "For those people that don't know, a Fluent API is where you",
        "start": 1055.88,
        "duration": 2.61
    },
    {
        "text": "say do this.do that.do that.",
        "start": 1058.49,
        "duration": 3.36
    },
    {
        "text": "Pretty popular in the JavaScript world,",
        "start": 1061.85,
        "duration": 2.91
    },
    {
        "text": "very popular in the kind of",
        "start": 1064.76,
        "duration": 1.53
    },
    {
        "text": "the VBA world with the Office applications.",
        "start": 1066.29,
        "duration": 3.745
    },
    {
        "text": "The problem with the fluent approach,",
        "start": 1070.035,
        "duration": 3.13
    },
    {
        "text": "which was the version 1 data blocks is first of all,",
        "start": 1073.165,
        "duration": 3.765
    },
    {
        "text": "you don't get great IntelliSense",
        "start": 1076.93,
        "duration": 2.58
    },
    {
        "text": "with fluent approaches because generally speaking,",
        "start": 1079.51,
        "duration": 2.64
    },
    {
        "text": "it's going to be very hard for the language server to",
        "start": 1082.15,
        "duration": 1.74
    },
    {
        "text": "know after all these dots,",
        "start": 1083.89,
        "duration": 2.16
    },
    {
        "text": "what object is this thing, especially in Python.",
        "start": 1086.05,
        "duration": 3.255
    },
    {
        "text": "Because in Python we don't really have all that static analysis.",
        "start": 1089.305,
        "duration": 3.51
    },
    {
        "text": "The second is it has to be in a particular order anyway.",
        "start": 1092.815,
        "duration": 4.765
    },
    {
        "text": "Why enforce that?",
        "start": 1098.43,
        "duration": 3.86
    },
    {
        "text": "In a recent course,",
        "start": 1102.29,
        "duration": 1.915
    },
    {
        "text": "I was lucky enough to be joined by Chris Lattner,",
        "start": 1104.205,
        "duration": 2.205
    },
    {
        "text": "who developed LLVM and",
        "start": 1106.41,
        "duration": 3.15
    },
    {
        "text": "develop Swift and developed Xcode playgrounds,",
        "start": 1109.56,
        "duration": 2.73
    },
    {
        "text": "one of the best programmers I've ever come across.",
        "start": 1112.29,
        "duration": 2.475
    },
    {
        "text": "Him and I co-taught a couple of lessons,",
        "start": 1114.765,
        "duration": 3.609
    },
    {
        "text": "and he brought along with",
        "start": 1118.374,
        "duration": 3.796
    },
    {
        "text": "him lots of other genius Swift programmers,",
        "start": 1122.17,
        "duration": 3.75
    },
    {
        "text": "so we did the whole thing in Swift.",
        "start": 1125.92,
        "duration": 2.34
    },
    {
        "text": "We replaced the whole data blocks API with a functional version.",
        "start": 1128.26,
        "duration": 5.37
    },
    {
        "text": "Also got some help from a guy called Alexis Gallagher,",
        "start": 1133.63,
        "duration": 3.435
    },
    {
        "text": "who's a terrific Swift programmer",
        "start": 1137.065,
        "duration": 1.695
    },
    {
        "text": "and author, amongst other things.",
        "start": 1138.76,
        "duration": 2.71
    },
    {
        "text": "Between us, we built this new functional data blocks API.",
        "start": 1141.96,
        "duration": 5.95
    },
    {
        "text": "I'm not a fractional weeny by any sense,",
        "start": 1147.91,
        "duration": 2.43
    },
    {
        "text": "but I certainly really",
        "start": 1150.34,
        "duration": 2.58
    },
    {
        "text": "enjoy a lot of the benefits that it can bring,",
        "start": 1152.92,
        "duration": 2.325
    },
    {
        "text": "and some of it turns out,",
        "start": 1155.245,
        "duration": 1.695
    },
    {
        "text": "we can bring that back to the Python world.",
        "start": 1156.94,
        "duration": 2.325
    },
    {
        "text": "Fast.ai tune now has this functional data blocks API",
        "start": 1159.265,
        "duration": 3.135
    },
    {
        "text": "where you don't have to worry about what order it goes in,",
        "start": 1162.4,
        "duration": 2.91
    },
    {
        "text": "and you get IntelliSense all the time,",
        "start": 1165.31,
        "duration": 2.22
    },
    {
        "text": "and it actually ends up more concise and more clear.",
        "start": 1167.53,
        "duration": 3.96
    },
    {
        "text": "These higher level APIs,",
        "start": 1171.49,
        "duration": 2.4
    },
    {
        "text": "like data blocks for the user,",
        "start": 1173.89,
        "duration": 2.67
    },
    {
        "text": "it ends up being this nice abstraction",
        "start": 1176.56,
        "duration": 2.46
    },
    {
        "text": "where they just have to learn one concept,",
        "start": 1179.02,
        "duration": 2.115
    },
    {
        "text": "which is data blocks,",
        "start": 1181.135,
        "duration": 1.665
    },
    {
        "text": "and then they can do vision,",
        "start": 1182.8,
        "duration": 1.47
    },
    {
        "text": "text, medical imaging, tabula, whatever.",
        "start": 1184.27,
        "duration": 4.84
    },
    {
        "text": "Then that is built on top of another level of abstractions,",
        "start": 1189.24,
        "duration": 5.38
    },
    {
        "text": "which is the mid tier API.",
        "start": 1194.62,
        "duration": 1.77
    },
    {
        "text": "The mid tier API is",
        "start": 1196.39,
        "duration": 2.37
    },
    {
        "text": "the API that we built a higher level abstractions on.",
        "start": 1198.76,
        "duration": 2.445
    },
    {
        "text": "When you want to change the high-level abstractions,",
        "start": 1201.205,
        "duration": 2.265
    },
    {
        "text": "you can use the mid tier API,",
        "start": 1203.47,
        "duration": 1.905
    },
    {
        "text": "and that includes things like transforms",
        "start": 1205.375,
        "duration": 2.325
    },
    {
        "text": "and pipelines and are going to follow level of stuff.",
        "start": 1207.7,
        "duration": 2.355
    },
    {
        "text": "Eventually you get all the way to the bottom and you'll find",
        "start": 1210.055,
        "duration": 3.32
    },
    {
        "text": "our optimized GPU primitives such",
        "start": 1213.375,
        "duration": 3.375
    },
    {
        "text": "example we wrote our own computer vision library from",
        "start": 1216.75,
        "duration": 2.64
    },
    {
        "text": "scratch so that all the transforms actually ran on the GPU.",
        "start": 1219.39,
        "duration": 5.105
    },
    {
        "text": "Which turns out to be really important",
        "start": 1224.495,
        "duration": 1.805
    },
    {
        "text": "because nowadays a lot of people find",
        "start": 1226.3,
        "duration": 2.01
    },
    {
        "text": "their training code is actually the bottleneck is not the GPU,",
        "start": 1228.31,
        "duration": 4.709
    },
    {
        "text": "but the CPU, trying to get",
        "start": 1233.019,
        "duration": 1.891
    },
    {
        "text": "the CPU just to deliver the JPEG decoding",
        "start": 1234.91,
        "duration": 2.37
    },
    {
        "text": "fast enough or deliver the rotations fast enough or whatever.",
        "start": 1237.28,
        "duration": 4.65
    },
    {
        "text": ">> That's quite interesting because when you're, for example,",
        "start": 1241.93,
        "duration": 2.97
    },
    {
        "text": "to augment your training data,",
        "start": 1244.9,
        "duration": 1.23
    },
    {
        "text": "you're going to be doing some transformations",
        "start": 1246.13,
        "duration": 1.65
    },
    {
        "text": "on the images anyways.",
        "start": 1247.78,
        "duration": 1.35
    },
    {
        "text": "You might as well do those on the GPU.",
        "start": 1249.13,
        "duration": 2.64
    },
    {
        "text": "Well, this is very impressive.",
        "start": 1251.77,
        "duration": 1.755
    },
    {
        "text": "Like I said, I briefly looked at",
        "start": 1253.525,
        "duration": 2.265
    },
    {
        "text": "everything and I was really excited about some of these stuff.",
        "start": 1255.79,
        "duration": 2.67
    },
    {
        "text": "I love the expressiveness of the API,",
        "start": 1258.46,
        "duration": 2.25
    },
    {
        "text": "we're sticking with programmer type concepts",
        "start": 1260.71,
        "duration": 2.52
    },
    {
        "text": "of convention over configuration,",
        "start": 1263.23,
        "duration": 2.46
    },
    {
        "text": "and if you want to dive in, you certainly can.",
        "start": 1265.69,
        "duration": 2.415
    },
    {
        "text": "Where can people go to find out more?",
        "start": 1268.105,
        "duration": 1.995
    },
    {
        "text": "Let's just give them those three links and put them up again.",
        "start": 1270.1,
        "duration": 2.715
    },
    {
        "text": ">> For learning more about the library go to docs.fast.ai.",
        "start": 1272.815,
        "duration": 3.24
    },
    {
        "text": "Docs.fast.ai is where you can",
        "start": 1276.055,
        "duration": 1.545
    },
    {
        "text": "learn about the library, you can get started.",
        "start": 1277.6,
        "duration": 1.755
    },
    {
        "text": "One of the really cool things is",
        "start": 1279.355,
        "duration": 1.98
    },
    {
        "text": "the entire library is actually built with Notebooks,",
        "start": 1281.335,
        "duration": 4.785
    },
    {
        "text": "the Jupyter Notebooks and so",
        "start": 1286.12,
        "duration": 2.01
    },
    {
        "text": "every Documentation page actually",
        "start": 1288.13,
        "duration": 3.63
    },
    {
        "text": "is the tests and is the documentation and is the implementation.",
        "start": 1291.76,
        "duration": 3.405
    },
    {
        "text": "You can click on any page, at the top,",
        "start": 1295.165,
        "duration": 2.055
    },
    {
        "text": "there will be an opening colab link and it'll pop open that",
        "start": 1297.22,
        "duration": 3.39
    },
    {
        "text": "Documentation page with actual working code examples",
        "start": 1300.61,
        "duration": 2.88
    },
    {
        "text": "that you can play with.",
        "start": 1303.49,
        "duration": 1.77
    },
    {
        "text": "It's a really nice way to see exactly how things work.",
        "start": 1305.26,
        "duration": 4.665
    },
    {
        "text": ">> Well, this is really cool.",
        "start": 1309.925,
        "duration": 2.205
    },
    {
        "text": "Again, for those that don't know,",
        "start": 1312.13,
        "duration": 1.74
    },
    {
        "text": "there's a book also. It's pretty good.",
        "start": 1313.87,
        "duration": 1.785
    },
    {
        "text": "I lived through it and I was very excited about learning more.",
        "start": 1315.655,
        "duration": 3.78
    },
    {
        "text": "Now to finish up, I want",
        "start": 1319.435,
        "duration": 1.665
    },
    {
        "text": "people to get a sense for your thoughts on",
        "start": 1321.1,
        "duration": 1.65
    },
    {
        "text": "the future of deep learning",
        "start": 1322.75,
        "duration": 1.725
    },
    {
        "text": "and AI in general and then we'll close up.",
        "start": 1324.475,
        "duration": 2.4
    },
    {
        "text": ">> I really feel like",
        "start": 1326.875,
        "duration": 3.87
    },
    {
        "text": "deep learning it's another way of building programs.",
        "start": 1330.745,
        "duration": 6.0
    },
    {
        "text": "If we go back to machine learning,",
        "start": 1336.745,
        "duration": 1.875
    },
    {
        "text": "machine learning was developed in",
        "start": 1338.62,
        "duration": 1.41
    },
    {
        "text": "the late '50s by a guy called Arthur Samuels.",
        "start": 1340.03,
        "duration": 2.625
    },
    {
        "text": "Arthur Samuels actually made a prediction that",
        "start": 1342.655,
        "duration": 2.535
    },
    {
        "text": "one day there would be very few people",
        "start": 1345.19,
        "duration": 2.93
    },
    {
        "text": "writing step-by-step code with",
        "start": 1348.12,
        "duration": 3.81
    },
    {
        "text": "loops and variables and conditionals.",
        "start": 1351.93,
        "duration": 2.37
    },
    {
        "text": "But instead, most code will be learned code.",
        "start": 1354.3,
        "duration": 3.73
    },
    {
        "text": "It'll be machine learned code.",
        "start": 1358.03,
        "duration": 1.365
    },
    {
        "text": "My guess is that's where we're heading.",
        "start": 1359.395,
        "duration": 2.475
    },
    {
        "text": "When I look at a lot of the code that I write,",
        "start": 1361.87,
        "duration": 2.52
    },
    {
        "text": "I realize a lot of it could actually be automated,",
        "start": 1364.39,
        "duration": 3.795
    },
    {
        "text": "a lot of the outputs could actually be automated.",
        "start": 1368.185,
        "duration": 2.655
    },
    {
        "text": "Now, one of the concerns is that people think to",
        "start": 1370.84,
        "duration": 4.02
    },
    {
        "text": "use deep learning on a lots of compute and lots of data and a PhD.",
        "start": 1374.86,
        "duration": 4.23
    },
    {
        "text": "and all these obstructions and",
        "start": 1379.09,
        "duration": 2.505
    },
    {
        "text": "our focus has been to make sure that's not the case.",
        "start": 1381.595,
        "duration": 3.195
    },
    {
        "text": "We've actually built state of",
        "start": 1384.79,
        "duration": 3.09
    },
    {
        "text": "the art competition winning algorithms",
        "start": 1387.88,
        "duration": 2.64
    },
    {
        "text": "have beaten the world's biggest companies at",
        "start": 1390.52,
        "duration": 2.7
    },
    {
        "text": "performance in machine learning using",
        "start": 1393.22,
        "duration": 3.045
    },
    {
        "text": "a single GPU with",
        "start": 1396.265,
        "duration": 2.955
    },
    {
        "text": "folks that are students with three months of expertise.",
        "start": 1399.22,
        "duration": 3.375
    },
    {
        "text": "We've got students that have built",
        "start": 1402.595,
        "duration": 2.265
    },
    {
        "text": "really practically useful models with less than 100 images.",
        "start": 1404.86,
        "duration": 4.87
    },
    {
        "text": "Really what I'm saying is deep learning is here to stay.",
        "start": 1410.04,
        "duration": 5.245
    },
    {
        "text": "It's going to get bigger and bigger and more and more important.",
        "start": 1415.285,
        "duration": 2.79
    },
    {
        "text": "But you can absolutely get started with it now,",
        "start": 1418.075,
        "duration": 3.18
    },
    {
        "text": "without huge data sets,",
        "start": 1421.255,
        "duration": 1.845
    },
    {
        "text": "without huge computers, and without years and",
        "start": 1423.1,
        "duration": 3.0
    },
    {
        "text": "years of linear algebra study.",
        "start": 1426.1,
        "duration": 3.66
    },
    {
        "text": ">> Well, Jeremy, this has been amazing.",
        "start": 1429.76,
        "duration": 2.775
    },
    {
        "text": "Thank you so much for spending some time.",
        "start": 1432.535,
        "duration": 1.83
    },
    {
        "text": "Again the book, Deep Learning for Coders with Fast.ai and PyTorch,",
        "start": 1434.365,
        "duration": 3.555
    },
    {
        "text": "if you have the time, make sure to go get it.",
        "start": 1437.92,
        "duration": 2.13
    },
    {
        "text": ">> Seth can I mention that book is",
        "start": 1440.05,
        "duration": 2.61
    },
    {
        "text": "also available for free as Jupyter Notebooks.",
        "start": 1442.66,
        "duration": 2.58
    },
    {
        "text": "We brought the whole thing in Jupyter Notebooks",
        "start": 1445.24,
        "duration": 1.68
    },
    {
        "text": "so if you got to GitHub repo,",
        "start": 1446.92,
        "duration": 1.41
    },
    {
        "text": "there's a repo called",
        "start": 1448.33,
        "duration": 1.08
    },
    {
        "text": "Fast Book where you can read the whole thing for free.",
        "start": 1449.41,
        "duration": 2.475
    },
    {
        "text": "But buy yourself a copy as well.",
        "start": 1451.885,
        "duration": 1.965
    },
    {
        "text": ">> Fantastic. Well, Jeremy, thank you so much.",
        "start": 1453.85,
        "duration": 2.31
    },
    {
        "text": "I really, really, really love how",
        "start": 1456.16,
        "duration": 2.025
    },
    {
        "text": "we're trying to get everyone to do deep learning.",
        "start": 1458.185,
        "duration": 2.205
    },
    {
        "text": "I am also like you,",
        "start": 1460.39,
        "duration": 1.38
    },
    {
        "text": "I think anyone who learn it,",
        "start": 1461.77,
        "duration": 1.05
    },
    {
        "text": "the hardest thing in all of this stuff is",
        "start": 1462.82,
        "duration": 2.73
    },
    {
        "text": "basically multiplication and maybe",
        "start": 1465.55,
        "duration": 2.43
    },
    {
        "text": "some flattening the zeros and that all it is.",
        "start": 1467.98,
        "duration": 2.76
    },
    {
        "text": "I'm really excited to have a kindred spirit in this.",
        "start": 1470.74,
        "duration": 2.07
    },
    {
        "text": "Thank you so much for being with us, Jeremy.",
        "start": 1472.81,
        "duration": 1.515
    },
    {
        "text": ">> Thank you.",
        "start": 1474.325,
        "duration": 0.96
    },
    {
        "text": ">> Again, thank you so much for watching.",
        "start": 1475.285,
        "duration": 2.265
    },
    {
        "text": "This has been another episode of",
        "start": 1477.55,
        "duration": 1.2
    },
    {
        "text": "the AI Show where hopefully you've been",
        "start": 1478.75,
        "duration": 1.65
    },
    {
        "text": "inspired that you don't need a PhD to do deep learning,",
        "start": 1480.4,
        "duration": 3.27
    },
    {
        "text": "just go to Fast.ai to learn more,",
        "start": 1483.67,
        "duration": 1.83
    },
    {
        "text": "course.fast.ai to actually take the course.",
        "start": 1485.5,
        "duration": 3.18
    },
    {
        "text": "Or if you want to look at the API docs.fast.ai.",
        "start": 1488.68,
        "duration": 3.51
    },
    {
        "text": "Thank you so much for watching and",
        "start": 1492.19,
        "duration": 1.17
    },
    {
        "text": "hopefully we'll see you next time. Take care.",
        "start": 1493.36,
        "duration": 1.5
    },
    {
        "text": "[MUSIC]",
        "start": 1494.86,
        "duration": 14.14
    }
]