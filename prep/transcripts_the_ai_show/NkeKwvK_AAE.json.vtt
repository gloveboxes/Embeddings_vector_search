[
    {
        "text": ">> You're not going to want to miss this episode of the AI Show.",
        "start": 0.0,
        "duration": 2.4
    },
    {
        "text": "We talk some high-level MLOps from Microsoft Data Scientist,",
        "start": 2.4,
        "duration": 3.81
    },
    {
        "text": "ML engineers, and data engineers. Make sure you tune in.",
        "start": 6.21,
        "duration": 3.36
    },
    {
        "text": "[MUSIC].",
        "start": 9.57,
        "duration": 7.71
    },
    {
        "text": ">> Hello and welcome to this episode of the AI Show.",
        "start": 17.28,
        "duration": 1.94
    },
    {
        "text": "We're talking to a",
        "start": 19.22,
        "duration": 1.515
    },
    {
        "text": "Microsoft Data Scientist,",
        "start": 20.735,
        "duration": 1.71
    },
    {
        "text": "a data engineer, and an ML engineer.",
        "start": 22.445,
        "duration": 2.395
    },
    {
        "text": "It sounds like the beginning of a really fun joke.",
        "start": 24.84,
        "duration": 1.635
    },
    {
        "text": "They all walked into a bar. What happened?",
        "start": 26.475,
        "duration": 1.8
    },
    {
        "text": "We're going to talk about high level MLOps.",
        "start": 28.275,
        "duration": 2.85
    },
    {
        "text": "Why don't we start with some introductions,",
        "start": 31.125,
        "duration": 2.16
    },
    {
        "text": "Spyros, why don't you start buddy.",
        "start": 33.285,
        "duration": 2.205
    },
    {
        "text": ">> I'm Spyros, I'm a Data Scientist with Microsoft and we",
        "start": 35.49,
        "duration": 6.38
    },
    {
        "text": "are here joined by",
        "start": 41.87,
        "duration": 1.86
    },
    {
        "text": "my esteemed colleagues Davide and Sam as part of an AI task force.",
        "start": 43.73,
        "duration": 5.045
    },
    {
        "text": "A data scientist, an ML engineer",
        "start": 48.775,
        "duration": 2.765
    },
    {
        "text": "and a data engineer and we're part of",
        "start": 51.54,
        "duration": 1.94
    },
    {
        "text": "a wider team that covers EMEA and worldwide time zones.",
        "start": 53.48,
        "duration": 5.015
    },
    {
        "text": "What we do is that we enable our customers to formalize,",
        "start": 58.495,
        "duration": 5.65
    },
    {
        "text": "design, and implement data science solutions in Azure.",
        "start": 64.145,
        "duration": 4.4
    },
    {
        "text": "I'm the data scientist of this team.",
        "start": 68.545,
        "duration": 2.645
    },
    {
        "text": "I pass it back to you.",
        "start": 71.19,
        "duration": 1.74
    },
    {
        "text": ">> Let's go to Sam.",
        "start": 72.93,
        "duration": 1.545
    },
    {
        "text": ">> Hi, my name is Samarendra Panda.",
        "start": 74.475,
        "duration": 2.775
    },
    {
        "text": "I'm the Data Engineer of this team and I work",
        "start": 77.25,
        "duration": 3.53
    },
    {
        "text": "as a data and AI consultant for Microsoft Industry Solutions team.",
        "start": 80.78,
        "duration": 4.145
    },
    {
        "text": ">> Fantastic. Davide.",
        "start": 84.925,
        "duration": 1.835
    },
    {
        "text": ">> Hi, my name is Davide Fornelli.",
        "start": 86.76,
        "duration": 1.74
    },
    {
        "text": "I am based in Italy.",
        "start": 88.5,
        "duration": 1.59
    },
    {
        "text": "I'm part of Spyros' ",
        "start": 90.09,
        "duration": 1.53
    },
    {
        "text": "customer transformation and Innovation Team in Microsoft.",
        "start": 91.62,
        "duration": 3.575
    },
    {
        "text": "In this AI Task force,",
        "start": 95.195,
        "duration": 2.115
    },
    {
        "text": "I cover the role of the machine learning engineer.",
        "start": 97.31,
        "duration": 2.675
    },
    {
        "text": ">> Fantastic. I know you can't talk",
        "start": 99.985,
        "duration": 2.425
    },
    {
        "text": "about customers in general specifically,",
        "start": 102.41,
        "duration": 2.46
    },
    {
        "text": "what projects do you work on?",
        "start": 104.87,
        "duration": 2.715
    },
    {
        "text": "I'm sure it's a bunch of them. Who would like to speak to that?",
        "start": 107.585,
        "duration": 3.145
    },
    {
        "text": ">> I'm going to speak about that.",
        "start": 110.78,
        "duration": 2.959
    },
    {
        "text": ">> Yeah.",
        "start": 113.739,
        "duration": 0.906
    },
    {
        "text": ">> The latest projects that we have delivered,",
        "start": 114.645,
        "duration": 3.47
    },
    {
        "text": "and as part of",
        "start": 118.115,
        "duration": 1.545
    },
    {
        "text": "this particular task force was",
        "start": 119.66,
        "duration": 2.52
    },
    {
        "text": "with the largest UK energy supplier.",
        "start": 122.18,
        "duration": 3.135
    },
    {
        "text": "That was a supply and demand optimization problem",
        "start": 125.315,
        "duration": 4.35
    },
    {
        "text": "combined with field service appointment optimization.",
        "start": 129.665,
        "duration": 3.944
    },
    {
        "text": "With a lot of overlapping ML models",
        "start": 133.609,
        "duration": 3.121
    },
    {
        "text": "working with each other and on top of each other.",
        "start": 136.73,
        "duration": 2.43
    },
    {
        "text": "Another one before that was with the world leader in shipping.",
        "start": 139.16,
        "duration": 5.915
    },
    {
        "text": "That was about huge consumption optimization,",
        "start": 145.075,
        "duration": 3.76
    },
    {
        "text": "and root optimization using onboard IoT sensor data.",
        "start": 148.835,
        "duration": 6.655
    },
    {
        "text": "The list goes on. There's multiple projects",
        "start": 155.63,
        "duration": 3.81
    },
    {
        "text": "across all disciplines from",
        "start": 159.44,
        "duration": 1.665
    },
    {
        "text": "finance to healthcare to anything you can think of.",
        "start": 161.105,
        "duration": 2.58
    },
    {
        "text": ">> When we're talking about these particular projects,",
        "start": 163.685,
        "duration": 4.11
    },
    {
        "text": "are they all completely different from one another?",
        "start": 167.795,
        "duration": 3.195
    },
    {
        "text": "I'm sure there's aspects of that but are there",
        "start": 170.99,
        "duration": 1.62
    },
    {
        "text": "common things as well that you see in them?",
        "start": 172.61,
        "duration": 3.31
    },
    {
        "text": ">> Absolutely. They can be very different in terms",
        "start": 176.32,
        "duration": 5.02
    },
    {
        "text": "of the context or the domain.",
        "start": 181.34,
        "duration": 5.19
    },
    {
        "text": "But when it comes to AI and ML,",
        "start": 186.53,
        "duration": 3.81
    },
    {
        "text": "there are a lot of common patterns,",
        "start": 190.34,
        "duration": 2.805
    },
    {
        "text": "and especially with our experience delivering such projects.",
        "start": 193.145,
        "duration": 5.78
    },
    {
        "text": "This is the topic of today's show, I guess.",
        "start": 198.925,
        "duration": 3.88
    },
    {
        "text": "One of them that stands out the most is how important it is",
        "start": 202.805,
        "duration": 4.665
    },
    {
        "text": "to do proper machine-learning operationalization, aka MLOps.",
        "start": 207.47,
        "duration": 6.093
    },
    {
        "text": ">> Okay.",
        "start": 213.563,
        "duration": 0.367
    },
    {
        "text": ">> How critical it is and",
        "start": 213.93,
        "duration": 1.97
    },
    {
        "text": "what effect it has downstream for a project.",
        "start": 215.9,
        "duration": 2.715
    },
    {
        "text": ">> I briefly showed the screen.",
        "start": 218.615,
        "duration": 2.355
    },
    {
        "text": "The whole concept of MLOps,",
        "start": 220.97,
        "duration": 2.04
    },
    {
        "text": "but for delivering value, which is pretty cool.",
        "start": 223.01,
        "duration": 3.105
    },
    {
        "text": "Let me ask this question.",
        "start": 226.115,
        "duration": 1.665
    },
    {
        "text": "Let me point it to you, Sam.",
        "start": 227.78,
        "duration": 3.35
    },
    {
        "text": "There's got to be some common pitfalls",
        "start": 231.13,
        "duration": 4.069
    },
    {
        "text": "that people jump into when they're doing these projects.",
        "start": 235.199,
        "duration": 3.816
    },
    {
        "text": "What are you finding that this",
        "start": 239.015,
        "duration": 1.77
    },
    {
        "text": "is common challenges, will go to your Sam.",
        "start": 240.785,
        "duration": 3.265
    },
    {
        "text": ">> That's a very good question.",
        "start": 244.4,
        "duration": 2.395
    },
    {
        "text": "I would like to talk from the data perspective",
        "start": 246.795,
        "duration": 3.14
    },
    {
        "text": "then I'll hand over to Davide",
        "start": 249.935,
        "duration": 1.53
    },
    {
        "text": "to talk from the machine learning perspective.",
        "start": 251.465,
        "duration": 1.77
    },
    {
        "text": "Let me just talk from the data perspective.",
        "start": 253.235,
        "duration": 2.82
    },
    {
        "text": "In my experience, I've seen that in most of",
        "start": 256.055,
        "duration": 2.865
    },
    {
        "text": "the time in any of machine leaning projects.",
        "start": 258.92,
        "duration": 2.775
    },
    {
        "text": "The main concentration goes into the model training or optimizing",
        "start": 261.695,
        "duration": 4.095
    },
    {
        "text": "the model to get the better performance metrics",
        "start": 265.79,
        "duration": 2.385
    },
    {
        "text": "or scoring of the model.",
        "start": 268.175,
        "duration": 2.405
    },
    {
        "text": "Although I believe that these are important, however,",
        "start": 270.58,
        "duration": 3.565
    },
    {
        "text": "not having an automated data ingestion pipeline as",
        "start": 274.145,
        "duration": 3.735
    },
    {
        "text": "a stable part of the process makes",
        "start": 277.88,
        "duration": 2.64
    },
    {
        "text": "a better model perform really bad over time.",
        "start": 280.52,
        "duration": 3.06
    },
    {
        "text": "If we are not training the model with the recent data,",
        "start": 283.58,
        "duration": 3.78
    },
    {
        "text": "the model will be biased towards",
        "start": 287.36,
        "duration": 1.53
    },
    {
        "text": "the previous version of the data. Which is really bad.",
        "start": 288.89,
        "duration": 2.58
    },
    {
        "text": ">> Right.",
        "start": 291.47,
        "duration": 1.22
    },
    {
        "text": ">> Then one more problem.",
        "start": 292.69,
        "duration": 2.89
    },
    {
        "text": "What I have seen is basically",
        "start": 295.58,
        "duration": 1.5
    },
    {
        "text": "the integration point between",
        "start": 297.08,
        "duration": 1.38
    },
    {
        "text": "the data scientist and the data engineer.",
        "start": 298.46,
        "duration": 1.995
    },
    {
        "text": "I'll just give you an example.",
        "start": 300.455,
        "duration": 2.04
    },
    {
        "text": "Let's say that the model training script",
        "start": 302.495,
        "duration": 5.065
    },
    {
        "text": "doesn't need lot many features.",
        "start": 307.56,
        "duration": 1.9
    },
    {
        "text": "It just need a couple of features.",
        "start": 309.46,
        "duration": 1.885
    },
    {
        "text": "But the data engineer who is working in",
        "start": 311.345,
        "duration": 2.265
    },
    {
        "text": "the project or the data in this framework is",
        "start": 313.61,
        "duration": 2.4
    },
    {
        "text": "basically sending lot of activities or lot of",
        "start": 316.01,
        "duration": 2.21
    },
    {
        "text": "columns to the training script.",
        "start": 318.22,
        "duration": 2.94
    },
    {
        "text": "Or let's say that",
        "start": 321.16,
        "duration": 1.5
    },
    {
        "text": "the machine learning model is",
        "start": 322.66,
        "duration": 3.01
    },
    {
        "text": "supposed to train the model on a specific hierarchy.",
        "start": 325.67,
        "duration": 3.51
    },
    {
        "text": "Take an example of geography hierarchy,",
        "start": 329.18,
        "duration": 2.565
    },
    {
        "text": "the training of the models should be done based on the country,",
        "start": 331.745,
        "duration": 8.05
    },
    {
        "text": "but we are supplying the data or we are",
        "start": 339.795,
        "duration": 1.595
    },
    {
        "text": "providing the data based on the city level.",
        "start": 341.39,
        "duration": 2.1
    },
    {
        "text": "Hence, what's happening that we're",
        "start": 343.49,
        "duration": 2.28
    },
    {
        "text": "providing lot many columns, lot many rows,",
        "start": 345.77,
        "duration": 2.895
    },
    {
        "text": "that basically makes the training of",
        "start": 348.665,
        "duration": 2.475
    },
    {
        "text": "the model becomes really slower because we need to do",
        "start": 351.14,
        "duration": 3.3
    },
    {
        "text": "some overrate functions like aggregating",
        "start": 354.44,
        "duration": 3.39
    },
    {
        "text": "the data or feature engineering and",
        "start": 357.83,
        "duration": 3.42
    },
    {
        "text": "all those steps we need to perform just before",
        "start": 361.25,
        "duration": 3.03
    },
    {
        "text": "we actually get into the actual training algorithm track.",
        "start": 364.28,
        "duration": 3.87
    },
    {
        "text": "I believe these are the main pitfalls or",
        "start": 368.15,
        "duration": 2.91
    },
    {
        "text": "the problems what I have seen in any machine learning project.",
        "start": 371.06,
        "duration": 4.025
    },
    {
        "text": ">> Just to summarize that, I",
        "start": 375.085,
        "duration": 2.715
    },
    {
        "text": "went to school and did research",
        "start": 379.37,
        "duration": 2.74
    },
    {
        "text": "in building machine learning models.",
        "start": 382.11,
        "duration": 1.92
    },
    {
        "text": "That part is super interesting to me.",
        "start": 384.03,
        "duration": 2.105
    },
    {
        "text": "But your models are only as good as your data process,",
        "start": 386.135,
        "duration": 2.955
    },
    {
        "text": "I think that's what you're saying, right, Sam?",
        "start": 389.09,
        "duration": 2.045
    },
    {
        "text": ">> That's true. If the processing of the data",
        "start": 391.135,
        "duration": 3.385
    },
    {
        "text": "is not great or if it is not automated,",
        "start": 394.52,
        "duration": 3.629
    },
    {
        "text": "or if it is not meeting the SLA,",
        "start": 398.149,
        "duration": 1.891
    },
    {
        "text": "then no point of having",
        "start": 400.04,
        "duration": 1.35
    },
    {
        "text": "a good model because that will perform bad over time.",
        "start": 401.39,
        "duration": 4.155
    },
    {
        "text": ">> Cool. All right, Davide,",
        "start": 405.545,
        "duration": 1.785
    },
    {
        "text": "what are some of the common challenges that you're seeing?",
        "start": 407.33,
        "duration": 2.71
    },
    {
        "text": ">> I would like to take a little bit far the answer.",
        "start": 410.27,
        "duration": 4.245
    },
    {
        "text": "There is a reason why in the sentence,",
        "start": 414.515,
        "duration": 3.93
    },
    {
        "text": "data science, there's the word science in it.",
        "start": 418.445,
        "duration": 2.43
    },
    {
        "text": "It is an exploratory activity that given",
        "start": 420.875,
        "duration": 3.655
    },
    {
        "text": "a thesis it requires experimentation to prove its feasibility.",
        "start": 424.53,
        "duration": 4.16
    },
    {
        "text": "This means that more of",
        "start": 428.69,
        "duration": 2.01
    },
    {
        "text": "the experimentation cycles that you can complete,",
        "start": 430.7,
        "duration": 2.85
    },
    {
        "text": "higher the chances to find a solution for the hypothesis.",
        "start": 433.55,
        "duration": 4.185
    },
    {
        "text": "Experimentation cycles are also",
        "start": 437.735,
        "duration": 2.655
    },
    {
        "text": "useful to gather a better understanding",
        "start": 440.39,
        "duration": 1.905
    },
    {
        "text": "of the actual business needs,",
        "start": 442.295,
        "duration": 1.32
    },
    {
        "text": "because sometimes we start with",
        "start": 443.615,
        "duration": 1.875
    },
    {
        "text": "the customers with an overview of the business needs,",
        "start": 445.49,
        "duration": 3.72
    },
    {
        "text": "which is going to become more specific across these cycles.",
        "start": 449.21,
        "duration": 4.515
    },
    {
        "text": "It could also happen that",
        "start": 453.725,
        "duration": 2.49
    },
    {
        "text": "the business need that we used at the very beginning,",
        "start": 456.215,
        "duration": 3.825
    },
    {
        "text": "at the origin of the project is going to change over time.",
        "start": 460.04,
        "duration": 2.58
    },
    {
        "text": "The experimentation velocity of",
        "start": 462.62,
        "duration": 2.85
    },
    {
        "text": "the cycles and the solution flexibility that we are delivering,",
        "start": 465.47,
        "duration": 4.5
    },
    {
        "text": "which has to be capable",
        "start": 469.97,
        "duration": 1.47
    },
    {
        "text": "of shifting depending on the business needs,",
        "start": 471.44,
        "duration": 3.48
    },
    {
        "text": "are two of the main pitfalls and key features",
        "start": 474.92,
        "duration": 3.025
    },
    {
        "text": "that we have to manage in our project.",
        "start": 477.945,
        "duration": 2.875
    },
    {
        "text": ">> That's really cool because",
        "start": 480.82,
        "duration": 2.18
    },
    {
        "text": "the word science everyone thinks it's like,",
        "start": 483.0,
        "duration": 2.445
    },
    {
        "text": "\"Oh, it's so scientific.\"",
        "start": 485.445,
        "duration": 1.78
    },
    {
        "text": "But science is really a rigorous process of guessing and checking.",
        "start": 487.225,
        "duration": 4.075
    },
    {
        "text": "Am I saying that right?",
        "start": 491.3,
        "duration": 2.225
    },
    {
        "text": ">> Exactly. That's perfect.",
        "start": 493.525,
        "duration": 2.54
    },
    {
        "text": "More experiments we do,",
        "start": 496.065,
        "duration": 2.175
    },
    {
        "text": "higher chances we have to solve the business problem.",
        "start": 498.24,
        "duration": 5.005
    },
    {
        "text": "To be really quick,",
        "start": 503.245,
        "duration": 2.105
    },
    {
        "text": "the concept of velocity here comes from the agile methodology.",
        "start": 505.35,
        "duration": 3.29
    },
    {
        "text": "We apply the concept of velocity of",
        "start": 508.64,
        "duration": 2.61
    },
    {
        "text": "the development team to the velocity of the data science team.",
        "start": 511.25,
        "duration": 4.235
    },
    {
        "text": "Higher is the velocity,",
        "start": 515.485,
        "duration": 2.23
    },
    {
        "text": "more experimentation you are going to be able to do,",
        "start": 517.715,
        "duration": 2.435
    },
    {
        "text": "higher the chances to",
        "start": 520.15,
        "duration": 1.84
    },
    {
        "text": "reach to the solution of the business problem.",
        "start": 521.99,
        "duration": 2.51
    },
    {
        "text": ">> That's really cool. Spyros,",
        "start": 524.5,
        "duration": 2.24
    },
    {
        "text": "what are some of the challenges that you've seen my friend?",
        "start": 526.74,
        "duration": 3.7
    },
    {
        "text": ">> Following up from what Davide had said about science,",
        "start": 530.48,
        "duration": 3.435
    },
    {
        "text": "we have to remember that you can get a PhD by trying to prove",
        "start": 533.915,
        "duration": 4.755
    },
    {
        "text": "something and getting to",
        "start": 538.67,
        "duration": 2.55
    },
    {
        "text": "the point where you can prove that it cannot be done.",
        "start": 541.22,
        "duration": 2.91
    },
    {
        "text": "That's one thing that the customers never have in mind.",
        "start": 544.13,
        "duration": 4.38
    },
    {
        "text": "That's one thing that sometimes it's not possible.",
        "start": 548.51,
        "duration": 4.845
    },
    {
        "text": "Then building up on that,",
        "start": 553.355,
        "duration": 2.745
    },
    {
        "text": "what I find to have is from",
        "start": 556.1,
        "duration": 2.16
    },
    {
        "text": "a data scientist perspective in close contact",
        "start": 558.26,
        "duration": 3.15
    },
    {
        "text": "with our stakeholders and",
        "start": 561.41,
        "duration": 1.53
    },
    {
        "text": "our business customers is that first of all,",
        "start": 562.94,
        "duration": 3.06
    },
    {
        "text": "the MLOps part is very often either very strong",
        "start": 566.0,
        "duration": 3.99
    },
    {
        "text": "being underestimated or being",
        "start": 569.99,
        "duration": 2.13
    },
    {
        "text": "missed completely in the planning stage,",
        "start": 572.12,
        "duration": 2.16
    },
    {
        "text": "which is a big problem.",
        "start": 574.28,
        "duration": 1.85
    },
    {
        "text": "Then most of the difficulties we run into",
        "start": 576.13,
        "duration": 4.6
    },
    {
        "text": "have to do with the definition of the data science,",
        "start": 580.73,
        "duration": 4.8
    },
    {
        "text": "user stories and targets and",
        "start": 585.53,
        "duration": 1.59
    },
    {
        "text": "the definition of done and the success criteria.",
        "start": 587.12,
        "duration": 2.25
    },
    {
        "text": "For example, what should",
        "start": 589.37,
        "duration": 1.83
    },
    {
        "text": "be the evaluation metrics that we should choose?",
        "start": 591.2,
        "duration": 2.13
    },
    {
        "text": "When is a model good enough?",
        "start": 593.33,
        "duration": 1.83
    },
    {
        "text": "Is 90 percent good? Is it bad?",
        "start": 595.16,
        "duration": 3.865
    },
    {
        "text": "Should we try for 91 percent?",
        "start": 599.025,
        "duration": 3.195
    },
    {
        "text": "When do we accept that there is",
        "start": 602.22,
        "duration": 3.77
    },
    {
        "text": "a realistic value for those metrics to be successful?",
        "start": 605.99,
        "duration": 3.27
    },
    {
        "text": "When are we done with the experimentation?",
        "start": 609.26,
        "duration": 2.43
    },
    {
        "text": "Those conversations are very important.",
        "start": 611.69,
        "duration": 4.225
    },
    {
        "text": "Another thing is that very often it is difficult to",
        "start": 615.915,
        "duration": 5.945
    },
    {
        "text": "decide when we should actually go",
        "start": 621.86,
        "duration": 2.925
    },
    {
        "text": "for data driven modeling approach versus",
        "start": 624.785,
        "duration": 4.345
    },
    {
        "text": ">> Subject matter expert inputs for decisioning.",
        "start": 629.25,
        "duration": 4.375
    },
    {
        "text": "When should we go with the data and when should we",
        "start": 633.625,
        "duration": 2.31
    },
    {
        "text": "go with the experience in the gut feeling?",
        "start": 635.935,
        "duration": 3.385
    },
    {
        "text": "Both of those things built on",
        "start": 640.62,
        "duration": 2.32
    },
    {
        "text": "top of everything else that the guys said.",
        "start": 642.94,
        "duration": 2.01
    },
    {
        "text": ">> I personally, I know we should think about these things,",
        "start": 644.95,
        "duration": 4.11
    },
    {
        "text": "but what does it mean to have success?",
        "start": 649.06,
        "duration": 3.885
    },
    {
        "text": "What does it mean to be done?",
        "start": 652.945,
        "duration": 1.92
    },
    {
        "text": "Then maybe we don't need this at all.",
        "start": 654.865,
        "duration": 2.655
    },
    {
        "text": "I mean, I've had customers come to me and asks me,",
        "start": 657.52,
        "duration": 2.88
    },
    {
        "text": "\"Hey, I want to do this thing,\" and I'm like,",
        "start": 660.4,
        "duration": 1.38
    },
    {
        "text": "\"Hey, that sounds like a database look-up and not actual AI.\"",
        "start": 661.78,
        "duration": 6.33
    },
    {
        "text": "Have any of you had something like that as well?",
        "start": 668.11,
        "duration": 2.805
    },
    {
        "text": ">> Yes, it's actually funny.",
        "start": 670.915,
        "duration": 4.465
    },
    {
        "text": "Working for Microsoft has this good thing that",
        "start": 676.14,
        "duration": 4.09
    },
    {
        "text": "we don't have to sell something by force.",
        "start": 680.23,
        "duration": 7.26
    },
    {
        "text": "That gives you the flexibility to",
        "start": 687.49,
        "duration": 2.4
    },
    {
        "text": "operate with honesty and transparency.",
        "start": 689.89,
        "duration": 3.164
    },
    {
        "text": "I find it and we've all seen that with our customers they really,",
        "start": 693.054,
        "duration": 5.476
    },
    {
        "text": "sometimes they're flabbergasted when we say,",
        "start": 698.53,
        "duration": 2.385
    },
    {
        "text": "that sounds cool, but we're not going to waste your time.",
        "start": 700.915,
        "duration": 3.255
    },
    {
        "text": "It's not going to work, it's not going to bring you value.",
        "start": 704.17,
        "duration": 2.34
    },
    {
        "text": "There's no point in doing that.",
        "start": 706.51,
        "duration": 1.395
    },
    {
        "text": "Here's how you can do it.",
        "start": 707.905,
        "duration": 1.65
    },
    {
        "text": "Another way, cheaper, faster,",
        "start": 709.555,
        "duration": 2.31
    },
    {
        "text": "and without going into the whole big data hype.",
        "start": 711.865,
        "duration": 4.675
    },
    {
        "text": "Having the ability to do that builds trust,",
        "start": 717.48,
        "duration": 3.475
    },
    {
        "text": "and it's the best way to go because it's the honest way to go.",
        "start": 720.955,
        "duration": 5.665
    },
    {
        "text": "If we're realistic, there are some cases where you don't",
        "start": 726.84,
        "duration": 4.42
    },
    {
        "text": "need to go with deep learning, for example.",
        "start": 731.26,
        "duration": 3.87
    },
    {
        "text": ">> Yeah, I mean,",
        "start": 735.13,
        "duration": 2.13
    },
    {
        "text": "I always start with decision trees and logistic regressions.",
        "start": 737.26,
        "duration": 3.735
    },
    {
        "text": "Always start simple and then you get complicated when you have to.",
        "start": 740.995,
        "duration": 4.065
    },
    {
        "text": "Here's another question, I'll put it to you,",
        "start": 745.06,
        "duration": 2.16
    },
    {
        "text": "Davide and then we'll cycle through.",
        "start": 747.22,
        "duration": 3.345
    },
    {
        "text": "We've talked about the table stakes challenges.",
        "start": 750.565,
        "duration": 3.48
    },
    {
        "text": "There's surprising challenges as",
        "start": 754.045,
        "duration": 2.475
    },
    {
        "text": "you work with customers that you're like,",
        "start": 756.52,
        "duration": 1.455
    },
    {
        "text": "\"Oh, this is interesting.",
        "start": 757.975,
        "duration": 1.815
    },
    {
        "text": "I need to make a mental note",
        "start": 759.79,
        "duration": 1.41
    },
    {
        "text": "of this for next time.\" What do you think, Davide?",
        "start": 761.2,
        "duration": 2.47
    },
    {
        "text": ">> As a machine learning engineer,",
        "start": 764.28,
        "duration": 2.245
    },
    {
        "text": "I'd like to think about the life cycle",
        "start": 766.525,
        "duration": 3.599
    },
    {
        "text": "of the models so one considerations that they make and",
        "start": 770.124,
        "duration": 4.426
    },
    {
        "text": "do this also with our customer is that the model's environment is",
        "start": 774.55,
        "duration": 4.77
    },
    {
        "text": "different between the PUC where you study",
        "start": 779.32,
        "duration": 3.33
    },
    {
        "text": "the model and the real world where you're going to use the model.",
        "start": 782.65,
        "duration": 3.705
    },
    {
        "text": "During our design sessions with the customers,",
        "start": 786.355,
        "duration": 3.239
    },
    {
        "text": "I typically suggest to experiment with the real world in mind.",
        "start": 789.594,
        "duration": 4.891
    },
    {
        "text": "Something like keeping consideration how",
        "start": 794.485,
        "duration": 3.675
    },
    {
        "text": "the data is ingested as Sam was mentioning.",
        "start": 798.16,
        "duration": 3.465
    },
    {
        "text": "How is the scoring done?",
        "start": 801.625,
        "duration": 1.965
    },
    {
        "text": "Which are the timings constraints for the training and scoring,",
        "start": 803.59,
        "duration": 3.09
    },
    {
        "text": "which is the source data during the training",
        "start": 806.68,
        "duration": 2.58
    },
    {
        "text": "and designing stages and the list goes on.",
        "start": 809.26,
        "duration": 3.87
    },
    {
        "text": "Designing a machine learning solution,",
        "start": 813.13,
        "duration": 2.655
    },
    {
        "text": "so what do we do as consultants is",
        "start": 815.785,
        "duration": 2.715
    },
    {
        "text": "not only about the designing architecture,",
        "start": 818.5,
        "duration": 2.835
    },
    {
        "text": "but it is mainly about",
        "start": 821.335,
        "duration": 1.965
    },
    {
        "text": "designing the overall life cycle of the model.",
        "start": 823.3,
        "duration": 3.645
    },
    {
        "text": ">> Interesting. Spyros,",
        "start": 826.945,
        "duration": 2.085
    },
    {
        "text": "some other surprising things.",
        "start": 829.03,
        "duration": 2.53
    },
    {
        "text": ">> Well, that's an easy one because it is surprising even for me,",
        "start": 831.9,
        "duration": 7.765
    },
    {
        "text": "how often the customer will",
        "start": 839.665,
        "duration": 3.075
    },
    {
        "text": "underestimate or overestimate the quality",
        "start": 842.74,
        "duration": 3.03
    },
    {
        "text": "of the data that they own.",
        "start": 845.77,
        "duration": 2.01
    },
    {
        "text": "We see, it's very often the case",
        "start": 847.78,
        "duration": 2.985
    },
    {
        "text": "that people are influenced by the tech sphere hype.",
        "start": 850.765,
        "duration": 5.925
    },
    {
        "text": "They go after high complexity use cases",
        "start": 856.69,
        "duration": 5.16
    },
    {
        "text": "that are very challenging to even define.",
        "start": 861.85,
        "duration": 3.97
    },
    {
        "text": "Very soon, I mean,",
        "start": 865.89,
        "duration": 2.11
    },
    {
        "text": "if you know what you're doing,",
        "start": 868.0,
        "duration": 1.08
    },
    {
        "text": "you can very quickly spot that",
        "start": 869.08,
        "duration": 2.925
    },
    {
        "text": "either there is no data available at all for that use case,",
        "start": 872.005,
        "duration": 4.32
    },
    {
        "text": "or that the granularity or quality or frequency of",
        "start": 876.325,
        "duration": 3.285
    },
    {
        "text": "the data is not appropriate for that problem.",
        "start": 879.61,
        "duration": 4.5
    },
    {
        "text": "So what is surprising,",
        "start": 884.11,
        "duration": 3.06
    },
    {
        "text": "and it shouldn't be surprising,",
        "start": 887.17,
        "duration": 2.34
    },
    {
        "text": "is that big data by itself",
        "start": 889.51,
        "duration": 4.5
    },
    {
        "text": "cannot solve any problem in AI with the data.",
        "start": 894.01,
        "duration": 4.8
    },
    {
        "text": "It has to have some quality aspects that come with it.",
        "start": 898.81,
        "duration": 8.265
    },
    {
        "text": "Another point which I find surprising,",
        "start": 907.075,
        "duration": 5.115
    },
    {
        "text": "is that it's still the case that many times we see that",
        "start": 912.19,
        "duration": 6.6
    },
    {
        "text": "a business will think that",
        "start": 918.79,
        "duration": 4.08
    },
    {
        "text": "it is almost equivalent to replace data-driven,",
        "start": 922.87,
        "duration": 3.945
    },
    {
        "text": "structured data flows with people-centric flows.",
        "start": 926.815,
        "duration": 5.065
    },
    {
        "text": "To have the belief that the people-centric flow",
        "start": 931.88,
        "duration": 3.95
    },
    {
        "text": "will either be less error prone or at least,",
        "start": 935.83,
        "duration": 3.69
    },
    {
        "text": "as good or as fast as a fully automated pipeline.",
        "start": 939.52,
        "duration": 4.455
    },
    {
        "text": "This is what we do basically.",
        "start": 943.975,
        "duration": 2.385
    },
    {
        "text": "This is where we come in and we explain and",
        "start": 946.36,
        "duration": 2.46
    },
    {
        "text": "demonstrate with POCs that, that's not the case.",
        "start": 948.82,
        "duration": 3.6
    },
    {
        "text": ">> Interesting. Sam, let's go to you.",
        "start": 952.42,
        "duration": 2.04
    },
    {
        "text": "Surprising challenges that you found?",
        "start": 954.46,
        "duration": 3.19
    },
    {
        "text": ">> I'll just talk about the real developments scenarios.",
        "start": 958.62,
        "duration": 6.265
    },
    {
        "text": "For example, I have seen that if you go",
        "start": 964.885,
        "duration": 3.225
    },
    {
        "text": "to the any customer place and they'd having so many models.",
        "start": 968.11,
        "duration": 3.675
    },
    {
        "text": "Now they're probably choosing",
        "start": 971.785,
        "duration": 2.235
    },
    {
        "text": "any tools for the machine learning like",
        "start": 974.02,
        "duration": 2.67
    },
    {
        "text": "any computer which would",
        "start": 976.69,
        "duration": 2.88
    },
    {
        "text": "be there to print the model or influence the model.",
        "start": 979.57,
        "duration": 3.0
    },
    {
        "text": "But one common thing, what I found that let's say there will be",
        "start": 982.57,
        "duration": 3.78
    },
    {
        "text": "some common script like",
        "start": 986.35,
        "duration": 1.785
    },
    {
        "text": "creating the computer or creating the data store,",
        "start": 988.135,
        "duration": 2.31
    },
    {
        "text": "creating the mount point.",
        "start": 990.445,
        "duration": 1.23
    },
    {
        "text": "Everything will be scattered and",
        "start": 991.675,
        "duration": 1.98
    },
    {
        "text": "all the machine learning model would",
        "start": 993.655,
        "duration": 1.905
    },
    {
        "text": "be having their own version of the strip.",
        "start": 995.56,
        "duration": 3.075
    },
    {
        "text": "Now, there is no modularization,",
        "start": 998.635,
        "duration": 2.58
    },
    {
        "text": "there is no module concert or nothing is there.",
        "start": 1001.215,
        "duration": 3.51
    },
    {
        "text": "I really found it is really difficult to work in those scenarios.",
        "start": 1004.725,
        "duration": 4.605
    },
    {
        "text": "Let's say one data scientists",
        "start": 1009.33,
        "duration": 2.55
    },
    {
        "text": "working in some part of a machine learning model.",
        "start": 1011.88,
        "duration": 3.54
    },
    {
        "text": "Now let's say he is going to sit to a different machine learning",
        "start": 1015.42,
        "duration": 4.665
    },
    {
        "text": "model problem that he needs to go through the whole framework",
        "start": 1020.085,
        "duration": 3.285
    },
    {
        "text": "again because that has been coded differently.",
        "start": 1023.37,
        "duration": 3.78
    },
    {
        "text": "I believe if we do not have",
        "start": 1027.15,
        "duration": 3.105
    },
    {
        "text": "any standardization or the uniqueness in the framework,",
        "start": 1030.255,
        "duration": 3.81
    },
    {
        "text": "that will create a lot of problem.",
        "start": 1034.065,
        "duration": 1.575
    },
    {
        "text": "Because in the machine learning process,",
        "start": 1035.64,
        "duration": 1.845
    },
    {
        "text": "what I feel only the changes,",
        "start": 1037.485,
        "duration": 2.985
    },
    {
        "text": "what happen is the input,",
        "start": 1040.47,
        "duration": 1.185
    },
    {
        "text": "output and the environment and the training algorithm.",
        "start": 1041.655,
        "duration": 3.12
    },
    {
        "text": "Everything else remains same and that everything else",
        "start": 1044.775,
        "duration": 3.3
    },
    {
        "text": "can be standardized across the organization,",
        "start": 1048.075,
        "duration": 3.825
    },
    {
        "text": "across the different machine learning problems.",
        "start": 1051.9,
        "duration": 4.2
    },
    {
        "text": ">> That's really cool because I think it's hitting on something.",
        "start": 1056.1,
        "duration": 3.525
    },
    {
        "text": "This is what I want to get into now.",
        "start": 1059.625,
        "duration": 1.77
    },
    {
        "text": "You talk about standardization,",
        "start": 1061.395,
        "duration": 2.025
    },
    {
        "text": "my sense is that some patterns emerge",
        "start": 1063.42,
        "duration": 2.699
    },
    {
        "text": "the more customers you work with.",
        "start": 1066.119,
        "duration": 3.511
    },
    {
        "text": "Can you talk about",
        "start": 1069.63,
        "duration": 1.26
    },
    {
        "text": "those patterns a little bit? We'll start with you Spyros.",
        "start": 1070.89,
        "duration": 2.595
    },
    {
        "text": ">> Yeah.",
        "start": 1073.485,
        "duration": 3.915
    },
    {
        "text": "Basically what we've realized is that the main pattern is",
        "start": 1077.4,
        "duration": 4.83
    },
    {
        "text": "that it's not enough to",
        "start": 1082.23,
        "duration": 2.97
    },
    {
        "text": "have a data science and AI involved in a project.",
        "start": 1085.2,
        "duration": 4.05
    },
    {
        "text": "You have to basically have",
        "start": 1089.25,
        "duration": 2.955
    },
    {
        "text": "a solid and flexible framework",
        "start": 1092.205,
        "duration": 4.44
    },
    {
        "text": "for machine learning operationalization,",
        "start": 1096.645,
        "duration": 3.24
    },
    {
        "text": "MLOps, how we call it,",
        "start": 1099.885,
        "duration": 1.65
    },
    {
        "text": "which covers three basic principles.",
        "start": 1101.535,
        "duration": 3.09
    },
    {
        "text": "One is that obviously it",
        "start": 1104.625,
        "duration": 2.745
    },
    {
        "text": "follows the DevOps methodology for machine-learning.",
        "start": 1107.37,
        "duration": 3.015
    },
    {
        "text": "Then it uses the machine-learning technology and",
        "start": 1110.385,
        "duration": 2.985
    },
    {
        "text": "enables the models to go end-to-end to production.",
        "start": 1113.37,
        "duration": 3.585
    },
    {
        "text": "It also allows for another culture.",
        "start": 1116.955,
        "duration": 3.865
    },
    {
        "text": "This needs to be in place so that we are",
        "start": 1122.36,
        "duration": 3.04
    },
    {
        "text": "flexible and we don't go down the road",
        "start": 1125.4,
        "duration": 2.625
    },
    {
        "text": "of chasing down a standalone use case",
        "start": 1128.025,
        "duration": 4.08
    },
    {
        "text": "and go waterfall trying to solve it,",
        "start": 1132.105,
        "duration": 2.685
    },
    {
        "text": "and then only to realize in the end that we need",
        "start": 1134.79,
        "duration": 2.46
    },
    {
        "text": "to change course or rebuild,",
        "start": 1137.25,
        "duration": 2.579
    },
    {
        "text": "or throw away everything we've",
        "start": 1139.829,
        "duration": 1.741
    },
    {
        "text": "done for the last four sprints, for example.",
        "start": 1141.57,
        "duration": 2.115
    },
    {
        "text": "Only if you have a solid and flexible framework for MLOps,",
        "start": 1143.685,
        "duration": 5.205
    },
    {
        "text": "you maximize your chances of",
        "start": 1148.89,
        "duration": 3.315
    },
    {
        "text": "being prepared for any eventuality",
        "start": 1152.205,
        "duration": 5.445
    },
    {
        "text": "and maximize chance for success.",
        "start": 1157.65,
        "duration": 2.58
    },
    {
        "text": ">> Let's talk about, because we kind of",
        "start": 1160.23,
        "duration": 2.28
    },
    {
        "text": "dancing around this notion of MLOps.",
        "start": 1162.51,
        "duration": 3.315
    },
    {
        "text": "How would you describe MLOps? Who wants to take this one?",
        "start": 1165.825,
        "duration": 5.365
    },
    {
        "text": ">> Spyros, you can go ahead with the presentation.",
        "start": 1172.76,
        "duration": 5.485
    },
    {
        "text": ">> We have the deck.",
        "start": 1178.245,
        "duration": 2.625
    },
    {
        "text": "I think we can bring up with deck.",
        "start": 1180.87,
        "duration": 2.19
    },
    {
        "text": "Yeah. This is what it looks like,",
        "start": 1183.06,
        "duration": 6.015
    },
    {
        "text": "MLOps in delivery, what it looks like in real life.",
        "start": 1189.075,
        "duration": 3.63
    },
    {
        "text": "MLOps is a set of practices and rules that allow,",
        "start": 1192.705,
        "duration": 5.965
    },
    {
        "text": "it follows the DevOps guidelines for machine learning.",
        "start": 1199.19,
        "duration": 4.49
    },
    {
        "text": "In terms of the technical aspect,",
        "start": 1203.68,
        "duration": 2.83
    },
    {
        "text": "there's not a lot of differences.",
        "start": 1206.51,
        "duration": 2.34
    },
    {
        "text": "What we're showing here is what it looks",
        "start": 1208.85,
        "duration": 3.03
    },
    {
        "text": "like from the people perspective,",
        "start": 1211.88,
        "duration": 3.36
    },
    {
        "text": "that the mission and what we do as an AI group here.",
        "start": 1215.24,
        "duration": 6.84
    },
    {
        "text": "We have overlapping skills to some extent,",
        "start": 1222.08,
        "duration": 7.585
    },
    {
        "text": "but each one are experts in our area.",
        "start": 1229.665,
        "duration": 2.685
    },
    {
        "text": "The data scientist will be covering",
        "start": 1232.35,
        "duration": 1.8
    },
    {
        "text": "the modeling aspect and creating the model to solve the problem.",
        "start": 1234.15,
        "duration": 4.455
    },
    {
        "text": "The ML engineer will also heavily participate in that,",
        "start": 1238.605,
        "duration": 5.235
    },
    {
        "text": "and also in tuning and operationalization.",
        "start": 1243.84,
        "duration": 2.49
    },
    {
        "text": "The data engineer will be",
        "start": 1246.33,
        "duration": 2.145
    },
    {
        "text": "predominantly doing all the implementation of the pipelines,",
        "start": 1248.475,
        "duration": 2.865
    },
    {
        "text": "the environments, and the framework.",
        "start": 1251.34,
        "duration": 2.62
    },
    {
        "text": "What's the key takeaway from here",
        "start": 1254.33,
        "duration": 2.995
    },
    {
        "text": "is that it is about not just the methodology,",
        "start": 1257.325,
        "duration": 2.595
    },
    {
        "text": "but also the technology used and the culture.",
        "start": 1259.92,
        "duration": 2.82
    },
    {
        "text": "You can't have one without the other.",
        "start": 1262.74,
        "duration": 2.505
    },
    {
        "text": "You can't run this successfully without",
        "start": 1265.245,
        "duration": 3.225
    },
    {
        "text": "having a very competent data engineer, for example.",
        "start": 1268.47,
        "duration": 4.05
    },
    {
        "text": "There is, unfortunately,",
        "start": 1272.52,
        "duration": 2.07
    },
    {
        "text": "I'm going to spoil it for you such that we can't",
        "start": 1274.59,
        "duration": 2.61
    },
    {
        "text": "have a unicorn data engineer,",
        "start": 1277.2,
        "duration": 3.345
    },
    {
        "text": "or a unicorn data scientist,",
        "start": 1280.545,
        "duration": 1.95
    },
    {
        "text": "if we're talking about",
        "start": 1282.495,
        "duration": 1.185
    },
    {
        "text": "a serious level of commitment of the project.",
        "start": 1283.68,
        "duration": 2.145
    },
    {
        "text": "If it's a standalone POC or a hackathon, you can do those things.",
        "start": 1285.825,
        "duration": 4.455
    },
    {
        "text": "But for a full-scale operational project",
        "start": 1290.28,
        "duration": 3.42
    },
    {
        "text": "for a large customer or a large organization,",
        "start": 1293.7,
        "duration": 2.939
    },
    {
        "text": "you really need to have",
        "start": 1296.639,
        "duration": 1.411
    },
    {
        "text": "the interoperability between these three roles.",
        "start": 1298.05,
        "duration": 2.745
    },
    {
        "text": "That's why we are successful when we go in like this.",
        "start": 1300.795,
        "duration": 4.455
    },
    {
        "text": ">> That's interesting. Davide, you have some to add here?",
        "start": 1305.25,
        "duration": 3.76
    },
    {
        "text": ">> In the next slide we're going to discuss,",
        "start": 1309.08,
        "duration": 3.61
    },
    {
        "text": "discusses about which are",
        "start": 1312.69,
        "duration": 1.71
    },
    {
        "text": "the principles about MLOps in the delivery.",
        "start": 1314.4,
        "duration": 5.11
    },
    {
        "text": "Basically, the principles are four.",
        "start": 1320.0,
        "duration": 4.09
    },
    {
        "text": "When we deliver something,",
        "start": 1324.09,
        "duration": 1.41
    },
    {
        "text": "we are based on a four pillars.",
        "start": 1325.5,
        "duration": 1.815
    },
    {
        "text": "The first one is the change management.",
        "start": 1327.315,
        "duration": 2.49
    },
    {
        "text": "Also this is something that most of the time it is underestimated",
        "start": 1329.805,
        "duration": 5.145
    },
    {
        "text": "because when AI is",
        "start": 1334.95,
        "duration": 2.52
    },
    {
        "text": "involved it is going to change some business processes.",
        "start": 1337.47,
        "duration": 3.195
    },
    {
        "text": "The solution that we are going to make is going to be used",
        "start": 1340.665,
        "duration": 4.215
    },
    {
        "text": "by someone from the customer side.",
        "start": 1344.88,
        "duration": 4.56
    },
    {
        "text": "We need to take care that",
        "start": 1349.44,
        "duration": 2.115
    },
    {
        "text": "the customer and the team of the customer,",
        "start": 1351.555,
        "duration": 2.265
    },
    {
        "text": "so the end-user is going to be able",
        "start": 1353.82,
        "duration": 2.76
    },
    {
        "text": "to use what we are going to deliver at its best,",
        "start": 1356.58,
        "duration": 5.14
    },
    {
        "text": "and without any fear because sometimes AI is perceived there's",
        "start": 1361.72,
        "duration": 4.78
    },
    {
        "text": "something that is going to replace",
        "start": 1366.5,
        "duration": 2.525
    },
    {
        "text": "the human being in their own job.",
        "start": 1369.025,
        "duration": 2.27
    },
    {
        "text": "Instead, what the solution that we do also for a concept of",
        "start": 1371.295,
        "duration": 3.525
    },
    {
        "text": "responsible AI is something that it's going to help the end user.",
        "start": 1374.82,
        "duration": 5.51
    },
    {
        "text": "It's not something that is going to replace the end user.",
        "start": 1380.33,
        "duration": 3.615
    },
    {
        "text": "It's something that is going to be used with the human being,",
        "start": 1383.945,
        "duration": 3.225
    },
    {
        "text": "not in place of.",
        "start": 1387.17,
        "duration": 1.35
    },
    {
        "text": "The other pillars are more about",
        "start": 1388.52,
        "duration": 2.025
    },
    {
        "text": "the delivery, the technical aspect.",
        "start": 1390.545,
        "duration": 2.82
    },
    {
        "text": "One is the development environment,",
        "start": 1393.365,
        "duration": 3.075
    },
    {
        "text": "which is something where,",
        "start": 1396.44,
        "duration": 2.105
    },
    {
        "text": "there are many types of data scientists,",
        "start": 1398.545,
        "duration": 2.375
    },
    {
        "text": "like as software engineers,",
        "start": 1400.92,
        "duration": 2.7
    },
    {
        "text": "you could have different flavors.",
        "start": 1403.62,
        "duration": 1.845
    },
    {
        "text": "I would like to use Python,",
        "start": 1405.465,
        "duration": 1.155
    },
    {
        "text": "I would like to use R,",
        "start": 1406.62,
        "duration": 1.02
    },
    {
        "text": "I would like to use Scala. The list goes on.",
        "start": 1407.64,
        "duration": 3.375
    },
    {
        "text": "What we take care about is also to try to,",
        "start": 1411.015,
        "duration": 3.105
    },
    {
        "text": "lets say, establish the language.",
        "start": 1414.12,
        "duration": 2.25
    },
    {
        "text": "If it's Python, we are going to put all the software engineers,",
        "start": 1416.37,
        "duration": 5.415
    },
    {
        "text": "all data scientists in a condition to be",
        "start": 1421.785,
        "duration": 3.48
    },
    {
        "text": "able to work in the same environment as quick as possible.",
        "start": 1425.265,
        "duration": 3.885
    },
    {
        "text": "Typically, we use visual studio code with a Docker environment,",
        "start": 1429.15,
        "duration": 3.45
    },
    {
        "text": "which is going to be attached altogether.",
        "start": 1432.6,
        "duration": 3.3
    },
    {
        "text": "We're going to also create an environment that is going to work",
        "start": 1435.9,
        "duration": 4.035
    },
    {
        "text": "remotely with the class with the compute target.",
        "start": 1439.935,
        "duration": 4.845
    },
    {
        "text": "These are technicalities that sometimes are underestimated because",
        "start": 1444.78,
        "duration": 4.11
    },
    {
        "text": "working with a remote Spark cluster from the local environment,",
        "start": 1448.89,
        "duration": 3.99
    },
    {
        "text": "it requires a lot of configurations.",
        "start": 1452.88,
        "duration": 2.865
    },
    {
        "text": "If you have another team member that is going to join the team,",
        "start": 1455.745,
        "duration": 2.625
    },
    {
        "text": "you have to put him or her up and running as soon as possible.",
        "start": 1458.37,
        "duration": 5.25
    },
    {
        "text": "Another pillar about the more technical aspect of",
        "start": 1463.62,
        "duration": 4.41
    },
    {
        "text": "the model is that we have to be able to basically log everything.",
        "start": 1468.03,
        "duration": 5.22
    },
    {
        "text": "I love logging. Logging saved our professional life many times.",
        "start": 1473.25,
        "duration": 6.78
    },
    {
        "text": "Because when the model breaks is not going to send you an email,",
        "start": 1480.03,
        "duration": 5.235
    },
    {
        "text": "hey, I'm going to break.",
        "start": 1485.265,
        "duration": 1.17
    },
    {
        "text": "Wake up. It's going just to break, and that's it.",
        "start": 1486.435,
        "duration": 4.215
    },
    {
        "text": "You need to be seeing sometimes what we develop.",
        "start": 1490.65,
        "duration": 3.33
    },
    {
        "text": "Sometimes, most of the time what we develop is mission critical",
        "start": 1493.98,
        "duration": 3.435
    },
    {
        "text": "because we have the skills to commit to such missions.",
        "start": 1497.415,
        "duration": 6.615
    },
    {
        "text": "We need to be able to,",
        "start": 1504.03,
        "duration": 1.89
    },
    {
        "text": "if something breaks to fix it as soon as possible.",
        "start": 1505.92,
        "duration": 2.79
    },
    {
        "text": "Logging the models is not that easy as it could sound.",
        "start": 1508.71,
        "duration": 5.625
    },
    {
        "text": "We put in place a framework and methodology",
        "start": 1514.335,
        "duration": 3.315
    },
    {
        "text": "also to ensure that everything that is",
        "start": 1517.65,
        "duration": 2.94
    },
    {
        "text": "developed by our teams is going to be logged properly and it's",
        "start": 1520.59,
        "duration": 5.16
    },
    {
        "text": "going to be easily searched when it is needed.",
        "start": 1525.75,
        "duration": 6.28
    },
    {
        "text": "The architecture. We need to be able to deploy",
        "start": 1535.4,
        "duration": 3.61
    },
    {
        "text": "the architecture in different environments,",
        "start": 1539.01,
        "duration": 2.745
    },
    {
        "text": "in the same way, every time.",
        "start": 1541.755,
        "duration": 2.385
    },
    {
        "text": "The customer can have that broad test pre-prod,",
        "start": 1544.14,
        "duration": 4.785
    },
    {
        "text": "another environment simulation of",
        "start": 1548.925,
        "duration": 3.165
    },
    {
        "text": "a digital twin of the production environment and so on.",
        "start": 1552.09,
        "duration": 3.63
    },
    {
        "text": "We need to be able to deploy",
        "start": 1555.72,
        "duration": 3.85
    },
    {
        "text": "the established architecture in every environment with ease,",
        "start": 1560.54,
        "duration": 7.105
    },
    {
        "text": "with just one click.",
        "start": 1567.645,
        "duration": 1.59
    },
    {
        "text": "This is mandatory also.",
        "start": 1569.235,
        "duration": 2.385
    },
    {
        "text": "All these things help us to improve what we've assumed before,",
        "start": 1571.62,
        "duration": 5.655
    },
    {
        "text": "so the velocity of",
        "start": 1577.275,
        "duration": 1.905
    },
    {
        "text": "the experimentation and to increase the solution flexibility.",
        "start": 1579.18,
        "duration": 4.755
    },
    {
        "text": "These four pillars are helping us to achieve these,",
        "start": 1583.935,
        "duration": 4.215
    },
    {
        "text": "to solve these two pitfalls that we were discussing before.",
        "start": 1588.15,
        "duration": 4.185
    },
    {
        "text": ">> That's cool. Sam, what are your thoughts on MLOps my friend.",
        "start": 1592.335,
        "duration": 4.485
    },
    {
        "text": ">> I think almost Davide has covered all those aspect,",
        "start": 1596.82,
        "duration": 4.05
    },
    {
        "text": "but I think I'll just try to add that data aspect of it.",
        "start": 1600.87,
        "duration": 3.495
    },
    {
        "text": "Because as I have been saying,",
        "start": 1604.365,
        "duration": 2.13
    },
    {
        "text": "without data, a model can't be a better model.",
        "start": 1606.495,
        "duration": 3.465
    },
    {
        "text": "The only things which I can think of,",
        "start": 1609.96,
        "duration": 2.34
    },
    {
        "text": "having a good integration point between your data",
        "start": 1612.3,
        "duration": 2.64
    },
    {
        "text": "pre-processing and the Machine learning",
        "start": 1614.94,
        "duration": 1.77
    },
    {
        "text": "model training script initiation.",
        "start": 1616.71,
        "duration": 2.46
    },
    {
        "text": "For example, I'll just take one example,",
        "start": 1619.17,
        "duration": 2.13
    },
    {
        "text": "let's say you have a Azure Machine Learning Service.",
        "start": 1621.3,
        "duration": 2.085
    },
    {
        "text": "Now, you'll probably be doing",
        "start": 1623.385,
        "duration": 1.875
    },
    {
        "text": "the data pre-processing somewhere else.",
        "start": 1625.26,
        "duration": 2.985
    },
    {
        "text": "Then you should be having",
        "start": 1628.245,
        "duration": 1.335
    },
    {
        "text": "a pipeline which basically tell us that,",
        "start": 1629.58,
        "duration": 3.135
    },
    {
        "text": "when the pre-processing of the data finishes,",
        "start": 1632.715,
        "duration": 2.145
    },
    {
        "text": "then only you start the training.",
        "start": 1634.86,
        "duration": 1.755
    },
    {
        "text": "You should not run in a silo mode.",
        "start": 1636.615,
        "duration": 2.55
    },
    {
        "text": "That should be having a good integration in between.",
        "start": 1639.165,
        "duration": 3.36
    },
    {
        "text": "That's something I can talk about.",
        "start": 1642.525,
        "duration": 2.37
    },
    {
        "text": "The data pre-processing or",
        "start": 1644.895,
        "duration": 2.985
    },
    {
        "text": "the data ingestion should be",
        "start": 1647.88,
        "duration": 2.01
    },
    {
        "text": "the integral part of the whole MLOps life cycle.",
        "start": 1649.89,
        "duration": 3.09
    },
    {
        "text": ">> Yeah, this has been super good.",
        "start": 1652.98,
        "duration": 4.155
    },
    {
        "text": "Let's just finish off with this because,",
        "start": 1657.135,
        "duration": 2.64
    },
    {
        "text": "all of this information has been good.",
        "start": 1659.775,
        "duration": 1.575
    },
    {
        "text": "I love the pragmatic approach to this.",
        "start": 1661.35,
        "duration": 2.19
    },
    {
        "text": "It's not like, hey, this is magic.",
        "start": 1663.54,
        "duration": 1.8
    },
    {
        "text": "Now it feels like it's actually engineering the stuff that",
        "start": 1665.34,
        "duration": 2.97
    },
    {
        "text": "we've been used to as programmers since forever.",
        "start": 1668.31,
        "duration": 2.96
    },
    {
        "text": "Any tips from any of you on someone that's like, yeah,",
        "start": 1671.27,
        "duration": 3.24
    },
    {
        "text": "we have a nascent machine learning practice",
        "start": 1674.51,
        "duration": 3.96
    },
    {
        "text": "that we want to start in our organization.",
        "start": 1678.47,
        "duration": 2.085
    },
    {
        "text": "What are some tips that you",
        "start": 1680.555,
        "duration": 1.605
    },
    {
        "text": "that you might have, will go to you Spyros?",
        "start": 1682.16,
        "duration": 2.65
    },
    {
        "text": ">> Yes. I'm going to touch on",
        "start": 1685.73,
        "duration": 2.95
    },
    {
        "text": "some things that we mentioned before.",
        "start": 1688.68,
        "duration": 2.505
    },
    {
        "text": "I would say number one would be",
        "start": 1691.185,
        "duration": 3.24
    },
    {
        "text": "invest the time in the beginning to,",
        "start": 1694.425,
        "duration": 7.145
    },
    {
        "text": "be very mindful actually to not over inflate expectations,",
        "start": 1701.57,
        "duration": 5.22
    },
    {
        "text": "and invest the time to explain",
        "start": 1706.79,
        "duration": 3.03
    },
    {
        "text": "that this is a scientific experiment essentially.",
        "start": 1709.82,
        "duration": 4.46
    },
    {
        "text": "Anytime that you invest in the beginning",
        "start": 1714.28,
        "duration": 2.375
    },
    {
        "text": "to set up your experiment,",
        "start": 1716.655,
        "duration": 1.619
    },
    {
        "text": "to set up your target,",
        "start": 1718.274,
        "duration": 1.636
    },
    {
        "text": "what you're going after,",
        "start": 1719.91,
        "duration": 1.29
    },
    {
        "text": "as clearly as possible,",
        "start": 1721.2,
        "duration": 1.5
    },
    {
        "text": "it's going to pay off in the long run.",
        "start": 1722.7,
        "duration": 2.835
    },
    {
        "text": "Another thing I would say is avoid",
        "start": 1725.535,
        "duration": 3.705
    },
    {
        "text": "going for the solo superstar approach.",
        "start": 1729.24,
        "duration": 4.08
    },
    {
        "text": "But get yourself a proper task force of experts,",
        "start": 1733.32,
        "duration": 4.62
    },
    {
        "text": "like we are talking about here,",
        "start": 1737.94,
        "duration": 2.55
    },
    {
        "text": "so that even if there is overlap,",
        "start": 1740.49,
        "duration": 4.785
    },
    {
        "text": "but you can cover all of the things that you need to cover.",
        "start": 1745.275,
        "duration": 3.585
    },
    {
        "text": "Another thing that I would mention would be, again,",
        "start": 1748.86,
        "duration": 5.91
    },
    {
        "text": "pay very much attention to clearly articulate to",
        "start": 1754.77,
        "duration": 3.78
    },
    {
        "text": "the stakeholders and what the possible outcomes can be,",
        "start": 1758.55,
        "duration": 6.09
    },
    {
        "text": "of the experiment with ML,",
        "start": 1764.64,
        "duration": 2.13
    },
    {
        "text": "that it can be total success,",
        "start": 1766.77,
        "duration": 3.03
    },
    {
        "text": "total failure, and anything in between.",
        "start": 1769.8,
        "duration": 2.91
    },
    {
        "text": "We have to be prepared for that.",
        "start": 1772.71,
        "duration": 1.44
    },
    {
        "text": "Because one of the most common pitfalls",
        "start": 1774.15,
        "duration": 2.565
    },
    {
        "text": "that we didn't really mention",
        "start": 1776.715,
        "duration": 1.665
    },
    {
        "text": "was that many times in a project,",
        "start": 1778.38,
        "duration": 4.665
    },
    {
        "text": "the component of AI is considered as done before we even start,",
        "start": 1783.045,
        "duration": 7.02
    },
    {
        "text": "that we are certain that",
        "start": 1790.065,
        "duration": 1.605
    },
    {
        "text": "the outcome will be what we expect it to be,",
        "start": 1791.67,
        "duration": 2.58
    },
    {
        "text": "and we only come back to pay attention and",
        "start": 1794.25,
        "duration": 3.87
    },
    {
        "text": "realize that it is central mission",
        "start": 1798.12,
        "duration": 2.07
    },
    {
        "text": "critical to the whole project when things go wrong,",
        "start": 1800.19,
        "duration": 2.4
    },
    {
        "text": "so way better to,",
        "start": 1802.59,
        "duration": 2.79
    },
    {
        "text": "do not over inflate expectations,",
        "start": 1805.38,
        "duration": 1.935
    },
    {
        "text": "explain the possible outcomes early on and pay",
        "start": 1807.315,
        "duration": 5.385
    },
    {
        "text": "attention and staff properly when you go in such endeavors.",
        "start": 1812.7,
        "duration": 6.075
    },
    {
        "text": ">> Great tips.",
        "start": 1818.775,
        "duration": 1.605
    },
    {
        "text": "Any from you Davide, tips?",
        "start": 1820.38,
        "duration": 2.07
    },
    {
        "text": ">> Like Spyros already some great advice.",
        "start": 1822.45,
        "duration": 3.87
    },
    {
        "text": "What I would like to add is just a repetition",
        "start": 1826.32,
        "duration": 2.88
    },
    {
        "text": "of what we said before about the architecture.",
        "start": 1829.2,
        "duration": 2.88
    },
    {
        "text": "When you're putting in place a team, try to make,",
        "start": 1832.08,
        "duration": 5.895
    },
    {
        "text": "as Spyros said before,",
        "start": 1837.975,
        "duration": 1.905
    },
    {
        "text": "there is no unicorn,",
        "start": 1839.88,
        "duration": 1.349
    },
    {
        "text": "but you could have a unicorn team.",
        "start": 1841.229,
        "duration": 4.381
    },
    {
        "text": "Once you have the kind of team,",
        "start": 1845.61,
        "duration": 2.535
    },
    {
        "text": "when you design your solution,",
        "start": 1848.145,
        "duration": 2.04
    },
    {
        "text": "keep in mind the model life cycle.",
        "start": 1850.185,
        "duration": 3.265
    },
    {
        "text": "Basically do not rush into coding the solution",
        "start": 1853.45,
        "duration": 4.249
    },
    {
        "text": "without having first in place clarified what you have,",
        "start": 1857.699,
        "duration": 4.771
    },
    {
        "text": "the full life cycle of the model,",
        "start": 1862.47,
        "duration": 2.1
    },
    {
        "text": "and experiment with the end goal in mind.",
        "start": 1864.57,
        "duration": 4.425
    },
    {
        "text": "This is going to save your model life by far.",
        "start": 1868.995,
        "duration": 7.08
    },
    {
        "text": ">> All right. To you Sam, tips.",
        "start": 1876.075,
        "duration": 3.015
    },
    {
        "text": ">> Yeah, I think, the tips is basically,",
        "start": 1879.09,
        "duration": 2.835
    },
    {
        "text": "I'll just take the word called velocity,",
        "start": 1881.925,
        "duration": 3.06
    },
    {
        "text": "what Davide was mentioning.",
        "start": 1884.985,
        "duration": 1.725
    },
    {
        "text": "Because as I work as a data engineer,",
        "start": 1886.71,
        "duration": 2.835
    },
    {
        "text": "most of the time what would happen,",
        "start": 1889.545,
        "duration": 1.635
    },
    {
        "text": "when I'm starting a project,",
        "start": 1891.18,
        "duration": 1.32
    },
    {
        "text": "my data scientists would be waiting for",
        "start": 1892.5,
        "duration": 1.86
    },
    {
        "text": "me to process the data and give the data to them.",
        "start": 1894.36,
        "duration": 3.705
    },
    {
        "text": "In those kind of scenario,",
        "start": 1898.065,
        "duration": 1.995
    },
    {
        "text": "I would rather be suggesting or you can give the tips.",
        "start": 1900.06,
        "duration": 4.11
    },
    {
        "text": "Like, let's have a logical segregation between",
        "start": 1904.17,
        "duration": 3.69
    },
    {
        "text": "the different roles and responsibility.",
        "start": 1907.86,
        "duration": 4.2
    },
    {
        "text": "Let's say data scientists wants to train the model,",
        "start": 1912.06,
        "duration": 2.865
    },
    {
        "text": "give him a quick snapshot of the data to",
        "start": 1914.925,
        "duration": 3.555
    },
    {
        "text": "him so that he can start working on that.",
        "start": 1918.48,
        "duration": 3.45
    },
    {
        "text": "Like you're set and start working on that.",
        "start": 1921.93,
        "duration": 2.13
    },
    {
        "text": "By the time he or she finishes the model,",
        "start": 1924.06,
        "duration": 3.09
    },
    {
        "text": "you basically take care of the whole data in decent piece,",
        "start": 1927.15,
        "duration": 2.685
    },
    {
        "text": "so that you can work parallelly.",
        "start": 1929.835,
        "duration": 1.89
    },
    {
        "text": "But that's something I can think of.",
        "start": 1931.725,
        "duration": 3.57
    },
    {
        "text": "Also, let's have a logical or the mutual agreement at",
        "start": 1935.295,
        "duration": 3.675
    },
    {
        "text": "the starting of the project",
        "start": 1938.97,
        "duration": 1.74
    },
    {
        "text": "when you are designing with the data scientist,",
        "start": 1940.71,
        "duration": 2.25
    },
    {
        "text": "okay, what you need as input,",
        "start": 1942.96,
        "duration": 1.905
    },
    {
        "text": "what environment do you need,",
        "start": 1944.865,
        "duration": 1.725
    },
    {
        "text": "and where you will be providing the output.",
        "start": 1946.59,
        "duration": 1.89
    },
    {
        "text": "I think being a ML engineer or the data engineer,",
        "start": 1948.48,
        "duration": 2.865
    },
    {
        "text": "these three question has to be answered by the data scientist.",
        "start": 1951.345,
        "duration": 3.015
    },
    {
        "text": "Input means the data which is required to train the model.",
        "start": 1954.36,
        "duration": 8.895
    },
    {
        "text": "Environment means the dependencies,",
        "start": 1963.255,
        "duration": 1.935
    },
    {
        "text": "the Python dependencies and all.",
        "start": 1965.19,
        "duration": 1.665
    },
    {
        "text": "Then the output where,",
        "start": 1966.855,
        "duration": 1.65
    },
    {
        "text": "if you have basically train the model,",
        "start": 1968.505,
        "duration": 2.595
    },
    {
        "text": "where you are going to save that trained model,",
        "start": 1971.1,
        "duration": 2.655
    },
    {
        "text": "so that you can basically",
        "start": 1973.755,
        "duration": 1.725
    },
    {
        "text": "integrate the DevOps pipeline and the other activities,",
        "start": 1975.48,
        "duration": 2.46
    },
    {
        "text": "whatever it is there.",
        "start": 1977.94,
        "duration": 1.575
    },
    {
        "text": "But I think these three questions have to be",
        "start": 1979.515,
        "duration": 3.0
    },
    {
        "text": "answered by the data scientists to",
        "start": 1982.515,
        "duration": 1.485
    },
    {
        "text": "the ML engineer or the data engineer.",
        "start": 1984.0,
        "duration": 1.8
    },
    {
        "text": "This kind of logical and the mutual agreement",
        "start": 1985.8,
        "duration": 2.19
    },
    {
        "text": "has to be there at the starting of the project.",
        "start": 1987.99,
        "duration": 2.49
    },
    {
        "text": ">> Well, this has been super informative.",
        "start": 1990.48,
        "duration": 3.059
    },
    {
        "text": "Where can people find you,",
        "start": 1993.539,
        "duration": 1.261
    },
    {
        "text": "if they want to get a hold of you?",
        "start": 1994.8,
        "duration": 5.73
    },
    {
        "text": ">> India. >> I have your LinkedIn links here.",
        "start": 2000.53,
        "duration": 3.25
    },
    {
        "text": "Spyros here, if you want to get a hold of him.",
        "start": 2003.82,
        "duration": 3.79
    },
    {
        "text": "If you want to get hold of Davide here is his LinkedIn address.",
        "start": 2007.61,
        "duration": 3.96
    },
    {
        "text": "Then if you want to get a hold of Sam, here you go.",
        "start": 2011.57,
        "duration": 3.015
    },
    {
        "text": "That's for Sam. Well,",
        "start": 2014.585,
        "duration": 1.515
    },
    {
        "text": "this has been awesome my friends.",
        "start": 2016.1,
        "duration": 1.41
    },
    {
        "text": "Thank you so much for spending some time with",
        "start": 2017.51,
        "duration": 1.62
    },
    {
        "text": "us and thank you so much for watching.",
        "start": 2019.13,
        "duration": 2.04
    },
    {
        "text": "You were learning all about high-level MLOps from Microsoft,",
        "start": 2021.17,
        "duration": 2.64
    },
    {
        "text": "a Data Scientist a Data Engineer and an ML Engineer.",
        "start": 2023.81,
        "duration": 3.87
    },
    {
        "text": "Thank you so much for watching and",
        "start": 2027.68,
        "duration": 1.11
    },
    {
        "text": "hopefully we'll see you next time. Take care.",
        "start": 2028.79,
        "duration": 2.44
    }
]