[
    {
        "text": ">> Today on this special build edition of the AI Show,",
        "start": 1.13,
        "duration": 4.0
    },
    {
        "text": "we'll get to hear from Mehrnoosh Sameki,",
        "start": 5.13,
        "duration": 1.65
    },
    {
        "text": "Senior Program Manager on the Azure Machine Learning Team,",
        "start": 6.78,
        "duration": 2.775
    },
    {
        "text": "and Joakim Astrom, Cloud Solution Architect.",
        "start": 9.555,
        "duration": 3.195
    },
    {
        "text": "Mehrnoosh and Joakim will talk about how Scandinavian Airlines",
        "start": 12.75,
        "duration": 3.3
    },
    {
        "text": "or SAS is using InterpretML. Make sure you tune in.",
        "start": 16.05,
        "duration": 3.36
    },
    {
        "text": "[MUSIC]",
        "start": 19.41,
        "duration": 9.69
    },
    {
        "text": ">> Hi, everyone. My name is Mehrnoosh Sameki.",
        "start": 29.1,
        "duration": 2.27
    },
    {
        "text": "I'm a Senior Product Manager at Azure AI working",
        "start": 31.37,
        "duration": 3.225
    },
    {
        "text": "on some of our responsibility AI offerings",
        "start": 34.595,
        "duration": 2.055
    },
    {
        "text": "like InterpretML and Fairlearn.",
        "start": 36.65,
        "duration": 1.875
    },
    {
        "text": "Today, I'm excited because I'm joined by",
        "start": 38.525,
        "duration": 2.145
    },
    {
        "text": "our awesome Cloud Solution Architect partner, Joakim Astrom,",
        "start": 40.67,
        "duration": 3.21
    },
    {
        "text": "to talk about how Scandinavian Airlines is",
        "start": 43.88,
        "duration": 2.73
    },
    {
        "text": "using Microsoft machine-learning interpretability toolkit,",
        "start": 46.61,
        "duration": 2.855
    },
    {
        "text": "InterpretML, within Azure Machine Learning to",
        "start": 49.465,
        "duration": 3.395
    },
    {
        "text": "understand and debug their EuroBonus fraud detection model.",
        "start": 52.86,
        "duration": 3.84
    },
    {
        "text": "EuroBonus is a loyalty program and basically,",
        "start": 56.7,
        "duration": 3.15
    },
    {
        "text": "they use the interpretability toolkit to",
        "start": 59.85,
        "duration": 2.15
    },
    {
        "text": "understand how that model has made this predictions.",
        "start": 62.0,
        "duration": 2.28
    },
    {
        "text": "InterpretML is a machine-learning interpretability package for",
        "start": 64.28,
        "duration": 4.26
    },
    {
        "text": "training interpretable machine-learning models",
        "start": 68.54,
        "duration": 2.43
    },
    {
        "text": "and explaining black box AI systems.",
        "start": 70.97,
        "duration": 3.045
    },
    {
        "text": "I would like to welcome Joakim to",
        "start": 74.015,
        "duration": 1.905
    },
    {
        "text": "this conversation, please introduce yourself.",
        "start": 75.92,
        "duration": 2.85
    },
    {
        "text": ">> Thank you, Mehrnoosh. My name is Joakim Astrom,",
        "start": 78.77,
        "duration": 2.99
    },
    {
        "text": "and I work as a Cloud Solution Architect",
        "start": 81.76,
        "duration": 2.22
    },
    {
        "text": "with folks in AI at Microsoft Sweden.",
        "start": 83.98,
        "duration": 2.245
    },
    {
        "text": "I worked in multiple industries with Machine Learning,",
        "start": 86.225,
        "duration": 2.535
    },
    {
        "text": "and I often see that AI solutions can be reused across industries,",
        "start": 88.76,
        "duration": 3.52
    },
    {
        "text": "but I also learned that productive tooling is key for success.",
        "start": 92.28,
        "duration": 3.68
    },
    {
        "text": "I'm not only speaking about Cloud computing power,",
        "start": 95.96,
        "duration": 2.67
    },
    {
        "text": "but also collaborative tool in getting your model",
        "start": 98.63,
        "duration": 2.64
    },
    {
        "text": "in production and your model in compliance,",
        "start": 101.27,
        "duration": 2.775
    },
    {
        "text": "able to automatically retrain and deploy your model",
        "start": 104.045,
        "duration": 2.565
    },
    {
        "text": "in a secure and also in a responsible way.",
        "start": 106.61,
        "duration": 3.29
    },
    {
        "text": "Azure Machine Learning enables this,",
        "start": 109.9,
        "duration": 2.4
    },
    {
        "text": "and my role is to help the customer and get the most out of",
        "start": 112.3,
        "duration": 2.98
    },
    {
        "text": "it to get the value with AI responsible and secure.",
        "start": 115.28,
        "duration": 4.23
    },
    {
        "text": "I'm happy to share how our customers,",
        "start": 119.51,
        "duration": 1.83
    },
    {
        "text": "Scandinavian Airlines aka SAS,",
        "start": 121.34,
        "duration": 2.365
    },
    {
        "text": "created value from InterpretML.",
        "start": 123.705,
        "duration": 2.565
    },
    {
        "text": ">> Awesome. Now, can you please spend a few minutes describing",
        "start": 126.27,
        "duration": 5.209
    },
    {
        "text": "this very specific use case that Scandinavian Airline had and",
        "start": 131.479,
        "duration": 3.871
    },
    {
        "text": "where the consideration of",
        "start": 135.35,
        "duration": 1.2
    },
    {
        "text": "interpretability and model explanation came in?",
        "start": 136.55,
        "duration": 3.53
    },
    {
        "text": ">> Sure. The use case is about their loyalty program.",
        "start": 140.08,
        "duration": 4.14
    },
    {
        "text": "The EuroBonus Loyalty Program is",
        "start": 144.22,
        "duration": 1.93
    },
    {
        "text": "a valuable customer feature for SAS,",
        "start": 146.15,
        "duration": 2.43
    },
    {
        "text": "and it's popularity reflects",
        "start": 148.58,
        "duration": 1.23
    },
    {
        "text": "the realities of air travel in Scandinavia.",
        "start": 149.81,
        "duration": 2.7
    },
    {
        "text": "Unfortunately, the popularity of",
        "start": 152.51,
        "duration": 2.16
    },
    {
        "text": "the EuroBonus program also makes it a target for fraud.",
        "start": 154.67,
        "duration": 3.225
    },
    {
        "text": "People see loyalty points in the program as",
        "start": 157.895,
        "duration": 2.565
    },
    {
        "text": "valuable assets and scammers trying to gain",
        "start": 160.46,
        "duration": 2.55
    },
    {
        "text": "as many points as possible to redeem for",
        "start": 163.01,
        "duration": 2.4
    },
    {
        "text": "their own travel or to purchase",
        "start": 165.41,
        "duration": 1.89
    },
    {
        "text": "tickets and sell them to other people.",
        "start": 167.3,
        "duration": 2.17
    },
    {
        "text": "SAS consider it extremely important to fight",
        "start": 169.47,
        "duration": 2.99
    },
    {
        "text": "fraud and ensure the integrity of the loyalty program, of course.",
        "start": 172.46,
        "duration": 3.48
    },
    {
        "text": "But even though they eventually managed to shut individuals down,",
        "start": 175.94,
        "duration": 3.825
    },
    {
        "text": "they may already have traveled with",
        "start": 179.765,
        "duration": 1.665
    },
    {
        "text": "fraudulent tickets or stolen someone's points.",
        "start": 181.43,
        "duration": 3.03
    },
    {
        "text": "So they made it their goal to",
        "start": 184.46,
        "duration": 1.9
    },
    {
        "text": "proactively the stop fraud and at the same time,",
        "start": 186.36,
        "duration": 2.51
    },
    {
        "text": "safeguarded EuroBonus experience for",
        "start": 188.87,
        "duration": 1.77
    },
    {
        "text": "valid loyal customers in a cost-effective way.",
        "start": 190.64,
        "duration": 3.645
    },
    {
        "text": "So they wanted to increase the detection capabilities",
        "start": 194.285,
        "duration": 2.895
    },
    {
        "text": "without having to increase the size of the fraud detection staff.",
        "start": 197.18,
        "duration": 3.12
    },
    {
        "text": "Hence with Azure Machine Learning,",
        "start": 200.3,
        "duration": 1.955
    },
    {
        "text": "they built a fraud prevention model to help identify and",
        "start": 202.255,
        "duration": 3.655
    },
    {
        "text": "mitigate fraud in its loyalty program",
        "start": 205.91,
        "duration": 1.83
    },
    {
        "text": "using AutoML for automatic retraining,",
        "start": 207.74,
        "duration": 2.505
    },
    {
        "text": "and InterpretML for the model",
        "start": 210.245,
        "duration": 1.905
    },
    {
        "text": "explainability and transparency needed.",
        "start": 212.15,
        "duration": 2.75
    },
    {
        "text": ">> Got it. Great. I can understand",
        "start": 214.9,
        "duration": 2.59
    },
    {
        "text": "that accusing a valued customer of fraud",
        "start": 217.49,
        "duration": 2.475
    },
    {
        "text": "is obviously a very negative experience that",
        "start": 219.965,
        "duration": 2.235
    },
    {
        "text": "they would like to avoid at any cost.",
        "start": 222.2,
        "duration": 2.46
    },
    {
        "text": "So can you now walk us through how you used",
        "start": 224.66,
        "duration": 3.66
    },
    {
        "text": "InterpretML within Azure Machine Learning",
        "start": 228.32,
        "duration": 2.19
    },
    {
        "text": "to understand and debug these models?",
        "start": 230.51,
        "duration": 2.96
    },
    {
        "text": ">> You're very right, Mehrnoosh.",
        "start": 233.47,
        "duration": 1.875
    },
    {
        "text": "SAS takes responsible AI very seriously.",
        "start": 235.345,
        "duration": 2.875
    },
    {
        "text": "They need to trust that using the model won't result in",
        "start": 238.22,
        "duration": 2.88
    },
    {
        "text": "an accusation of fraud against an innocent customer.",
        "start": 241.1,
        "duration": 3.0
    },
    {
        "text": "They still keep a human in the loop to make the final decision,",
        "start": 244.1,
        "duration": 3.36
    },
    {
        "text": "but it's important that the machine on",
        "start": 247.46,
        "duration": 1.5
    },
    {
        "text": "the model that are pointing at a fraud",
        "start": 248.96,
        "duration": 2.069
    },
    {
        "text": "is based on explainable factors and not the output of a black box.",
        "start": 251.029,
        "duration": 4.356
    },
    {
        "text": "SAS and Microsoft started with",
        "start": 255.385,
        "duration": 2.28
    },
    {
        "text": "a proof of concept together to see how",
        "start": 257.665,
        "duration": 2.035
    },
    {
        "text": "can we utilize Azure Machine Learning Studio",
        "start": 259.7,
        "duration": 1.95
    },
    {
        "text": "with it's new capabilities with InterpretML,",
        "start": 261.65,
        "duration": 2.415
    },
    {
        "text": "and how do we leverage this for",
        "start": 264.065,
        "duration": 2.025
    },
    {
        "text": "debugging and to bring value from it?",
        "start": 266.09,
        "duration": 2.54
    },
    {
        "text": "The model has data from around seven data sources,",
        "start": 268.63,
        "duration": 3.84
    },
    {
        "text": "so we wanted to debug and see if we could",
        "start": 272.47,
        "duration": 2.11
    },
    {
        "text": "reduce the number of features and what",
        "start": 274.58,
        "duration": 2.19
    },
    {
        "text": "specific features are important for the model",
        "start": 276.77,
        "duration": 2.46
    },
    {
        "text": "during training and during inference.",
        "start": 279.23,
        "duration": 2.895
    },
    {
        "text": "The goal here, besides opening up the black box,",
        "start": 282.125,
        "duration": 2.745
    },
    {
        "text": "was to reduce the features and still keep good accuracy.",
        "start": 284.87,
        "duration": 3.65
    },
    {
        "text": "Thanks to interpretability, we in Azure ML studio,",
        "start": 288.52,
        "duration": 3.025
    },
    {
        "text": "we were able to both debug and compare",
        "start": 291.545,
        "duration": 2.025
    },
    {
        "text": "different training rounds with different data sets of features.",
        "start": 293.57,
        "duration": 3.6
    },
    {
        "text": "This using both global feature importance",
        "start": 297.17,
        "duration": 2.355
    },
    {
        "text": "and local feature importance to",
        "start": 299.525,
        "duration": 1.755
    },
    {
        "text": "detect the less important features to",
        "start": 301.28,
        "duration": 1.83
    },
    {
        "text": "remove and to get insights from them.",
        "start": 303.11,
        "duration": 2.835
    },
    {
        "text": "They were able to decrease the number of features from",
        "start": 305.945,
        "duration": 3.375
    },
    {
        "text": "54 to 31 without losing accuracy,",
        "start": 309.32,
        "duration": 3.42
    },
    {
        "text": "and they also got the benefits of easier understanding of",
        "start": 312.74,
        "duration": 2.91
    },
    {
        "text": "the model and easier compliance because using less data,",
        "start": 315.65,
        "duration": 4.14
    },
    {
        "text": "and less maintenance and optimized performance,",
        "start": 319.79,
        "duration": 2.38
    },
    {
        "text": "and it also saves cost since less data to process.",
        "start": 322.17,
        "duration": 3.59
    },
    {
        "text": "But most important, they get full transparency and no black box.",
        "start": 325.76,
        "duration": 4.73
    },
    {
        "text": ">> This is fascinating.",
        "start": 330.49,
        "duration": 1.565
    },
    {
        "text": "I truly understand this open that black box,",
        "start": 332.055,
        "duration": 2.615
    },
    {
        "text": "understood their model better,",
        "start": 334.67,
        "duration": 1.5
    },
    {
        "text": "also we're able to reduce the features which was beneficial",
        "start": 336.17,
        "duration": 2.85
    },
    {
        "text": "for optimization and making the runs faster,",
        "start": 339.02,
        "duration": 3.06
    },
    {
        "text": "but also for compliance purposes.",
        "start": 342.08,
        "duration": 2.939
    },
    {
        "text": "That is very great,",
        "start": 345.019,
        "duration": 1.676
    },
    {
        "text": "thanks for putting it into this perspective for us.",
        "start": 346.695,
        "duration": 3.59
    },
    {
        "text": "Now, what were the benefits of using InterpretML for",
        "start": 350.285,
        "duration": 3.555
    },
    {
        "text": "this use case and how they can serve",
        "start": 353.84,
        "duration": 1.98
    },
    {
        "text": "customers better as a result of this tooling?",
        "start": 355.82,
        "duration": 3.23
    },
    {
        "text": ">> I talked to SAS and they feel that they have",
        "start": 359.05,
        "duration": 2.635
    },
    {
        "text": "better insights into the levels of",
        "start": 361.685,
        "duration": 1.845
    },
    {
        "text": "fraud that was earlier hard to find.",
        "start": 363.53,
        "duration": 2.25
    },
    {
        "text": "According to SAS, if someone tries to",
        "start": 365.78,
        "duration": 1.65
    },
    {
        "text": "commit a fraud on a large scale,",
        "start": 367.43,
        "duration": 1.86
    },
    {
        "text": "you can find them relatively easy because they stick out.",
        "start": 369.29,
        "duration": 3.315
    },
    {
        "text": "But now, they are much better equipped with",
        "start": 372.605,
        "duration": 1.815
    },
    {
        "text": "anti-fraud on a small-scale and a large-scale,",
        "start": 374.42,
        "duration": 3.435
    },
    {
        "text": "to keep the seating on airplane available",
        "start": 377.855,
        "duration": 2.175
    },
    {
        "text": "for their true loyal customers,",
        "start": 380.03,
        "duration": 2.09
    },
    {
        "text": "not taken by scammers.",
        "start": 382.12,
        "duration": 1.76
    },
    {
        "text": "The new machine learning model was actually able to",
        "start": 383.88,
        "duration": 2.24
    },
    {
        "text": "surface 300 percent more frauds than earlier,",
        "start": 386.12,
        "duration": 3.27
    },
    {
        "text": "this is by combining more data sources using",
        "start": 389.39,
        "duration": 2.97
    },
    {
        "text": "Azure AutoML to re-tune and optimize the model continuously,",
        "start": 392.36,
        "duration": 3.62
    },
    {
        "text": "both detecting small frauds and big ones.",
        "start": 395.98,
        "duration": 3.35
    },
    {
        "text": "They could decrease the number of",
        "start": 399.33,
        "duration": 1.7
    },
    {
        "text": "features without losing accuracy.",
        "start": 401.03,
        "duration": 2.805
    },
    {
        "text": "Some features detected and dropped was",
        "start": 403.835,
        "duration": 2.31
    },
    {
        "text": "features with high cardinality and dropping",
        "start": 406.145,
        "duration": 2.715
    },
    {
        "text": "these saves compute cost by itself and",
        "start": 408.86,
        "duration": 2.67
    },
    {
        "text": "also increase their machine learning algorithm options,",
        "start": 411.53,
        "duration": 2.835
    },
    {
        "text": "potentially better score to get.",
        "start": 414.365,
        "duration": 2.84
    },
    {
        "text": ">> Awesome. Now, InterpretML is an open source toolkit,",
        "start": 417.205,
        "duration": 3.97
    },
    {
        "text": "but it has been integrated within Azure Machine Learning.",
        "start": 421.175,
        "duration": 2.88
    },
    {
        "text": "How did you harness the power of Cloud",
        "start": 424.055,
        "duration": 2.085
    },
    {
        "text": "for generating these explanations?",
        "start": 426.14,
        "duration": 2.855
    },
    {
        "text": ">> SAS were using Azure as a Cloud and Azure ML at its fullest.",
        "start": 428.995,
        "duration": 4.33
    },
    {
        "text": "They're using Azure ML Studio for",
        "start": 433.325,
        "duration": 2.235
    },
    {
        "text": "model management to see their run history,",
        "start": 435.56,
        "duration": 2.805
    },
    {
        "text": "they used AutoML for training and",
        "start": 438.365,
        "duration": 2.205
    },
    {
        "text": "connected this to the feature important with",
        "start": 440.57,
        "duration": 2.55
    },
    {
        "text": "embedded InterpretML dashboards to",
        "start": 443.12,
        "duration": 1.965
    },
    {
        "text": "each training round and during inferences.",
        "start": 445.085,
        "duration": 2.685
    },
    {
        "text": "So everything is connected and automated with",
        "start": 447.77,
        "duration": 2.535
    },
    {
        "text": "envelopes and in Azure with a full picture.",
        "start": 450.305,
        "duration": 3.315
    },
    {
        "text": "For each training run,",
        "start": 453.62,
        "duration": 1.32
    },
    {
        "text": "we can see the scoring and a feature importance,",
        "start": 454.94,
        "duration": 2.67
    },
    {
        "text": "and the explanation of this training run there,",
        "start": 457.61,
        "duration": 2.265
    },
    {
        "text": "and how the model is performing out in production.",
        "start": 459.875,
        "duration": 3.135
    },
    {
        "text": "When they commit a code change to Git,",
        "start": 463.01,
        "duration": 2.64
    },
    {
        "text": "it triggers the process to",
        "start": 465.65,
        "duration": 1.14
    },
    {
        "text": "automatically create a new model version,",
        "start": 466.79,
        "duration": 2.235
    },
    {
        "text": "train it, validate it,",
        "start": 469.025,
        "duration": 1.755
    },
    {
        "text": "and publish it to a web service powered",
        "start": 470.78,
        "duration": 2.13
    },
    {
        "text": "by, Azure Kubernetes service.",
        "start": 472.91,
        "duration": 2.34
    },
    {
        "text": "I quote, \"That's our time to value and it's extremely quick.\"",
        "start": 475.25,
        "duration": 3.995
    },
    {
        "text": "So this is where Azure, as an ecosystem,",
        "start": 479.245,
        "duration": 2.78
    },
    {
        "text": "works together with InterpretML,",
        "start": 482.025,
        "duration": 2.485
    },
    {
        "text": "connecting each model with a dashboard of",
        "start": 484.51,
        "duration": 2.38
    },
    {
        "text": "both model runs with scoring and also,",
        "start": 486.89,
        "duration": 2.31
    },
    {
        "text": "InterpretML with feature importance to support",
        "start": 489.2,
        "duration": 2.46
    },
    {
        "text": "a responsible AI so we can both understand the model's decision,",
        "start": 491.66,
        "duration": 4.254
    },
    {
        "text": "and we can add and remove key features",
        "start": 495.914,
        "duration": 1.666
    },
    {
        "text": "to get the model prediction accurate,",
        "start": 497.58,
        "duration": 1.944
    },
    {
        "text": "and also to understand the behavior of this.",
        "start": 499.524,
        "duration": 2.696
    },
    {
        "text": "Plus, we have model management and lineage,",
        "start": 502.22,
        "duration": 2.73
    },
    {
        "text": "the complete model life cycle.",
        "start": 504.95,
        "duration": 2.72
    },
    {
        "text": ">> Fascinating. This was a very great use case that showcased",
        "start": 507.67,
        "duration": 4.6
    },
    {
        "text": "how interpretability can bring",
        "start": 512.27,
        "duration": 1.56
    },
    {
        "text": "major value to a machine learning life cycle.",
        "start": 513.83,
        "duration": 2.385
    },
    {
        "text": "I really appreciate you shared it with us.",
        "start": 516.215,
        "duration": 2.7
    },
    {
        "text": "Thank you so much for joining us. Have a great day.",
        "start": 518.915,
        "duration": 2.885
    },
    {
        "text": ">> Thank you very much. Have a great day.",
        "start": 521.8,
        "duration": 1.97
    },
    {
        "text": "[MUSIC]",
        "start": 523.77,
        "duration": 13.78
    }
]