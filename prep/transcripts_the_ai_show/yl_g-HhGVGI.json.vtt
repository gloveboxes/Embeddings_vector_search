[
    {
        "text": ">> You don't want to miss this episode of",
        "start": 0.0,
        "duration": 1.53
    },
    {
        "text": "The AI Show where I'll be talking with Bozhong Lin",
        "start": 1.53,
        "duration": 2.54
    },
    {
        "text": "about Arc-enable ML on Azure. Stay tuned.",
        "start": 4.07,
        "duration": 3.73
    },
    {
        "text": "[MUSIC]",
        "start": 7.8,
        "duration": 7.35
    },
    {
        "text": "Hello and welcome to this episode of The AI Show.",
        "start": 15.15,
        "duration": 2.655
    },
    {
        "text": "Today, I'll be talking with Bozhong Lin",
        "start": 17.805,
        "duration": 1.815
    },
    {
        "text": "about Arc-enabled machine learning.",
        "start": 19.62,
        "duration": 2.73
    },
    {
        "text": "Hi, Bozhong. How are you?",
        "start": 22.35,
        "duration": 2.355
    },
    {
        "text": ">> Hi, Bea. I'm great.",
        "start": 24.705,
        "duration": 1.545
    },
    {
        "text": "Great to be here.",
        "start": 26.25,
        "duration": 1.001
    },
    {
        "text": ">> Super happy to have you here on the show.",
        "start": 27.89,
        "duration": 4.11
    },
    {
        "text": "I'm really excited about your future in particular.",
        "start": 32.0,
        "duration": 3.465
    },
    {
        "text": "Having you here, it's just super exciting for me.",
        "start": 35.465,
        "duration": 2.655
    },
    {
        "text": ">> Great to be here.",
        "start": 38.12,
        "duration": 2.17
    },
    {
        "text": ">> Why don't we tell us who you are and what you do?",
        "start": 40.29,
        "duration": 3.805
    },
    {
        "text": ">> I work in Azure machine learning team as a Product Manager,",
        "start": 44.095,
        "duration": 5.92
    },
    {
        "text": "focusing on Azure machine learning",
        "start": 50.015,
        "duration": 3.615
    },
    {
        "text": "with the Kubernetes being as your hybrid Cloud.",
        "start": 53.63,
        "duration": 3.805
    },
    {
        "text": "I'm passionate about helping customers",
        "start": 57.435,
        "duration": 3.65
    },
    {
        "text": "with their digital transformation and machine learning.",
        "start": 61.085,
        "duration": 3.915
    },
    {
        "text": ">> That's great. You have a big announcement at Ignite.",
        "start": 65.0,
        "duration": 3.8
    },
    {
        "text": "Can you tell us what you're announcing?",
        "start": 68.8,
        "duration": 1.885
    },
    {
        "text": ">> Yeah, we announced the public preview",
        "start": 70.685,
        "duration": 3.57
    },
    {
        "text": "of Azure Arc-enabled machine learning for inference.",
        "start": 74.255,
        "duration": 4.645
    },
    {
        "text": "With a simple Azure ML extension deployment,",
        "start": 78.95,
        "duration": 5.32
    },
    {
        "text": "customers can deploy and solve model on Kubernetes anywhere.",
        "start": 84.27,
        "duration": 6.46
    },
    {
        "text": ">> Just to be clear, so the announcement is just for inference.",
        "start": 91.22,
        "duration": 4.38
    },
    {
        "text": "Training was already working before, right?",
        "start": 95.6,
        "duration": 3.54
    },
    {
        "text": ">> Yes.These builds on our earlier training announcement in June.",
        "start": 99.14,
        "duration": 4.895
    },
    {
        "text": ">> Got it. That makes sense.",
        "start": 104.035,
        "duration": 2.855
    },
    {
        "text": "Now we have a full picture,",
        "start": 106.89,
        "duration": 1.5
    },
    {
        "text": "we've training and deployment.",
        "start": 108.39,
        "duration": 1.92
    },
    {
        "text": "We can do the whole thing on Kubernetes.",
        "start": 110.31,
        "duration": 2.37
    },
    {
        "text": ">> All machine learning life cycle.",
        "start": 112.68,
        "duration": 2.22
    },
    {
        "text": ">> Awesome. You mentioned Azure Arc-enabled ML.",
        "start": 114.9,
        "duration": 4.82
    },
    {
        "text": "Can you tell us exactly what that is?",
        "start": 119.72,
        "duration": 2.435
    },
    {
        "text": ">> Azure Arc-enabled machine learning",
        "start": 122.155,
        "duration": 2.495
    },
    {
        "text": "enables customer to have enterprise grade",
        "start": 124.65,
        "duration": 5.58
    },
    {
        "text": "and machine learning on Kubernetes easily.",
        "start": 130.23,
        "duration": 3.29
    },
    {
        "text": "With a simple Azure ML extension deployment,",
        "start": 133.52,
        "duration": 4.78
    },
    {
        "text": "customer can onboard a led data scientist's team",
        "start": 138.3,
        "duration": 6.28
    },
    {
        "text": "with the Azure ML",
        "start": 144.58,
        "duration": 3.85
    },
    {
        "text": "service capabilities for four machine learning life cycle.",
        "start": 148.43,
        "duration": 4.35
    },
    {
        "text": "Customer have access to both Azure managed compute",
        "start": 152.78,
        "duration": 5.59
    },
    {
        "text": "and customer managed Kubernetes.",
        "start": 158.37,
        "duration": 4.2
    },
    {
        "text": "They can [inaudible] and deploy model",
        "start": 162.57,
        "duration": 3.69
    },
    {
        "text": "whenever they want or whenever business require so.",
        "start": 166.26,
        "duration": 9.315
    },
    {
        "text": ">> Why would people want to have their models on-premise?",
        "start": 175.575,
        "duration": 5.75
    },
    {
        "text": "Why is that a good thing?",
        "start": 181.325,
        "duration": 2.75
    },
    {
        "text": ">> Through our customer engagement,",
        "start": 184.075,
        "duration": 4.145
    },
    {
        "text": "we saw two needs for our customers with machine learning,",
        "start": 188.22,
        "duration": 6.72
    },
    {
        "text": "the need to use Kubernetes container platform",
        "start": 194.94,
        "duration": 4.28
    },
    {
        "text": "and the need to have machine learning on-premises.",
        "start": 199.22,
        "duration": 5.08
    },
    {
        "text": "Our customers runs into two key challenge",
        "start": 205.0,
        "duration": 4.245
    },
    {
        "text": "when using Kubernetes for machine learning.",
        "start": 209.245,
        "duration": 3.235
    },
    {
        "text": "The first is to deploy and host,",
        "start": 212.48,
        "duration": 3.63
    },
    {
        "text": "and maintain a variety of",
        "start": 216.11,
        "duration": 2.31
    },
    {
        "text": "data science productivity tools and frameworks,",
        "start": 218.42,
        "duration": 3.645
    },
    {
        "text": "and ensure all those up-to-date all the time.",
        "start": 222.065,
        "duration": 3.44
    },
    {
        "text": "The second challenge is",
        "start": 225.505,
        "duration": 3.185
    },
    {
        "text": "about automation machine learning workflow,",
        "start": 228.69,
        "duration": 4.45
    },
    {
        "text": "and scale machine learning adoption in their organization.",
        "start": 233.14,
        "duration": 4.07
    },
    {
        "text": "Following needs to have machine learning on-premise,",
        "start": 237.53,
        "duration": 5.125
    },
    {
        "text": "it varies among organizations.",
        "start": 242.655,
        "duration": 2.94
    },
    {
        "text": "Some organization have petabytes of data",
        "start": 245.595,
        "duration": 4.14
    },
    {
        "text": "on-premise and it's impractical",
        "start": 249.735,
        "duration": 3.815
    },
    {
        "text": "for them to move the data to Cloud.",
        "start": 253.55,
        "duration": 3.37
    },
    {
        "text": "Some organizations simply have",
        "start": 257.05,
        "duration": 3.46
    },
    {
        "text": "compliance requirements to keep all data on-premises.",
        "start": 260.51,
        "duration": 4.155
    },
    {
        "text": "While the other organization essentially have",
        "start": 264.665,
        "duration": 3.78
    },
    {
        "text": "a need to have machine learning in a hybrid environment.",
        "start": 268.445,
        "duration": 4.065
    },
    {
        "text": "For example, they have data in Cloud",
        "start": 272.51,
        "duration": 4.92
    },
    {
        "text": "and then they want to leverage powerful Cloud computer",
        "start": 277.43,
        "duration": 3.57
    },
    {
        "text": "to train model in Cloud.",
        "start": 281.0,
        "duration": 2.945
    },
    {
        "text": "After the model is trained,",
        "start": 283.945,
        "duration": 1.775
    },
    {
        "text": "they want to deploy model",
        "start": 285.72,
        "duration": 1.64
    },
    {
        "text": "to on-premises for latency and security requirement.",
        "start": 287.36,
        "duration": 5.135
    },
    {
        "text": "Vice versa, some category may wants to train a model",
        "start": 292.495,
        "duration": 5.05
    },
    {
        "text": "on-premises and then deploy",
        "start": 297.545,
        "duration": 2.415
    },
    {
        "text": "the model to Cloud for broader service access.",
        "start": 299.96,
        "duration": 3.81
    },
    {
        "text": "Lastly, organization usually has",
        "start": 303.77,
        "duration": 4.37
    },
    {
        "text": "a portion of machine learning requiring total confidentiality.",
        "start": 308.14,
        "duration": 5.07
    },
    {
        "text": "In this case, they want to have",
        "start": 313.28,
        "duration": 2.8
    },
    {
        "text": "full machine learning life cycle on-premises.",
        "start": 316.08,
        "duration": 3.62
    },
    {
        "text": "Azure Arc-enabled machine learning",
        "start": 319.7,
        "duration": 2.68
    },
    {
        "text": "address all these customer needs well.",
        "start": 322.38,
        "duration": 3.79
    },
    {
        "text": "With a simple Azure ML extension deployment,",
        "start": 326.17,
        "duration": 5.715
    },
    {
        "text": "customer gets all existing Azure ML tools",
        "start": 331.885,
        "duration": 5.489
    },
    {
        "text": "for full machine learning life cycle,",
        "start": 337.374,
        "duration": 2.671
    },
    {
        "text": "and then they have access to Azure manage your compute,",
        "start": 340.045,
        "duration": 4.245
    },
    {
        "text": "and customer managed Kubernetes computer.",
        "start": 344.29,
        "duration": 2.47
    },
    {
        "text": "Now, they can do machine learning",
        "start": 346.76,
        "duration": 2.3
    },
    {
        "text": "anywhere to meet their business need.",
        "start": 349.06,
        "duration": 3.925
    },
    {
        "text": ">> That's great, because so many people are already doing that.",
        "start": 352.985,
        "duration": 3.375
    },
    {
        "text": "They have their data on-premise",
        "start": 356.36,
        "duration": 1.578
    },
    {
        "text": "and they don't necessarily want to change",
        "start": 357.938,
        "duration": 1.652
    },
    {
        "text": "what they're doing and we're going,",
        "start": 359.59,
        "duration": 1.41
    },
    {
        "text": "and meeting their needs instead of expecting them to come our way.",
        "start": 361.0,
        "duration": 3.21
    },
    {
        "text": "That's really great.",
        "start": 364.21,
        "duration": 2.33
    },
    {
        "text": "Who is this feature for?",
        "start": 366.54,
        "duration": 1.83
    },
    {
        "text": "Who's going to be using this?",
        "start": 368.37,
        "duration": 1.755
    },
    {
        "text": ">> Azure Arc-enabled machine learning is intended",
        "start": 370.125,
        "duration": 3.494
    },
    {
        "text": "for customers, machine learning infrastructing.",
        "start": 373.619,
        "duration": 6.211
    },
    {
        "text": "The Team usually is responsible for setting up",
        "start": 379.83,
        "duration": 2.65
    },
    {
        "text": "a Kubernetes cluster and enable",
        "start": 382.48,
        "duration": 2.58
    },
    {
        "text": "Kubernetes cluster for the data science team to use",
        "start": 385.06,
        "duration": 3.48
    },
    {
        "text": "so that data science team can focus on building quality model",
        "start": 388.54,
        "duration": 5.735
    },
    {
        "text": "and put a model into production without",
        "start": 394.275,
        "duration": 3.88
    },
    {
        "text": "getting involved into too much details about Kubernetes.",
        "start": 398.155,
        "duration": 4.735
    },
    {
        "text": ">> I identify as a developer more than as an IT pro.",
        "start": 403.41,
        "duration": 4.03
    },
    {
        "text": "As a developer, I like that.",
        "start": 407.44,
        "duration": 2.055
    },
    {
        "text": "Somebody else has all the tools to make my life easier,",
        "start": 409.495,
        "duration": 5.385
    },
    {
        "text": "so that's all great.",
        "start": 414.88,
        "duration": 2.22
    },
    {
        "text": "But I want to see a demo and I think",
        "start": 417.1,
        "duration": 2.31
    },
    {
        "text": "people watching want see a demo too.",
        "start": 419.41,
        "duration": 1.56
    },
    {
        "text": "Can you show us a demo?",
        "start": 420.97,
        "duration": 1.51
    },
    {
        "text": ">> Great, definitely.",
        "start": 422.48,
        "duration": 2.29
    },
    {
        "text": "Let me have the screen here.",
        "start": 424.77,
        "duration": 3.75
    },
    {
        "text": "Enabling an existing cluster",
        "start": 428.52,
        "duration": 3.18
    },
    {
        "text": "to have Azure machine learning very easy.",
        "start": 431.7,
        "duration": 4.065
    },
    {
        "text": "It's about like a four step.",
        "start": 435.765,
        "duration": 1.985
    },
    {
        "text": "The first step is connect.",
        "start": 437.75,
        "duration": 1.98
    },
    {
        "text": "You connect the existing cluster to Kubernetes.",
        "start": 439.73,
        "duration": 4.275
    },
    {
        "text": "Then the second step is to deploy Azure ML extension.",
        "start": 444.005,
        "duration": 4.5
    },
    {
        "text": "Then the third step.",
        "start": 448.505,
        "duration": 1.125
    },
    {
        "text": "Basically, you attach Kubernetes cluster",
        "start": 449.63,
        "duration": 2.19
    },
    {
        "text": "to Azure machine learning workspace.",
        "start": 451.82,
        "duration": 2.52
    },
    {
        "text": "Then you create a computer target",
        "start": 454.34,
        "duration": 2.28
    },
    {
        "text": "that could be used for data science team.",
        "start": 456.62,
        "duration": 3.02
    },
    {
        "text": "The last step is basically,",
        "start": 459.64,
        "duration": 2.285
    },
    {
        "text": "data science team use the computer target.",
        "start": 461.925,
        "duration": 2.94
    },
    {
        "text": "Let me show how easy it is to turn this four step.",
        "start": 464.865,
        "duration": 5.765
    },
    {
        "text": "Here is a cluster that I have on my desktop,",
        "start": 470.63,
        "duration": 6.33
    },
    {
        "text": "so Docker Desktop Kubernetes cluster.",
        "start": 476.96,
        "duration": 3.945
    },
    {
        "text": "I can run a simple command,",
        "start": 480.905,
        "duration": 4.195
    },
    {
        "text": "so easy Connect and then connect to my desktop cluster,",
        "start": 485.1,
        "duration": 5.63
    },
    {
        "text": "Kubernetes cluster to Azure Cloud.",
        "start": 490.73,
        "duration": 4.3
    },
    {
        "text": "While it's connecting,",
        "start": 498.79,
        "duration": 3.15
    },
    {
        "text": "I have already a cluster and is connected to Azure Cloud already.",
        "start": 501.94,
        "duration": 9.875
    },
    {
        "text": "The second step is about deploying Azure ML extension.",
        "start": 511.815,
        "duration": 5.625
    },
    {
        "text": "You can run a simple CLI command",
        "start": 517.44,
        "duration": 4.78
    },
    {
        "text": "and then deploy Azure ML expansion",
        "start": 522.22,
        "duration": 3.06
    },
    {
        "text": "to a cluster that is already connected.",
        "start": 525.28,
        "duration": 3.61
    },
    {
        "text": "Let me run these extension command.",
        "start": 528.89,
        "duration": 4.24
    },
    {
        "text": "Now, while this both CLI commands are running,",
        "start": 533.13,
        "duration": 4.33
    },
    {
        "text": "we can head over to the Azure Portal",
        "start": 537.46,
        "duration": 4.13
    },
    {
        "text": "to see an Azure Arc-connected cluster,",
        "start": 541.59,
        "duration": 4.42
    },
    {
        "text": "which is already connected and then with the extension deployment.",
        "start": 546.01,
        "duration": 5.07
    },
    {
        "text": "I have a cluster on-premise.",
        "start": 551.08,
        "duration": 3.11
    },
    {
        "text": "This is A-K-S on Azure Stack HCI cluster on-premises",
        "start": 554.19,
        "duration": 6.53
    },
    {
        "text": "and outer is connected to Azure Cloud",
        "start": 560.72,
        "duration": 3.81
    },
    {
        "text": "is showing us Kubernetes Azure Arc.",
        "start": 564.53,
        "duration": 4.555
    },
    {
        "text": "Then the resource is created in Cloud.",
        "start": 569.085,
        "duration": 3.845
    },
    {
        "text": "Then I also have extension deployed.",
        "start": 572.93,
        "duration": 3.42
    },
    {
        "text": "You can see the extension is deployed here,",
        "start": 576.35,
        "duration": 2.465
    },
    {
        "text": "so this is the Azure ML extension.",
        "start": 578.815,
        "duration": 3.985
    },
    {
        "text": "Microsoft Azure ML Kubernetes extension, this is installed.",
        "start": 582.8,
        "duration": 4.59
    },
    {
        "text": "We can see some properties of these Azure ML extension.",
        "start": 587.39,
        "duration": 5.18
    },
    {
        "text": "You can see here I have enabled",
        "start": 592.57,
        "duration": 3.58
    },
    {
        "text": "a cluster for training and also for inference,",
        "start": 596.15,
        "duration": 4.655
    },
    {
        "text": "which means again, use these Kubernetes cluster",
        "start": 600.805,
        "duration": 3.994
    },
    {
        "text": "to try a model or deploy a model on these cluster.",
        "start": 604.799,
        "duration": 6.431
    },
    {
        "text": "Now, let's say, the cluster is",
        "start": 611.96,
        "duration": 3.955
    },
    {
        "text": "already deployed with the Azure ML potential.",
        "start": 615.915,
        "duration": 5.225
    },
    {
        "text": "I want to basically to deploy a model.",
        "start": 621.14,
        "duration": 8.07
    },
    {
        "text": "I can easily use the CLI command to deploy model.",
        "start": 629.21,
        "duration": 8.59
    },
    {
        "text": "Here's a project that I have.",
        "start": 638.15,
        "duration": 3.325
    },
    {
        "text": "It's an image classification model.",
        "start": 641.475,
        "duration": 3.145
    },
    {
        "text": "It's already trained.",
        "start": 644.62,
        "duration": 1.265
    },
    {
        "text": "I want to deploy the model to Azure Cloud using",
        "start": 645.885,
        "duration": 5.185
    },
    {
        "text": "basically the new Azure Arc-enabled model deployment capability,",
        "start": 651.07,
        "duration": 6.06
    },
    {
        "text": "safe roll out with blue and green deployment.",
        "start": 657.13,
        "duration": 4.29
    },
    {
        "text": "I have a endpoint YAML file,",
        "start": 661.42,
        "duration": 3.965
    },
    {
        "text": "which basically will create running a CLI command",
        "start": 665.385,
        "duration": 4.695
    },
    {
        "text": "with the these endpoint YAML.",
        "start": 670.08,
        "duration": 1.95
    },
    {
        "text": "It will create create an endpoint,",
        "start": 672.03,
        "duration": 6.18
    },
    {
        "text": "and usually, it can be detected,",
        "start": 678.21,
        "duration": 3.13
    },
    {
        "text": "Azure ML AI shop.",
        "start": 681.47,
        "duration": 3.77
    },
    {
        "text": "I also have a blue deployment YAML.",
        "start": 689.78,
        "duration": 4.585
    },
    {
        "text": "This will create a blue deployment first.",
        "start": 694.365,
        "duration": 3.665
    },
    {
        "text": "Let me first basically run a command to create an endpoint.",
        "start": 698.03,
        "duration": 5.89
    },
    {
        "text": "This will create endpoint.",
        "start": 718.01,
        "duration": 4.34
    },
    {
        "text": "Actually, we missed a step.",
        "start": 727.16,
        "duration": 3.8
    },
    {
        "text": "Intention in deployment,",
        "start": 737.18,
        "duration": 2.47
    },
    {
        "text": "the third step is about Attach that can be detect.",
        "start": 739.65,
        "duration": 4.38
    },
    {
        "text": "So, we attach and create a computer tab.",
        "start": 744.03,
        "duration": 3.7
    },
    {
        "text": "While it can be attached to the engine running,",
        "start": 751.25,
        "duration": 3.49
    },
    {
        "text": "I can go to the directory.",
        "start": 754.74,
        "duration": 3.87
    },
    {
        "text": "Now, I can create an endpoint.",
        "start": 758.61,
        "duration": 6.52
    },
    {
        "text": "With this simple CUI Command,",
        "start": 778.58,
        "duration": 5.41
    },
    {
        "text": "I can create an endpoint.",
        "start": 783.99,
        "duration": 4.03
    },
    {
        "text": "With endpoint being created,",
        "start": 795.23,
        "duration": 4.52
    },
    {
        "text": "I can head over to the Portal to",
        "start": 802.61,
        "duration": 4.795
    },
    {
        "text": "see the endpoint here.",
        "start": 807.405,
        "duration": 7.525
    },
    {
        "text": "This is the endpoint that just being created.",
        "start": 815.84,
        "duration": 5.9
    },
    {
        "text": "The endpoint creation is done.",
        "start": 824.66,
        "duration": 3.145
    },
    {
        "text": "Now, I can create a Blue Deployment.",
        "start": 827.805,
        "duration": 6.445
    },
    {
        "text": "Blue Deployment take time,",
        "start": 838.73,
        "duration": 3.58
    },
    {
        "text": "so let's head over to Azure Studio portal again.",
        "start": 842.31,
        "duration": 6.135
    },
    {
        "text": "I will show an already existing endpoint.",
        "start": 848.445,
        "duration": 4.815
    },
    {
        "text": "Here I show endpoint and you have Blue Deployment already created.",
        "start": 853.26,
        "duration": 6.345
    },
    {
        "text": "Now we have Blue Deployment with 100 percent of traffic.",
        "start": 859.605,
        "duration": 5.01
    },
    {
        "text": "I wanted to create another deployment called Green Deployment.",
        "start": 864.615,
        "duration": 5.545
    },
    {
        "text": "I have a new Green Deployment",
        "start": 871.69,
        "duration": 4.93
    },
    {
        "text": "and then with specifying instant type,",
        "start": 876.62,
        "duration": 4.28
    },
    {
        "text": "which is using a big CPU is that.",
        "start": 880.9,
        "duration": 2.96
    },
    {
        "text": "My original Blue Deployment",
        "start": 883.86,
        "duration": 1.769
    },
    {
        "text": "that the traffic is not meeting requirement.",
        "start": 885.629,
        "duration": 2.926
    },
    {
        "text": "Now I wanted to change using a big CPU incident type,",
        "start": 888.555,
        "duration": 3.12
    },
    {
        "text": "so I can handle more traffic.",
        "start": 891.675,
        "duration": 3.055
    },
    {
        "text": "Let me start creating",
        "start": 894.83,
        "duration": 2.41
    },
    {
        "text": "a Green Deployment using a simple CUI Command.",
        "start": 897.24,
        "duration": 4.69
    },
    {
        "text": ">> So you're going to have one endpoint to a two deployments?",
        "start": 908.96,
        "duration": 4.54
    },
    {
        "text": ">> Yes.",
        "start": 913.5,
        "duration": 0.93
    },
    {
        "text": ">> A Green and Blue Deployment",
        "start": 914.43,
        "duration": 2.92
    },
    {
        "text": "and all running on your local Kubernetes.",
        "start": 917.72,
        "duration": 4.765
    },
    {
        "text": ">> Yes. This is running on on-premise cluster,",
        "start": 922.485,
        "duration": 5.625
    },
    {
        "text": "so now it's creating the Green Deployment.",
        "start": 928.11,
        "duration": 4.035
    },
    {
        "text": "Let's head over to the portal to",
        "start": 932.145,
        "duration": 2.445
    },
    {
        "text": "see this Green Deployment in action.",
        "start": 934.59,
        "duration": 3.45
    },
    {
        "text": "If I refresh, we'll see the Green Deployment is being created and",
        "start": 938.04,
        "duration": 6.99
    },
    {
        "text": "this will be very quick and",
        "start": 945.03,
        "duration": 3.375
    },
    {
        "text": "we also see the notification here while it's being created.",
        "start": 948.405,
        "duration": 4.545
    },
    {
        "text": "Then outer lease is created.",
        "start": 952.95,
        "duration": 2.52
    },
    {
        "text": "We can change the trafficker",
        "start": 955.47,
        "duration": 2.16
    },
    {
        "text": "using this endpoint that you are also.",
        "start": 957.63,
        "duration": 4.39
    },
    {
        "text": "It should be very quick to create Green Deployment.",
        "start": 964.25,
        "duration": 6.88
    },
    {
        "text": ">> Can you just show us the command of how that would be updated?",
        "start": 971.13,
        "duration": 4.755
    },
    {
        "text": "You just pin it.",
        "start": 975.885,
        "duration": 0.825
    },
    {
        "text": "Great.",
        "start": 976.71,
        "duration": 1.26
    },
    {
        "text": ">> Now see, I wanted to update the traffic, okay?",
        "start": 977.97,
        "duration": 2.925
    },
    {
        "text": "I can use CUI but in this case I prefer to use UI.",
        "start": 980.895,
        "duration": 4.695
    },
    {
        "text": "Let me see.",
        "start": 985.59,
        "duration": 1.32
    },
    {
        "text": "I wanted to go with the 10 percent of traffic at",
        "start": 986.91,
        "duration": 2.91
    },
    {
        "text": "first and then I just update.",
        "start": 989.82,
        "duration": 3.735
    },
    {
        "text": "I give 10 percent of the green to update.",
        "start": 993.555,
        "duration": 5.155
    },
    {
        "text": "Once I have trafficker,",
        "start": 999.71,
        "duration": 2.5
    },
    {
        "text": "I can go to the Tester.",
        "start": 1002.21,
        "duration": 2.41
    },
    {
        "text": "Again, select green and do a simple test.",
        "start": 1005.92,
        "duration": 4.135
    },
    {
        "text": "Let me have the test example here.",
        "start": 1010.055,
        "duration": 7.945
    },
    {
        "text": "These are basically an image",
        "start": 1023.65,
        "duration": 3.56
    },
    {
        "text": "and is a handwriting disk with eight image.",
        "start": 1027.4,
        "duration": 6.595
    },
    {
        "text": "If I tests the green, it give me eight.",
        "start": 1033.995,
        "duration": 6.12
    },
    {
        "text": ">> Awesome.",
        "start": 1040.115,
        "duration": 0.39
    },
    {
        "text": ">> Which is running well.",
        "start": 1040.505,
        "duration": 3.42
    },
    {
        "text": "Now, see I want to go back.",
        "start": 1043.925,
        "duration": 3.045
    },
    {
        "text": "Everything is tested, it work great.",
        "start": 1046.97,
        "duration": 3.18
    },
    {
        "text": "I wanted to give all trafficker to green.",
        "start": 1050.15,
        "duration": 3.75
    },
    {
        "text": "Again, just move to 100 percent and update it",
        "start": 1053.9,
        "duration": 3.795
    },
    {
        "text": "again and this should be done in very quick.",
        "start": 1057.695,
        "duration": 5.655
    },
    {
        "text": ">> There it is.",
        "start": 1063.35,
        "duration": 0.6
    },
    {
        "text": ">> Now, do you see Blue Deployment is zero now.",
        "start": 1063.95,
        "duration": 3.675
    },
    {
        "text": "Now I can retire the Blue Deployment.",
        "start": 1067.625,
        "duration": 2.775
    },
    {
        "text": "The traffic is going all green now so I can retire, just delete.",
        "start": 1070.4,
        "duration": 5.71
    },
    {
        "text": ">> Now we'll have one endpoint with one deployment.",
        "start": 1078.04,
        "duration": 5.98
    },
    {
        "text": ">> I just showed how easy it is to safely roll out",
        "start": 1084.02,
        "duration": 4.65
    },
    {
        "text": "a model with Blue-Green Deployment.",
        "start": 1088.67,
        "duration": 2.7
    },
    {
        "text": ">> Yeah. On-premises on Kubernetes.",
        "start": 1091.37,
        "duration": 3.18
    },
    {
        "text": ">> Yes.",
        "start": 1094.55,
        "duration": 1.065
    },
    {
        "text": ">> That's what's special about that.",
        "start": 1095.615,
        "duration": 1.425
    },
    {
        "text": "That's super awesome.",
        "start": 1097.04,
        "duration": 0.84
    },
    {
        "text": "Thank you, Bozhong.",
        "start": 1097.88,
        "duration": 4.98
    },
    {
        "text": "This is really great.",
        "start": 1102.86,
        "duration": 1.365
    },
    {
        "text": "But Azure ML has one other feature Manage Online endpoints,",
        "start": 1104.225,
        "duration": 4.11
    },
    {
        "text": "which sounds very similar to what you've shown us.",
        "start": 1108.335,
        "duration": 2.595
    },
    {
        "text": "Can you tell us the difference?",
        "start": 1110.93,
        "duration": 2.71
    },
    {
        "text": ">> Both the online endpoint are built",
        "start": 1114.58,
        "duration": 3.205
    },
    {
        "text": "upon Azure Machine Learning Online endpoint,",
        "start": 1117.785,
        "duration": 4.225
    },
    {
        "text": "usually use the same set",
        "start": 1122.8,
        "duration": 2.74
    },
    {
        "text": "of tools to create a Magnitude Online endpoint.",
        "start": 1125.54,
        "duration": 5.43
    },
    {
        "text": "For Azure Managed Online endpoint influence on as you manage",
        "start": 1130.97,
        "duration": 8.64
    },
    {
        "text": "the compute and customer doesn't need to manage a computer and",
        "start": 1139.61,
        "duration": 5.775
    },
    {
        "text": "infrastructure and get a two key solution",
        "start": 1145.385,
        "duration": 4.17
    },
    {
        "text": "with the guarantee the SLA.",
        "start": 1149.555,
        "duration": 2.815
    },
    {
        "text": "For Kubernetes on my endpoint,",
        "start": 1152.47,
        "duration": 2.98
    },
    {
        "text": "it runs on customer managed Kubernetes.",
        "start": 1155.45,
        "duration": 4.515
    },
    {
        "text": "Customer has to be responsible for maintaining",
        "start": 1159.965,
        "duration": 4.035
    },
    {
        "text": "Kubernetes cluster and ensure Online endpoint the SLA.",
        "start": 1164.0,
        "duration": 5.235
    },
    {
        "text": "So that's our lucky difference.",
        "start": 1169.235,
        "duration": 2.115
    },
    {
        "text": ">> All right. So, if we want to manage on endpoints,",
        "start": 1171.35,
        "duration": 2.88
    },
    {
        "text": "then we choose Kubernetes Online endpoint",
        "start": 1174.23,
        "duration": 2.895
    },
    {
        "text": "and if you want Azure Tool Management for us,",
        "start": 1177.125,
        "duration": 2.085
    },
    {
        "text": "then we should use Manage Online endpoints.",
        "start": 1179.21,
        "duration": 3.135
    },
    {
        "text": ">> Yes.",
        "start": 1182.345,
        "duration": 0.705
    },
    {
        "text": ">> That's makes a lot of sense.",
        "start": 1183.05,
        "duration": 0.96
    },
    {
        "text": "Where can people go to find out more?",
        "start": 1184.01,
        "duration": 3.435
    },
    {
        "text": ">> There's a blog and also we have GitHub available,",
        "start": 1187.445,
        "duration": 9.165
    },
    {
        "text": "and then there's a video documentation aka MLDocs.",
        "start": 1196.61,
        "duration": 8.04
    },
    {
        "text": "All these are resource for you",
        "start": 1204.65,
        "duration": 3.06
    },
    {
        "text": "to find out more information and get started easy.",
        "start": 1207.71,
        "duration": 3.315
    },
    {
        "text": ">> This is so awesome,",
        "start": 1211.025,
        "duration": 1.215
    },
    {
        "text": "Bozhong, thank you.",
        "start": 1212.24,
        "duration": 1.71
    },
    {
        "text": "It was so great to have you on the show.",
        "start": 1213.95,
        "duration": 2.43
    },
    {
        "text": ">> Thank you, my pleasure.",
        "start": 1216.38,
        "duration": 1.86
    },
    {
        "text": ">> In this episode, you learn how you can use",
        "start": 1218.24,
        "duration": 2.715
    },
    {
        "text": "Arc-enabled ML for inference on Azure.",
        "start": 1220.955,
        "duration": 2.865
    },
    {
        "text": "This feature allows you to deploy",
        "start": 1223.82,
        "duration": 1.62
    },
    {
        "text": "and serve models in any infrastructure,",
        "start": 1225.44,
        "duration": 1.89
    },
    {
        "text": "on-premises, and across multi-Cloud using Kubernetes.",
        "start": 1227.33,
        "duration": 3.48
    },
    {
        "text": "How cool is that?",
        "start": 1230.81,
        "duration": 0.93
    },
    {
        "text": "Thank you for watching",
        "start": 1231.74,
        "duration": 1.74
    },
    {
        "text": "and we'll see you next time.",
        "start": 1233.48,
        "duration": 1.62
    },
    {
        "text": "[MUSIC]",
        "start": 1235.1,
        "duration": 8.9
    }
]