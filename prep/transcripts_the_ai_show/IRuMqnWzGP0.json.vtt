[
    {
        "text": ">> You're not going to want to miss this episode",
        "start": 0.0,
        "duration": 1.5
    },
    {
        "text": "of the AI Show where we learn all about",
        "start": 1.5,
        "duration": 1.41
    },
    {
        "text": "time series forecasting with automated machine learning,",
        "start": 2.91,
        "duration": 3.06
    },
    {
        "text": "a new capability that you can use",
        "start": 5.97,
        "duration": 2.07
    },
    {
        "text": "today, make sure you check it out.",
        "start": 8.04,
        "duration": 2.13
    },
    {
        "text": "[MUSIC]",
        "start": 10.17,
        "duration": 8.25
    },
    {
        "text": ">> Hello and welcome to this episode of the AI Show,",
        "start": 18.42,
        "duration": 1.92
    },
    {
        "text": "a special build addition,",
        "start": 20.34,
        "duration": 1.05
    },
    {
        "text": "where we're talking about time series forecasting",
        "start": 21.39,
        "duration": 1.95
    },
    {
        "text": "with automated machine learning.",
        "start": 23.34,
        "duration": 1.35
    },
    {
        "text": "I've got a special guest with me.",
        "start": 24.69,
        "duration": 1.02
    },
    {
        "text": "Hello my friend, tell us who you are and what you do?",
        "start": 25.71,
        "duration": 2.07
    },
    {
        "text": ">> Hi everyone. My name is",
        "start": 27.78,
        "duration": 1.44
    },
    {
        "text": "Sabina Cartacio and I'm a Program Manager for",
        "start": 29.22,
        "duration": 2.25
    },
    {
        "text": "Azure Machine Learning and I",
        "start": 31.47,
        "duration": 1.35
    },
    {
        "text": "focus on forecasting with automated ML.",
        "start": 32.82,
        "duration": 2.15
    },
    {
        "text": ">> Thanks Cartacio.",
        "start": 34.97,
        "duration": 0.55
    },
    {
        "text": "Let's start with the first and obvious question,",
        "start": 35.52,
        "duration": 3.03
    },
    {
        "text": "what is time series forecasting?",
        "start": 38.55,
        "duration": 2.62
    },
    {
        "text": ">> So time series forecasting is the process of",
        "start": 41.17,
        "duration": 3.25
    },
    {
        "text": "using historical data to predict future observations.",
        "start": 44.42,
        "duration": 3.42
    },
    {
        "text": "This is commonly used in industry for tasks such as financial,",
        "start": 47.84,
        "duration": 3.93
    },
    {
        "text": "resource, inventory and capacity planning.",
        "start": 51.77,
        "duration": 3.585
    },
    {
        "text": ">> That's amazing. So what kinds of things",
        "start": 55.355,
        "duration": 3.405
    },
    {
        "text": "do we have to consider when we're doing forecasting.",
        "start": 58.76,
        "duration": 3.06
    },
    {
        "text": "I understand the historical data nature of this,",
        "start": 61.82,
        "duration": 3.18
    },
    {
        "text": "but is there anything else we need to think about?",
        "start": 65.0,
        "duration": 2.36
    },
    {
        "text": ">> Yeah, well when creating a machine learning model in general,",
        "start": 67.36,
        "duration": 3.01
    },
    {
        "text": "we have to consider many different",
        "start": 70.37,
        "duration": 1.365
    },
    {
        "text": "algorithms and hyperparameter values.",
        "start": 71.735,
        "duration": 2.145
    },
    {
        "text": "When we focus specifically on forecasting,",
        "start": 73.88,
        "duration": 2.58
    },
    {
        "text": "we need to consider seasonality,",
        "start": 76.46,
        "duration": 1.68
    },
    {
        "text": "trends and even the effects of holidays.",
        "start": 78.14,
        "duration": 2.72
    },
    {
        "text": ">> So you're saying that my data that has",
        "start": 80.86,
        "duration": 3.115
    },
    {
        "text": "time series is just different inherently.",
        "start": 83.975,
        "duration": 3.225
    },
    {
        "text": "It sounds like it makes things a little bit more complex though.",
        "start": 87.2,
        "duration": 3.36
    },
    {
        "text": "How do we train models with these additional considerations?",
        "start": 90.56,
        "duration": 4.069
    },
    {
        "text": ">> Definitely. So it is very tricky to consider all of these,",
        "start": 94.629,
        "duration": 3.711
    },
    {
        "text": "but what if instead of manually considering all of these factors,",
        "start": 98.34,
        "duration": 3.44
    },
    {
        "text": "we could actually automate them.",
        "start": 101.78,
        "duration": 2.115
    },
    {
        "text": "So with automated machine learning,",
        "start": 103.895,
        "duration": 1.485
    },
    {
        "text": "we can automate the algorithm selection,",
        "start": 105.38,
        "duration": 2.459
    },
    {
        "text": "the hyperparameter value surge,",
        "start": 107.839,
        "duration": 2.266
    },
    {
        "text": "as well as even data featurization, including holidays.",
        "start": 110.105,
        "duration": 3.56
    },
    {
        "text": "This all comes together to basically help you",
        "start": 113.665,
        "duration": 2.665
    },
    {
        "text": "find the best machine learning model for your data.",
        "start": 116.33,
        "duration": 2.82
    },
    {
        "text": ">> So we already had automated machine learning before,",
        "start": 119.15,
        "duration": 3.885
    },
    {
        "text": "now what we're doing is we're basically making it work",
        "start": 123.035,
        "duration": 3.645
    },
    {
        "text": "with new time series forecasting data, is that all right?",
        "start": 126.68,
        "duration": 3.925
    },
    {
        "text": ">> That is correct, yes.",
        "start": 130.605,
        "duration": 1.305
    },
    {
        "text": ">> All right, who is using this?",
        "start": 131.91,
        "duration": 1.2
    },
    {
        "text": ">> So we have a few deeply engaged customers.",
        "start": 133.11,
        "duration": 3.56
    },
    {
        "text": "As you can see, some of these include Wood Group,",
        "start": 136.67,
        "duration": 3.21
    },
    {
        "text": "Schneider Electric, Walmart, JNJ,",
        "start": 139.88,
        "duration": 2.4
    },
    {
        "text": "Pepsi, and most recently DriveTime.",
        "start": 142.28,
        "duration": 2.72
    },
    {
        "text": ">> All right, so let's see. I'd love",
        "start": 145.0,
        "duration": 1.69
    },
    {
        "text": "to see one of these use cases.",
        "start": 146.69,
        "duration": 1.5
    },
    {
        "text": "Is there a particular customer you'd like to focus on?",
        "start": 148.19,
        "duration": 2.675
    },
    {
        "text": ">> Yeah. Let's focus on DriveTime.",
        "start": 150.865,
        "duration": 2.625
    },
    {
        "text": "So a little bit of background on DriveTime before we jump in.",
        "start": 153.49,
        "duration": 3.01
    },
    {
        "text": "DriveTime is actually one of",
        "start": 156.5,
        "duration": 1.59
    },
    {
        "text": "the largest used car retailers in the United States.",
        "start": 158.09,
        "duration": 3.195
    },
    {
        "text": "They focus on helping customers find",
        "start": 161.285,
        "duration": 2.055
    },
    {
        "text": "the best vehicle and financing for their needs.",
        "start": 163.34,
        "duration": 2.975
    },
    {
        "text": ">> All right, so what are they doing?",
        "start": 166.315,
        "duration": 2.09
    },
    {
        "text": ">> Yeah, so they're actually are",
        "start": 168.405,
        "duration": 1.985
    },
    {
        "text": "building using Azure Machine Learning.",
        "start": 170.39,
        "duration": 2.475
    },
    {
        "text": "They're building ML pipelines and leveraging AutoML to basically",
        "start": 172.865,
        "duration": 4.065
    },
    {
        "text": "fuse automated modeling into",
        "start": 176.93,
        "duration": 2.79
    },
    {
        "text": "their proprietary scoring and finance models.",
        "start": 179.72,
        "duration": 3.185
    },
    {
        "text": ">> So I'm trying to understand,",
        "start": 182.905,
        "duration": 3.005
    },
    {
        "text": "so what about their data makes it time series based data?",
        "start": 185.91,
        "duration": 5.265
    },
    {
        "text": ">> Yeah. A lot of times especially in finance,",
        "start": 191.175,
        "duration": 3.125
    },
    {
        "text": "what we're looking at is trends.",
        "start": 194.3,
        "duration": 1.53
    },
    {
        "text": "So we want to know for a financial cycle how maybe",
        "start": 195.83,
        "duration": 2.85
    },
    {
        "text": "things are selling or whether or not customers are returning,",
        "start": 198.68,
        "duration": 3.36
    },
    {
        "text": "and a lot of this is based under a seasonality.",
        "start": 202.04,
        "duration": 2.835
    },
    {
        "text": "How do things act over time,",
        "start": 204.875,
        "duration": 2.42
    },
    {
        "text": "and they tend to repeat.",
        "start": 207.295,
        "duration": 1.34
    },
    {
        "text": "That's where we get trends.",
        "start": 208.635,
        "duration": 1.185
    },
    {
        "text": "Around Christmas, toys sell more.",
        "start": 209.82,
        "duration": 2.445
    },
    {
        "text": "It's that pattern that you're looking for with time series.",
        "start": 212.265,
        "duration": 2.995
    },
    {
        "text": ">> So basically what they did is they fed their data",
        "start": 215.26,
        "duration": 2.8
    },
    {
        "text": "to automated machine learning and it just generated models.",
        "start": 218.06,
        "duration": 3.045
    },
    {
        "text": "How many models did they generate?",
        "start": 221.105,
        "duration": 2.195
    },
    {
        "text": ">> Yeah. So they actually built",
        "start": 223.3,
        "duration": 1.705
    },
    {
        "text": "a multi-step pipeline using ML pipelines to",
        "start": 225.005,
        "duration": 3.465
    },
    {
        "text": "process their different data and they ended up",
        "start": 228.47,
        "duration": 2.13
    },
    {
        "text": "building over 20,000 different models.",
        "start": 230.6,
        "duration": 2.94
    },
    {
        "text": "This was not just models,",
        "start": 233.54,
        "duration": 2.07
    },
    {
        "text": "but also featurization techniques and hyperparameter values,",
        "start": 235.61,
        "duration": 3.03
    },
    {
        "text": "and they were able to cherry pick",
        "start": 238.64,
        "duration": 1.26
    },
    {
        "text": "the best model for their use case.",
        "start": 239.9,
        "duration": 1.97
    },
    {
        "text": "Going forward, they are even looking to optimize this whole setup",
        "start": 241.87,
        "duration": 3.625
    },
    {
        "text": "and make it usable for their other high-volume data scenarios.",
        "start": 245.495,
        "duration": 3.755
    },
    {
        "text": ">> That's really cool. So tell us a little bit more about",
        "start": 249.25,
        "duration": 2.56
    },
    {
        "text": "automated machine learning's forecasting capabilities,",
        "start": 251.81,
        "duration": 2.88
    },
    {
        "text": "because I think this is a new thing.",
        "start": 254.69,
        "duration": 2.855
    },
    {
        "text": ">> So the first thing that you can see here is deep learning.",
        "start": 257.545,
        "duration": 3.565
    },
    {
        "text": "We actually had a DNN web",
        "start": 261.11,
        "duration": 2.64
    },
    {
        "text": "forecasting specifically that was brought in Microsoft research.",
        "start": 263.75,
        "duration": 3.87
    },
    {
        "text": "Along the same lines,",
        "start": 267.62,
        "duration": 1.74
    },
    {
        "text": "we also have forecasting specific backtrack.",
        "start": 269.36,
        "duration": 4.215
    },
    {
        "text": "We also have models that are popular",
        "start": 273.575,
        "duration": 2.325
    },
    {
        "text": "within the forecasting realms such as a Riemann profit.",
        "start": 275.9,
        "duration": 2.94
    },
    {
        "text": "These models are wildly popular and",
        "start": 278.84,
        "duration": 2.01
    },
    {
        "text": "they're available within automated machine learning.",
        "start": 280.85,
        "duration": 2.235
    },
    {
        "text": "Alongside this, we also have auto settings and holiday detection.",
        "start": 283.085,
        "duration": 4.53
    },
    {
        "text": ">> What do you mean by holiday detection?",
        "start": 287.615,
        "duration": 2.175
    },
    {
        "text": "That's interesting to me.",
        "start": 289.79,
        "duration": 1.41
    },
    {
        "text": ">> Yeah, this is definitely a very popular feature.",
        "start": 291.2,
        "duration": 2.805
    },
    {
        "text": "Essentially you just specify your country or region and",
        "start": 294.005,
        "duration": 2.88
    },
    {
        "text": "AutoML will go ahead and enrich",
        "start": 296.885,
        "duration": 1.575
    },
    {
        "text": "your data with holiday information.",
        "start": 298.46,
        "duration": 2.67
    },
    {
        "text": ">> That's interesting to me because",
        "start": 301.13,
        "duration": 2.94
    },
    {
        "text": "usually when it comes to seasonality,",
        "start": 304.07,
        "duration": 2.79
    },
    {
        "text": "like holidays are usually when things are just weird,",
        "start": 306.86,
        "duration": 3.09
    },
    {
        "text": "and we have to make sure that we account for that weirdness.",
        "start": 309.95,
        "duration": 3.215
    },
    {
        "text": ">> Exactly.",
        "start": 313.165,
        "duration": 1.19
    },
    {
        "text": ">> So we've talked a lot about this.",
        "start": 314.355,
        "duration": 2.135
    },
    {
        "text": "I'd love to see some demo,",
        "start": 316.49,
        "duration": 1.83
    },
    {
        "text": "do you have something you show us?",
        "start": 318.32,
        "duration": 1.425
    },
    {
        "text": ">> Yeah definitely.",
        "start": 319.745,
        "duration": 1.77
    },
    {
        "text": "So we're actually going to go through",
        "start": 321.515,
        "duration": 2.355
    },
    {
        "text": "an example of orange juice forecasting.",
        "start": 323.87,
        "duration": 2.73
    },
    {
        "text": "So we have a couple of stores across",
        "start": 326.6,
        "duration": 2.04
    },
    {
        "text": "the United States that are selling",
        "start": 328.64,
        "duration": 1.26
    },
    {
        "text": "different brands of orange juice,",
        "start": 329.9,
        "duration": 1.365
    },
    {
        "text": "and we want to know how they're selling, so the quantity,",
        "start": 331.265,
        "duration": 3.135
    },
    {
        "text": "and we're going to walk through this notebook,",
        "start": 334.4,
        "duration": 1.485
    },
    {
        "text": "it is a basic automated ML notebook at the skeleton",
        "start": 335.885,
        "duration": 3.195
    },
    {
        "text": "with some forecasting",
        "start": 339.08,
        "duration": 1.17
    },
    {
        "text": "specific variables that we're going to talk about.",
        "start": 340.25,
        "duration": 2.67
    },
    {
        "text": "So the first thing we're going to do is like with",
        "start": 342.92,
        "duration": 2.16
    },
    {
        "text": "any automated ML experiment just go ahead and setup.",
        "start": 345.08,
        "duration": 3.105
    },
    {
        "text": "So we're importing the red libraries",
        "start": 348.185,
        "duration": 2.235
    },
    {
        "text": "making sure that our subscription is setup correctly,",
        "start": 350.42,
        "duration": 2.94
    },
    {
        "text": "and the next important thing is the compute.",
        "start": 353.36,
        "duration": 1.815
    },
    {
        "text": "You're able to use either local or remote compute.",
        "start": 355.175,
        "duration": 3.66
    },
    {
        "text": "Moving forward, we start with",
        "start": 358.835,
        "duration": 2.1
    },
    {
        "text": "arguably the most important part, the data.",
        "start": 360.935,
        "duration": 2.475
    },
    {
        "text": "So here we can see that we're passing in the time, column, name.",
        "start": 363.41,
        "duration": 3.39
    },
    {
        "text": "The time, column, name is WeekStarting.",
        "start": 366.8,
        "duration": 1.95
    },
    {
        "text": "We always have to specify what",
        "start": 368.75,
        "duration": 1.38
    },
    {
        "text": "the time is for time series forecasting.",
        "start": 370.13,
        "duration": 2.15
    },
    {
        "text": "We actually have weekly data.",
        "start": 372.28,
        "duration": 1.78
    },
    {
        "text": "Although if you notice here, we have",
        "start": 374.06,
        "duration": 1.26
    },
    {
        "text": "the same timestamp repeated many times.",
        "start": 375.32,
        "duration": 2.31
    },
    {
        "text": "This is because we have a unique combination of store and brand.",
        "start": 377.63,
        "duration": 3.39
    },
    {
        "text": "So here we can see we have Store 2 for Dominicks, Minute Maid,",
        "start": 381.02,
        "duration": 3.09
    },
    {
        "text": "Tropicana, and then you see the same date before a new store.",
        "start": 384.11,
        "duration": 3.3
    },
    {
        "text": "So that's the trend of our data.",
        "start": 387.41,
        "duration": 2.21
    },
    {
        "text": ">> Before we go on and this is what makes it intrinsically",
        "start": 389.62,
        "duration": 4.72
    },
    {
        "text": "time series based is that we have a timestamp of store,",
        "start": 394.34,
        "duration": 4.735
    },
    {
        "text": "but the timestamp is coupled with in this case a difference store.",
        "start": 399.075,
        "duration": 3.945
    },
    {
        "text": "So that way you have two things going on at the same time.",
        "start": 403.02,
        "duration": 2.575
    },
    {
        "text": ">> So this is actually a multi-time series problem.",
        "start": 405.595,
        "duration": 3.475
    },
    {
        "text": "So we are dealing with multiple time series",
        "start": 409.07,
        "duration": 2.01
    },
    {
        "text": "and AutoML can handle this,",
        "start": 411.08,
        "duration": 1.21
    },
    {
        "text": "and I'm going to show you how we do that.",
        "start": 412.29,
        "duration": 1.31
    },
    {
        "text": ">> Awesome.",
        "start": 413.6,
        "duration": 0.875
    },
    {
        "text": ">> So right here to your question,",
        "start": 414.475,
        "duration": 2.5
    },
    {
        "text": "we have a variable called time_column_names,",
        "start": 416.975,
        "duration": 2.97
    },
    {
        "text": "and this is what we referred to internally as a time series ID.",
        "start": 419.945,
        "duration": 3.315
    },
    {
        "text": "How do you uniquely identify these duplicate timestamps,",
        "start": 423.26,
        "duration": 3.224
    },
    {
        "text": "and we said that this was the combination of store and brand.",
        "start": 426.484,
        "duration": 3.066
    },
    {
        "text": "We're going to actually go ahead and cut down this problem a",
        "start": 429.55,
        "duration": 2.5
    },
    {
        "text": "little bit and we're just going to focus on three stores;",
        "start": 432.05,
        "duration": 2.42
    },
    {
        "text": "stores 2, 5 and 8.",
        "start": 434.47,
        "duration": 1.565
    },
    {
        "text": "We saw from above that there are",
        "start": 436.035,
        "duration": 1.445
    },
    {
        "text": "three brands of orange juice for every store.",
        "start": 437.48,
        "duration": 2.865
    },
    {
        "text": "So it's actually telling us that when we",
        "start": 440.345,
        "duration": 1.485
    },
    {
        "text": "cut down to only three stores,",
        "start": 441.83,
        "duration": 1.41
    },
    {
        "text": "there are nine individual time series.",
        "start": 443.24,
        "duration": 2.6
    },
    {
        "text": ">> I see, cool.",
        "start": 445.84,
        "duration": 1.64
    },
    {
        "text": "So basically it's going to do",
        "start": 447.48,
        "duration": 1.58
    },
    {
        "text": "the combination for all of those stores,",
        "start": 449.06,
        "duration": 2.565
    },
    {
        "text": "all of those times.",
        "start": 451.625,
        "duration": 1.295
    },
    {
        "text": ">> Exactly.",
        "start": 452.92,
        "duration": 0.65
    },
    {
        "text": ">> I love it.",
        "start": 453.57,
        "duration": 0.97
    },
    {
        "text": ">> The next part is the data splitting.",
        "start": 454.54,
        "duration": 2.23
    },
    {
        "text": "This is pretty standard for most machine learning,",
        "start": 456.77,
        "duration": 2.01
    },
    {
        "text": "but one thing I want to take note here is these end test periods.",
        "start": 458.78,
        "duration": 3.53
    },
    {
        "text": "What this is referring to is your forecast horizon.",
        "start": 462.31,
        "duration": 2.73
    },
    {
        "text": "So this is how far out into the future you may want to predict.",
        "start": 465.04,
        "duration": 3.625
    },
    {
        "text": "If you notice we're not passing in a unit,",
        "start": 468.665,
        "duration": 2.16
    },
    {
        "text": "that's because we infer the unit from the data that's passed in.",
        "start": 470.825,
        "duration": 3.405
    },
    {
        "text": "So in our example we know that we have",
        "start": 474.23,
        "duration": 1.35
    },
    {
        "text": "weekly data so this 20 [inaudible].",
        "start": 475.58,
        "duration": 3.09
    },
    {
        "text": ">> I see.",
        "start": 478.67,
        "duration": 1.125
    },
    {
        "text": ">> Then we're just going to go ahead and upload",
        "start": 479.795,
        "duration": 2.115
    },
    {
        "text": "the data to the data store,",
        "start": 481.91,
        "duration": 1.485
    },
    {
        "text": "and as you can see there, and then create a dataset for training.",
        "start": 483.395,
        "duration": 3.015
    },
    {
        "text": "Now I do want to point out here that we're printing out the tail.",
        "start": 486.41,
        "duration": 2.91
    },
    {
        "text": "So the end of the data,",
        "start": 489.32,
        "duration": 1.335
    },
    {
        "text": "this is extremely important because when you go to",
        "start": 490.655,
        "duration": 2.22
    },
    {
        "text": "predict out or forecast out those 20 units,",
        "start": 492.875,
        "duration": 3.315
    },
    {
        "text": "you know that you have to start from this date point,",
        "start": 496.19,
        "duration": 2.095
    },
    {
        "text": "from the last date in the training data.",
        "start": 498.285,
        "duration": 2.645
    },
    {
        "text": ">> Got it.",
        "start": 500.93,
        "duration": 1.265
    },
    {
        "text": ">> Now we go into modeling.",
        "start": 502.195,
        "duration": 2.495
    },
    {
        "text": "Again this is a pretty standard process for all machine learning.",
        "start": 504.69,
        "duration": 3.62
    },
    {
        "text": "You're just passing in the target column,",
        "start": 508.31,
        "duration": 2.01
    },
    {
        "text": "what you want to predict.",
        "start": 510.32,
        "duration": 1.14
    },
    {
        "text": "In our case it's quantity;",
        "start": 511.46,
        "duration": 1.335
    },
    {
        "text": "how much orange juice was sold.",
        "start": 512.795,
        "duration": 2.175
    },
    {
        "text": "We also have a small step and customization.",
        "start": 514.97,
        "duration": 3.21
    },
    {
        "text": "This essentially allows you to decide if you want to",
        "start": 518.18,
        "duration": 2.37
    },
    {
        "text": "drop certain columns or change how they're imputed.",
        "start": 520.55,
        "duration": 2.535
    },
    {
        "text": "So if you have a missing value, should we use mean,",
        "start": 523.085,
        "duration": 2.145
    },
    {
        "text": "should we use pass contexts to fill",
        "start": 525.23,
        "duration": 1.98
    },
    {
        "text": "future contexts. You can decide all that.",
        "start": 527.21,
        "duration": 2.3
    },
    {
        "text": ">> Got it. So standard machine learning featurization stuff.",
        "start": 529.51,
        "duration": 3.14
    },
    {
        "text": ">> Exactly.",
        "start": 532.65,
        "duration": 0.66
    },
    {
        "text": ">> Got it.",
        "start": 533.31,
        "duration": 0.57
    },
    {
        "text": ">> Below training; the training",
        "start": 533.88,
        "duration": 1.61
    },
    {
        "text": "is exactly the same as other AutoML.",
        "start": 535.49,
        "duration": 1.59
    },
    {
        "text": "If you noticed the only difference here",
        "start": 537.08,
        "duration": 1.68
    },
    {
        "text": "is we have specific time series settings.",
        "start": 538.76,
        "duration": 1.815
    },
    {
        "text": "So we're setting that time column, that grain,",
        "start": 540.575,
        "duration": 2.385
    },
    {
        "text": "and that horizon that we talked about,",
        "start": 542.96,
        "duration": 1.69
    },
    {
        "text": "and then we're passing it in at the bottom here to AutoML.",
        "start": 544.65,
        "duration": 3.095
    },
    {
        "text": "Once that's done, we go ahead and submit that run.",
        "start": 547.745,
        "duration": 3.405
    },
    {
        "text": "You can go ahead and track this run in",
        "start": 551.15,
        "duration": 2.19
    },
    {
        "text": "the studio and I'll show you",
        "start": 553.34,
        "duration": 1.275
    },
    {
        "text": "quickly what that looks like once it's done.",
        "start": 554.615,
        "duration": 1.98
    },
    {
        "text": "So here I can see many different models that were attempted,",
        "start": 556.595,
        "duration": 3.015
    },
    {
        "text": "and I can go ahead and dig into them,",
        "start": 559.61,
        "duration": 1.5
    },
    {
        "text": "I can see graphs and more metrics for each of them.",
        "start": 561.11,
        "duration": 3.375
    },
    {
        "text": "Here we're going to focus on the best model.",
        "start": 564.485,
        "duration": 2.58
    },
    {
        "text": "So we retrieve the best model which",
        "start": 567.065,
        "duration": 2.125
    },
    {
        "text": "happens to be the standard scalar rapper,",
        "start": 569.19,
        "duration": 1.95
    },
    {
        "text": "and we can even get transformation and",
        "start": 571.14,
        "duration": 1.97
    },
    {
        "text": "transparency for this model.",
        "start": 573.11,
        "duration": 2.1
    },
    {
        "text": "So we can see all the different transformers,",
        "start": 575.21,
        "duration": 2.16
    },
    {
        "text": "we can see the detected type,",
        "start": 577.37,
        "duration": 2.01
    },
    {
        "text": "whether they were dropped in",
        "start": 579.38,
        "duration": 1.14
    },
    {
        "text": "the preprocessing state or not and more.",
        "start": 580.52,
        "duration": 2.83
    },
    {
        "text": ">> This is cool. So basically it's just standard,",
        "start": 583.35,
        "duration": 3.915
    },
    {
        "text": "because the data is only thing is different,",
        "start": 587.265,
        "duration": 2.3
    },
    {
        "text": "after that it's just standard automated machine",
        "start": 589.565,
        "duration": 2.775
    },
    {
        "text": "learning with just an additional three settings?",
        "start": 592.34,
        "duration": 2.625
    },
    {
        "text": ">> Yes.",
        "start": 594.965,
        "duration": 0.915
    },
    {
        "text": ">> That's cool.",
        "start": 595.88,
        "duration": 0.24
    },
    {
        "text": ">> Then it becomes a little different when",
        "start": 596.12,
        "duration": 2.13
    },
    {
        "text": "we come at the evaluation portion.",
        "start": 598.25,
        "duration": 2.23
    },
    {
        "text": "So when we come to actually gather forecasts,",
        "start": 600.48,
        "duration": 2.33
    },
    {
        "text": "because we're actually time aware.",
        "start": 602.81,
        "duration": 2.46
    },
    {
        "text": "So that's the next different step.",
        "start": 605.27,
        "duration": 2.73
    },
    {
        "text": "So here we're going to quickly view",
        "start": 608.0,
        "duration": 2.085
    },
    {
        "text": "the test data that we're going to pass in.",
        "start": 610.085,
        "duration": 1.95
    },
    {
        "text": "So if we were to look at the tail",
        "start": 612.035,
        "duration": 1.845
    },
    {
        "text": "from above and this would be able to see that",
        "start": 613.88,
        "duration": 1.83
    },
    {
        "text": "these dates fall within a range of",
        "start": 615.71,
        "duration": 1.56
    },
    {
        "text": "the last date and 20 units forward,",
        "start": 617.27,
        "duration": 2.34
    },
    {
        "text": "and we're not passing in quantity,",
        "start": 619.61,
        "duration": 2.28
    },
    {
        "text": "so we're not passing in that target.",
        "start": 621.89,
        "duration": 1.665
    },
    {
        "text": "So if we go down here,",
        "start": 623.555,
        "duration": 1.935
    },
    {
        "text": "what we're going to do is evaluate.",
        "start": 625.49,
        "duration": 1.905
    },
    {
        "text": "Before we actually ask for predictions,",
        "start": 627.395,
        "duration": 1.545
    },
    {
        "text": "what we want to know how did this model perform,",
        "start": 628.94,
        "duration": 2.175
    },
    {
        "text": "let me see some metrics,",
        "start": 631.115,
        "duration": 1.215
    },
    {
        "text": "some of the validation that was done for the model,",
        "start": 632.33,
        "duration": 2.4
    },
    {
        "text": "and you can see how the model performed.",
        "start": 634.73,
        "duration": 1.62
    },
    {
        "text": "So I ran this one for a very short amount of time but it's",
        "start": 636.35,
        "duration": 2.43
    },
    {
        "text": "still pretty impressive to see such good results,",
        "start": 638.78,
        "duration": 2.69
    },
    {
        "text": "but now I'm more interested in how do I get my forecast.",
        "start": 641.47,
        "duration": 3.38
    },
    {
        "text": "So we're going to operationalize this.",
        "start": 644.85,
        "duration": 2.195
    },
    {
        "text": "When we see operationalize,",
        "start": 647.045,
        "duration": 1.575
    },
    {
        "text": "we mean that we're going to develop",
        "start": 648.62,
        "duration": 1.32
    },
    {
        "text": "a scoring script and we're going to deploy the model.",
        "start": 649.94,
        "duration": 2.49
    },
    {
        "text": "This is going to generate a REST API and",
        "start": 652.43,
        "duration": 2.07
    },
    {
        "text": "we can hit that endpoint to get our forecast.",
        "start": 654.5,
        "duration": 2.49
    },
    {
        "text": "So here we're deploying as an Azure Container instance,",
        "start": 656.99,
        "duration": 4.139
    },
    {
        "text": "and then we're going to call the service.",
        "start": 661.129,
        "duration": 2.566
    },
    {
        "text": "So what we see here when we call the service is",
        "start": 663.695,
        "duration": 1.875
    },
    {
        "text": "that we have a new column of data,",
        "start": 665.57,
        "duration": 1.89
    },
    {
        "text": "forecasts, and these are actually",
        "start": 667.46,
        "duration": 1.62
    },
    {
        "text": "the predictions returned from the model.",
        "start": 669.08,
        "duration": 1.865
    },
    {
        "text": ">> I see. Can we scroll up because I have",
        "start": 670.945,
        "duration": 1.78
    },
    {
        "text": "a couple of questions here?",
        "start": 672.725,
        "duration": 1.65
    },
    {
        "text": ">> Yeah.",
        "start": 674.375,
        "duration": 0.47
    },
    {
        "text": ">> So as we scroll up,",
        "start": 674.845,
        "duration": 1.495
    },
    {
        "text": "the one question I had was about that one right there.",
        "start": 676.34,
        "duration": 4.15
    },
    {
        "text": "So if we scroll down,",
        "start": 680.49,
        "duration": 1.755
    },
    {
        "text": "so developing the scoring script,",
        "start": 682.245,
        "duration": 1.695
    },
    {
        "text": "is the scoring script something that developer would",
        "start": 683.94,
        "duration": 2.21
    },
    {
        "text": "have to write line in 27 I think?",
        "start": 686.15,
        "duration": 2.555
    },
    {
        "text": ">> Yeah, so we can actually develop the scoring script for you,",
        "start": 688.705,
        "duration": 4.495
    },
    {
        "text": "but a lot of times when we think",
        "start": 693.2,
        "duration": 1.32
    },
    {
        "text": "about the data scientists persona.",
        "start": 694.52,
        "duration": 2.1
    },
    {
        "text": "This persona might want to go in and actually further develop",
        "start": 696.62,
        "duration": 3.0
    },
    {
        "text": "the scoring script to meet their needs and",
        "start": 699.62,
        "duration": 1.935
    },
    {
        "text": "actually analyze the model compared to other models.",
        "start": 701.555,
        "duration": 2.67
    },
    {
        "text": "However, if you are more than",
        "start": 704.225,
        "duration": 1.905
    },
    {
        "text": "that developer [inaudible] data scientists role,",
        "start": 706.13,
        "duration": 2.28
    },
    {
        "text": "you don't have to worry about it.",
        "start": 708.41,
        "duration": 1.47
    },
    {
        "text": "This is giving you access to it,",
        "start": 709.88,
        "duration": 1.56
    },
    {
        "text": "should you want to do more, but it's all automated.",
        "start": 711.44,
        "duration": 2.04
    },
    {
        "text": ">> So it's the best of both worlds because basically if you",
        "start": 713.48,
        "duration": 3.45
    },
    {
        "text": "just want to use the best model",
        "start": 716.93,
        "duration": 1.68
    },
    {
        "text": "of all the millions of them that you ran,",
        "start": 718.61,
        "duration": 2.745
    },
    {
        "text": "then it just has this scoring script",
        "start": 721.355,
        "duration": 2.205
    },
    {
        "text": "for you that you can just use,",
        "start": 723.56,
        "duration": 1.25
    },
    {
        "text": "but if you're a data scientist and you want to evaluate, \"Okay,",
        "start": 724.81,
        "duration": 2.949
    },
    {
        "text": "I'm going to use this as the starting point for",
        "start": 727.759,
        "duration": 2.716
    },
    {
        "text": "a starter model and then do",
        "start": 730.475,
        "duration": 1.575
    },
    {
        "text": "more research from there,\" you totally have that option as well.",
        "start": 732.05,
        "duration": 3.095
    },
    {
        "text": ">> Exactly.",
        "start": 735.145,
        "duration": 1.7
    },
    {
        "text": ">> This is pretty cool.",
        "start": 736.845,
        "duration": 1.755
    },
    {
        "text": "Where can people go to find out more?",
        "start": 738.6,
        "duration": 2.955
    },
    {
        "text": ">> Definitely. So I've actually",
        "start": 741.555,
        "duration": 3.125
    },
    {
        "text": "gone ahead and included two links here.",
        "start": 744.68,
        "duration": 2.775
    },
    {
        "text": "The first one is actually a tutorial for",
        "start": 747.455,
        "duration": 2.805
    },
    {
        "text": "our UI offering which we saw very quickly on the studio,",
        "start": 750.26,
        "duration": 3.93
    },
    {
        "text": "and running you through our forecasting example.",
        "start": 754.19,
        "duration": 2.595
    },
    {
        "text": "Now if you want to get more in depth,",
        "start": 756.785,
        "duration": 1.56
    },
    {
        "text": "I have a second URL,",
        "start": 758.345,
        "duration": 2.275
    },
    {
        "text": "www.aka.ms/AutoMLForecast and this is a very in depth on how to,",
        "start": 761.41,
        "duration": 2.99
    },
    {
        "text": "showing you everything that AutoML does",
        "start": 764.4,
        "duration": 1.65
    },
    {
        "text": "behind the scenes with time series ML.",
        "start": 766.05,
        "duration": 1.74
    },
    {
        "text": ">> Well this has been really amazing.",
        "start": 767.79,
        "duration": 2.09
    },
    {
        "text": "Thank you so much for spending some time with us.",
        "start": 769.88,
        "duration": 2.325
    },
    {
        "text": "Thank you so much for watching,",
        "start": 772.205,
        "duration": 0.995
    },
    {
        "text": "we're learning all about time series",
        "start": 773.2,
        "duration": 1.3
    },
    {
        "text": "forecasting with automated machine learning,",
        "start": 774.5,
        "duration": 2.609
    },
    {
        "text": "make sure you check it out. See you next time.",
        "start": 777.109,
        "duration": 2.941
    },
    {
        "text": "[MUSIC]",
        "start": 780.05,
        "duration": 14.09
    }
]