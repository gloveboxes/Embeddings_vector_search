[
    {
        "text": ">> What if we could make AI answer your e-mails on its own,",
        "start": 0.0,
        "duration": 4.515
    },
    {
        "text": "well with your help of course.",
        "start": 4.515,
        "duration": 2.13
    },
    {
        "text": "You're not going to want to miss this episode of the AI Show,",
        "start": 6.645,
        "duration": 2.265
    },
    {
        "text": "we go into exactly how",
        "start": 8.91,
        "duration": 1.44
    },
    {
        "text": "outlook.com does just that. Make sure you tune in.",
        "start": 10.35,
        "duration": 3.42
    },
    {
        "text": "[MUSIC]",
        "start": 13.77,
        "duration": 8.609
    },
    {
        "text": ">> Hello. Welcome to this episode of the AI Show.",
        "start": 22.379,
        "duration": 1.781
    },
    {
        "text": "We're going to look at a feature that",
        "start": 24.16,
        "duration": 1.385
    },
    {
        "text": "almost everybody is going to love.",
        "start": 25.545,
        "duration": 1.605
    },
    {
        "text": "I know I do at least.",
        "start": 27.15,
        "duration": 1.38
    },
    {
        "text": "I have Kalyan and Abhishek with me. How are you doing my friends?",
        "start": 28.53,
        "duration": 2.505
    },
    {
        "text": ">> Good. How are you?",
        "start": 31.035,
        "duration": 0.645
    },
    {
        "text": ">> Why don't you tell us what you do?",
        "start": 31.68,
        "duration": 1.8
    },
    {
        "text": ">> I'm a Principal PM in the Office Org and my role is to",
        "start": 33.48,
        "duration": 2.54
    },
    {
        "text": "infuse intelligence into our office apps.",
        "start": 36.02,
        "duration": 2.64
    },
    {
        "text": ">> Fantastic.",
        "start": 38.66,
        "duration": 1.11
    },
    {
        "text": ">> I'm Abhishek. I'm a data scientist",
        "start": 39.77,
        "duration": 2.1
    },
    {
        "text": "in the same group and we worked",
        "start": 41.87,
        "duration": 1.53
    },
    {
        "text": "together and then it's our mission to",
        "start": 43.4,
        "duration": 1.68
    },
    {
        "text": "actually infuse productivity into Office apps.",
        "start": 45.08,
        "duration": 2.17
    },
    {
        "text": ">> Fantastic. So everyone is always in e-mails.",
        "start": 47.25,
        "duration": 2.51
    },
    {
        "text": "I know I was in there today responding to a bunch of things,",
        "start": 49.76,
        "duration": 2.55
    },
    {
        "text": "tell us about the feature that you're using AI to help augment.",
        "start": 52.31,
        "duration": 3.42
    },
    {
        "text": ">> Absolutely. So, I think it's",
        "start": 55.73,
        "duration": 1.71
    },
    {
        "text": "our intuition and also data suggests that",
        "start": 57.44,
        "duration": 1.965
    },
    {
        "text": "information workers and users spend a lot of",
        "start": 59.405,
        "duration": 1.995
    },
    {
        "text": "time reading and responding to e-mail.",
        "start": 61.4,
        "duration": 2.56
    },
    {
        "text": "One of the critical features that we've designed is to",
        "start": 63.96,
        "duration": 3.05
    },
    {
        "text": "reduce the time and effort it takes",
        "start": 67.01,
        "duration": 1.74
    },
    {
        "text": "for users to read e-mail and respond,",
        "start": 68.75,
        "duration": 1.95
    },
    {
        "text": "especially as more and more information workers are on mobile,",
        "start": 70.7,
        "duration": 3.015
    },
    {
        "text": "we want to reduce that number of clicks that are required",
        "start": 73.715,
        "duration": 2.385
    },
    {
        "text": "to send a response to reply.",
        "start": 76.1,
        "duration": 2.685
    },
    {
        "text": "So we recently introduced a feature",
        "start": 78.785,
        "duration": 1.815
    },
    {
        "text": "called suggested replies in Outlook.",
        "start": 80.6,
        "duration": 2.205
    },
    {
        "text": "The basic idea is that for some segment of e-mails, short e-mails,",
        "start": 82.805,
        "duration": 5.255
    },
    {
        "text": "we are able to suggest",
        "start": 88.06,
        "duration": 1.225
    },
    {
        "text": "a quick responses and the user is able to look at the e-mail",
        "start": 89.285,
        "duration": 3.705
    },
    {
        "text": "and see some suggested replies and we built in",
        "start": 92.99,
        "duration": 2.49
    },
    {
        "text": "one or two clicks be able to respond to that giving e-mail.",
        "start": 95.48,
        "duration": 3.06
    },
    {
        "text": ">> It's not just like we could just do no",
        "start": 98.54,
        "duration": 1.935
    },
    {
        "text": "like is a single button and save everybody budget time,",
        "start": 100.475,
        "duration": 2.355
    },
    {
        "text": "but you want to be nice to?",
        "start": 102.83,
        "duration": 1.185
    },
    {
        "text": ">> Yes.",
        "start": 104.015,
        "duration": 0.315
    },
    {
        "text": ">> So there's a set of responses that we're looking at then,",
        "start": 104.33,
        "duration": 3.09
    },
    {
        "text": "that then we're suggesting based upon the e-mail?",
        "start": 107.42,
        "duration": 2.085
    },
    {
        "text": ">> Yes. So given a message,",
        "start": 109.505,
        "duration": 1.665
    },
    {
        "text": "given say for example you've got a message in your inbox,",
        "start": 111.17,
        "duration": 2.63
    },
    {
        "text": "algorithm is able to look at",
        "start": 113.8,
        "duration": 1.63
    },
    {
        "text": "that message and be able to figure out what are",
        "start": 115.43,
        "duration": 2.43
    },
    {
        "text": "the potential responses set here",
        "start": 117.86,
        "duration": 2.34
    },
    {
        "text": "might want to respond to that e-mail.",
        "start": 120.2,
        "duration": 2.855
    },
    {
        "text": ">> I see. So that's that's awesome.",
        "start": 123.055,
        "duration": 1.885
    },
    {
        "text": "But my sense is that there is bit machine learning or AI going on,",
        "start": 124.94,
        "duration": 4.005
    },
    {
        "text": "can you describe a little bit about first the data that",
        "start": 128.945,
        "duration": 2.985
    },
    {
        "text": "we're using and then the kind of models that we're building.",
        "start": 131.93,
        "duration": 2.995
    },
    {
        "text": ">> Of course. So, yeah.",
        "start": 134.925,
        "duration": 1.35
    },
    {
        "text": "You're totally on the money here with there's",
        "start": 136.275,
        "duration": 2.435
    },
    {
        "text": "a very complicated machine learning algorithm",
        "start": 138.71,
        "duration": 2.19
    },
    {
        "text": "behind the hood which is taking care of that.",
        "start": 140.9,
        "duration": 2.235
    },
    {
        "text": "For the data, as you have said,",
        "start": 143.135,
        "duration": 1.845
    },
    {
        "text": "these are real e-mails.",
        "start": 144.98,
        "duration": 1.665
    },
    {
        "text": "So we have very smart distributed",
        "start": 146.645,
        "duration": 2.205
    },
    {
        "text": "compliant infrastructure which is able to sample emails",
        "start": 148.85,
        "duration": 4.08
    },
    {
        "text": "from our user base and then we use Azure Data Lakes which",
        "start": 152.93,
        "duration": 4.715
    },
    {
        "text": "basically use the distributed computing and get them",
        "start": 157.645,
        "duration": 3.685
    },
    {
        "text": "together and we curated something called the messages responses.",
        "start": 161.33,
        "duration": 3.93
    },
    {
        "text": "So you had the messages and their corresponding responses there,",
        "start": 165.26,
        "duration": 2.48
    },
    {
        "text": "and you have hundreds of millions of data points like that,",
        "start": 167.74,
        "duration": 2.895
    },
    {
        "text": "and then we built,",
        "start": 170.635,
        "duration": 1.235
    },
    {
        "text": "we train using very sophisticated GPU infrastructure.",
        "start": 171.87,
        "duration": 3.515
    },
    {
        "text": "We train a deep neural network which tries",
        "start": 175.385,
        "duration": 4.155
    },
    {
        "text": "to encode both these messages",
        "start": 179.54,
        "duration": 2.4
    },
    {
        "text": "and responses and tries to match them together.",
        "start": 181.94,
        "duration": 2.64
    },
    {
        "text": "So we learn a model which is able to do that and obviously",
        "start": 184.58,
        "duration": 3.495
    },
    {
        "text": "you don't want to predict very arbitrary kind of messages.",
        "start": 188.075,
        "duration": 3.555
    },
    {
        "text": "So what you want to do is you want to",
        "start": 191.63,
        "duration": 1.995
    },
    {
        "text": "only respond with generic messages which",
        "start": 193.625,
        "duration": 2.505
    },
    {
        "text": "makes sense a lot of e-mail so that you",
        "start": 196.13,
        "duration": 1.98
    },
    {
        "text": "do not say any kind of offensive things there.",
        "start": 198.11,
        "duration": 2.775
    },
    {
        "text": "So there's also a controlled responsive pipeline,",
        "start": 200.885,
        "duration": 3.285
    },
    {
        "text": "so the responses that we're suggesting, there is no are arbitrary.",
        "start": 204.17,
        "duration": 3.69
    },
    {
        "text": "They are coming from a fixed set which is",
        "start": 207.86,
        "duration": 2.19
    },
    {
        "text": "curated and Microsoft make sure that they are",
        "start": 210.05,
        "duration": 3.24
    },
    {
        "text": "very generic and they are aligned to the principles of Microsoft,",
        "start": 213.29,
        "duration": 5.68
    },
    {
        "text": "which is basically to be fair and impartial that we want.",
        "start": 218.97,
        "duration": 4.28
    },
    {
        "text": "So we makes sure that all these responses follow",
        "start": 223.25,
        "duration": 3.06
    },
    {
        "text": "those standards and then only then",
        "start": 226.31,
        "duration": 1.32
    },
    {
        "text": "the machine learning algorithm picks one of those suggestions.",
        "start": 227.63,
        "duration": 2.405
    },
    {
        "text": ">> So there's a lot to unpack there.",
        "start": 230.035,
        "duration": 1.57
    },
    {
        "text": "I mean there's a ton of information.",
        "start": 231.605,
        "duration": 1.515
    },
    {
        "text": "Hopefully, we'll go step-by-step.",
        "start": 233.12,
        "duration": 1.02
    },
    {
        "text": "The first one that stood out me and",
        "start": 234.14,
        "duration": 1.77
    },
    {
        "text": "hopefully you can hit on this pretty hard is,",
        "start": 235.91,
        "duration": 2.265
    },
    {
        "text": "the data you're getting are actual e-mails.",
        "start": 238.175,
        "duration": 3.955
    },
    {
        "text": ">> Yes.",
        "start": 242.13,
        "duration": 0.615
    },
    {
        "text": ">> Some people might find that to be a little",
        "start": 242.745,
        "duration": 1.865
    },
    {
        "text": "bit difficult to digest.",
        "start": 244.61,
        "duration": 1.74
    },
    {
        "text": "Why don't you talk a little bit about",
        "start": 246.35,
        "duration": 1.47
    },
    {
        "text": "what that process looks like.",
        "start": 247.82,
        "duration": 1.47
    },
    {
        "text": ">> Sure.",
        "start": 249.29,
        "duration": 0.17
    },
    {
        "text": ">> Because I feel like people are going to be like,",
        "start": 249.46,
        "duration": 1.93
    },
    {
        "text": "I don't want you to read my e-mails number one.",
        "start": 251.39,
        "duration": 1.83
    },
    {
        "text": "Number two, is this happening automatically, can I opt out?",
        "start": 253.22,
        "duration": 3.76
    },
    {
        "text": "So, why don't you just talk about those two things.",
        "start": 256.98,
        "duration": 1.35
    },
    {
        "text": ">> Of course totally. So trust is",
        "start": 258.33,
        "duration": 2.24
    },
    {
        "text": "at the forefront of all of our design principles.",
        "start": 260.57,
        "duration": 2.565
    },
    {
        "text": "So I think Microsoft always goes by trust and so",
        "start": 263.135,
        "duration": 3.84
    },
    {
        "text": "all of this training is happening in a",
        "start": 266.975,
        "duration": 1.845
    },
    {
        "text": "total compliant in ISOF fashion.",
        "start": 268.82,
        "duration": 2.04
    },
    {
        "text": "So there's no person who is actually looking at those e-mails.",
        "start": 270.86,
        "duration": 3.25
    },
    {
        "text": "This all ISO, the Azure compute taking care of all the compliance.",
        "start": 274.11,
        "duration": 4.64
    },
    {
        "text": "You have Offices 365 compliance",
        "start": 278.75,
        "duration": 1.74
    },
    {
        "text": "certified systems which are in play here.",
        "start": 280.49,
        "duration": 3.735
    },
    {
        "text": "So everything is happening offline,",
        "start": 284.225,
        "duration": 1.545
    },
    {
        "text": "no person is actually looking at your e-mails.",
        "start": 285.77,
        "duration": 2.01
    },
    {
        "text": "It's all done in ISOF fashion.",
        "start": 287.78,
        "duration": 2.43
    },
    {
        "text": "People are still again again",
        "start": 290.21,
        "duration": 2.205
    },
    {
        "text": "once you see the feature and if people don't like it,",
        "start": 292.415,
        "duration": 2.175
    },
    {
        "text": "you're always free to turn it off,",
        "start": 294.59,
        "duration": 1.76
    },
    {
        "text": "wheel of the feature, but I feel that is very extremely",
        "start": 296.35,
        "duration": 3.43
    },
    {
        "text": "useful but you can turn it off and then we want to do this.",
        "start": 299.78,
        "duration": 3.21
    },
    {
        "text": ">> So basically, like nobody ever reads anybody's e-mail because I",
        "start": 302.99,
        "duration": 3.7
    },
    {
        "text": "know nobody's really getting your e-mails like maybe not even you.",
        "start": 306.69,
        "duration": 6.06
    },
    {
        "text": "But the other thing is if you like",
        "start": 312.75,
        "duration": 2.7
    },
    {
        "text": "an auto suggested like response,",
        "start": 315.45,
        "duration": 2.909
    },
    {
        "text": "if you like that turn it on,",
        "start": 318.359,
        "duration": 1.681
    },
    {
        "text": "but if you don't like to turn it off?",
        "start": 320.04,
        "duration": 1.575
    },
    {
        "text": ">> Yes, absolutely.",
        "start": 321.615,
        "duration": 1.605
    },
    {
        "text": ">> The other thing that I that I heard is that",
        "start": 323.22,
        "duration": 2.6
    },
    {
        "text": "your sampling at random.",
        "start": 325.82,
        "duration": 3.27
    },
    {
        "text": "So again, hopefully, this makes you a little more",
        "start": 329.09,
        "duration": 4.05
    },
    {
        "text": "comfortable as you're watching because like for me, I love AI.",
        "start": 333.14,
        "duration": 5.385
    },
    {
        "text": "You-all know this. I'm okay with",
        "start": 338.525,
        "duration": 2.685
    },
    {
        "text": "people looking at my data to build models,",
        "start": 341.21,
        "duration": 2.89
    },
    {
        "text": "but a very specific subset and I like being able",
        "start": 344.1,
        "duration": 2.39
    },
    {
        "text": "to know what's being looked at and I like that.",
        "start": 346.49,
        "duration": 2.49
    },
    {
        "text": "So I like that. That's the first thing.",
        "start": 348.98,
        "duration": 1.62
    },
    {
        "text": "The second thing is you went really fast and talked",
        "start": 350.6,
        "duration": 3.42
    },
    {
        "text": "about a couple of things and I want to understand this model,",
        "start": 354.02,
        "duration": 4.15
    },
    {
        "text": "because usually what I'm",
        "start": 358.17,
        "duration": 2.12
    },
    {
        "text": "looking at like a sequence-to-sequence type model,",
        "start": 360.29,
        "duration": 2.475
    },
    {
        "text": "I have a bunch of like,",
        "start": 362.765,
        "duration": 1.185
    },
    {
        "text": "let's just say I have e-mail text that's",
        "start": 363.95,
        "duration": 1.83
    },
    {
        "text": "going to respond and it makes some other text,",
        "start": 365.78,
        "duration": 2.01
    },
    {
        "text": "but that's not what you're doing, right?",
        "start": 367.79,
        "duration": 1.47
    },
    {
        "text": ">> No.",
        "start": 369.26,
        "duration": 0.285
    },
    {
        "text": ">> Because if feels like you said you had a subset of",
        "start": 369.545,
        "duration": 2.355
    },
    {
        "text": "responses that's you are going to respond to you if appropriate?",
        "start": 371.9,
        "duration": 4.325
    },
    {
        "text": ">> True.",
        "start": 376.225,
        "duration": 0.665
    },
    {
        "text": ">> Maybe I'll take a first step and then Abhishek can jump in.",
        "start": 376.89,
        "duration": 2.05
    },
    {
        "text": "So the the basic idea is we have",
        "start": 378.94,
        "duration": 2.635
    },
    {
        "text": "all this message response pairs",
        "start": 381.575,
        "duration": 1.905
    },
    {
        "text": "that we sample and stored it in ADLS.",
        "start": 383.48,
        "duration": 2.445
    },
    {
        "text": "Now, we write some analytics pipelines on top of",
        "start": 385.925,
        "duration": 3.225
    },
    {
        "text": "that and the goal of that analytics pipeline is to curate what",
        "start": 389.15,
        "duration": 3.88
    },
    {
        "text": "are the top say 30,000 or",
        "start": 393.03,
        "duration": 1.95
    },
    {
        "text": "50,000 most commonly-used responses and we do this",
        "start": 394.98,
        "duration": 2.9
    },
    {
        "text": "in a completely ISOF blind manner",
        "start": 397.88,
        "duration": 2.28
    },
    {
        "text": "and algorithm runs on this dataset and it's able",
        "start": 400.16,
        "duration": 2.43
    },
    {
        "text": "to determine what are",
        "start": 402.59,
        "duration": 1.89
    },
    {
        "text": "the most commonly-used responses",
        "start": 404.48,
        "duration": 2.225
    },
    {
        "text": "and that becomes our candidate set.",
        "start": 406.705,
        "duration": 2.095
    },
    {
        "text": "Now, the idea is,",
        "start": 408.8,
        "duration": 1.32
    },
    {
        "text": "given any arbitrary e-mail,",
        "start": 410.12,
        "duration": 1.92
    },
    {
        "text": "are we able to select one of these",
        "start": 412.04,
        "duration": 2.685
    },
    {
        "text": "top 50,000 responses as a potential response?",
        "start": 414.725,
        "duration": 2.875
    },
    {
        "text": ">> Got it. So it's not like",
        "start": 417.6,
        "duration": 1.515
    },
    {
        "text": "a sequence-to-sequence model where you put it",
        "start": 419.115,
        "duration": 3.485
    },
    {
        "text": "a big sequence and it goes into",
        "start": 422.6,
        "duration": 1.995
    },
    {
        "text": "some latent space and then it responds with what it thinks,",
        "start": 424.595,
        "duration": 3.015
    },
    {
        "text": "you are saying you can only",
        "start": 427.61,
        "duration": 1.89
    },
    {
        "text": "respond with one of these target responses, is that right?",
        "start": 429.5,
        "duration": 3.045
    },
    {
        "text": ">> That's certainly correct. There's no answers there obviously,",
        "start": 432.545,
        "duration": 4.15
    },
    {
        "text": "because we also have",
        "start": 436.695,
        "duration": 1.355
    },
    {
        "text": "experimented with sequence-to-sequence models,",
        "start": 438.05,
        "duration": 1.86
    },
    {
        "text": "but we constrain it to",
        "start": 439.91,
        "duration": 1.71
    },
    {
        "text": "even like the final sequence which comes out.",
        "start": 441.62,
        "duration": 1.99
    },
    {
        "text": "It's still belongs to this set.",
        "start": 443.61,
        "duration": 1.79
    },
    {
        "text": "The current models that we have during production,",
        "start": 445.4,
        "duration": 2.955
    },
    {
        "text": "they're not like pure sequence-to-sequence model in that sense,",
        "start": 448.355,
        "duration": 3.36
    },
    {
        "text": "we use a matching model essentially,",
        "start": 451.715,
        "duration": 2.575
    },
    {
        "text": "where there we have towers of encoders which encode",
        "start": 454.29,
        "duration": 3.59
    },
    {
        "text": "both the message and these target responses",
        "start": 457.88,
        "duration": 2.475
    },
    {
        "text": "and tries to pick the best",
        "start": 460.355,
        "duration": 1.365
    },
    {
        "text": "one which matches with the introduction.",
        "start": 461.72,
        "duration": 1.53
    },
    {
        "text": ">> I see.",
        "start": 463.25,
        "duration": 1.05
    },
    {
        "text": "So let's say if I'm understand this right in",
        "start": 464.3,
        "duration": 2.16
    },
    {
        "text": "my limited machine learning understanding",
        "start": 466.46,
        "duration": 2.325
    },
    {
        "text": "is obviously not as good as yours,",
        "start": 468.785,
        "duration": 1.355
    },
    {
        "text": "we're putting the e-mail message into a latent space,",
        "start": 470.14,
        "duration": 3.195
    },
    {
        "text": "we're putting the candidate responses into",
        "start": 473.335,
        "duration": 2.875
    },
    {
        "text": "a latent space and then we're doing some kind of distance metric,",
        "start": 476.21,
        "duration": 3.6
    },
    {
        "text": "maybe clustering to find the ones that are all together?",
        "start": 479.81,
        "duration": 2.205
    },
    {
        "text": ">> You have gotten it right.",
        "start": 482.015,
        "duration": 1.185
    },
    {
        "text": ">> Well, I guess I do know a little bit of machine learning.",
        "start": 483.2,
        "duration": 2.8
    },
    {
        "text": ">> You are very smart.",
        "start": 486.0,
        "duration": 1.275
    },
    {
        "text": ">> Thank you. My mom thinks so.",
        "start": 487.275,
        "duration": 2.115
    },
    {
        "text": "So there's two people now.",
        "start": 489.39,
        "duration": 1.74
    },
    {
        "text": "Abhishek and my mom.",
        "start": 491.13,
        "duration": 1.19
    },
    {
        "text": "So, as we're looking at this,",
        "start": 492.32,
        "duration": 1.23
    },
    {
        "text": "you mentioned a couple of Azure things that I",
        "start": 493.55,
        "duration": 1.8
    },
    {
        "text": "want to dive into a little bit.",
        "start": 495.35,
        "duration": 1.87
    },
    {
        "text": "One was ADL and the other was ADLA,",
        "start": 497.22,
        "duration": 2.055
    },
    {
        "text": "can you describe what those things are because if",
        "start": 499.275,
        "duration": 2.595
    },
    {
        "text": "feels like one is doing like complimentary things.",
        "start": 501.87,
        "duration": 2.7
    },
    {
        "text": "What is ADL versus ADLA and how did you use it?",
        "start": 504.57,
        "duration": 3.1
    },
    {
        "text": ">> Sure. Basically, we use two components.",
        "start": 507.74,
        "duration": 3.09
    },
    {
        "text": "One is we need storage,",
        "start": 510.83,
        "duration": 1.77
    },
    {
        "text": "because we have very large user space and we're trying to",
        "start": 512.6,
        "duration": 4.5
    },
    {
        "text": "make this algorithm basically work across a lot of users,",
        "start": 517.1,
        "duration": 4.74
    },
    {
        "text": "so we need a large amount of data.",
        "start": 521.84,
        "duration": 1.65
    },
    {
        "text": "So we sample this large amount of data in",
        "start": 523.49,
        "duration": 2.25
    },
    {
        "text": "an ISOF manner and we need storage for that,",
        "start": 525.74,
        "duration": 2.56
    },
    {
        "text": "and for that purpose we use ADLS,",
        "start": 528.3,
        "duration": 1.86
    },
    {
        "text": "that ADLS essentially gives us GDPR compliance.",
        "start": 530.16,
        "duration": 2.88
    },
    {
        "text": "Basically, we have to expire this date",
        "start": 533.04,
        "duration": 1.91
    },
    {
        "text": "every 30 days because those are the GDPR constraints.",
        "start": 534.95,
        "duration": 2.73
    },
    {
        "text": "So ADLS provides that compliance story for us.",
        "start": 537.68,
        "duration": 3.33
    },
    {
        "text": "It gives us agility to",
        "start": 541.01,
        "duration": 2.745
    },
    {
        "text": "basically write jobs against the storage and build the MR pairs,",
        "start": 543.755,
        "duration": 5.475
    },
    {
        "text": "which are message response pairs.",
        "start": 549.23,
        "duration": 1.5
    },
    {
        "text": "So we use ADLS for storing and for compliance of this data.",
        "start": 550.73,
        "duration": 4.065
    },
    {
        "text": "So at rest, it's encrypted so",
        "start": 554.795,
        "duration": 1.545
    },
    {
        "text": "that there is no data leak or data theft around that.",
        "start": 556.34,
        "duration": 3.72
    },
    {
        "text": "So ADLS basically takes care of that.",
        "start": 560.06,
        "duration": 2.085
    },
    {
        "text": "On top of that, we have this analytics pipeline that we write,",
        "start": 562.145,
        "duration": 3.72
    },
    {
        "text": "which essentially does a lot of filtering,",
        "start": 565.865,
        "duration": 2.505
    },
    {
        "text": "curation and transformation of this basic e-mails that we got.",
        "start": 568.37,
        "duration": 3.45
    },
    {
        "text": "So that's how we use ADLA and ADLS which are part of Azure data.",
        "start": 571.82,
        "duration": 3.66
    },
    {
        "text": ">> So let me talk about because I am the kind of",
        "start": 575.48,
        "duration": 2.28
    },
    {
        "text": "person that has like that by 1,000 acronyms,",
        "start": 577.76,
        "duration": 3.09
    },
    {
        "text": "what is ADLS and what is ADLA stand for?",
        "start": 580.85,
        "duration": 3.535
    },
    {
        "text": ">> So ADLA stands for",
        "start": 584.385,
        "duration": 1.82
    },
    {
        "text": "Azure Data Lake Analytics and",
        "start": 586.205,
        "duration": 1.815
    },
    {
        "text": "ADLS stands for Azure Data Lake Storage.",
        "start": 588.02,
        "duration": 2.19
    },
    {
        "text": "These are basically two components of",
        "start": 590.21,
        "duration": 1.83
    },
    {
        "text": "the Azure Data Lake store that we have in Azure.",
        "start": 592.04,
        "duration": 2.07
    },
    {
        "text": ">> I see. So one is just like a place where",
        "start": 594.11,
        "duration": 1.8
    },
    {
        "text": "you put data and another is like,",
        "start": 595.91,
        "duration": 1.92
    },
    {
        "text": "okay now let's in there,",
        "start": 597.83,
        "duration": 1.365
    },
    {
        "text": "let's do some computation.",
        "start": 599.195,
        "duration": 1.365
    },
    {
        "text": "That's where you're getting the pairs.",
        "start": 600.56,
        "duration": 2.725
    },
    {
        "text": "Where's the actual model being built?",
        "start": 603.285,
        "duration": 2.31
    },
    {
        "text": ">> So we use Azure Batch.",
        "start": 605.595,
        "duration": 3.135
    },
    {
        "text": "Essentially there's a platform called Metrics,",
        "start": 608.73,
        "duration": 3.195
    },
    {
        "text": "which is a GPU platform which is built on top of Azure Batch,",
        "start": 611.925,
        "duration": 3.425
    },
    {
        "text": "where we actually do all their machine",
        "start": 615.35,
        "duration": 1.56
    },
    {
        "text": "learning training there and then we get the middle",
        "start": 616.91,
        "duration": 1.83
    },
    {
        "text": "and then obviously import that model and deploy it.",
        "start": 618.74,
        "duration": 3.7
    },
    {
        "text": ">> That's amazing. So right now if you have",
        "start": 622.44,
        "duration": 1.97
    },
    {
        "text": "a bunch of data and you want to train something similar to that,",
        "start": 624.41,
        "duration": 2.46
    },
    {
        "text": "ADLS and ADLA are really good places to start dumping data and",
        "start": 626.87,
        "duration": 3.45
    },
    {
        "text": "start doing some data cleaning",
        "start": 630.32,
        "duration": 1.875
    },
    {
        "text": "which sounds pretty impressive to me.",
        "start": 632.195,
        "duration": 1.815
    },
    {
        "text": "Are there any other takeaways",
        "start": 634.01,
        "duration": 1.92
    },
    {
        "text": "that you want to give before we sign off?",
        "start": 635.93,
        "duration": 2.15
    },
    {
        "text": ">> Sure, I think if I",
        "start": 638.08,
        "duration": 2.4
    },
    {
        "text": "ask my data scientists what is your experience in Azure,",
        "start": 640.48,
        "duration": 2.79
    },
    {
        "text": "I think a couple of things really pop out.",
        "start": 643.27,
        "duration": 2.215
    },
    {
        "text": "One is Azure gives us an enormous amount of agility.",
        "start": 645.485,
        "duration": 3.66
    },
    {
        "text": "Even for a data scientist has a quick idea,",
        "start": 649.145,
        "duration": 5.095
    },
    {
        "text": "he can test it out with some 5,000 e-mails,",
        "start": 654.24,
        "duration": 2.64
    },
    {
        "text": "these could be personal e-mails that you can dump it on on",
        "start": 656.88,
        "duration": 2.78
    },
    {
        "text": "a VM and be able to test it from anywhere in the world.",
        "start": 659.66,
        "duration": 2.55
    },
    {
        "text": "So I think it gives you the inner loop agility.",
        "start": 662.21,
        "duration": 1.92
    },
    {
        "text": "So I think that's a great takeaway from",
        "start": 664.13,
        "duration": 2.4
    },
    {
        "text": "our experience working on Azure for this project.",
        "start": 666.53,
        "duration": 2.79
    },
    {
        "text": "The other one is Azure actually",
        "start": 669.32,
        "duration": 1.56
    },
    {
        "text": "takes care of the compliance for us.",
        "start": 670.88,
        "duration": 1.695
    },
    {
        "text": "So we know that by storing our content in ADLS or Azure Data Lake,",
        "start": 672.575,
        "duration": 3.78
    },
    {
        "text": "we are GDPR compliant.",
        "start": 676.355,
        "duration": 2.39
    },
    {
        "text": "There's Just-in-Time escalation of",
        "start": 678.745,
        "duration": 3.295
    },
    {
        "text": "credentials to access that data for example, for that experiment.",
        "start": 682.04,
        "duration": 2.955
    },
    {
        "text": "So all the goodness of compliance comes out-of-the-box.",
        "start": 684.995,
        "duration": 3.99
    },
    {
        "text": "The third one is basically around scale.",
        "start": 688.985,
        "duration": 5.95
    },
    {
        "text": "Because now we can basically auto scale",
        "start": 694.935,
        "duration": 4.77
    },
    {
        "text": "how many our GPUs that we want",
        "start": 699.705,
        "duration": 1.955
    },
    {
        "text": "based on demand and experimentation workload.",
        "start": 701.66,
        "duration": 2.765
    },
    {
        "text": ">> This pretty amazing. Where do people",
        "start": 704.425,
        "duration": 1.795
    },
    {
        "text": "go to find out more about the work you're doing?",
        "start": 706.22,
        "duration": 2.565
    },
    {
        "text": "Do we have a blog, is like an office blog we can go to?",
        "start": 708.785,
        "duration": 3.695
    },
    {
        "text": ">> Yes, there is a blog of Suggested Replies.",
        "start": 712.48,
        "duration": 1.97
    },
    {
        "text": "So just go to Bing and search for Suggested Replies.",
        "start": 714.45,
        "duration": 2.745
    },
    {
        "text": ">> We'll put a link below.",
        "start": 717.195,
        "duration": 1.905
    },
    {
        "text": "I feel like I put them on a spot there.",
        "start": 719.1,
        "duration": 3.16
    },
    {
        "text": ">> Or actually just go to outlook.com and just start using.",
        "start": 722.45,
        "duration": 3.76
    },
    {
        "text": "You'll see our feature of life.",
        "start": 726.21,
        "duration": 2.25
    },
    {
        "text": ">> That's pretty amazing.",
        "start": 728.46,
        "duration": 1.13
    },
    {
        "text": "Well, thanks so much for spending the time.",
        "start": 729.59,
        "duration": 1.83
    },
    {
        "text": "We've been learning all about the suggested auto replies,",
        "start": 731.42,
        "duration": 3.48
    },
    {
        "text": "that was called suggested auto reply?",
        "start": 734.9,
        "duration": 1.23
    },
    {
        "text": ">> It's called Suggested Replies.",
        "start": 736.13,
        "duration": 1.005
    },
    {
        "text": ">> Suggested Replies in Outlook.",
        "start": 737.135,
        "duration": 2.06
    },
    {
        "text": "Hopefully, you'll use it.",
        "start": 739.195,
        "duration": 1.235
    },
    {
        "text": "If you it, let us know.",
        "start": 740.43,
        "duration": 1.705
    },
    {
        "text": "Thanks so much for watching and we'll see you next time.",
        "start": 742.135,
        "duration": 1.615
    },
    {
        "text": "Take care.",
        "start": 743.75,
        "duration": 0.765
    },
    {
        "text": ">> Thank you.",
        "start": 744.515,
        "duration": 0.96
    },
    {
        "text": ">> Thank you.",
        "start": 745.475,
        "duration": 0.345
    },
    {
        "text": "[MUSIC]",
        "start": 745.82,
        "duration": 8.23
    }
]