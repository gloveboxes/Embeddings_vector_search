[
    {
        "text": ">> You're not going to want to miss this episode of The AI Show.",
        "start": 0.0,
        "duration": 2.49
    },
    {
        "text": "We talk about building computer vision models",
        "start": 2.49,
        "duration": 1.95
    },
    {
        "text": "using AutoML for images.",
        "start": 4.44,
        "duration": 1.62
    },
    {
        "text": "Make sure you tune in.",
        "start": 6.06,
        "duration": 1.14
    },
    {
        "text": "[MUSIC]",
        "start": 7.2,
        "duration": 7.41
    },
    {
        "text": ">> Hello and welcome to this episode of",
        "start": 14.61,
        "duration": 1.2
    },
    {
        "text": "The AI Show where we're talking about",
        "start": 15.81,
        "duration": 1.965
    },
    {
        "text": "building computer vision models using AutoML for images.",
        "start": 17.775,
        "duration": 3.255
    },
    {
        "text": "I'm here with Swati.",
        "start": 21.03,
        "duration": 0.84
    },
    {
        "text": "How you doing my friend?",
        "start": 21.87,
        "duration": 1.2
    },
    {
        "text": ">> Doing good.",
        "start": 23.07,
        "duration": 0.9
    },
    {
        "text": "How are you doing Seth?",
        "start": 23.97,
        "duration": 0.99
    },
    {
        "text": ">> Fantastic.",
        "start": 24.96,
        "duration": 0.66
    },
    {
        "text": "Why don't you tell us who you are and what you do?",
        "start": 25.62,
        "duration": 2.385
    },
    {
        "text": ">> I'm Swati Gharse.",
        "start": 28.005,
        "duration": 1.455
    },
    {
        "text": "I'm a Product Manager",
        "start": 29.46,
        "duration": 2.015
    },
    {
        "text": "on the Azure Machine Learning Team.",
        "start": 31.475,
        "duration": 2.105
    },
    {
        "text": "I am very excited to talk to you-all about",
        "start": 33.58,
        "duration": 2.8
    },
    {
        "text": "a brand new capability we launched just this past week.",
        "start": 36.38,
        "duration": 3.165
    },
    {
        "text": "This is AutoML for images where you can use AutoML",
        "start": 39.545,
        "duration": 3.495
    },
    {
        "text": "to build computer vision models.",
        "start": 43.04,
        "duration": 2.12
    },
    {
        "text": ">> Fantastic. Let's start with the kinds of problems",
        "start": 45.16,
        "duration": 3.11
    },
    {
        "text": "that computer vision can actually solve",
        "start": 48.27,
        "duration": 3.41
    },
    {
        "text": "so that we can ground the discussion in the actual problem set.",
        "start": 51.68,
        "duration": 2.975
    },
    {
        "text": ">> Yeah. There's a whole bunch of problems",
        "start": 54.655,
        "duration": 3.295
    },
    {
        "text": "actually out in the industry.",
        "start": 57.95,
        "duration": 1.95
    },
    {
        "text": "Customers across various industries,",
        "start": 59.9,
        "duration": 2.52
    },
    {
        "text": "they are looking to build models that can process image data.",
        "start": 62.42,
        "duration": 4.265
    },
    {
        "text": "Applications can range from",
        "start": 66.685,
        "duration": 2.59
    },
    {
        "text": "image classification of fashion photos,",
        "start": 69.275,
        "duration": 1.965
    },
    {
        "text": "say on the Internet,",
        "start": 71.24,
        "duration": 1.29
    },
    {
        "text": "or PPE detection in industrial environments.",
        "start": 72.53,
        "duration": 4.02
    },
    {
        "text": "This includes a variety of tasks",
        "start": 76.55,
        "duration": 2.37
    },
    {
        "text": "including image classification, object detection,",
        "start": 78.92,
        "duration": 3.72
    },
    {
        "text": "instance segmentation, and AutoML has newly",
        "start": 82.64,
        "duration": 3.03
    },
    {
        "text": "added support for all of these computer vision related tasks.",
        "start": 85.67,
        "duration": 3.555
    },
    {
        "text": "I'll try to have a quick slide showing what these tasks mean.",
        "start": 89.225,
        "duration": 3.795
    },
    {
        "text": "Image classification is simply identifying different classes.",
        "start": 93.02,
        "duration": 3.78
    },
    {
        "text": "Like here you can see are there cats are there dogs?",
        "start": 96.8,
        "duration": 2.565
    },
    {
        "text": "We support both multi-class and multi-label.",
        "start": 99.365,
        "duration": 2.955
    },
    {
        "text": "With object detection,",
        "start": 102.32,
        "duration": 1.56
    },
    {
        "text": "you might want to find out where exactly are",
        "start": 103.88,
        "duration": 1.95
    },
    {
        "text": "these cats and dogs",
        "start": 105.83,
        "duration": 0.96
    },
    {
        "text": "and draw a rectangular bounding boxes around them.",
        "start": 106.79,
        "duration": 2.565
    },
    {
        "text": "With instance segmentation you want to do",
        "start": 109.355,
        "duration": 2.265
    },
    {
        "text": "this detection at the pixel level and draw polygons around these.",
        "start": 111.62,
        "duration": 4.385
    },
    {
        "text": "AutoML has added support for all of these tasks",
        "start": 116.005,
        "duration": 3.055
    },
    {
        "text": "where it can boost data scientists productivity",
        "start": 119.06,
        "duration": 3.18
    },
    {
        "text": "as they're building models for these computer vision tasks.",
        "start": 122.24,
        "duration": 3.155
    },
    {
        "text": ">> This is awesome.",
        "start": 125.395,
        "duration": 0.755
    },
    {
        "text": "For those who don't know,",
        "start": 126.15,
        "duration": 1.46
    },
    {
        "text": "this is actually a challenging problem.",
        "start": 127.61,
        "duration": 3.57
    },
    {
        "text": "Could you tell us why it's challenging?",
        "start": 131.18,
        "duration": 2.38
    },
    {
        "text": ">> Absolutely. In the ideal world,",
        "start": 133.56,
        "duration": 4.105
    },
    {
        "text": "when you're building models for computer vision tasks,",
        "start": 137.665,
        "duration": 2.905
    },
    {
        "text": "you would want to have an easy way to build these models.",
        "start": 140.57,
        "duration": 3.855
    },
    {
        "text": "But at the same time,",
        "start": 144.425,
        "duration": 1.5
    },
    {
        "text": "you also want to have control on",
        "start": 145.925,
        "duration": 2.7
    },
    {
        "text": "how that model is trained",
        "start": 148.625,
        "duration": 1.365
    },
    {
        "text": "so that you can optimize model performance.",
        "start": 149.99,
        "duration": 2.63
    },
    {
        "text": "You want to use these models out in the real world",
        "start": 152.62,
        "duration": 3.07
    },
    {
        "text": "so you need to operationalize them",
        "start": 155.69,
        "duration": 1.92
    },
    {
        "text": "and you want to have control on the",
        "start": 157.61,
        "duration": 2.355
    },
    {
        "text": "end-to-end model lifecycle once that model is generated.",
        "start": 159.965,
        "duration": 3.21
    },
    {
        "text": "But in reality, what happens is",
        "start": 163.175,
        "duration": 2.31
    },
    {
        "text": "data scientists are traditionally relying now",
        "start": 165.485,
        "duration": 2.73
    },
    {
        "text": "on really manual methods for manually building these models.",
        "start": 168.215,
        "duration": 5.29
    },
    {
        "text": "It's a tedious task trying to try these different algorithms,",
        "start": 173.505,
        "duration": 3.185
    },
    {
        "text": "you come in with your own training scripts.",
        "start": 176.69,
        "duration": 1.925
    },
    {
        "text": "You got to identify the right hyperparameters",
        "start": 178.615,
        "duration": 2.965
    },
    {
        "text": "that are going to make your model work.",
        "start": 181.58,
        "duration": 1.83
    },
    {
        "text": "All of this typically is painstakingly manual",
        "start": 183.41,
        "duration": 4.47
    },
    {
        "text": "and requires a lot of data scientist's effort and time,",
        "start": 187.88,
        "duration": 3.285
    },
    {
        "text": "something that's at a premium.",
        "start": 191.165,
        "duration": 2.365
    },
    {
        "text": "That's where AutoML can help.",
        "start": 193.54,
        "duration": 2.755
    },
    {
        "text": "Because using AutoML, you can easily build models",
        "start": 196.295,
        "duration": 5.34
    },
    {
        "text": "for all of these computer vision related tasks",
        "start": 201.635,
        "duration": 3.105
    },
    {
        "text": "without having to write any training code.",
        "start": 204.74,
        "duration": 3.515
    },
    {
        "text": "AutoML makes it really easy for you as a user",
        "start": 208.255,
        "duration": 3.745
    },
    {
        "text": "to optimize your model training",
        "start": 212.0,
        "duration": 1.8
    },
    {
        "text": "so that you have a model that performs really well.",
        "start": 213.8,
        "duration": 2.86
    },
    {
        "text": "You can control the model algorithms at the hyperparameters.",
        "start": 216.66,
        "duration": 3.96
    },
    {
        "text": "Once that model generated,",
        "start": 220.78,
        "duration": 3.22
    },
    {
        "text": "you can easily deploy this model as a web service in",
        "start": 224.0,
        "duration": 4.17
    },
    {
        "text": "Azure Machine Learning or you can download it",
        "start": 228.17,
        "duration": 2.76
    },
    {
        "text": "and use it in your local inferencing scenarios.",
        "start": 230.93,
        "duration": 2.78
    },
    {
        "text": "All of this comes to you as a part of",
        "start": 233.71,
        "duration": 2.53
    },
    {
        "text": "the Azure Machine Learning service",
        "start": 236.24,
        "duration": 1.619
    },
    {
        "text": "so you can very easily and seamlessly integrate",
        "start": 237.859,
        "duration": 3.361
    },
    {
        "text": "with other Azure ML capabilities.",
        "start": 241.22,
        "duration": 1.59
    },
    {
        "text": "I'm talking about things like",
        "start": 242.81,
        "duration": 1.59
    },
    {
        "text": "the data labeling capability in Azure ML.",
        "start": 244.4,
        "duration": 2.43
    },
    {
        "text": "You can now have multiple labelers coming",
        "start": 246.83,
        "duration": 2.73
    },
    {
        "text": "and labeling your training data.",
        "start": 249.56,
        "duration": 1.68
    },
    {
        "text": "You can export the training data and use that with AutoML",
        "start": 251.24,
        "duration": 3.27
    },
    {
        "text": "or you can bring it your own labeled dataset",
        "start": 254.51,
        "duration": 1.71
    },
    {
        "text": "if you already have labeled training data.",
        "start": 256.22,
        "duration": 1.965
    },
    {
        "text": "The other big thing we hear is",
        "start": 258.185,
        "duration": 1.575
    },
    {
        "text": "about operationalizing these models.",
        "start": 259.76,
        "duration": 1.91
    },
    {
        "text": "Because AutoML is a part of Azure Machine Learning,",
        "start": 261.67,
        "duration": 3.43
    },
    {
        "text": "once you've generated this model,",
        "start": 265.1,
        "duration": 1.875
    },
    {
        "text": "you can very easily operationalized it at scale",
        "start": 266.975,
        "duration": 2.895
    },
    {
        "text": "using the MLOps capabilities within Azure Machine Learning.",
        "start": 269.87,
        "duration": 3.3
    },
    {
        "text": "Think of things like their automated retraining or batch scoring,",
        "start": 273.17,
        "duration": 4.755
    },
    {
        "text": "all of this is within your control.",
        "start": 277.925,
        "duration": 3.32
    },
    {
        "text": ">> This is awesome, but generally,",
        "start": 281.245,
        "duration": 2.485
    },
    {
        "text": "when we talk about AutoML,",
        "start": 283.73,
        "duration": 1.8
    },
    {
        "text": "it feels a little black boxy.",
        "start": 285.53,
        "duration": 2.48
    },
    {
        "text": "You talked about data scientists.",
        "start": 288.01,
        "duration": 1.795
    },
    {
        "text": "How does AutoML for images go about solving these challenges",
        "start": 289.805,
        "duration": 4.905
    },
    {
        "text": "in a way that empowers data scientists,",
        "start": 294.71,
        "duration": 2.97
    },
    {
        "text": "but also allows them to look inside?",
        "start": 297.68,
        "duration": 2.21
    },
    {
        "text": ">> That is a great question because",
        "start": 299.89,
        "duration": 2.23
    },
    {
        "text": "I think you summarized this really well.",
        "start": 302.12,
        "duration": 1.62
    },
    {
        "text": "This is about letting the data scientist control",
        "start": 303.74,
        "duration": 3.0
    },
    {
        "text": "all of the different things that go into model making",
        "start": 306.74,
        "duration": 4.08
    },
    {
        "text": "and empowering them to be more productive.",
        "start": 310.82,
        "duration": 2.565
    },
    {
        "text": "As a data scientist, you can come in",
        "start": 313.385,
        "duration": 2.025
    },
    {
        "text": "and while you're training these models",
        "start": 315.41,
        "duration": 2.13
    },
    {
        "text": "for the different task types,",
        "start": 317.54,
        "duration": 2.025
    },
    {
        "text": "you can select from a variety of",
        "start": 319.565,
        "duration": 2.865
    },
    {
        "text": "state-of-the-art algorithms that we support",
        "start": 322.43,
        "duration": 2.04
    },
    {
        "text": "and here, I've named some of the algorithms that you can use.",
        "start": 324.47,
        "duration": 3.06
    },
    {
        "text": "You can either come in and say,",
        "start": 327.53,
        "duration": 2.86
    },
    {
        "text": "choose this one single algorithm and try that out",
        "start": 330.39,
        "duration": 3.38
    },
    {
        "text": "or you can choose multiple options",
        "start": 333.77,
        "duration": 2.34
    },
    {
        "text": "and explore these multiple algorithms in a single AutoML run.",
        "start": 336.11,
        "duration": 5.405
    },
    {
        "text": "The other big thing that's really important when data scientists",
        "start": 341.515,
        "duration": 3.235
    },
    {
        "text": "are building models is finding the right hyperparameters.",
        "start": 344.75,
        "duration": 3.315
    },
    {
        "text": "Because your model performance is going",
        "start": 348.065,
        "duration": 2.085
    },
    {
        "text": "to depend heavily on the values that you choose.",
        "start": 350.15,
        "duration": 3.11
    },
    {
        "text": "Of course, you've got to have your machine learning knowledge",
        "start": 353.26,
        "duration": 4.39
    },
    {
        "text": "and your data science skills because",
        "start": 357.65,
        "duration": 1.59
    },
    {
        "text": "you've got to know what hyper-parameters you're tuning.",
        "start": 359.24,
        "duration": 3.27
    },
    {
        "text": "But AutoML exposes a variety of hyperparameters",
        "start": 362.51,
        "duration": 3.78
    },
    {
        "text": "for each of these tasks.",
        "start": 366.29,
        "duration": 1.74
    },
    {
        "text": "Many of these hyperparameters are model agnostic.",
        "start": 368.03,
        "duration": 2.909
    },
    {
        "text": "Some of them are task specific,",
        "start": 370.939,
        "duration": 1.561
    },
    {
        "text": "and some of them are model specific.",
        "start": 372.5,
        "duration": 2.16
    },
    {
        "text": "By exposing these hyperparameters,",
        "start": 374.66,
        "duration": 2.595
    },
    {
        "text": "you as the user can easily try these different values",
        "start": 377.255,
        "duration": 3.795
    },
    {
        "text": "and tune your model for best performance in a single run.",
        "start": 381.05,
        "duration": 3.29
    },
    {
        "text": "Think of things like learning rate or batch size and all of this",
        "start": 384.34,
        "duration": 4.15
    },
    {
        "text": "you can try very easily exploited all in a single AutoML run,",
        "start": 388.49,
        "duration": 3.945
    },
    {
        "text": "while you're still leveraging your",
        "start": 392.435,
        "duration": 1.32
    },
    {
        "text": "machine learning scheme but you're",
        "start": 393.755,
        "duration": 1.905
    },
    {
        "text": "being more productive because all of this is",
        "start": 395.66,
        "duration": 1.77
    },
    {
        "text": "happening so easily in a single run.",
        "start": 397.43,
        "duration": 1.81
    },
    {
        "text": ">> Interesting.",
        "start": 399.24,
        "duration": 0.54
    },
    {
        "text": "This is more like a stick shift car",
        "start": 399.78,
        "duration": 3.26
    },
    {
        "text": "as opposed to an automatic car",
        "start": 403.04,
        "duration": 1.11
    },
    {
        "text": "because you actually need to know,",
        "start": 404.15,
        "duration": 1.68
    },
    {
        "text": "like for example, if you don't know what a YoloV5",
        "start": 405.83,
        "duration": 2.61
    },
    {
        "text": "is or a Faster-RCNN or a Retinanet.",
        "start": 408.44,
        "duration": 2.745
    },
    {
        "text": "This is probably not going to be for you.",
        "start": 411.185,
        "duration": 2.115
    },
    {
        "text": "But if you're a data scientist that wants to go through",
        "start": 413.3,
        "duration": 2.19
    },
    {
        "text": "the entire process of figuring out what's the best solution.",
        "start": 415.49,
        "duration": 3.3
    },
    {
        "text": "This is a good shock on to get",
        "start": 418.79,
        "duration": 1.32
    },
    {
        "text": "a sense for where things are, right?",
        "start": 420.11,
        "duration": 1.68
    },
    {
        "text": ">> Absolutely right. Once you know what to try,",
        "start": 421.79,
        "duration": 3.825
    },
    {
        "text": "this allows you to try these different values very easily.",
        "start": 425.615,
        "duration": 3.945
    },
    {
        "text": "I like that analogy.",
        "start": 429.56,
        "duration": 1.63
    },
    {
        "text": "I'm going to use that the next time.",
        "start": 431.19,
        "duration": 1.11
    },
    {
        "text": ">> Yes, I did a good thing.",
        "start": 432.3,
        "duration": 1.665
    },
    {
        "text": ">> It's the stick shift car of model-building.",
        "start": 433.965,
        "duration": 2.91
    },
    {
        "text": ">> Cool. Now I feel like I want to see how it actually works.",
        "start": 436.875,
        "duration": 3.965
    },
    {
        "text": "Can you give us a demo of the capabilities?",
        "start": 440.84,
        "duration": 3.224
    },
    {
        "text": ">> Absolutely.",
        "start": 444.064,
        "duration": 0.881
    },
    {
        "text": ">> Let me bring that one here. You have my screen.",
        "start": 444.945,
        "duration": 4.405
    },
    {
        "text": ">> I got it.",
        "start": 449.35,
        "duration": 1.245
    },
    {
        "text": ">> All right, so here is a sample notebook.",
        "start": 450.595,
        "duration": 2.565
    },
    {
        "text": "I'm going to show you guys really quick where",
        "start": 453.16,
        "duration": 3.015
    },
    {
        "text": "user's coming in and let's see what the user's doing.",
        "start": 456.175,
        "duration": 3.36
    },
    {
        "text": "I'm going to build an object detection model here",
        "start": 459.535,
        "duration": 2.49
    },
    {
        "text": "for a simple task of detecting objects from my fridge.",
        "start": 462.025,
        "duration": 3.195
    },
    {
        "text": "I have a toy dataset with things",
        "start": 465.22,
        "duration": 1.56
    },
    {
        "text": "like cans of Coke or water bottles.",
        "start": 466.78,
        "duration": 2.34
    },
    {
        "text": "I'm going to use AutoML to help",
        "start": 469.12,
        "duration": 2.25
    },
    {
        "text": "me build an object detection model for this.",
        "start": 471.37,
        "duration": 2.235
    },
    {
        "text": "To get started I'm",
        "start": 473.605,
        "duration": 2.025
    },
    {
        "text": "using all of the goodness of Azure Machine Learning,",
        "start": 475.63,
        "duration": 2.04
    },
    {
        "text": "I create my workspace.",
        "start": 477.67,
        "duration": 1.32
    },
    {
        "text": "I bring in my compute target,",
        "start": 478.99,
        "duration": 2.13
    },
    {
        "text": "set up an experiment.",
        "start": 481.12,
        "duration": 1.86
    },
    {
        "text": "Out here I need to bring in my training data.",
        "start": 482.98,
        "duration": 2.535
    },
    {
        "text": "Like I mentioned earlier,",
        "start": 485.515,
        "duration": 1.425
    },
    {
        "text": "I can either bring in my previously labeled training data or I",
        "start": 486.94,
        "duration": 3.6
    },
    {
        "text": "can leverage Azure Machine Learning data labeling capabilities,",
        "start": 490.54,
        "duration": 4.05
    },
    {
        "text": "and export that labels data to use for training.",
        "start": 494.59,
        "duration": 2.625
    },
    {
        "text": "Let's get to the good stuff real quick.",
        "start": 497.215,
        "duration": 1.92
    },
    {
        "text": "All of this notebook shows how to bring in",
        "start": 499.135,
        "duration": 2.745
    },
    {
        "text": "your training data and create",
        "start": 501.88,
        "duration": 2.28
    },
    {
        "text": "that as an Azure Machine Learning dataset.",
        "start": 504.16,
        "duration": 2.76
    },
    {
        "text": "Here is the part I want to show you where",
        "start": 506.92,
        "duration": 2.31
    },
    {
        "text": "you can get started with the AutoML goodness.",
        "start": 509.23,
        "duration": 2.595
    },
    {
        "text": "Let's say I'm getting started.",
        "start": 511.825,
        "duration": 2.025
    },
    {
        "text": "I know I want try your YoloV5,",
        "start": 513.85,
        "duration": 2.175
    },
    {
        "text": "but to start, I'm not quite sure which hyperparameters to use.",
        "start": 516.025,
        "duration": 3.99
    },
    {
        "text": "I set up my AutoML config like this.",
        "start": 520.015,
        "duration": 2.355
    },
    {
        "text": "I say my task is object detection,",
        "start": 522.37,
        "duration": 2.94
    },
    {
        "text": "I give it a compute target, my training data,",
        "start": 525.31,
        "duration": 2.295
    },
    {
        "text": "I can optionally give it validation data",
        "start": 527.605,
        "duration": 1.965
    },
    {
        "text": "or reserve a part of my training dataset for validation.",
        "start": 529.57,
        "duration": 3.825
    },
    {
        "text": "Here I come in and say, try YoloV5.",
        "start": 533.395,
        "duration": 3.255
    },
    {
        "text": "In this example, I'm giving just one algorithm,",
        "start": 536.65,
        "duration": 2.46
    },
    {
        "text": "but I could totally have used more.",
        "start": 539.11,
        "duration": 1.965
    },
    {
        "text": "By doing this simple step,",
        "start": 541.075,
        "duration": 2.115
    },
    {
        "text": "it's going to try the default",
        "start": 543.19,
        "duration": 1.77
    },
    {
        "text": "YoloV5 algorithm the default hyperparameter response.",
        "start": 544.96,
        "duration": 3.885
    },
    {
        "text": "But now I want to take this one step further.",
        "start": 548.845,
        "duration": 2.805
    },
    {
        "text": "I really want to get the best model performance out of this.",
        "start": 551.65,
        "duration": 3.81
    },
    {
        "text": "The default was good,",
        "start": 555.46,
        "duration": 1.35
    },
    {
        "text": "but I want to see how much more performance",
        "start": 556.81,
        "duration": 2.22
    },
    {
        "text": "and accuracy I can squeeze out of that model.",
        "start": 559.03,
        "duration": 2.73
    },
    {
        "text": "I can now come in",
        "start": 561.76,
        "duration": 1.95
    },
    {
        "text": "and easily tune the different hyperparameters",
        "start": 563.71,
        "duration": 3.03
    },
    {
        "text": "or try different algorithms all in a single run.",
        "start": 566.74,
        "duration": 2.19
    },
    {
        "text": "Here's how I do that.",
        "start": 568.93,
        "duration": 2.235
    },
    {
        "text": "In this case I'm trying a combination of YoloV5 and Faster-RCNN.",
        "start": 571.165,
        "duration": 4.89
    },
    {
        "text": "For each of these,",
        "start": 576.055,
        "duration": 1.275
    },
    {
        "text": "I'm calling out which hyperparameters I want to tune.",
        "start": 577.33,
        "duration": 3.135
    },
    {
        "text": "I'm actually giving it ranges of learning rate,",
        "start": 580.465,
        "duration": 2.475
    },
    {
        "text": "giving a different choices of model size.",
        "start": 582.94,
        "duration": 2.235
    },
    {
        "text": "Similarly with Faster-RCNN,",
        "start": 585.175,
        "duration": 1.575
    },
    {
        "text": "I'm using different learning rates and optimizers.",
        "start": 586.75,
        "duration": 2.385
    },
    {
        "text": "I can build this model space,",
        "start": 589.135,
        "duration": 2.46
    },
    {
        "text": "however it is,",
        "start": 591.595,
        "duration": 1.555
    },
    {
        "text": "and try multiple algorithms for each one,",
        "start": 593.15,
        "duration": 3.02
    },
    {
        "text": "I can try multiple hyperparameters.",
        "start": 596.17,
        "duration": 2.535
    },
    {
        "text": "Then here I control how I'm actually going to be trying",
        "start": 598.705,
        "duration": 5.415
    },
    {
        "text": "all these different algorithms and hyperparameter combinations.",
        "start": 604.12,
        "duration": 3.36
    },
    {
        "text": "I give it my budget.",
        "start": 607.48,
        "duration": 1.455
    },
    {
        "text": "I leveraged concurrency of my compute target.",
        "start": 608.935,
        "duration": 3.75
    },
    {
        "text": "I had a multi-node computer target here.",
        "start": 612.685,
        "duration": 2.4
    },
    {
        "text": "I can select things like,",
        "start": 615.085,
        "duration": 2.145
    },
    {
        "text": "what sampling do I want?",
        "start": 617.23,
        "duration": 1.485
    },
    {
        "text": "Do I want random",
        "start": 618.715,
        "duration": 1.125
    },
    {
        "text": "or I can pick vision or grid as well.",
        "start": 619.84,
        "duration": 2.685
    },
    {
        "text": "This is another cool feature",
        "start": 622.525,
        "duration": 1.635
    },
    {
        "text": "where I can leverage early termination.",
        "start": 624.16,
        "duration": 2.04
    },
    {
        "text": "Meaning any of my configurations that aren't performing as well,",
        "start": 626.2,
        "duration": 3.9
    },
    {
        "text": "they'll be automatically terminated to save me compute resources.",
        "start": 630.1,
        "duration": 3.975
    },
    {
        "text": "Once I've set up my config,",
        "start": 634.075,
        "duration": 2.595
    },
    {
        "text": "I go in and I say again, \"Hey,",
        "start": 636.67,
        "duration": 1.5
    },
    {
        "text": "give me an object detection model.",
        "start": 638.17,
        "duration": 1.545
    },
    {
        "text": "Here's my compute target,",
        "start": 639.715,
        "duration": 1.125
    },
    {
        "text": "my training data.",
        "start": 640.84,
        "duration": 0.93
    },
    {
        "text": "Submit this run.\"",
        "start": 641.77,
        "duration": 1.74
    },
    {
        "text": ">> That's cool.",
        "start": 643.51,
        "duration": 0.6
    },
    {
        "text": "Can you scroll up?",
        "start": 644.11,
        "duration": 0.63
    },
    {
        "text": "I have a question here because I want to make sure",
        "start": 644.74,
        "duration": 1.83
    },
    {
        "text": "I'm understanding this correctly.",
        "start": 646.57,
        "duration": 1.695
    },
    {
        "text": "Basically this parameter space is you saying,",
        "start": 648.265,
        "duration": 3.51
    },
    {
        "text": "\"If I were to do this on my own as a data scientist,",
        "start": 651.775,
        "duration": 3.225
    },
    {
        "text": "I would go through all of these choices one by one,",
        "start": 655.0,
        "duration": 3.885
    },
    {
        "text": "but I'm just going to put them in a parameter space",
        "start": 658.885,
        "duration": 1.785
    },
    {
        "text": "until AutoML for images.",
        "start": 660.67,
        "duration": 1.38
    },
    {
        "text": "Just go do all of that for me.\"",
        "start": 662.05,
        "duration": 1.86
    },
    {
        "text": ">> Absolutely right. When you were doing this manually,",
        "start": 663.91,
        "duration": 3.24
    },
    {
        "text": "you would be trying one at a time,",
        "start": 667.15,
        "duration": 1.515
    },
    {
        "text": "going through that manual iterative process that this work,",
        "start": 668.665,
        "duration": 2.55
    },
    {
        "text": "that does not work, what should I try next?",
        "start": 671.215,
        "duration": 1.83
    },
    {
        "text": "You're not only saying try all of these.",
        "start": 673.045,
        "duration": 3.42
    },
    {
        "text": "But if you take a look at the learning rate here,",
        "start": 676.465,
        "duration": 2.55
    },
    {
        "text": "and simply saying use a uniformly distributed space,",
        "start": 679.015,
        "duration": 3.045
    },
    {
        "text": "try values from 0.001-0.01 and pick randomly from that space.",
        "start": 682.06,
        "duration": 5.13
    },
    {
        "text": "I'm not even calling out individual learning rates",
        "start": 687.19,
        "duration": 2.43
    },
    {
        "text": "like I can basically give it a continuous or discrete space",
        "start": 689.62,
        "duration": 4.14
    },
    {
        "text": "and tell it how you want it to sample from that space,",
        "start": 693.76,
        "duration": 3.0
    },
    {
        "text": "and it does that all for you in one run.",
        "start": 696.76,
        "duration": 2.43
    },
    {
        "text": ">> That's really cool.",
        "start": 699.19,
        "duration": 2.01
    },
    {
        "text": "What does this look like when it actually runs?",
        "start": 701.2,
        "duration": 2.655
    },
    {
        "text": ">> Good question.",
        "start": 703.855,
        "duration": 1.365
    },
    {
        "text": "Out here, I have a completed run with",
        "start": 705.22,
        "duration": 3.465
    },
    {
        "text": "a similar parameter space that I gave for object detection.",
        "start": 708.685,
        "duration": 2.97
    },
    {
        "text": "This is my completed AutoML run.",
        "start": 711.655,
        "duration": 2.22
    },
    {
        "text": "I can go in here and it's loading.",
        "start": 713.875,
        "duration": 5.1
    },
    {
        "text": ">> As it's loading so basically is running",
        "start": 718.975,
        "duration": 5.015
    },
    {
        "text": "all of these experiments for you on the Cloud Compute.",
        "start": 723.99,
        "duration": 5.55
    },
    {
        "text": "Is that right?",
        "start": 729.54,
        "duration": 1.08
    },
    {
        "text": ">> That is correct.",
        "start": 730.62,
        "duration": 1.08
    },
    {
        "text": "It's running.",
        "start": 731.7,
        "duration": 0.63
    },
    {
        "text": "It is doing your job for you when you will get a coffee,",
        "start": 732.33,
        "duration": 4.42
    },
    {
        "text": "you just need your skills.",
        "start": 736.75,
        "duration": 2.475
    },
    {
        "text": ">> That's right. Basically,",
        "start": 739.225,
        "duration": 1.995
    },
    {
        "text": "the cool thing about this is if you have",
        "start": 741.22,
        "duration": 2.58
    },
    {
        "text": "an image classification or object detection.",
        "start": 743.8,
        "duration": 5.49
    },
    {
        "text": "You can basically just say over the weekend.",
        "start": 749.29,
        "duration": 2.325
    },
    {
        "text": "Let's try all the things that I know work",
        "start": 751.615,
        "duration": 2.865
    },
    {
        "text": "and then leave it running over the weekend",
        "start": 754.48,
        "duration": 1.62
    },
    {
        "text": "and then you will see something like this at the end.",
        "start": 756.1,
        "duration": 2.505
    },
    {
        "text": ">> One of my users actually said exactly that.",
        "start": 758.605,
        "duration": 2.505
    },
    {
        "text": "They said, \"This functionality is so cool,",
        "start": 761.11,
        "duration": 2.97
    },
    {
        "text": "I'm getting my weekends back.\"",
        "start": 764.08,
        "duration": 1.32
    },
    {
        "text": ">> Nice.",
        "start": 765.4,
        "duration": 1.81
    },
    {
        "text": ">> Once I have my models,",
        "start": 767.79,
        "duration": 2.11
    },
    {
        "text": "this is my leaderboard of all the top models,",
        "start": 769.9,
        "duration": 2.19
    },
    {
        "text": "and you've complete visibility into what was tried,",
        "start": 772.09,
        "duration": 2.7
    },
    {
        "text": "what hyperparameter values were tried.",
        "start": 774.79,
        "duration": 1.935
    },
    {
        "text": "I can select any one of them and then go either",
        "start": 776.725,
        "duration": 2.925
    },
    {
        "text": "deploy the model out to Azure Machine Learning as a web service,",
        "start": 779.65,
        "duration": 3.69
    },
    {
        "text": "or I can download the model and use it locally.",
        "start": 783.34,
        "duration": 2.73
    },
    {
        "text": "Then I want to show you real quick a couple of the things.",
        "start": 786.07,
        "duration": 3.075
    },
    {
        "text": "Here are my Child runs.",
        "start": 789.145,
        "duration": 1.77
    },
    {
        "text": "I can go and explore each of these",
        "start": 790.915,
        "duration": 6.315
    },
    {
        "text": "and see how all of those performed.",
        "start": 797.23,
        "duration": 4.155
    },
    {
        "text": "Out here you can see these runs that weren't performing as well.",
        "start": 801.385,
        "duration": 3.315
    },
    {
        "text": "They got early dominated,",
        "start": 804.7,
        "duration": 1.41
    },
    {
        "text": "which is super cool for me as a user",
        "start": 806.11,
        "duration": 1.83
    },
    {
        "text": "because it's saving me compute resources.",
        "start": 807.94,
        "duration": 2.535
    },
    {
        "text": "These weren't promising runs.",
        "start": 810.475,
        "duration": 1.47
    },
    {
        "text": "What's the point in spending compute resources on that?",
        "start": 811.945,
        "duration": 4.065
    },
    {
        "text": "While these runs up on top are the ones that would win well,",
        "start": 816.01,
        "duration": 3.21
    },
    {
        "text": "and the system automatically decided",
        "start": 819.22,
        "duration": 1.92
    },
    {
        "text": "they should continue all the way through the end",
        "start": 821.14,
        "duration": 1.92
    },
    {
        "text": "because those are going to give me",
        "start": 823.06,
        "duration": 1.23
    },
    {
        "text": "the most promising model performance.",
        "start": 824.29,
        "duration": 2.71
    },
    {
        "text": "I can then get into any individual run here.",
        "start": 827.7,
        "duration": 2.965
    },
    {
        "text": "Let's take this guy for example and get into the outputs,",
        "start": 830.665,
        "duration": 8.575
    },
    {
        "text": "and out here I can access the model PyTorch file or the ONNX file",
        "start": 841.02,
        "duration": 5.98
    },
    {
        "text": "and I'm free to use it however I like in my AutoML.",
        "start": 847.0,
        "duration": 3.63
    },
    {
        "text": ">> That is the next question I wanted to ask,",
        "start": 850.63,
        "duration": 1.56
    },
    {
        "text": "because sometimes when we're looking at auto things,",
        "start": 852.19,
        "duration": 3.165
    },
    {
        "text": "it feels like we get locked in.",
        "start": 855.355,
        "duration": 3.39
    },
    {
        "text": "If you're going to use our auto thing,",
        "start": 858.745,
        "duration": 1.665
    },
    {
        "text": "you're going to have to use our auto.",
        "start": 860.41,
        "duration": 1.515
    },
    {
        "text": "Basically, when you're running this,",
        "start": 861.925,
        "duration": 1.875
    },
    {
        "text": "the outcome is whatever you would have done",
        "start": 863.8,
        "duration": 2.07
    },
    {
        "text": "before as a data scientist,",
        "start": 865.87,
        "duration": 1.365
    },
    {
        "text": "except it was done automatically for you.",
        "start": 867.235,
        "duration": 2.625
    },
    {
        "text": "Can you do whatever you want with the models?",
        "start": 869.86,
        "duration": 1.935
    },
    {
        "text": ">> Absolutely. At this point,",
        "start": 871.795,
        "duration": 1.365
    },
    {
        "text": "you can take your model and go and deployed it",
        "start": 873.16,
        "duration": 4.425
    },
    {
        "text": "as a web service out in Azure Machine Learning use that",
        "start": 877.585,
        "duration": 2.085
    },
    {
        "text": "in your inferencing scenario",
        "start": 879.67,
        "duration": 1.17
    },
    {
        "text": "or let's say you have a local inferencing scenario.",
        "start": 880.84,
        "duration": 2.595
    },
    {
        "text": "You can download these model files right here",
        "start": 883.435,
        "duration": 1.905
    },
    {
        "text": "and use them in local inferencing.",
        "start": 885.34,
        "duration": 2.43
    },
    {
        "text": "Then you can also use these with",
        "start": 887.77,
        "duration": 2.035
    },
    {
        "text": "other MLOps capabilities within Azure machine learning,",
        "start": 889.805,
        "duration": 3.405
    },
    {
        "text": "you can now use this automated retraining batch scoring,",
        "start": 893.21,
        "duration": 3.225
    },
    {
        "text": "whatever else you would do with a custom trained model",
        "start": 896.435,
        "duration": 2.475
    },
    {
        "text": "in Azure Machine Learning,",
        "start": 898.91,
        "duration": 0.87
    },
    {
        "text": "you can go ahead and do that.",
        "start": 899.78,
        "duration": 1.38
    },
    {
        "text": "You have full control of your model.",
        "start": 901.16,
        "duration": 1.77
    },
    {
        "text": ">> It feels like a really awesome productivity tool",
        "start": 902.93,
        "duration": 3.54
    },
    {
        "text": "for someone that wants to solve a computer vision problem.",
        "start": 906.47,
        "duration": 2.82
    },
    {
        "text": "Now I'm going to ask a question that might",
        "start": 909.29,
        "duration": 1.56
    },
    {
        "text": "seem to me that there's a little bit of a confusion.",
        "start": 910.85,
        "duration": 3.105
    },
    {
        "text": "We have something called custom vision.",
        "start": 913.955,
        "duration": 1.905
    },
    {
        "text": "We have computer vision, custom vision,",
        "start": 915.86,
        "duration": 2.562
    },
    {
        "text": "and now AutoML for images.",
        "start": 918.422,
        "duration": 1.608
    },
    {
        "text": "Can you maybe describe what the difference might be",
        "start": 920.03,
        "duration": 2.19
    },
    {
        "text": "and when you might choose one over the other.",
        "start": 922.22,
        "duration": 1.92
    },
    {
        "text": ">> Great question.",
        "start": 924.14,
        "duration": 1.29
    },
    {
        "text": "Custom vision is a great tool that helps",
        "start": 925.43,
        "duration": 3.69
    },
    {
        "text": "you build computer vision models",
        "start": 929.12,
        "duration": 2.325
    },
    {
        "text": "without needing any data science or ML expertise.",
        "start": 931.445,
        "duration": 3.565
    },
    {
        "text": "These models are built,",
        "start": 935.5,
        "duration": 2.05
    },
    {
        "text": "they're pre-trained with datasets",
        "start": 937.55,
        "duration": 1.68
    },
    {
        "text": "that are optimized for specific tasks.",
        "start": 939.23,
        "duration": 2.415
    },
    {
        "text": "Sometimes though, your scenario",
        "start": 941.645,
        "duration": 2.295
    },
    {
        "text": "might require you to have more control",
        "start": 943.94,
        "duration": 1.77
    },
    {
        "text": "on either model training or model deployment",
        "start": 945.71,
        "duration": 2.82
    },
    {
        "text": "or just the end-to-end ML lifecycle of that model.",
        "start": 948.53,
        "duration": 3.585
    },
    {
        "text": ">> I see.",
        "start": 952.115,
        "duration": 0.54
    },
    {
        "text": ">> Then you need this additional control.",
        "start": 952.655,
        "duration": 1.815
    },
    {
        "text": "AutoML offers you all of this control and flexibility,",
        "start": 954.47,
        "duration": 3.87
    },
    {
        "text": "while still making it easy for you to use.",
        "start": 958.34,
        "duration": 2.505
    },
    {
        "text": "Think of AutoML as being targeted to data scientists",
        "start": 960.845,
        "duration": 3.045
    },
    {
        "text": "with ML expertise in the computer vision area.",
        "start": 963.89,
        "duration": 2.355
    },
    {
        "text": "But it's boosting your productivity",
        "start": 966.245,
        "duration": 2.865
    },
    {
        "text": "as a data scientist as you're building these models.",
        "start": 969.11,
        "duration": 2.075
    },
    {
        "text": ">> I see, so auto for images is like stick shift.",
        "start": 971.185,
        "duration": 3.615
    },
    {
        "text": "Computer custom vision",
        "start": 974.8,
        "duration": 2.52
    },
    {
        "text": "is like you driving your own automatic car,",
        "start": 977.32,
        "duration": 2.67
    },
    {
        "text": "and computer vision is like getting",
        "start": 979.99,
        "duration": 1.69
    },
    {
        "text": "chauffeured around, so to speak,",
        "start": 981.68,
        "duration": 2.04
    },
    {
        "text": "because everything is a lot,",
        "start": 983.72,
        "duration": 1.65
    },
    {
        "text": "like you basically are doing less",
        "start": 985.37,
        "duration": 1.29
    },
    {
        "text": "and less of the data science work at that point.",
        "start": 986.66,
        "duration": 2.515
    },
    {
        "text": ">> I like your analogy, I guess you could say that.",
        "start": 989.175,
        "duration": 3.165
    },
    {
        "text": ">> Fantastic.",
        "start": 992.34,
        "duration": 1.18
    },
    {
        "text": "Where can folks go to find out more?",
        "start": 993.52,
        "duration": 2.77
    },
    {
        "text": ">> I'm going to share a link to a release announcement",
        "start": 996.48,
        "duration": 3.98
    },
    {
        "text": "that has all the information on the wonderful capabilities here,",
        "start": 1000.46,
        "duration": 3.06
    },
    {
        "text": "and also more importantly,",
        "start": 1003.52,
        "duration": 1.26
    },
    {
        "text": "links to documentation and sample notebooks.",
        "start": 1004.78,
        "duration": 3.255
    },
    {
        "text": "I would love for folks to try this out",
        "start": 1008.035,
        "duration": 1.875
    },
    {
        "text": "and get feedback on the product.",
        "start": 1009.91,
        "duration": 1.975
    },
    {
        "text": ">> Fantastic.",
        "start": 1011.885,
        "duration": 1.195
    },
    {
        "text": "Well, Swati. Thank you so much for being with us",
        "start": 1013.08,
        "duration": 2.08
    },
    {
        "text": "and be learning all about building computer vision models",
        "start": 1015.16,
        "duration": 2.22
    },
    {
        "text": "using AutoML for images on The AI Show.",
        "start": 1017.38,
        "duration": 2.34
    },
    {
        "text": "Thank you so much for watching and hopefully",
        "start": 1019.72,
        "duration": 1.5
    },
    {
        "text": "we'll see you next time take care.",
        "start": 1021.22,
        "duration": 1.08
    },
    {
        "text": "[MUSIC]",
        "start": 1022.3,
        "duration": 10.699
    }
]