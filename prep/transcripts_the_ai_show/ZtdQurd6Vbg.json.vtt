[
    {
        "text": ">> You're not going to want to miss",
        "start": 0.0,
        "duration": 1.41
    },
    {
        "text": "this episode of the AI Show",
        "start": 1.41,
        "duration": 1.74
    },
    {
        "text": "where we look at something that all of you use,",
        "start": 3.15,
        "duration": 3.045
    },
    {
        "text": "a little hint, the [inaudible] underneath are produced by",
        "start": 6.195,
        "duration": 3.045
    },
    {
        "text": "some amazing AI from the Office Team. Make sure you tune in.",
        "start": 9.24,
        "duration": 3.63
    },
    {
        "text": "[MUSIC].",
        "start": 12.87,
        "duration": 10.26
    },
    {
        "text": ">> Hello, and welcome to this episode of",
        "start": 23.13,
        "duration": 1.23
    },
    {
        "text": "the AI Show where we're going to talk a little bit",
        "start": 24.36,
        "duration": 1.95
    },
    {
        "text": "about some of the stuff that you use all of the time,",
        "start": 26.31,
        "duration": 3.39
    },
    {
        "text": "and how it actually works.",
        "start": 29.7,
        "duration": 1.05
    },
    {
        "text": "I have [inaudible] ,",
        "start": 30.75,
        "duration": 1.02
    },
    {
        "text": "and [inaudible] with me. How are you doing my friends?",
        "start": 31.77,
        "duration": 1.53
    },
    {
        "text": ">> Good. How are you?",
        "start": 33.3,
        "duration": 1.17
    },
    {
        "text": ">> Why don't you introduce yourselves,",
        "start": 34.47,
        "duration": 1.32
    },
    {
        "text": "tell us who you are, and what you do.",
        "start": 35.79,
        "duration": 1.86
    },
    {
        "text": ">> Cool, I'm [inaudible].",
        "start": 37.65,
        "duration": 0.89
    },
    {
        "text": "I'm a data scientist on Office Intelligence,",
        "start": 38.54,
        "duration": 2.82
    },
    {
        "text": "and I work on the red and blue",
        "start": 41.36,
        "duration": 1.92
    },
    {
        "text": "underlines that you see in Word pretty much all the time.",
        "start": 43.28,
        "duration": 2.535
    },
    {
        "text": ">> Fantastic.",
        "start": 45.815,
        "duration": 0.83
    },
    {
        "text": ">> I'm an applied scientist on",
        "start": 46.645,
        "duration": 1.6
    },
    {
        "text": "natural language experience group as well.",
        "start": 48.245,
        "duration": 2.01
    },
    {
        "text": "We build machine learning models that help people write better.",
        "start": 50.255,
        "duration": 3.135
    },
    {
        "text": ">> So tell us what it is that you actually do because you",
        "start": 53.39,
        "duration": 2.16
    },
    {
        "text": "work on something that everyone uses,",
        "start": 55.55,
        "duration": 2.495
    },
    {
        "text": "and that's supposed to help us,",
        "start": 58.045,
        "duration": 1.465
    },
    {
        "text": "at least help me because I'm",
        "start": 59.51,
        "duration": 1.08
    },
    {
        "text": "terrible at English, tells what you do.",
        "start": 60.59,
        "duration": 2.045
    },
    {
        "text": ">> Sure. So on a daily basis what we do is",
        "start": 62.635,
        "duration": 2.92
    },
    {
        "text": "we train NLP models using some of",
        "start": 65.555,
        "duration": 3.015
    },
    {
        "text": "the latest neural architectures to help understand",
        "start": 68.57,
        "duration": 2.73
    },
    {
        "text": "the context of your text in order to give you",
        "start": 71.3,
        "duration": 1.74
    },
    {
        "text": "the right grammar and spelling corrections that you need.",
        "start": 73.04,
        "duration": 2.25
    },
    {
        "text": ">> So when I'm typing,",
        "start": 75.29,
        "duration": 1.47
    },
    {
        "text": "usually there's a little colored bar",
        "start": 76.76,
        "duration": 2.28
    },
    {
        "text": "that says, \"You should fix it.\"",
        "start": 79.04,
        "duration": 1.53
    },
    {
        "text": "I feel like you were going to say something.",
        "start": 80.57,
        "duration": 1.14
    },
    {
        "text": ">> Yeah. So what I was saying that we",
        "start": 81.71,
        "duration": 1.62
    },
    {
        "text": "are building machine learning models,",
        "start": 83.33,
        "duration": 2.31
    },
    {
        "text": "and making sure that we try to augment",
        "start": 85.64,
        "duration": 2.31
    },
    {
        "text": "the writing experience of users but not step on the boundaries,",
        "start": 87.95,
        "duration": 3.69
    },
    {
        "text": "and try to be more of inclusive experience for you.",
        "start": 91.64,
        "duration": 5.83
    },
    {
        "text": ">> So you are trying to help out and you are, \"Hey,",
        "start": 97.47,
        "duration": 1.17
    },
    {
        "text": "it might be good to change your Word in this",
        "start": 98.64,
        "duration": 1.73
    },
    {
        "text": "way,\" as opposed to, \"Yeah, I'm going to rewrite this.\"",
        "start": 100.37,
        "duration": 1.995
    },
    {
        "text": ">> Yeah.",
        "start": 102.365,
        "duration": 0.405
    },
    {
        "text": ">> So how many people use this?",
        "start": 102.77,
        "duration": 1.89
    },
    {
        "text": "I feel like I use it all the time.",
        "start": 104.66,
        "duration": 1.64
    },
    {
        "text": ">> Yeah. Our monthly active users are in the tens of millions.",
        "start": 106.3,
        "duration": 4.105
    },
    {
        "text": "So it's very widely used service,",
        "start": 110.405,
        "duration": 3.105
    },
    {
        "text": "and essentially at the core",
        "start": 113.51,
        "duration": 2.07
    },
    {
        "text": "we're an intelligent writing assistant.",
        "start": 115.58,
        "duration": 1.425
    },
    {
        "text": "So when you as a writer come and use our service,",
        "start": 117.005,
        "duration": 3.405
    },
    {
        "text": "we want you to just focus on getting your ideas",
        "start": 120.41,
        "duration": 2.19
    },
    {
        "text": "on Word or any Office app,",
        "start": 122.6,
        "duration": 3.0
    },
    {
        "text": "but at the end of the day all the polishing stuff should be on us,",
        "start": 125.6,
        "duration": 3.09
    },
    {
        "text": "and we'll help you polish your document as need be.",
        "start": 128.69,
        "duration": 3.245
    },
    {
        "text": ">> So generally what I do is if I'm trying to be super proactive,",
        "start": 131.935,
        "duration": 4.175
    },
    {
        "text": "I just start writing,",
        "start": 136.11,
        "duration": 1.14
    },
    {
        "text": "and get the ideas all out.",
        "start": 137.25,
        "duration": 2.04
    },
    {
        "text": "You're saying that in Word,",
        "start": 139.29,
        "duration": 1.89
    },
    {
        "text": "in the editor, you're just going to make",
        "start": 141.18,
        "duration": 1.4
    },
    {
        "text": "sure to polish it as it goes.",
        "start": 142.58,
        "duration": 1.755
    },
    {
        "text": ">> Exactly.",
        "start": 144.335,
        "duration": 0.675
    },
    {
        "text": ">> That's pretty amazing. So let's get into the machine learning",
        "start": 145.01,
        "duration": 1.74
    },
    {
        "text": "part because this is obviously the AI Show.",
        "start": 146.75,
        "duration": 2.565
    },
    {
        "text": "This must be some crazy model that you're building.",
        "start": 149.315,
        "duration": 3.525
    },
    {
        "text": "Can you describe a little bit about,",
        "start": 152.84,
        "duration": 1.56
    },
    {
        "text": "how you're building it.",
        "start": 154.4,
        "duration": 2.52
    },
    {
        "text": "Maybe describe a little bit for those that are out there watching.",
        "start": 156.92,
        "duration": 1.89
    },
    {
        "text": ">> Sure. Yeah. So Editor initially had rule-based systems,",
        "start": 158.81,
        "duration": 3.63
    },
    {
        "text": "and in recent years we are trying to augment",
        "start": 162.44,
        "duration": 2.22
    },
    {
        "text": "it with machine learning and deep learning models,",
        "start": 164.66,
        "duration": 2.61
    },
    {
        "text": "and so all of these models they",
        "start": 167.27,
        "duration": 1.53
    },
    {
        "text": "are huge models as you already know,",
        "start": 168.8,
        "duration": 2.58
    },
    {
        "text": "and they are usually drained for days on end,",
        "start": 171.38,
        "duration": 4.32
    },
    {
        "text": "and so, yeah, they are RNN based, LSTM based models.",
        "start": 175.7,
        "duration": 3.93
    },
    {
        "text": ">> So these are just neural networks, standard RNNs, LSTMs.",
        "start": 179.63,
        "duration": 4.26
    },
    {
        "text": ">> Yes.",
        "start": 183.89,
        "duration": 0.36
    },
    {
        "text": ">> But I imagine that you have a lot of data to train it on.",
        "start": 184.25,
        "duration": 3.5
    },
    {
        "text": "Could you give everyone a sense of",
        "start": 187.75,
        "duration": 1.63
    },
    {
        "text": "the scale of the data that you're training with.",
        "start": 189.38,
        "duration": 1.91
    },
    {
        "text": ">> Yeah. So it's definitely large for an NLP scenario you need.",
        "start": 191.29,
        "duration": 3.955
    },
    {
        "text": "These are tens and tens of millions of sentences.",
        "start": 195.245,
        "duration": 1.92
    },
    {
        "text": "So the corpus has to be big in order for us",
        "start": 197.165,
        "duration": 2.895
    },
    {
        "text": "to make sure we suggest grammatically accurate rewrite.",
        "start": 200.06,
        "duration": 3.56
    },
    {
        "text": ">> Is this text coming from books or where's it",
        "start": 203.62,
        "duration": 2.53
    },
    {
        "text": "coming from that you're training on?",
        "start": 206.15,
        "duration": 2.46
    },
    {
        "text": ">> So we are training on public available data",
        "start": 208.61,
        "duration": 2.955
    },
    {
        "text": "but we are getting some users signals as well,",
        "start": 211.565,
        "duration": 2.495
    },
    {
        "text": "whether user accepted or ignored our suggestion,",
        "start": 214.06,
        "duration": 3.1
    },
    {
        "text": "and use that to augment our models.",
        "start": 217.16,
        "duration": 2.32
    },
    {
        "text": ">> The important thing to note is",
        "start": 219.48,
        "duration": 1.34
    },
    {
        "text": "that Microsoft we care a lot about privacy.",
        "start": 220.82,
        "duration": 1.89
    },
    {
        "text": ">> Absolutely.",
        "start": 222.71,
        "duration": 0.615
    },
    {
        "text": ">> So anytime user signals are used,",
        "start": 223.325,
        "duration": 3.165
    },
    {
        "text": "they are done in a totally eyes off fashion.",
        "start": 226.49,
        "duration": 2.085
    },
    {
        "text": "So there's definitely from a data science perspective,",
        "start": 228.575,
        "duration": 3.57
    },
    {
        "text": "user privacy is treated as the utmost priority.",
        "start": 232.145,
        "duration": 2.235
    },
    {
        "text": ">> Yeah.",
        "start": 234.38,
        "duration": 0.41
    },
    {
        "text": ">> So we do try as much as possible to train on public corpuses.",
        "start": 234.79,
        "duration": 3.31
    },
    {
        "text": "You know Google billion Word corpus, Wikipedia text,",
        "start": 238.1,
        "duration": 2.775
    },
    {
        "text": "these are large corpuses",
        "start": 240.875,
        "duration": 1.785
    },
    {
        "text": "used for natural language processing training.",
        "start": 242.66,
        "duration": 1.53
    },
    {
        "text": ">> Where we hope the English is good.",
        "start": 244.19,
        "duration": 1.455
    },
    {
        "text": ">> Exactly. Yeah.",
        "start": 245.645,
        "duration": 0.735
    },
    {
        "text": ">> You were going to say something.",
        "start": 246.38,
        "duration": 1.1
    },
    {
        "text": ">> I was just going to add on that \"Eyes off\" mean",
        "start": 247.48,
        "duration": 1.77
    },
    {
        "text": "we don't look at the data at all.",
        "start": 249.25,
        "duration": 1.885
    },
    {
        "text": ">> Yeah.",
        "start": 251.135,
        "duration": 0.645
    },
    {
        "text": ">> User data.",
        "start": 251.78,
        "duration": 0.645
    },
    {
        "text": ">> It's very important. Cognitive services is same way.",
        "start": 252.425,
        "duration": 2.925
    },
    {
        "text": "We don't use people's data.",
        "start": 255.35,
        "duration": 1.8
    },
    {
        "text": "We have stuff that's publicly available,",
        "start": 257.15,
        "duration": 1.64
    },
    {
        "text": "and then if there are signals that we sent back,",
        "start": 258.79,
        "duration": 1.8
    },
    {
        "text": "nobody knows about any of that.",
        "start": 260.59,
        "duration": 1.87
    },
    {
        "text": "So let's talk about again,",
        "start": 262.46,
        "duration": 1.96
    },
    {
        "text": "can you give us a sense of the amount of data.",
        "start": 264.42,
        "duration": 2.96
    },
    {
        "text": "Is it gigabytes, terabytes, [inaudible] bytes?",
        "start": 267.38,
        "duration": 3.64
    },
    {
        "text": ">> It's hundreds of millions of sentences.",
        "start": 271.02,
        "duration": 2.625
    },
    {
        "text": ">> So obviously this is not going to fit in RAM.",
        "start": 273.645,
        "duration": 2.175
    },
    {
        "text": "So the size of the VM you're using must be ginormous.",
        "start": 275.82,
        "duration": 2.935
    },
    {
        "text": ">> No, Seth. Actually fortunately",
        "start": 278.755,
        "duration": 1.765
    },
    {
        "text": "for us we use Azure Machine Learning.",
        "start": 280.52,
        "duration": 1.65
    },
    {
        "text": ">> Okay.",
        "start": 282.17,
        "duration": 0.1
    },
    {
        "text": ">> So what that enables us to do is we can",
        "start": 282.27,
        "duration": 1.82
    },
    {
        "text": "train on hundreds of GPUs simultaneously.",
        "start": 284.09,
        "duration": 3.21
    },
    {
        "text": "So we can distribute our training workloads using Azure ML.",
        "start": 287.3,
        "duration": 3.78
    },
    {
        "text": ">> So let's get into this in the engineering,",
        "start": 291.08,
        "duration": 2.61
    },
    {
        "text": "because I love machine learning specific level.",
        "start": 293.69,
        "duration": 2.5
    },
    {
        "text": "I love doing deep learning, I'm more of a vision guy,",
        "start": 296.19,
        "duration": 2.355
    },
    {
        "text": "but I imagine it must be using some framework.",
        "start": 298.545,
        "duration": 3.185
    },
    {
        "text": ">> Yeah. So we use Py Torch which has",
        "start": 301.73,
        "duration": 2.1
    },
    {
        "text": "become state of the art for most deep-learning tasks.",
        "start": 303.83,
        "duration": 2.42
    },
    {
        "text": ">> So when you're using Py Torch, how do you,",
        "start": 306.25,
        "duration": 2.59
    },
    {
        "text": "look do I understand is that you give it some data,",
        "start": 308.84,
        "duration": 3.41
    },
    {
        "text": "and then you run through a number of batches,",
        "start": 312.25,
        "duration": 1.5
    },
    {
        "text": "and then once you go through all the data,",
        "start": 313.75,
        "duration": 1.51
    },
    {
        "text": "you're done with an epoch.",
        "start": 315.26,
        "duration": 1.5
    },
    {
        "text": "How do you do this with so much data distributed [inaudible]?",
        "start": 316.76,
        "duration": 4.02
    },
    {
        "text": ">> It's almost as easy as you train on a single VM.",
        "start": 320.78,
        "duration": 3.33
    },
    {
        "text": "You just specify the number of VMs,",
        "start": 324.11,
        "duration": 2.01
    },
    {
        "text": "and then we use Horovod which takes care",
        "start": 326.12,
        "duration": 2.73
    },
    {
        "text": "of distribution on the Azure Machine Learning platform,",
        "start": 328.85,
        "duration": 3.3
    },
    {
        "text": "and you can just run jobs on 100 VMs,",
        "start": 332.15,
        "duration": 2.83
    },
    {
        "text": "1,000 VMs without even worrying about it,",
        "start": 334.98,
        "duration": 2.31
    },
    {
        "text": "and when they are all done Azure machine",
        "start": 337.29,
        "duration": 1.58
    },
    {
        "text": "learning helps to bring all the results together,",
        "start": 338.87,
        "duration": 2.55
    },
    {
        "text": "and you don't even see that you have run the job 1,000 VMs.",
        "start": 341.42,
        "duration": 4.02
    },
    {
        "text": ">> I see. So you're using Azure Machine Learning Service.",
        "start": 345.44,
        "duration": 2.52
    },
    {
        "text": "Do you have a sneaky special work space",
        "start": 347.96,
        "duration": 3.895
    },
    {
        "text": "that no one else has or is this a regular one?",
        "start": 351.855,
        "duration": 1.81
    },
    {
        "text": ">> No it's the same.",
        "start": 353.665,
        "duration": 0.795
    },
    {
        "text": ">> It's the same. Everyone else can use it.",
        "start": 354.46,
        "duration": 2.79
    },
    {
        "text": ">> Let's go to this screen here. So we are",
        "start": 357.25,
        "duration": 2.43
    },
    {
        "text": "looking here at your work space where you train this?",
        "start": 359.68,
        "duration": 2.61
    },
    {
        "text": ">> Exactly, yeah.",
        "start": 362.29,
        "duration": 0.865
    },
    {
        "text": ">> Yes.",
        "start": 363.155,
        "duration": 0.415
    },
    {
        "text": ">> This is the same one that anyone else can start up with.",
        "start": 363.57,
        "duration": 2.26
    },
    {
        "text": ">> Absolutely.",
        "start": 365.83,
        "duration": 0.42
    },
    {
        "text": ">> Exactly.",
        "start": 366.25,
        "duration": 0.57
    },
    {
        "text": ">> So let me see if I'm understanding",
        "start": 366.82,
        "duration": 1.17
    },
    {
        "text": "this right because I want to make sure I",
        "start": 367.99,
        "duration": 1.26
    },
    {
        "text": "clarify because I know Py Torch, I know how to run it.",
        "start": 369.25,
        "duration": 2.79
    },
    {
        "text": "I've seen some examples with Horovod,",
        "start": 372.04,
        "duration": 2.04
    },
    {
        "text": "you add a couple of things.",
        "start": 374.08,
        "duration": 1.32
    },
    {
        "text": ">> Exactly.",
        "start": 375.4,
        "duration": 0.18
    },
    {
        "text": ">> A couple of lines, and then you just say run it.",
        "start": 375.58,
        "duration": 2.225
    },
    {
        "text": ">> Yeah.",
        "start": 377.805,
        "duration": 0.18
    },
    {
        "text": ">> Yeah you just add your subscription ID, a few other details,",
        "start": 377.985,
        "duration": 2.9
    },
    {
        "text": "and specify how many number of nodes you want to use,",
        "start": 380.885,
        "duration": 3.455
    },
    {
        "text": "and then just click \"Run\",",
        "start": 384.34,
        "duration": 1.365
    },
    {
        "text": "and it dynamically spins up a cluster,",
        "start": 385.705,
        "duration": 1.935
    },
    {
        "text": "and you're good to go.",
        "start": 387.64,
        "duration": 1.43
    },
    {
        "text": ">> How long does this take to run?",
        "start": 389.07,
        "duration": 1.575
    },
    {
        "text": ">> So in order to spin up everything is a matter of minutes,",
        "start": 390.645,
        "duration": 2.56
    },
    {
        "text": "and then after that it's how big your model is,",
        "start": 393.205,
        "duration": 2.295
    },
    {
        "text": "how big the data set is,",
        "start": 395.5,
        "duration": 1.425
    },
    {
        "text": "and of course if you want to distribute over",
        "start": 396.925,
        "duration": 2.08
    },
    {
        "text": "hundreds of GPUs it's going to be really fast.",
        "start": 399.005,
        "duration": 2.15
    },
    {
        "text": ">> Are we taking hours,",
        "start": 401.155,
        "duration": 1.894
    },
    {
        "text": "days, weeks, I know there's",
        "start": 403.049,
        "duration": 1.161
    },
    {
        "text": "some machine learning models that take weeks.",
        "start": 404.21,
        "duration": 1.38
    },
    {
        "text": ">> So our model would have taken weeks if we",
        "start": 405.59,
        "duration": 2.49
    },
    {
        "text": "didn't have Azure Machine Learning but given that we do,",
        "start": 408.08,
        "duration": 3.27
    },
    {
        "text": "we can do this in matter of hours now.",
        "start": 411.35,
        "duration": 2.135
    },
    {
        "text": ">> Yeah.",
        "start": 413.485,
        "duration": 1.085
    },
    {
        "text": ">> Oh! Snap. You didn't",
        "start": 414.57,
        "duration": 2.07
    },
    {
        "text": "tell me this before the video when we prepared.",
        "start": 416.64,
        "duration": 1.945
    },
    {
        "text": "That's pretty amazing especially",
        "start": 418.585,
        "duration": 1.285
    },
    {
        "text": "over hundreds of millions of sentences.",
        "start": 419.87,
        "duration": 2.46
    },
    {
        "text": ">> Exactly.",
        "start": 422.33,
        "duration": 0.405
    },
    {
        "text": ">> Which is pretty amazing.",
        "start": 422.735,
        "duration": 1.335
    },
    {
        "text": "So let's talk a little bit about the actual feature because I",
        "start": 424.07,
        "duration": 3.21
    },
    {
        "text": "want to see it in action because it's very subtle, right?",
        "start": 427.28,
        "duration": 3.59
    },
    {
        "text": "When you're doing it. So let's go to the screen or more time,",
        "start": 430.87,
        "duration": 2.32
    },
    {
        "text": "and let's see what it is that it's actually doing.",
        "start": 433.19,
        "duration": 3.065
    },
    {
        "text": ">> Sure. So initially I'm sure",
        "start": 436.255,
        "duration": 2.605
    },
    {
        "text": "people have been using Word for a decade now,",
        "start": 438.86,
        "duration": 3.015
    },
    {
        "text": "and these are some of the grammar rules",
        "start": 441.875,
        "duration": 2.505
    },
    {
        "text": "that they may have seen while using Word.",
        "start": 444.38,
        "duration": 2.295
    },
    {
        "text": "Things like resolve your subject verb disagreement",
        "start": 446.675,
        "duration": 2.79
    },
    {
        "text": "or even punctuation.",
        "start": 449.465,
        "duration": 2.335
    },
    {
        "text": "errors like add a hyphen.",
        "start": 451.8,
        "duration": 2.85
    },
    {
        "text": ">> Yeah.",
        "start": 454.65,
        "duration": 0.435
    },
    {
        "text": ">> So without Machine Learning it was possible to do some of",
        "start": 455.085,
        "duration": 4.985
    },
    {
        "text": "those grammar corrections but in order to do some of",
        "start": 460.07,
        "duration": 2.4
    },
    {
        "text": "the more complicated linguistic corrections,",
        "start": 462.47,
        "duration": 2.865
    },
    {
        "text": "we need to understand the context of the sentence.",
        "start": 465.335,
        "duration": 1.815
    },
    {
        "text": ">> Sure.",
        "start": 467.15,
        "duration": 0.23
    },
    {
        "text": ">> So that's where our AI capabilities come in.",
        "start": 467.38,
        "duration": 3.22
    },
    {
        "text": ">> One instance in this sentence",
        "start": 470.6,
        "duration": 2.505
    },
    {
        "text": "it's very easy to miss an article.",
        "start": 473.105,
        "duration": 3.155
    },
    {
        "text": "When you write a sentence, \"I have apple",
        "start": 476.26,
        "duration": 1.88
    },
    {
        "text": "and you have a banana,\" but our model,",
        "start": 478.14,
        "duration": 2.355
    },
    {
        "text": "it shows that, you need to add an article there.",
        "start": 480.495,
        "duration": 2.825
    },
    {
        "text": ">> I see. Right. Because usually,",
        "start": 483.32,
        "duration": 3.61
    },
    {
        "text": "if with rules-based things because that's what it was previously,",
        "start": 486.93,
        "duration": 3.35
    },
    {
        "text": "and you still do rule-based but now you've augment with AI,",
        "start": 490.28,
        "duration": 2.36
    },
    {
        "text": "it's hard to add text.",
        "start": 492.64,
        "duration": 1.815
    },
    {
        "text": ">> Yes.",
        "start": 494.455,
        "duration": 0.47
    },
    {
        "text": ">> It's easy to see where things might be wrong.",
        "start": 494.925,
        "duration": 2.34
    },
    {
        "text": ">> Yeah.",
        "start": 497.265,
        "duration": 0.345
    },
    {
        "text": ">> But not to get the sequence",
        "start": 497.61,
        "duration": 1.49
    },
    {
        "text": "which sequence models are super good at.",
        "start": 499.1,
        "duration": 1.59
    },
    {
        "text": ">> It's a click wear mechanism with rule-based system.",
        "start": 500.69,
        "duration": 3.525
    },
    {
        "text": ">> That's really cool,",
        "start": 504.215,
        "duration": 1.095
    },
    {
        "text": "and so I'm writing this stuff I can",
        "start": 505.31,
        "duration": 2.35
    },
    {
        "text": "just spill the ideas out in my uncluttered fashion,",
        "start": 507.66,
        "duration": 3.545
    },
    {
        "text": "and then the editor will go ahead and say,",
        "start": 511.205,
        "duration": 2.77
    },
    {
        "text": "\"Here's some rules that might be broken,",
        "start": 513.975,
        "duration": 2.18
    },
    {
        "text": "augment it with some AI that we [inaudible].",
        "start": 516.155,
        "duration": 1.425
    },
    {
        "text": ">> Exactly.",
        "start": 517.58,
        "duration": 0.915
    },
    {
        "text": ">> One thing I do want to stress to is,",
        "start": 518.495,
        "duration": 1.86
    },
    {
        "text": "there's some people who are coming from languages that",
        "start": 520.355,
        "duration": 2.775
    },
    {
        "text": "don't necessarily use articles in",
        "start": 523.13,
        "duration": 1.44
    },
    {
        "text": "their language and when they try to write English,",
        "start": 524.57,
        "duration": 1.5
    },
    {
        "text": "they make these mistakes a lot.",
        "start": 526.07,
        "duration": 1.515
    },
    {
        "text": "So this is a way for us to help",
        "start": 527.585,
        "duration": 2.955
    },
    {
        "text": "them also sound a lot more",
        "start": 530.54,
        "duration": 1.23
    },
    {
        "text": "professional when they write their documents.",
        "start": 531.77,
        "duration": 1.655
    },
    {
        "text": ">> That's pretty amazing.",
        "start": 533.425,
        "duration": 1.135
    },
    {
        "text": "So a couple of more questions if I may.",
        "start": 534.56,
        "duration": 2.855
    },
    {
        "text": "How are you getting all these hundreds of millions of sentences",
        "start": 537.415,
        "duration": 4.075
    },
    {
        "text": "into the distributed things",
        "start": 541.49,
        "duration": 2.73
    },
    {
        "text": "that are running in Azure Machine Learning service?",
        "start": 544.22,
        "duration": 1.68
    },
    {
        "text": "How does it know where to look",
        "start": 545.9,
        "duration": 1.44
    },
    {
        "text": "or where is it getting that data front?",
        "start": 547.34,
        "duration": 1.455
    },
    {
        "text": ">> So that data is something that we have, as data scientists,",
        "start": 548.795,
        "duration": 2.865
    },
    {
        "text": "have a curate and make sure we have on Azure Blob Storage.",
        "start": 551.66,
        "duration": 3.15
    },
    {
        "text": ">> Okay.",
        "start": 554.81,
        "duration": 0.63
    },
    {
        "text": ">> Our machine learning compute will point to",
        "start": 555.44,
        "duration": 1.98
    },
    {
        "text": "that Blob storage in order to distribute across.",
        "start": 557.42,
        "duration": 2.235
    },
    {
        "text": ">> I see it. So you don't have to",
        "start": 559.655,
        "duration": 1.395
    },
    {
        "text": "download the data to each machine,",
        "start": 561.05,
        "duration": 1.89
    },
    {
        "text": "because hundreds of millions of sentences,",
        "start": 562.94,
        "duration": 1.38
    },
    {
        "text": "that's a ginormous text file. We don't want it-",
        "start": 564.32,
        "duration": 2.13
    },
    {
        "text": ">> It's just an unstructured data store",
        "start": 566.45,
        "duration": 1.905
    },
    {
        "text": "where you can store images,",
        "start": 568.355,
        "duration": 2.145
    },
    {
        "text": "you can store audio,",
        "start": 570.5,
        "duration": 1.47
    },
    {
        "text": "you can store text.",
        "start": 571.97,
        "duration": 1.14
    },
    {
        "text": ">> Then Azure Machine Learning Service will mount",
        "start": 573.11,
        "duration": 2.52
    },
    {
        "text": "it to these VMs that are running [inaudible].",
        "start": 575.63,
        "duration": 2.58
    },
    {
        "text": "This is pretty amazing. Where can",
        "start": 578.21,
        "duration": 1.32
    },
    {
        "text": "people go to find out more about this?",
        "start": 579.53,
        "duration": 1.565
    },
    {
        "text": ">> So we have an office AI",
        "start": 581.095,
        "duration": 1.685
    },
    {
        "text": "Blog which talks specifically about Editor,",
        "start": 582.78,
        "duration": 2.15
    },
    {
        "text": "and that's a place where people can go to find out more.",
        "start": 584.93,
        "duration": 3.18
    },
    {
        "text": "Also the Azure Machine Learning Service is on lot of Azure blogs,",
        "start": 588.11,
        "duration": 4.19
    },
    {
        "text": "and that's where they can find out how to",
        "start": 592.3,
        "duration": 1.54
    },
    {
        "text": "use the service for their own projects.",
        "start": 593.84,
        "duration": 1.59
    },
    {
        "text": ">> Awesome. We'll put some links below",
        "start": 595.43,
        "duration": 1.11
    },
    {
        "text": "obviously. You were going to say something?",
        "start": 596.54,
        "duration": 1.155
    },
    {
        "text": ">> That was specific Azure Machine Learning blog.",
        "start": 597.695,
        "duration": 2.21
    },
    {
        "text": ">> Fantastic. I'm pretty impressed.",
        "start": 599.905,
        "duration": 2.89
    },
    {
        "text": "The thing that's cool is that it",
        "start": 602.795,
        "duration": 1.965
    },
    {
        "text": "feels like we just don't make things,",
        "start": 604.76,
        "duration": 2.04
    },
    {
        "text": "we actually use the things that we",
        "start": 606.8,
        "duration": 1.47
    },
    {
        "text": "make for some of the products around it.",
        "start": 608.27,
        "duration": 1.56
    },
    {
        "text": "So it feels pretty cool to see that,",
        "start": 609.83,
        "duration": 1.48
    },
    {
        "text": "because when I looked at the work space this",
        "start": 611.31,
        "duration": 1.64
    },
    {
        "text": "is one that I've been working with all the time,",
        "start": 612.95,
        "duration": 1.94
    },
    {
        "text": "like doing mNest over and over again. Very sorry.",
        "start": 614.89,
        "duration": 3.155
    },
    {
        "text": "This is a real actual problem that",
        "start": 618.045,
        "duration": 2.555
    },
    {
        "text": "maybe would have taken weeks and now down to hours.",
        "start": 620.6,
        "duration": 3.09
    },
    {
        "text": "When we say this in Machine Learning for those that are just like,",
        "start": 623.69,
        "duration": 2.76
    },
    {
        "text": "\"Hey I want to be an AI person,\" weeks is",
        "start": 626.45,
        "duration": 3.06
    },
    {
        "text": "generally the standard amount of time to run on",
        "start": 629.51,
        "duration": 1.68
    },
    {
        "text": "a real scale production model,",
        "start": 631.19,
        "duration": 1.85
    },
    {
        "text": "and now my sense is that you probably put this model out,",
        "start": 633.04,
        "duration": 2.47
    },
    {
        "text": "and lots of people are using, and it's impactful.",
        "start": 635.51,
        "duration": 1.11
    },
    {
        "text": ">> Yes, absolutely.",
        "start": 636.62,
        "duration": 1.155
    },
    {
        "text": ">> I little Machine Learning to now you are going to",
        "start": 637.775,
        "duration": 1.815
    },
    {
        "text": "use Cypher 100 instead of mNest.",
        "start": 639.59,
        "duration": 1.95
    },
    {
        "text": ">> Oh. Yeah. He's given me some tips now so this is good.",
        "start": 641.54,
        "duration": 4.66
    },
    {
        "text": "Thank you so much for spending some time with us.",
        "start": 646.2,
        "duration": 1.885
    },
    {
        "text": "Thank you so much for watching.",
        "start": 648.085,
        "duration": 1.645
    },
    {
        "text": "We're learning all about the enhanced AI",
        "start": 649.73,
        "duration": 2.535
    },
    {
        "text": "inside of the Word editor.",
        "start": 652.265,
        "duration": 1.955
    },
    {
        "text": "Thanks so much for watching, and",
        "start": 654.22,
        "duration": 1.2
    },
    {
        "text": "we'll see you next time. Take care.",
        "start": 655.42,
        "duration": 1.05
    },
    {
        "text": "[MUSIC]",
        "start": 656.47,
        "duration": 9.08
    }
]