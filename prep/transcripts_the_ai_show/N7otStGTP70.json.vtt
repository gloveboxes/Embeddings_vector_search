[
    {
        "text": ">> You're not going to miss this episode of",
        "start": 0.0,
        "duration": 1.89
    },
    {
        "text": "the AI Show where we talk all about",
        "start": 1.89,
        "duration": 1.38
    },
    {
        "text": "pre-built Docker images for inference",
        "start": 3.27,
        "duration": 1.905
    },
    {
        "text": "in Azure Machine Learning with the amazing Shivani,",
        "start": 5.175,
        "duration": 2.22
    },
    {
        "text": "make sure you tune in.",
        "start": 7.395,
        "duration": 1.545
    },
    {
        "text": "[MUSIC]",
        "start": 8.94,
        "duration": 7.74
    },
    {
        "text": ">> Hello, and welcome to this episode of",
        "start": 16.68,
        "duration": 1.14
    },
    {
        "text": "the AI Show where we're talking all about",
        "start": 17.82,
        "duration": 1.56
    },
    {
        "text": "pre-built Docker images for inference in Azure Machine Learning.",
        "start": 19.38,
        "duration": 3.225
    },
    {
        "text": "Welcome Shivani, why don't",
        "start": 22.605,
        "duration": 1.305
    },
    {
        "text": "you tell us who you are and what you do?",
        "start": 23.91,
        "duration": 1.65
    },
    {
        "text": ">> Sure. Thanks, Seth for having me.",
        "start": 25.56,
        "duration": 2.31
    },
    {
        "text": "Hi, everyone. My name is Shivani.",
        "start": 27.87,
        "duration": 1.875
    },
    {
        "text": "I am PM on the Azure Machine Learning Team",
        "start": 29.745,
        "duration": 2.175
    },
    {
        "text": "and I work on the model deployment and serving area.",
        "start": 31.92,
        "duration": 3.36
    },
    {
        "text": ">> Fantastic. What are some of the challenges that people",
        "start": 35.28,
        "duration": 3.99
    },
    {
        "text": "face or what they tell you about when",
        "start": 39.27,
        "duration": 2.04
    },
    {
        "text": "they're working with machine learning?",
        "start": 41.31,
        "duration": 2.43
    },
    {
        "text": ">> Sure, absolutely.",
        "start": 43.74,
        "duration": 1.62
    },
    {
        "text": "We have interacted with many of",
        "start": 45.36,
        "duration": 1.67
    },
    {
        "text": "our customers and data scientists,",
        "start": 47.03,
        "duration": 2.22
    },
    {
        "text": "and what we know once you've trained a machine learning model,",
        "start": 49.25,
        "duration": 3.78
    },
    {
        "text": "getting that model to production is key,",
        "start": 53.03,
        "duration": 2.7
    },
    {
        "text": "especially having the right environments.",
        "start": 55.73,
        "duration": 2.79
    },
    {
        "text": "Environments encapsulates all your Python packages",
        "start": 58.52,
        "duration": 3.465
    },
    {
        "text": "and software setting on obvious scoring script,",
        "start": 61.985,
        "duration": 2.52
    },
    {
        "text": "and hence having the right dependency when you",
        "start": 64.505,
        "duration": 2.475
    },
    {
        "text": "deploy your machine learning model is very important.",
        "start": 66.98,
        "duration": 3.96
    },
    {
        "text": ">> Let's talk about the solution.",
        "start": 70.94,
        "duration": 2.565
    },
    {
        "text": "What is it that you've done to make this pernicious?",
        "start": 73.505,
        "duration": 3.165
    },
    {
        "text": "Because obviously, building a model and",
        "start": 76.67,
        "duration": 2.07
    },
    {
        "text": "handcrafting it and making it wonderful is nice,",
        "start": 78.74,
        "duration": 3.03
    },
    {
        "text": "but we need to actually have business value.",
        "start": 81.77,
        "duration": 2.52
    },
    {
        "text": "What's the solution that you're suggesting we should use?",
        "start": 84.29,
        "duration": 3.275
    },
    {
        "text": ">> As I mentioned, having the right environment",
        "start": 87.565,
        "duration": 2.995
    },
    {
        "text": "for a model deployment is very important.",
        "start": 90.56,
        "duration": 2.505
    },
    {
        "text": "During Microsoft Build 2021 we've",
        "start": 93.065,
        "duration": 2.805
    },
    {
        "text": "released pre-built Docker images for inferencing.",
        "start": 95.87,
        "duration": 3.33
    },
    {
        "text": "As the name suggests, these are pre-built Docker images",
        "start": 99.2,
        "duration": 3.66
    },
    {
        "text": "that come with popular machine learning framework",
        "start": 102.86,
        "duration": 2.31
    },
    {
        "text": "and Python packages.",
        "start": 105.17,
        "duration": 1.26
    },
    {
        "text": "Our customers, users, data scientists don't have to",
        "start": 106.43,
        "duration": 3.03
    },
    {
        "text": "start from scratch and it will",
        "start": 109.46,
        "duration": 1.8
    },
    {
        "text": "improve their getting started experience.",
        "start": 111.26,
        "duration": 2.225
    },
    {
        "text": ">> Let's go. If I'm understanding this right,",
        "start": 113.485,
        "duration": 2.725
    },
    {
        "text": "these pre-built Docker images have a set of",
        "start": 116.21,
        "duration": 2.19
    },
    {
        "text": "things already preinstalled. Am I getting it right?",
        "start": 118.4,
        "duration": 3.44
    },
    {
        "text": ">> Yeah, you're [inaudible] . We have",
        "start": 121.84,
        "duration": 1.58
    },
    {
        "text": "pre-built Docker images like TensorFlow,",
        "start": 123.42,
        "duration": 1.895
    },
    {
        "text": "PyTorch, X- Runtime,",
        "start": 125.315,
        "duration": 1.875
    },
    {
        "text": "and we're continuing to adding more.",
        "start": 127.19,
        "duration": 1.985
    },
    {
        "text": ">> What if I have",
        "start": 129.175,
        "duration": 2.855
    },
    {
        "text": "a special unicorn environment that",
        "start": 132.03,
        "duration": 2.45
    },
    {
        "text": "only I have and obviously I love PyTorch,",
        "start": 134.48,
        "duration": 2.69
    },
    {
        "text": "I'm using PyTorch, but then I'm using",
        "start": 137.17,
        "duration": 1.66
    },
    {
        "text": "something like spaCy because it is an NLP thing.",
        "start": 138.83,
        "duration": 2.865
    },
    {
        "text": "How do I make that work with those pre-built containers?",
        "start": 141.695,
        "duration": 4.19
    },
    {
        "text": ">> Definitely, we all know in",
        "start": 145.885,
        "duration": 2.255
    },
    {
        "text": "machine learning world models have a lot of",
        "start": 148.14,
        "duration": 1.95
    },
    {
        "text": "dependency and we definitely cannot",
        "start": 150.09,
        "duration": 2.39
    },
    {
        "text": "capture all of them in our pre-built Docker images.",
        "start": 152.48,
        "duration": 2.465
    },
    {
        "text": "But what we do and",
        "start": 154.945,
        "duration": 1.07
    },
    {
        "text": "what capability we provide to our customers is to",
        "start": 156.015,
        "duration": 2.39
    },
    {
        "text": "extend on top of our pre-built Docker images.",
        "start": 158.405,
        "duration": 3.765
    },
    {
        "text": "That is, if you have",
        "start": 162.17,
        "duration": 1.32
    },
    {
        "text": "dependencies that are not included in our images,",
        "start": 163.49,
        "duration": 2.535
    },
    {
        "text": "we provide you with a capability to add these Python packages.",
        "start": 166.025,
        "duration": 4.73
    },
    {
        "text": "We can do that in two ways.",
        "start": 170.755,
        "duration": 2.48
    },
    {
        "text": "Number 1 is the dynamic installation.",
        "start": 173.235,
        "duration": 2.79
    },
    {
        "text": "In this method, you would provide",
        "start": 176.025,
        "duration": 1.985
    },
    {
        "text": "us with the requirements.txt file.",
        "start": 178.01,
        "duration": 2.235
    },
    {
        "text": "This txt file would contain",
        "start": 180.245,
        "duration": 2.055
    },
    {
        "text": "the extra Python packages that are required for your use case.",
        "start": 182.3,
        "duration": 3.165
    },
    {
        "text": "During container boot time,",
        "start": 185.465,
        "duration": 1.5
    },
    {
        "text": "we need this Python packages in the",
        "start": 186.965,
        "duration": 2.415
    },
    {
        "text": "requirements.txt file and install them.",
        "start": 189.38,
        "duration": 2.745
    },
    {
        "text": "Now, this is very handy for rapid prototyping and death best Loop.",
        "start": 192.125,
        "duration": 4.31
    },
    {
        "text": "Now let's see, you have finalized the dependencies that",
        "start": 196.435,
        "duration": 3.215
    },
    {
        "text": "your model requires and you want to take this model to production.",
        "start": 199.65,
        "duration": 4.31
    },
    {
        "text": "The second method we provide is pre-installed mounting solution.",
        "start": 203.96,
        "duration": 5.07
    },
    {
        "text": "In this, you provide us with a folder which has",
        "start": 209.03,
        "duration": 2.91
    },
    {
        "text": "all your Python packages installed and",
        "start": 211.94,
        "duration": 1.89
    },
    {
        "text": "we mount to this filter onto the container.",
        "start": 213.83,
        "duration": 3.065
    },
    {
        "text": "Both this method do not trigger that image",
        "start": 216.895,
        "duration": 2.425
    },
    {
        "text": "built so it also improves a modern deployment latency.",
        "start": 219.32,
        "duration": 3.725
    },
    {
        "text": ">> That's really cool. For those",
        "start": 223.045,
        "duration": 2.165
    },
    {
        "text": "that are watching, they are wondering,",
        "start": 225.21,
        "duration": 1.685
    },
    {
        "text": "building a container takes a long time,",
        "start": 226.895,
        "duration": 3.105
    },
    {
        "text": "and this notion of being able to have the dependency is just",
        "start": 230.0,
        "duration": 3.69
    },
    {
        "text": "mounted directly, super-fast.",
        "start": 233.69,
        "duration": 3.615
    },
    {
        "text": "That's pretty amazing. I feel like I want to take",
        "start": 237.305,
        "duration": 1.835
    },
    {
        "text": "a look at how it works. Can you show us how it works?",
        "start": 239.14,
        "duration": 2.04
    },
    {
        "text": ">> Definitely. Now,",
        "start": 241.18,
        "duration": 2.1
    },
    {
        "text": "can you-all see my notebook that I have up here?",
        "start": 243.28,
        "duration": 3.51
    },
    {
        "text": ">> We got it.",
        "start": 246.79,
        "duration": 1.435
    },
    {
        "text": ">> In this particular example,",
        "start": 248.225,
        "duration": 2.435
    },
    {
        "text": "I'm going to deploy",
        "start": 250.66,
        "duration": 1.14
    },
    {
        "text": "a PyTorch model using our Azure Machine Learning Python SDK.",
        "start": 251.8,
        "duration": 3.9
    },
    {
        "text": "This particular model is trained to",
        "start": 255.7,
        "duration": 2.19
    },
    {
        "text": "classify chickens and turkeys. Very interesting.",
        "start": 257.89,
        "duration": 3.095
    },
    {
        "text": "Now first, if you can take a look at my folder structure,",
        "start": 260.985,
        "duration": 4.015
    },
    {
        "text": "I have my requirements.txt file in",
        "start": 265.0,
        "duration": 2.4
    },
    {
        "text": "the same folder as my scoring script. This is important.",
        "start": 267.4,
        "duration": 3.905
    },
    {
        "text": "Next, I'm going to register my PyTorch model that I have here,",
        "start": 271.305,
        "duration": 4.41
    },
    {
        "text": "and next step is to write my requirements.txt file.",
        "start": 275.715,
        "duration": 3.64
    },
    {
        "text": "Now, just to note,",
        "start": 279.355,
        "duration": 1.87
    },
    {
        "text": "even when you're prototyping,",
        "start": 281.225,
        "duration": 1.575
    },
    {
        "text": "we always recommend our customers to pin their package washers.",
        "start": 282.8,
        "duration": 3.6
    },
    {
        "text": "This make sure that you're scoring script does not",
        "start": 286.4,
        "duration": 2.79
    },
    {
        "text": "break and it does not cause",
        "start": 289.19,
        "duration": 1.08
    },
    {
        "text": "any failure during deployment or scaling.",
        "start": 290.27,
        "duration": 2.295
    },
    {
        "text": "Now once you have written your requirements.txt file,",
        "start": 292.565,
        "duration": 3.045
    },
    {
        "text": "I'm going to go ahead and define my environment.",
        "start": 295.61,
        "duration": 2.73
    },
    {
        "text": "As mentioned previously, this contains",
        "start": 298.34,
        "duration": 2.4
    },
    {
        "text": "all the Python packages and your software dependency,",
        "start": 300.74,
        "duration": 2.52
    },
    {
        "text": "you can deploy it for deployment.",
        "start": 303.26,
        "duration": 1.655
    },
    {
        "text": "You see my environment name is PyTorch deploy pre-built example.",
        "start": 304.915,
        "duration": 4.965
    },
    {
        "text": "I'm using one of our PyTorch pre-built Docker images here,",
        "start": 309.88,
        "duration": 3.85
    },
    {
        "text": "and using the environment variables",
        "start": 313.73,
        "duration": 1.83
    },
    {
        "text": "concept that we have in Azure Machine Learning,",
        "start": 315.56,
        "duration": 2.35
    },
    {
        "text": "I'm referring to my requirements.txt file.",
        "start": 317.91,
        "duration": 3.035
    },
    {
        "text": "Once you create this environment,",
        "start": 320.945,
        "duration": 2.505
    },
    {
        "text": "we have a amazing environment",
        "start": 323.45,
        "duration": 2.4
    },
    {
        "text": "CY in our Azure Machine Learning Studio,",
        "start": 325.85,
        "duration": 2.13
    },
    {
        "text": "and you can look at the custom environment list,",
        "start": 327.98,
        "duration": 2.265
    },
    {
        "text": "and you can see the one that I've created right now.",
        "start": 330.245,
        "duration": 3.305
    },
    {
        "text": "We also have curated environments.",
        "start": 333.55,
        "duration": 2.93
    },
    {
        "text": "Right now I'm filtering them by influence equal to true doc.",
        "start": 336.48,
        "duration": 3.24
    },
    {
        "text": "We can also take a look at all the environments that we provide.",
        "start": 339.72,
        "duration": 3.275
    },
    {
        "text": "Now heading back to our notebook.",
        "start": 342.995,
        "duration": 2.015
    },
    {
        "text": "Once you have created your environment,",
        "start": 345.01,
        "duration": 1.855
    },
    {
        "text": "you're going to go and create a scoring script.",
        "start": 346.865,
        "duration": 2.565
    },
    {
        "text": "Once you have your scoring script ready,",
        "start": 349.43,
        "duration": 2.325
    },
    {
        "text": "which I have right here,",
        "start": 351.755,
        "duration": 3.235
    },
    {
        "text": "what you're going to do is you're going to",
        "start": 355.28,
        "duration": 2.43
    },
    {
        "text": "deploy your model to an ACI container.",
        "start": 357.71,
        "duration": 2.66
    },
    {
        "text": "You can also deploy to Kubernetes,",
        "start": 360.37,
        "duration": 1.615
    },
    {
        "text": "managed endpoints in Azure machine learning.",
        "start": 361.985,
        "duration": 2.13
    },
    {
        "text": "But for right now,",
        "start": 364.115,
        "duration": 1.095
    },
    {
        "text": "I'm deploying to an ACI.",
        "start": 365.21,
        "duration": 2.12
    },
    {
        "text": "Once this deployment is completed,",
        "start": 367.33,
        "duration": 2.92
    },
    {
        "text": "it creates an endpoint for you.",
        "start": 370.25,
        "duration": 1.68
    },
    {
        "text": "I already had deployed this model",
        "start": 371.93,
        "duration": 2.145
    },
    {
        "text": "and I have an up and running endpoint.",
        "start": 374.075,
        "duration": 2.505
    },
    {
        "text": "As you can see, my status is healthy and my Container Instance,",
        "start": 376.58,
        "duration": 4.124
    },
    {
        "text": "and this is the model that I deployed.",
        "start": 380.704,
        "duration": 2.551
    },
    {
        "text": "Now next, you have a web service up and running.",
        "start": 383.255,
        "duration": 3.72
    },
    {
        "text": "Let's see if it actually works.",
        "start": 386.975,
        "duration": 3.119
    },
    {
        "text": "I'm going to pass this image",
        "start": 390.094,
        "duration": 3.016
    },
    {
        "text": "to our endpoint and see what it replies.",
        "start": 393.11,
        "duration": 3.82
    },
    {
        "text": "The results that we're getting,",
        "start": 397.24,
        "duration": 2.335
    },
    {
        "text": "that it's a turkey with probability of 0.93.",
        "start": 399.575,
        "duration": 2.79
    },
    {
        "text": "Not bad. As you can see,",
        "start": 402.365,
        "duration": 3.36
    },
    {
        "text": "I have my environment using dynamic installation methods.",
        "start": 405.725,
        "duration": 4.335
    },
    {
        "text": ">> This is really cool. Let's scroll back a little bit.",
        "start": 410.06,
        "duration": 3.24
    },
    {
        "text": "Let's go to the environments tab,",
        "start": 413.3,
        "duration": 2.13
    },
    {
        "text": "if you will, the second tab that you were looking at.",
        "start": 415.43,
        "duration": 2.96
    },
    {
        "text": "Basically what we're doing,",
        "start": 418.39,
        "duration": 2.27
    },
    {
        "text": "and this is the Kubernetes look,",
        "start": 420.66,
        "duration": 1.755
    },
    {
        "text": "I struggle with this all the time.",
        "start": 422.415,
        "duration": 2.265
    },
    {
        "text": "I have the environment and I have this.",
        "start": 424.68,
        "duration": 1.775
    },
    {
        "text": "It works on my machine problem with my dependencies.",
        "start": 426.455,
        "duration": 3.69
    },
    {
        "text": "These environments basically encapsulate",
        "start": 430.145,
        "duration": 2.535
    },
    {
        "text": "them as a noun inside of Azure Machine Learning, is that right?",
        "start": 432.68,
        "duration": 2.99
    },
    {
        "text": ">> Yes, exactly.",
        "start": 435.67,
        "duration": 1.73
    },
    {
        "text": "We have these beautiful frameworks, TensorFlow,",
        "start": 437.4,
        "duration": 2.57
    },
    {
        "text": "ByDraw, scikit-learn, Exebaz,",
        "start": 439.97,
        "duration": 2.295
    },
    {
        "text": "the ones that are very popular,",
        "start": 442.265,
        "duration": 1.485
    },
    {
        "text": "and we have curated them and we have them in EML.",
        "start": 443.75,
        "duration": 3.875
    },
    {
        "text": ">> Fantastic. Then the second thing and this was",
        "start": 447.625,
        "duration": 2.665
    },
    {
        "text": "super subtle and it went by really fast,",
        "start": 450.29,
        "duration": 2.685
    },
    {
        "text": "and I want to be able to understand this is,",
        "start": 452.975,
        "duration": 2.145
    },
    {
        "text": "you basically married that environment",
        "start": 455.12,
        "duration": 2.955
    },
    {
        "text": "with a scoring file and then what was it that produced?",
        "start": 458.075,
        "duration": 5.635
    },
    {
        "text": ">> Once you have your scoring file what we did is,",
        "start": 463.88,
        "duration": 4.07
    },
    {
        "text": "with our dynamic installation method,",
        "start": 467.95,
        "duration": 2.44
    },
    {
        "text": "you have this environment on top of that.",
        "start": 470.39,
        "duration": 2.52
    },
    {
        "text": "All the requirements.txt Python packages that I have mentioned,",
        "start": 472.91,
        "duration": 3.345
    },
    {
        "text": "it gets installed on top of your pre-built Docker image.",
        "start": 476.255,
        "duration": 3.575
    },
    {
        "text": ">> I see. Then once you do that,",
        "start": 479.83,
        "duration": 2.765
    },
    {
        "text": "what is this endpoint your tie?",
        "start": 482.595,
        "duration": 1.695
    },
    {
        "text": "Is it like a rest endpoint than people can call?",
        "start": 484.29,
        "duration": 2.56
    },
    {
        "text": ">> Yeah, exactly.",
        "start": 486.85,
        "duration": 1.43
    },
    {
        "text": "You have this resting point here which you",
        "start": 488.28,
        "duration": 1.82
    },
    {
        "text": "can go and take a look at our endpoint CY,",
        "start": 490.1,
        "duration": 2.715
    },
    {
        "text": "and then I have this ''Nice click to copy'' button,",
        "start": 492.815,
        "duration": 2.52
    },
    {
        "text": "and I can use that for all my inferencing requests.",
        "start": 495.335,
        "duration": 3.395
    },
    {
        "text": ">> It's basically you take in a model,",
        "start": 498.73,
        "duration": 3.455
    },
    {
        "text": "add an environment around it,",
        "start": 502.185,
        "duration": 1.94
    },
    {
        "text": "like the scoring script and we'll",
        "start": 504.125,
        "duration": 2.245
    },
    {
        "text": "take a look at a scoring script in a little bit,",
        "start": 506.37,
        "duration": 2.09
    },
    {
        "text": "and then push it out into",
        "start": 508.46,
        "duration": 1.98
    },
    {
        "text": "a rest endpoint that now is actually consumable by the business?",
        "start": 510.44,
        "duration": 3.36
    },
    {
        "text": ">> Yes, exactly.",
        "start": 513.8,
        "duration": 1.365
    },
    {
        "text": ">> That's fantastic. Can we take a look at",
        "start": 515.165,
        "duration": 1.305
    },
    {
        "text": "the scoring script for a second,",
        "start": 516.47,
        "duration": 1.5
    },
    {
        "text": "just so people can get a sense for what it is that that looks like?",
        "start": 517.97,
        "duration": 4.08
    },
    {
        "text": "Let me go full screen here.",
        "start": 522.05,
        "duration": 2.52
    },
    {
        "text": "It's just basically loading up",
        "start": 524.57,
        "duration": 2.1
    },
    {
        "text": "the model and then running the model?",
        "start": 526.67,
        "duration": 2.89
    },
    {
        "text": ">> That's it, yes. You're inner turn drawn function is",
        "start": 529.56,
        "duration": 3.08
    },
    {
        "text": "basically the logic that you would",
        "start": 532.64,
        "duration": 1.5
    },
    {
        "text": "require to run up your scoring scripts.",
        "start": 534.14,
        "duration": 2.25
    },
    {
        "text": "So you load your model and you get your predictions.",
        "start": 536.39,
        "duration": 3.195
    },
    {
        "text": ">> Well, this is amazing.",
        "start": 539.585,
        "duration": 2.985
    },
    {
        "text": "Where can people go to find out more, my friend?",
        "start": 542.57,
        "duration": 2.375
    },
    {
        "text": ">> Definitely you can see the link",
        "start": 544.945,
        "duration": 2.035
    },
    {
        "text": "for our pre-built Docker images.",
        "start": 546.98,
        "duration": 2.61
    },
    {
        "text": "We have documents that talk all about",
        "start": 549.59,
        "duration": 2.13
    },
    {
        "text": "the Docker images we provide and as I say,",
        "start": 551.72,
        "duration": 2.415
    },
    {
        "text": "we are continuing to add more,",
        "start": 554.135,
        "duration": 1.455
    },
    {
        "text": "and we also provide documents on how customers can",
        "start": 555.59,
        "duration": 2.61
    },
    {
        "text": "use our extensibility solutions that I mentioned earlier.",
        "start": 558.2,
        "duration": 3.35
    },
    {
        "text": ">> Let me put another link up here.",
        "start": 561.55,
        "duration": 1.955
    },
    {
        "text": "There's the extensibility solutions that you were talking about.",
        "start": 563.505,
        "duration": 3.235
    },
    {
        "text": "Then finally, I think there's",
        "start": 566.74,
        "duration": 1.4
    },
    {
        "text": "a blog post that people can take a look at.",
        "start": 568.14,
        "duration": 1.64
    },
    {
        "text": "Do you want to give us a preview on what that is?",
        "start": 569.78,
        "duration": 1.79
    },
    {
        "text": ">> Yes, exactly. The blog post talk about",
        "start": 571.57,
        "duration": 2.275
    },
    {
        "text": "improved environments experience both",
        "start": 573.845,
        "duration": 1.815
    },
    {
        "text": "for training and inferencing.",
        "start": 575.66,
        "duration": 1.8
    },
    {
        "text": "We have environment CY,",
        "start": 577.46,
        "duration": 1.815
    },
    {
        "text": "we have pre-built Docker images,",
        "start": 579.275,
        "duration": 1.485
    },
    {
        "text": "we have curated environments all to help",
        "start": 580.76,
        "duration": 2.13
    },
    {
        "text": "our customers to improve their machine learning models.",
        "start": 582.89,
        "duration": 4.055
    },
    {
        "text": ">> Well, this has been amazing.",
        "start": 586.945,
        "duration": 2.135
    },
    {
        "text": "Shivani, thank you so much.",
        "start": 589.08,
        "duration": 1.14
    },
    {
        "text": "We've been learning all about pre-built Docker images",
        "start": 590.22,
        "duration": 1.94
    },
    {
        "text": "for inference in Azure Machine Learning.",
        "start": 592.16,
        "duration": 2.435
    },
    {
        "text": "Thank you so much for watching and",
        "start": 594.595,
        "duration": 1.105
    },
    {
        "text": "hopefully we'll see you next time. Take care.",
        "start": 595.7,
        "duration": 1.26
    },
    {
        "text": "[MUSIC]",
        "start": 596.96,
        "duration": 10.55
    }
]